{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Brute-Force Training and Evaluation Pipeline for Datasets and Models - by Selman Tabet @ https://selman.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import socket\n",
    "\n",
    "TEMP_DIR = \"tmp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname:  Chaos\n"
     ]
    }
   ],
   "source": [
    "print(\"Hostname: \", socket.gethostname())\n",
    "try: # for CUDA enviroment\n",
    "    os.system(\"nvidia-smi\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Data processing libraries\n",
    "import numpy as np\n",
    "from itertools import combinations # For brute force combinatoric search\n",
    "import json # For saving and loading training results\n",
    "import argparse # For command line arguments\n",
    "\n",
    "# Tensorflow-Keras ML libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Input, Resizing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model # To plot model architecture\n",
    "\n",
    "from IPython import get_ipython # To check if code is running in Jupyter notebook\n",
    "import importlib.util # To import config module from str\n",
    "from pprint import pprint # To show config\n",
    "\n",
    "# Custom helper libraries\n",
    "from notebook_cfg import * # Default parameters\n",
    "from wildfirenet import * # WildfireNet model, for comparison to other SOTA models in dissertation.\n",
    "from utils.img_processing import enforce_image_params\n",
    "from utils.dataset_processors import * # Dataset and generator processing functions\n",
    "from utils.plot_functions import * # Plotting functions\n",
    "from utils.evaluator import * # Complete evaluation program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES: None\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cuda_visible_devices = os.environ.get('CUDA_VISIBLE_DEVICES')\n",
    "print(f\"CUDA_VISIBLE_DEVICES: {cuda_visible_devices}\")\n",
    "print(tf.config.get_visible_devices())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse arguments from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Config Path: None\n",
      "No Python config file specified, using default config.\n"
     ]
    }
   ],
   "source": [
    "# Detect if running in a Jupyter notebook\n",
    "# Generated using GPT-4o. Prompt: \"Detect if running in a Jupyter notebook\"\n",
    "def in_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        else:\n",
    "            return False  # Other type (terminal, etc.)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "    \n",
    "from_py = False\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Parse command line arguments\")\n",
    "parser.add_argument('--from-py-cfg', type=str,\n",
    "                    help='Path to the config Python file')\n",
    "if not in_notebook():\n",
    "    args = parser.parse_args()\n",
    "    config_file_path = args.from_py_cfg\n",
    "    print(f\"Python Config Path: {config_file_path}\")\n",
    "else:\n",
    "    config_file_path = False\n",
    "\n",
    "if config_file_path:\n",
    "    spec = importlib.util.spec_from_file_location(\"config_module\", config_file_path)\n",
    "    config_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(config_module)\n",
    "    config = config_module.cfg\n",
    "    print(\"Loaded config from Python file:\")\n",
    "    pprint(config)\n",
    "    # Datasets, models, and hyperparameters are mandatory and must be processed now.\n",
    "    training_datasets = config.get('datasets', {})\n",
    "    if training_datasets is None or len(training_datasets) == 0:\n",
    "        raise ValueError(\"No train datasets defined in config.\")\n",
    "    full_test_dir = config.get('test')\n",
    "    base_models = config.get('keras_models', [])\n",
    "    custom_models = config.get('custom_models', [])\n",
    "    if base_models is None or len(base_models) == 0:\n",
    "        if custom_models is None or len(custom_models) == 0:\n",
    "            raise ValueError(\"No models defined in config.\")\n",
    "    \n",
    "    hyperparameters = config.get('hyperparameters')\n",
    "    default_hyperparameters = default_cfg.get('hyperparameters', {})\n",
    "    if hyperparameters is None or len(hyperparameters) == 0:\n",
    "        print(\"No training hyperparameters defined in config, using defaults.\")\n",
    "        hyperparameters = default_hyperparameters\n",
    "    else:\n",
    "        for key, value in default_hyperparameters.items():\n",
    "            if key not in hyperparameters:\n",
    "                print(f\"Missing parameter - falling back to default hyperparameter {key}:{default_hyperparameters[key]}\")\n",
    "                hyperparameters[key] = default_hyperparameters[key]\n",
    "    from_py = True # Successfully completed the import\n",
    "else:\n",
    "    print(\"No Python config file specified, using default config.\")\n",
    "    config = default_cfg\n",
    "    training_datasets = config.get('datasets', {})\n",
    "    base_models = config.get('keras_models', [])\n",
    "    custom_models = config.get('custom_models', [])\n",
    "    hyperparameters = config.get('hyperparameters')\n",
    "    full_test_dir = config.get('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dirs = [training_datasets[ds].get('train') for ds in training_datasets]\n",
    "test_dirs = [training_datasets[ds].get('test') for ds in training_datasets]\n",
    "val_dirs = [training_datasets[ds].get('val') for ds in training_datasets]\n",
    "\n",
    "all_dirs = train_dirs + test_dirs + val_dirs + [full_test_dir]\n",
    "all_dirs = [d for d in all_dirs if d is not None] # Remove None values\n",
    "\n",
    "# Combine base_models and custom_models\n",
    "all_models = base_models + custom_models\n",
    "# Create a list to keep track of which models are custom\n",
    "is_custom_model = [False] * len(base_models) + [True] * len(custom_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if from_py:\n",
    "    epochs = hyperparameters.get('epochs')\n",
    "    batch_size = hyperparameters.get('batch_size')\n",
    "    img_height = config.get('image_height', default_cfg.get('image_height'))\n",
    "    img_width = config.get('image_width', default_cfg.get('image_width'))\n",
    "    optimizer_fn = config.get('optimizer', default_cfg.get('optimizer'))\n",
    "    loss_fn = config.get('loss', default_cfg.get('loss'))\n",
    "    callbacks_list = config.get('callbacks', default_cfg.get('callbacks'))\n",
    "    metrics_list = config.get('metrics', default_cfg.get('metrics'))\n",
    "    enforce_image_size = config.get('enforce_image_settings', default_cfg.get('enforce_image_settings'))\n",
    "else:\n",
    "    epochs = hyperparameters.get('epochs')\n",
    "    batch_size = hyperparameters.get('batch_size')\n",
    "    img_height = default_cfg.get('image_height')\n",
    "    img_width = default_cfg.get('image_width')\n",
    "    optimizer_fn = default_cfg.get('optimizer')\n",
    "    loss_fn = default_cfg.get('loss')\n",
    "    callbacks_list = default_cfg.get('callbacks')\n",
    "    metrics_list = default_cfg.get('metrics')\n",
    "    enforce_image_size = default_cfg.get('enforce_image_settings')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforce defined resolution and colour mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting image properties in datasets\\dataset_1\\train\n",
      "Adjusting image properties in datasets\\dataset_2\\Training\n",
      "Adjusting image properties in datasets\\dataset_3\n",
      "Adjusting image properties in datasets\\dataset_4\\train\n",
      "Adjusting image properties in datasets\\dataset_1\\test\n",
      "Adjusting image properties in datasets\\dataset_2\\Testing\n",
      "Adjusting image properties in datasets\\dataset_4\\test\n",
      "Adjusting image properties in datasets\\dataset_1\\val\n"
     ]
    }
   ],
   "source": [
    "if enforce_image_size:\n",
    "    for directory in all_dirs:\n",
    "        print(f\"Adjusting image properties in {directory}\")\n",
    "        enforce_image_params(directory, target_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: The Wildfire Dataset\n",
      "Augmenting The Wildfire Dataset\n",
      "Creating generators for training\n",
      "Found 1887 images belonging to 2 classes.\n",
      "Found 1887 images belonging to 2 classes.\n",
      "Creating generators for validation\n",
      "Found 402 images belonging to 2 classes.\n",
      "Found 402 images belonging to 2 classes.\n",
      "--------------------\n",
      "Number of samples in generator: 1887\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 730\n",
      "nofire: 1157\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 730\n",
      "nofire: 1157\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 1460\n",
      "nofire: 2314\n",
      "--------------------\n",
      "--------------------\n",
      "Number of samples in generator: 402\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 156\n",
      "nofire: 246\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 156\n",
      "nofire: 246\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 312\n",
      "nofire: 492\n",
      "--------------------\n",
      "Processing: DeepFire\n",
      "Augmenting DeepFire\n",
      "Creating generators for training\n",
      "Found 1520 images belonging to 2 classes.\n",
      "Found 1520 images belonging to 2 classes.\n",
      "No validation set, splitting training set.\n",
      "Splitted dataset:\n",
      "Training dataset size: 2432 samples\n",
      "Validation dataset size: 608 samples\n",
      "--------------------\n",
      "Number of samples in generator: 1520\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 760\n",
      "nofire: 760\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 760\n",
      "nofire: 760\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 1520\n",
      "nofire: 1520\n",
      "--------------------\n",
      "Processing: FIRE\n",
      "Augmenting FIRE\n",
      "Creating generators for training\n",
      "Found 999 images belonging to 2 classes.\n",
      "Found 999 images belonging to 2 classes.\n",
      "No validation set, splitting training set.\n",
      "Splitted dataset:\n",
      "Training dataset size: 1599 samples\n",
      "Validation dataset size: 399 samples\n",
      "--------------------\n",
      "Number of samples in generator: 999\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 755\n",
      "nofire: 244\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 755\n",
      "nofire: 244\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 1510\n",
      "nofire: 488\n",
      "--------------------\n",
      "Processing: Forest Fire\n",
      "Augmenting Forest Fire\n",
      "Creating generators for training\n",
      "Found 4611 images belonging to 2 classes.\n",
      "Found 4611 images belonging to 2 classes.\n",
      "No validation set, splitting training set.\n",
      "Splitted dataset:\n",
      "Training dataset size: 7378 samples\n",
      "Validation dataset size: 1844 samples\n",
      "--------------------\n",
      "Number of samples in generator: 4611\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 2111\n",
      "nofire: 2500\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 2111\n",
      "nofire: 2500\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 4222\n",
      "nofire: 5000\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "resize_fn = Resizing(img_height, img_width)\n",
    "\n",
    "dataset_names = []\n",
    "train_datasets = [] # [ (dataset_1_train, dataset_2_train), ... ]\n",
    "train_sizes = [] # [ (dataset_1_train_size, dataset_2_train_size), ... ]\n",
    "val_datasets = [] # [ (dataset_1_val, dataset_2_val), ... ]\n",
    "val_sizes = [] # [ (dataset_1_val_size, dataset_2_val_size), ... ]\n",
    "train_counts = [] # [ (dataset_1_train_counts, dataset_2_train_counts), ... ]\n",
    "val_counts = [] # [ (dataset_1_val_counts, dataset_2_val_counts), ... ]\n",
    "\n",
    "for d in training_datasets:\n",
    "    print(f\"Processing: {d}\")\n",
    "    train_dir = training_datasets[d].get('train')\n",
    "    augment = training_datasets[d].get('augment', True)\n",
    "    print(\"Augmenting\" if augment else \"Not augmenting\", d)\n",
    "    # Apply original and augmented data generators for training\n",
    "    print(\"Creating generators for training\")\n",
    "    train_generator, augmented_train_generator = create_generators(train_dir, batch_size=batch_size, augment=augment, img_width=img_width, img_height=img_height)\n",
    "    train_samples = samples_from_generators([train_generator, augmented_train_generator])\n",
    "    train_dataset = generators_to_dataset([train_generator, augmented_train_generator], batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "    train_dataset = train_dataset.map(lambda x, y: (resize_fn(x), y))\n",
    "    # Apply original and augmented data generators for validation\n",
    "    if \"val\" in training_datasets[d]:\n",
    "        val_dir = training_datasets[d]['val']\n",
    "        print(\"Creating generators for validation\")\n",
    "        val_generator, augmented_val_generator = create_generators(val_dir, batch_size=batch_size, augment=augment, shuffle=False, img_width=img_width, img_height=img_height)\n",
    "        val_samples = samples_from_generators([val_generator, augmented_val_generator])\n",
    "        val_dataset = generators_to_dataset([train_generator, augmented_train_generator], batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "        val_dataset = val_dataset.map(lambda x, y: (resize_fn(x), y))\n",
    "    else:\n",
    "        print(\"No validation set, splitting training set.\")\n",
    "        train_dataset, val_dataset, train_samples, val_samples = val_split(train_dataset, train_samples)\n",
    "        train_dataset = train_dataset.map(lambda x, y: (resize_fn(x), y))\n",
    "        val_dataset = val_dataset.map(lambda x, y: (resize_fn(x), y))\n",
    "        val_generator, augmented_val_generator = None, None\n",
    "    \n",
    "    # Calculate the number of samples for training and validation\n",
    "    train_sizes.append(train_samples)\n",
    "    val_sizes.append(val_samples)\n",
    "\n",
    "    train_count_dict = class_counts_from_generators(train_generator, augmented_train_generator)\n",
    "    if val_generator is not None:\n",
    "        val_count_dict = class_counts_from_generators(val_generator, augmented_val_generator)\n",
    "    else:\n",
    "        val_count_dict = {k: 0 for k in train_count_dict.keys()}\n",
    "    \n",
    "    train_counts.append(train_count_dict)\n",
    "    val_counts.append(val_count_dict)\n",
    "    train_datasets.append(train_dataset)\n",
    "    val_datasets.append(val_dataset)\n",
    "    dataset_names.append(d)\n",
    "    \n",
    "# Ensure that the lengths are consistent across the board before continuing\n",
    "assert len(train_sizes) == len(train_datasets) == len(val_sizes) == len(val_datasets) == len(val_counts) == len(train_counts) == len(dataset_names), \"Dataset lengths are inconsistent.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute Force Combinatorial Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_combos = [] # [(0,), (1,), (0, 1), ...] where 0, 1 are the indices of the datasets within their respective lists\n",
    "for r in range(1, len(dataset_names) + 1):\n",
    "    dataset_combos.extend(combinations(range(len(dataset_names)), r))\n",
    "combined_training_datasets = []\n",
    "combined_val_datasets = []\n",
    "combined_dataset_names = []\n",
    "steps_per_epoch_list = []\n",
    "validation_steps_list = []\n",
    "train_counts_list = []\n",
    "val_counts_list = []\n",
    "\n",
    "for combo in dataset_combos:\n",
    "    training_dataset = None\n",
    "    val_dataset = None\n",
    "    train_size = None\n",
    "    val_size = None\n",
    "    train_count = None\n",
    "    val_count = None\n",
    "    for idx in combo:\n",
    "        if training_dataset is None:\n",
    "            training_dataset = train_datasets[idx]\n",
    "            val_dataset = val_datasets[idx]\n",
    "            train_size = train_sizes[idx]\n",
    "            val_size = val_sizes[idx]\n",
    "            train_count = train_counts[idx]\n",
    "            val_count = val_counts[idx]\n",
    "        else:\n",
    "            training_dataset = training_dataset.concatenate(train_datasets[idx])\n",
    "            val_dataset = val_dataset.concatenate(val_datasets[idx])\n",
    "            train_size += train_sizes[idx]\n",
    "            val_size += val_sizes[idx]\n",
    "            train_count = {k: train_count.get(k, 0) + train_counts[idx].get(k, 0) for k in set(train_count) | set(train_counts[idx])}\n",
    "            val_count = {k: val_count.get(k, 0) + val_counts[idx].get(k, 0) for k in set(val_count) | set(val_counts[idx])}\n",
    "        train_count = {k: int(v) for k, v in train_count.items()}\n",
    "        val_count = {k: int(v) for k, v in val_count.items()}\n",
    "\n",
    "    combined_dataset_names.append(\"_\".join([dataset_names[idx] for idx in combo]))\n",
    "    combined_training_datasets.append(training_dataset)\n",
    "    combined_val_datasets.append(val_dataset)\n",
    "    steps_per_epoch_list.append(train_size // batch_size)\n",
    "    validation_steps_list.append(val_size // batch_size)\n",
    "    train_counts_list.append(train_count)\n",
    "    val_counts_list.append(val_count)\n",
    "\n",
    "    training_params = zip(combined_dataset_names, combined_training_datasets, combined_val_datasets, steps_per_epoch_list, validation_steps_list, train_counts_list, val_counts_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No target test directory provided, merging all tests from provided datasets if available.\n",
      "Found 410 images belonging to 2 classes.\n",
      "Found 380 images belonging to 2 classes.\n",
      "Found 50 images belonging to 2 classes.\n",
      "Test Dataset Class Counts:\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "fire: 159\n",
      "nofire: 251\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "fire: 190\n",
      "nofire: 190\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "fire: 25\n",
      "nofire: 25\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if full_test_dir is None:\n",
    "    test_generators = []\n",
    "    print(\"No target test directory provided, merging all tests from provided datasets if available.\")\n",
    "    for d in test_dirs:\n",
    "        if d is not None:\n",
    "            test_generators.append(create_generators(d, batch_size=batch_size, augment=False, shuffle=False, img_height=img_height, img_width=img_width)[0]) # No augmentation/shuffle for testing\n",
    "    if len(test_generators) == 0:\n",
    "        raise ValueError(\"No tests found in the provided datasets.\")\n",
    "    true_labels = np.concatenate([gen.classes for gen in test_generators])\n",
    "    test_dataset = generators_to_dataset(test_generators, batch_size=batch_size)\n",
    "    test_steps = sum([gen.samples for gen in test_generators]) // batch_size\n",
    "    print(\"Test Dataset Class Counts:\")\n",
    "    for gen in test_generators:\n",
    "        print(\"Class indices:\", gen.class_indices)\n",
    "        for class_name, class_index in gen.class_indices.items():\n",
    "            print(f\"{class_name}: {sum(gen.classes == class_index)}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "else:\n",
    "    test_generator, augmented_test_generator = create_generators(full_test_dir, batch_size=batch_size, augment=False, shuffle=False, img_height=img_height, img_width=img_width) # No augmentation/shuffle for testing\n",
    "    test_dataset = create_dataset(test_generator, batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "    test_steps = test_generator.samples // batch_size\n",
    "    true_labels = test_generator.classes\n",
    "    print(\"Class indices:\", test_generator.class_indices)\n",
    "    print(\"\\n\")\n",
    "    print(\"Test Dataset Class Counts:\")\n",
    "    for class_name, class_index in test_generator.class_indices.items():\n",
    "        print(f\"{class_name}: {sum(test_generator.classes == class_index)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "true_labels = true_labels[: (len(true_labels) // batch_size) * batch_size] # Ensure that the true labels are divisible by the batch size to avoid size mismatch with predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_model(bm, custom=False, run_dir=TEMP_DIR):\n",
    "    if custom:\n",
    "        model = bm\n",
    "        model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list)\n",
    "        model.save(os.path.join(run_dir, model.name, f\"{model.name}_initial.keras\"))  \n",
    "        return model\n",
    "    \n",
    "    base_model = bm(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(img_height, img_width, 3)\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create the model\n",
    "    inputs = Input(shape=(img_height, img_width, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=bm.__name__)\n",
    "    model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list)\n",
    "    model.save(os.path.join(run_dir, model.name, f\"{model.name}_initial.keras\"))  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the models and combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "run_number = len([d for d in os.listdir(\"runs\") if os.path.isdir(os.path.join(\"runs\", d)) and d.startswith('run_')]) + 1\n",
    "run_dir = os.path.join(\"runs\", f\"run_{run_number}\")\n",
    "os.makedirs(run_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ResNet50V2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ResNet50V2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │    \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,098,817</span> (91.93 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,098,817\u001b[0m (91.93 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">529,409</span> (2.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m529,409\u001b[0m (2.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,569,408</span> (89.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,569,408\u001b[0m (89.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: ResNet50V2 on dataset: The Wildfire Dataset\n",
      "Epoch 1/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 607ms/step - accuracy: 0.7264 - auc: 0.8127 - f1_score: 0.7621 - loss: 0.6322 - precision: 0.8010 - recall: 0.7337 - val_accuracy: 0.8888 - val_auc: 0.9643 - val_f1_score: 0.9084 - val_loss: 0.2874 - val_precision: 0.9485 - val_recall: 0.8718 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 617ms/step - accuracy: 0.8557 - auc: 0.9301 - f1_score: 0.8802 - loss: 0.3456 - precision: 0.8793 - recall: 0.8819 - val_accuracy: 0.9237 - val_auc: 0.9820 - val_f1_score: 0.9354 - val_loss: 0.2006 - val_precision: 0.9344 - val_recall: 0.9402 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 628ms/step - accuracy: 0.8916 - auc: 0.9550 - f1_score: 0.9115 - loss: 0.2662 - precision: 0.9089 - recall: 0.9145 - val_accuracy: 0.9625 - val_auc: 0.9926 - val_f1_score: 0.9688 - val_loss: 0.1491 - val_precision: 0.9817 - val_recall: 0.9583 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 748ms/step - accuracy: 0.9023 - auc: 0.9616 - f1_score: 0.9200 - loss: 0.2472 - precision: 0.9317 - recall: 0.9114 - val_accuracy: 0.9688 - val_auc: 0.9953 - val_f1_score: 0.9737 - val_loss: 0.1247 - val_precision: 0.9797 - val_recall: 0.9698 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 654ms/step - accuracy: 0.9140 - auc: 0.9754 - f1_score: 0.9283 - loss: 0.1925 - precision: 0.9238 - recall: 0.9364 - val_accuracy: 0.9812 - val_auc: 0.9984 - val_f1_score: 0.9854 - val_loss: 0.0950 - val_precision: 0.9866 - val_recall: 0.9848 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 658ms/step - accuracy: 0.9194 - auc: 0.9745 - f1_score: 0.9331 - loss: 0.1957 - precision: 0.9307 - recall: 0.9374 - val_accuracy: 0.9875 - val_auc: 0.9994 - val_f1_score: 0.9886 - val_loss: 0.0785 - val_precision: 0.9938 - val_recall: 0.9857 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 740ms/step - accuracy: 0.9291 - auc: 0.9792 - f1_score: 0.9425 - loss: 0.1746 - precision: 0.9440 - recall: 0.9405 - val_accuracy: 0.9900 - val_auc: 0.9994 - val_f1_score: 0.9915 - val_loss: 0.0695 - val_precision: 0.9855 - val_recall: 0.9979 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 660ms/step - accuracy: 0.9276 - auc: 0.9793 - f1_score: 0.9404 - loss: 0.1795 - precision: 0.9421 - recall: 0.9396 - val_accuracy: 0.9925 - val_auc: 0.9998 - val_f1_score: 0.9939 - val_loss: 0.0602 - val_precision: 0.9940 - val_recall: 0.9940 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 651ms/step - accuracy: 0.9398 - auc: 0.9865 - f1_score: 0.9502 - loss: 0.1467 - precision: 0.9504 - recall: 0.9509 - val_accuracy: 0.9962 - val_auc: 1.0000 - val_f1_score: 0.9968 - val_loss: 0.0522 - val_precision: 0.9940 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 732ms/step - accuracy: 0.9456 - auc: 0.9873 - f1_score: 0.9541 - loss: 0.1445 - precision: 0.9449 - recall: 0.9655 - val_accuracy: 0.9950 - val_auc: 0.9999 - val_f1_score: 0.9962 - val_loss: 0.0441 - val_precision: 1.0000 - val_recall: 0.9920 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 665ms/step - accuracy: 0.9450 - auc: 0.9876 - f1_score: 0.9543 - loss: 0.1392 - precision: 0.9524 - recall: 0.9580 - val_accuracy: 0.9962 - val_auc: 1.0000 - val_f1_score: 0.9967 - val_loss: 0.0409 - val_precision: 0.9940 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 673ms/step - accuracy: 0.9496 - auc: 0.9906 - f1_score: 0.9584 - loss: 0.1226 - precision: 0.9596 - recall: 0.9583 - val_accuracy: 0.9975 - val_auc: 1.0000 - val_f1_score: 0.9979 - val_loss: 0.0375 - val_precision: 1.0000 - val_recall: 0.9959 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 715ms/step - accuracy: 0.9516 - auc: 0.9894 - f1_score: 0.9592 - loss: 0.1261 - precision: 0.9596 - recall: 0.9613 - val_accuracy: 0.9975 - val_auc: 1.0000 - val_f1_score: 0.9976 - val_loss: 0.0356 - val_precision: 0.9980 - val_recall: 0.9980 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 654ms/step - accuracy: 0.9544 - auc: 0.9919 - f1_score: 0.9639 - loss: 0.1123 - precision: 0.9637 - recall: 0.9633 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0317 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 668ms/step - accuracy: 0.9696 - auc: 0.9955 - f1_score: 0.9749 - loss: 0.0869 - precision: 0.9805 - recall: 0.9706 - val_accuracy: 0.9987 - val_auc: 1.0000 - val_f1_score: 0.9989 - val_loss: 0.0307 - val_precision: 0.9980 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 745ms/step - accuracy: 0.9640 - auc: 0.9934 - f1_score: 0.9701 - loss: 0.0997 - precision: 0.9687 - recall: 0.9725 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0278 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 645ms/step - accuracy: 0.9724 - auc: 0.9959 - f1_score: 0.9765 - loss: 0.0852 - precision: 0.9730 - recall: 0.9813 - val_accuracy: 0.9987 - val_auc: 1.0000 - val_f1_score: 0.9991 - val_loss: 0.0243 - val_precision: 0.9979 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 670ms/step - accuracy: 0.9703 - auc: 0.9946 - f1_score: 0.9751 - loss: 0.0887 - precision: 0.9710 - recall: 0.9809 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0258 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 738ms/step - accuracy: 0.9689 - auc: 0.9956 - f1_score: 0.9743 - loss: 0.0824 - precision: 0.9783 - recall: 0.9708 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0204 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 652ms/step - accuracy: 0.9681 - auc: 0.9958 - f1_score: 0.9733 - loss: 0.0817 - precision: 0.9722 - recall: 0.9766 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0176 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 679ms/step - accuracy: 0.9729 - auc: 0.9960 - f1_score: 0.9778 - loss: 0.0768 - precision: 0.9777 - recall: 0.9783 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0171 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 726ms/step - accuracy: 0.9766 - auc: 0.9975 - f1_score: 0.9806 - loss: 0.0644 - precision: 0.9771 - recall: 0.9852 - val_accuracy: 0.9987 - val_auc: 1.0000 - val_f1_score: 0.9991 - val_loss: 0.0141 - val_precision: 1.0000 - val_recall: 0.9980 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 641ms/step - accuracy: 0.9702 - auc: 0.9969 - f1_score: 0.9758 - loss: 0.0726 - precision: 0.9802 - recall: 0.9714 - val_accuracy: 0.9987 - val_auc: 1.0000 - val_f1_score: 0.9990 - val_loss: 0.0205 - val_precision: 0.9979 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 683ms/step - accuracy: 0.9752 - auc: 0.9971 - f1_score: 0.9796 - loss: 0.0633 - precision: 0.9809 - recall: 0.9787 - val_accuracy: 0.9987 - val_auc: 1.0000 - val_f1_score: 0.9988 - val_loss: 0.0169 - val_precision: 1.0000 - val_recall: 0.9980 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 708ms/step - accuracy: 0.9701 - auc: 0.9954 - f1_score: 0.9757 - loss: 0.0766 - precision: 0.9784 - recall: 0.9731 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0134 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 654ms/step - accuracy: 0.9761 - auc: 0.9963 - f1_score: 0.9798 - loss: 0.0692 - precision: 0.9827 - recall: 0.9787 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0131 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 707ms/step - accuracy: 0.9708 - auc: 0.9966 - f1_score: 0.9762 - loss: 0.0723 - precision: 0.9785 - recall: 0.9735 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0149 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 697ms/step - accuracy: 0.9731 - auc: 0.9958 - f1_score: 0.9773 - loss: 0.0765 - precision: 0.9768 - recall: 0.9800 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0110 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 659ms/step - accuracy: 0.9679 - auc: 0.9955 - f1_score: 0.9719 - loss: 0.0809 - precision: 0.9689 - recall: 0.9786 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0119 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 705ms/step - accuracy: 0.9794 - auc: 0.9971 - f1_score: 0.9827 - loss: 0.0600 - precision: 0.9836 - recall: 0.9825 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0110 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 31/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 676ms/step - accuracy: 0.9786 - auc: 0.9973 - f1_score: 0.9817 - loss: 0.0625 - precision: 0.9799 - recall: 0.9854 - val_accuracy: 0.9987 - val_auc: 1.0000 - val_f1_score: 0.9992 - val_loss: 0.0159 - val_precision: 1.0000 - val_recall: 0.9980 - learning_rate: 0.0010\n",
      "Epoch 32/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 656ms/step - accuracy: 0.9768 - auc: 0.9979 - f1_score: 0.9803 - loss: 0.0584 - precision: 0.9833 - recall: 0.9788 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0109 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 33/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 709ms/step - accuracy: 0.9733 - auc: 0.9959 - f1_score: 0.9778 - loss: 0.0707 - precision: 0.9764 - recall: 0.9809 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0109 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 34/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 710ms/step - accuracy: 0.9744 - auc: 0.9973 - f1_score: 0.9786 - loss: 0.0638 - precision: 0.9722 - recall: 0.9855 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0130 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 35/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 666ms/step - accuracy: 0.9785 - auc: 0.9970 - f1_score: 0.9823 - loss: 0.0577 - precision: 0.9842 - recall: 0.9811 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0121 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 36/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 734ms/step - accuracy: 0.9803 - auc: 0.9975 - f1_score: 0.9838 - loss: 0.0596 - precision: 0.9834 - recall: 0.9844 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0096 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 37/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 655ms/step - accuracy: 0.9799 - auc: 0.9975 - f1_score: 0.9838 - loss: 0.0559 - precision: 0.9862 - recall: 0.9810 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0092 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 38/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 663ms/step - accuracy: 0.9829 - auc: 0.9974 - f1_score: 0.9846 - loss: 0.0544 - precision: 0.9872 - recall: 0.9847 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0075 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 39/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 741ms/step - accuracy: 0.9803 - auc: 0.9974 - f1_score: 0.9834 - loss: 0.0577 - precision: 0.9825 - recall: 0.9856 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0086 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 40/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 642ms/step - accuracy: 0.9835 - auc: 0.9977 - f1_score: 0.9863 - loss: 0.0511 - precision: 0.9872 - recall: 0.9859 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0114 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 41/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 665ms/step - accuracy: 0.9761 - auc: 0.9973 - f1_score: 0.9809 - loss: 0.0633 - precision: 0.9771 - recall: 0.9843 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0097 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 42/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 739ms/step - accuracy: 0.9834 - auc: 0.9989 - f1_score: 0.9858 - loss: 0.0422 - precision: 0.9869 - recall: 0.9861 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0083 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 43/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526ms/step - accuracy: 0.9832 - auc: 0.9971 - f1_score: 0.9864 - loss: 0.0531 - precision: 0.9885 - recall: 0.9840\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 642ms/step - accuracy: 0.9832 - auc: 0.9971 - f1_score: 0.9864 - loss: 0.0532 - precision: 0.9885 - recall: 0.9840 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0080 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Training time: 3425.89 seconds\n",
      "Evaluating ResNet50V2 on The Wildfire Dataset...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 531ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 539ms/step - accuracy: 0.8797 - auc: 0.8401 - f1_score: 0.4667 - loss: 0.3851 - precision: 0.7358 - recall: 0.8201\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.8930288553237915,\n",
      "                'auc': 0.9465653300285339,\n",
      "                'f1_score': 0.6204124689102173,\n",
      "                'loss': 0.3413488268852234,\n",
      "                'precision': 0.9009708762168884,\n",
      "                'recall': 0.9243028163909912},\n",
      " 'history': {'accuracy': [0.78392094373703,\n",
      "                          0.8653846383094788,\n",
      "                          0.8888888955116272,\n",
      "                          0.9038461446762085,\n",
      "                          0.9078525900840759,\n",
      "                          0.9161324501037598,\n",
      "                          0.9292200803756714,\n",
      "                          0.9241452813148499,\n",
      "                          0.9391025900840759,\n",
      "                          0.942307710647583,\n",
      "                          0.9468482732772827,\n",
      "                          0.9497863054275513,\n",
      "                          0.9537927508354187,\n",
      "                          0.9529914259910583,\n",
      "                          0.9647436141967773,\n",
      "                          0.961271345615387,\n",
      "                          0.9700854420661926,\n",
      "                          0.9634081125259399,\n",
      "                          0.9676816463470459,\n",
      "                          0.97142094373703,\n",
      "                          0.97142094373703,\n",
      "                          0.970886766910553,\n",
      "                          0.9695512652397156,\n",
      "                          0.9732906222343445,\n",
      "                          0.9727563858032227,\n",
      "                          0.976228654384613,\n",
      "                          0.9740918874740601,\n",
      "                          0.9748931527137756,\n",
      "                          0.9679487347602844,\n",
      "                          0.9815705418586731,\n",
      "                          0.9759615659713745,\n",
      "                          0.9805021286010742,\n",
      "                          0.9756944179534912,\n",
      "                          0.9772970080375671,\n",
      "                          0.9740918874740601,\n",
      "                          0.9802350401878357,\n",
      "                          0.9775640964508057,\n",
      "                          0.9823718070983887,\n",
      "                          0.9783653616905212,\n",
      "                          0.9799679517745972,\n",
      "                          0.9786324501037598,\n",
      "                          0.9826388955116272,\n",
      "                          0.9818376302719116],\n",
      "             'auc': [0.8692595362663269,\n",
      "                     0.93535315990448,\n",
      "                     0.9549589157104492,\n",
      "                     0.9624329209327698,\n",
      "                     0.9735616445541382,\n",
      "                     0.9734594225883484,\n",
      "                     0.9798182845115662,\n",
      "                     0.9768345355987549,\n",
      "                     0.9860347509384155,\n",
      "                     0.98605877161026,\n",
      "                     0.9876983165740967,\n",
      "                     0.9899715781211853,\n",
      "                     0.9897098541259766,\n",
      "                     0.991651713848114,\n",
      "                     0.9942507743835449,\n",
      "                     0.9933204054832458,\n",
      "                     0.9951550960540771,\n",
      "                     0.9935877919197083,\n",
      "                     0.9950457811355591,\n",
      "                     0.995782732963562,\n",
      "                     0.9963284134864807,\n",
      "                     0.9964367747306824,\n",
      "                     0.9961446523666382,\n",
      "                     0.996565580368042,\n",
      "                     0.995469331741333,\n",
      "                     0.9966381788253784,\n",
      "                     0.9969528317451477,\n",
      "                     0.9960638880729675,\n",
      "                     0.9952334761619568,\n",
      "                     0.9979020953178406,\n",
      "                     0.9974308013916016,\n",
      "                     0.9976789951324463,\n",
      "                     0.9967266321182251,\n",
      "                     0.9969442486763,\n",
      "                     0.9963036179542542,\n",
      "                     0.9977903366088867,\n",
      "                     0.9970700740814209,\n",
      "                     0.9974163174629211,\n",
      "                     0.9974254369735718,\n",
      "                     0.9971219301223755,\n",
      "                     0.9980449676513672,\n",
      "                     0.9983556866645813,\n",
      "                     0.996466338634491],\n",
      "             'f1_score': [0.8165997862815857,\n",
      "                          0.8888764381408691,\n",
      "                          0.9086105227470398,\n",
      "                          0.9196742177009583,\n",
      "                          0.9230901002883911,\n",
      "                          0.9303228259086609,\n",
      "                          0.9422327280044556,\n",
      "                          0.9375710487365723,\n",
      "                          0.9497197270393372,\n",
      "                          0.9519858956336975,\n",
      "                          0.9558785557746887,\n",
      "                          0.9583088159561157,\n",
      "                          0.9615035057067871,\n",
      "                          0.9612761735916138,\n",
      "                          0.9700166583061218,\n",
      "                          0.9679712653160095,\n",
      "                          0.9752789735794067,\n",
      "                          0.9696252346038818,\n",
      "                          0.9729481339454651,\n",
      "                          0.97601717710495,\n",
      "                          0.9766795039176941,\n",
      "                          0.9758480787277222,\n",
      "                          0.974835991859436,\n",
      "                          0.9777578115463257,\n",
      "                          0.9773201942443848,\n",
      "                          0.9800031185150146,\n",
      "                          0.9785519242286682,\n",
      "                          0.978604257106781,\n",
      "                          0.9722065329551697,\n",
      "                          0.9843881130218506,\n",
      "                          0.9795960187911987,\n",
      "                          0.9834280610084534,\n",
      "                          0.9798886775970459,\n",
      "                          0.9811863303184509,\n",
      "                          0.9779240489006042,\n",
      "                          0.9834545850753784,\n",
      "                          0.9816888570785522,\n",
      "                          0.9843659400939941,\n",
      "                          0.981598973274231,\n",
      "                          0.9834446310997009,\n",
      "                          0.9828315377235413,\n",
      "                          0.9853502511978149,\n",
      "                          0.9849705100059509],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513],\n",
      "             'loss': [0.5186904072761536,\n",
      "                      0.3273525536060333,\n",
      "                      0.26606285572052,\n",
      "                      0.24037174880504608,\n",
      "                      0.20125755667686462,\n",
      "                      0.20209099352359772,\n",
      "                      0.17479977011680603,\n",
      "                      0.18839842081069946,\n",
      "                      0.14843007922172546,\n",
      "                      0.14768239855766296,\n",
      "                      0.1381562203168869,\n",
      "                      0.12431986629962921,\n",
      "                      0.12363334745168686,\n",
      "                      0.11430102586746216,\n",
      "                      0.09512625634670258,\n",
      "                      0.10206794738769531,\n",
      "                      0.08822985738515854,\n",
      "                      0.09663346409797668,\n",
      "                      0.08609938621520996,\n",
      "                      0.07911372184753418,\n",
      "                      0.0754518136382103,\n",
      "                      0.07554205507040024,\n",
      "                      0.07665766775608063,\n",
      "                      0.06949544697999954,\n",
      "                      0.07440055906772614,\n",
      "                      0.06842446327209473,\n",
      "                      0.06617662310600281,\n",
      "                      0.07158062607049942,\n",
      "                      0.08020039647817612,\n",
      "                      0.05312841385602951,\n",
      "                      0.06267302483320236,\n",
      "                      0.0566735565662384,\n",
      "                      0.06365233659744263,\n",
      "                      0.06266127526760101,\n",
      "                      0.0662580281496048,\n",
      "                      0.05631624162197113,\n",
      "                      0.061296507716178894,\n",
      "                      0.053119998425245285,\n",
      "                      0.05846860259771347,\n",
      "                      0.05822204053401947,\n",
      "                      0.054655127227306366,\n",
      "                      0.046124767512083054,\n",
      "                      0.05617077648639679],\n",
      "             'precision': [0.8383424282073975,\n",
      "                           0.889229416847229,\n",
      "                           0.905030369758606,\n",
      "                           0.9217657446861267,\n",
      "                           0.9188255667686462,\n",
      "                           0.926701545715332,\n",
      "                           0.9430186748504639,\n",
      "                           0.9376906156539917,\n",
      "                           0.9508482217788696,\n",
      "                           0.9481481313705444,\n",
      "                           0.9560295939445496,\n",
      "                           0.9556521773338318,\n",
      "                           0.9593952298164368,\n",
      "                           0.9607672095298767,\n",
      "                           0.9734320640563965,\n",
      "                           0.9640692472457886,\n",
      "                           0.974403440952301,\n",
      "                           0.9671280384063721,\n",
      "                           0.9759930372238159,\n",
      "                           0.9761698246002197,\n",
      "                           0.977680504322052,\n",
      "                           0.9752174019813538,\n",
      "                           0.9773420691490173,\n",
      "                           0.9764910936355591,\n",
      "                           0.9769965410232544,\n",
      "                           0.9809027910232544,\n",
      "                           0.9797713160514832,\n",
      "                           0.9775571823120117,\n",
      "                           0.971416175365448,\n",
      "                           0.9850746393203735,\n",
      "                           0.978723406791687,\n",
      "                           0.984696090221405,\n",
      "                           0.9791756868362427,\n",
      "                           0.9789103865623474,\n",
      "                           0.9783174395561218,\n",
      "                           0.982555627822876,\n",
      "                           0.982525110244751,\n",
      "                           0.9854881167411804,\n",
      "                           0.9813043475151062,\n",
      "                           0.9860687851905823,\n",
      "                           0.9804602861404419,\n",
      "                           0.9865684509277344,\n",
      "                           0.9864391684532166],\n",
      "             'recall': [0.8021786212921143,\n",
      "                        0.8900087475776672,\n",
      "                        0.9137477874755859,\n",
      "                        0.9209607243537903,\n",
      "                        0.9312910437583923,\n",
      "                        0.9356828331947327,\n",
      "                        0.9417897462844849,\n",
      "                        0.9385085105895996,\n",
      "                        0.9500217437744141,\n",
      "                        0.9573251008987427,\n",
      "                        0.9572798609733582,\n",
      "                        0.9623467326164246,\n",
      "                        0.9656521677970886,\n",
      "                        0.9624454379081726,\n",
      "                        0.9692107439041138,\n",
      "                        0.972913920879364,\n",
      "                        0.9769464731216431,\n",
      "                        0.9734436273574829,\n",
      "                        0.9713292717933655,\n",
      "                        0.977440357208252,\n",
      "                        0.9755458235740662,\n",
      "                        0.9773420691490173,\n",
      "                        0.9731019735336304,\n",
      "                        0.9799038767814636,\n",
      "                        0.9786956310272217,\n",
      "                        0.9804772138595581,\n",
      "                        0.9776217341423035,\n",
      "                        0.981794536113739,\n",
      "                        0.9764910936355591,\n",
      "                        0.9846423864364624,\n",
      "                        0.9821350574493408,\n",
      "                        0.983406126499176,\n",
      "                        0.9813043475151062,\n",
      "                        0.9836644530296326,\n",
      "                        0.9795918464660645,\n",
      "                        0.9851333498954773,\n",
      "                        0.9808111786842346,\n",
      "                        0.9854881167411804,\n",
      "                        0.9834422469139099,\n",
      "                        0.981369137763977,\n",
      "                        0.9847361445426941,\n",
      "                        0.9852877259254456,\n",
      "                        0.9838569164276123],\n",
      "             'val_accuracy': [0.8887500166893005,\n",
      "                              0.9237499833106995,\n",
      "                              0.9624999761581421,\n",
      "                              0.96875,\n",
      "                              0.981249988079071,\n",
      "                              0.987500011920929,\n",
      "                              0.9900000095367432,\n",
      "                              0.9925000071525574,\n",
      "                              0.9962499737739563,\n",
      "                              0.9950000047683716,\n",
      "                              0.9962499737739563,\n",
      "                              0.9975000023841858,\n",
      "                              0.9975000023841858,\n",
      "                              1.0,\n",
      "                              0.9987499713897705,\n",
      "                              1.0,\n",
      "                              0.9987499713897705,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              0.9987499713897705,\n",
      "                              0.9987499713897705,\n",
      "                              0.9987499713897705,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              0.9987499713897705,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9642648100852966,\n",
      "                         0.9819833040237427,\n",
      "                         0.992603063583374,\n",
      "                         0.9953217506408691,\n",
      "                         0.9983723163604736,\n",
      "                         0.9993923902511597,\n",
      "                         0.9994412064552307,\n",
      "                         0.9997599720954895,\n",
      "                         0.9999571442604065,\n",
      "                         0.9999468326568604,\n",
      "                         0.9999933242797852,\n",
      "                         0.9999999403953552,\n",
      "                         0.9999867677688599,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.90839022397995,\n",
      "                              0.9354485273361206,\n",
      "                              0.9687853455543518,\n",
      "                              0.9736874103546143,\n",
      "                              0.9853733777999878,\n",
      "                              0.9886428713798523,\n",
      "                              0.9915147423744202,\n",
      "                              0.9939303398132324,\n",
      "                              0.9968491196632385,\n",
      "                              0.9961695075035095,\n",
      "                              0.9966886639595032,\n",
      "                              0.9979268908500671,\n",
      "                              0.9975882768630981,\n",
      "                              1.0,\n",
      "                              0.9988571405410767,\n",
      "                              1.0,\n",
      "                              0.9991111159324646,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              0.9990697503089905,\n",
      "                              0.9989743828773499,\n",
      "                              0.9987878203392029,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              0.9991836547851562,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.2874409556388855,\n",
      "                          0.20055744051933289,\n",
      "                          0.1490972489118576,\n",
      "                          0.12472677230834961,\n",
      "                          0.09504059702157974,\n",
      "                          0.07849250733852386,\n",
      "                          0.06949359178543091,\n",
      "                          0.060200247913599014,\n",
      "                          0.05220307037234306,\n",
      "                          0.04411015659570694,\n",
      "                          0.04094602167606354,\n",
      "                          0.03745870292186737,\n",
      "                          0.03562530130147934,\n",
      "                          0.031718116253614426,\n",
      "                          0.030653314664959908,\n",
      "                          0.027812398970127106,\n",
      "                          0.02425330877304077,\n",
      "                          0.025777500122785568,\n",
      "                          0.020437344908714294,\n",
      "                          0.01756145805120468,\n",
      "                          0.017084874212741852,\n",
      "                          0.014110476709902287,\n",
      "                          0.020472856238484383,\n",
      "                          0.016894495114684105,\n",
      "                          0.013396991416811943,\n",
      "                          0.013055193237960339,\n",
      "                          0.014901705086231232,\n",
      "                          0.011023552156984806,\n",
      "                          0.011899230070412159,\n",
      "                          0.011045996099710464,\n",
      "                          0.015852052718400955,\n",
      "                          0.010929194279015064,\n",
      "                          0.010872822254896164,\n",
      "                          0.012998215854167938,\n",
      "                          0.012113858014345169,\n",
      "                          0.009621856734156609,\n",
      "                          0.009244236163794994,\n",
      "                          0.007526927627623081,\n",
      "                          0.008583488874137402,\n",
      "                          0.01143994927406311,\n",
      "                          0.009690096601843834,\n",
      "                          0.00825284980237484,\n",
      "                          0.008012644946575165],\n",
      "             'val_precision': [0.9484978318214417,\n",
      "                               0.9344262480735779,\n",
      "                               0.9817073345184326,\n",
      "                               0.9796748161315918,\n",
      "                               0.9866412281990051,\n",
      "                               0.9938016533851624,\n",
      "                               0.9855371713638306,\n",
      "                               0.9940000176429749,\n",
      "                               0.9939516186714172,\n",
      "                               1.0,\n",
      "                               0.9940239191055298,\n",
      "                               1.0,\n",
      "                               0.9979757070541382,\n",
      "                               1.0,\n",
      "                               0.9979798197746277,\n",
      "                               1.0,\n",
      "                               0.9979079365730286,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               0.9979296326637268,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.8717948794364929,\n",
      "                            0.9402061700820923,\n",
      "                            0.9583333134651184,\n",
      "                            0.9698188900947571,\n",
      "                            0.9847618937492371,\n",
      "                            0.9856557250022888,\n",
      "                            0.9979079365730286,\n",
      "                            0.9940000176429749,\n",
      "                            1.0,\n",
      "                            0.9919678568840027,\n",
      "                            1.0,\n",
      "                            0.9958763122558594,\n",
      "                            0.9979757070541382,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            0.9979919791221619,\n",
      "                            1.0,\n",
      "                            0.9980158805847168,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            0.9980000257492065,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.8121146559715271,\n",
      " 'train_counts': {'fire': 730, 'nofire': 1157},\n",
      " 'train_dataset_size': 3744,\n",
      " 'training_time': 3425.886086702347,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_dataset_size': 800}\n",
      "Training model: ResNet50V2 on dataset: DeepFire\n",
      "Epoch 1/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 749ms/step - accuracy: 0.8862 - auc: 0.9615 - f1_score: 0.8802 - loss: 0.2706 - precision: 0.9056 - recall: 0.9206 - val_accuracy: 0.9901 - val_auc: 0.9992 - val_f1_score: 0.9886 - val_loss: 0.0400 - val_precision: 0.9934 - val_recall: 0.9868 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 696ms/step - accuracy: 0.9760 - auc: 0.9951 - f1_score: 0.9738 - loss: 0.0719 - precision: 0.9757 - recall: 0.9766 - val_accuracy: 0.9918 - val_auc: 0.9999 - val_f1_score: 0.9918 - val_loss: 0.0265 - val_precision: 0.9966 - val_recall: 0.9866 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 669ms/step - accuracy: 0.9807 - auc: 0.9971 - f1_score: 0.9803 - loss: 0.0540 - precision: 0.9805 - recall: 0.9812 - val_accuracy: 0.9934 - val_auc: 0.9999 - val_f1_score: 0.9941 - val_loss: 0.0215 - val_precision: 1.0000 - val_recall: 0.9874 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 678ms/step - accuracy: 0.9859 - auc: 0.9988 - f1_score: 0.9850 - loss: 0.0377 - precision: 0.9852 - recall: 0.9862 - val_accuracy: 0.9984 - val_auc: 1.0000 - val_f1_score: 0.9982 - val_loss: 0.0095 - val_precision: 1.0000 - val_recall: 0.9967 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 743ms/step - accuracy: 0.9867 - auc: 0.9991 - f1_score: 0.9866 - loss: 0.0314 - precision: 0.9903 - recall: 0.9835 - val_accuracy: 0.9984 - val_auc: 1.0000 - val_f1_score: 0.9986 - val_loss: 0.0057 - val_precision: 1.0000 - val_recall: 0.9966 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 746ms/step - accuracy: 0.9915 - auc: 0.9998 - f1_score: 0.9910 - loss: 0.0196 - precision: 0.9911 - recall: 0.9921 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0033 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 673ms/step - accuracy: 0.9853 - auc: 0.9978 - f1_score: 0.9843 - loss: 0.0495 - precision: 0.9870 - recall: 0.9830 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0020 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 707ms/step - accuracy: 0.9874 - auc: 0.9989 - f1_score: 0.9855 - loss: 0.0318 - precision: 0.9867 - recall: 0.9884 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0017 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 734ms/step - accuracy: 0.9907 - auc: 0.9996 - f1_score: 0.9913 - loss: 0.0291 - precision: 0.9940 - recall: 0.9878 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0012 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 756ms/step - accuracy: 0.9942 - auc: 0.9997 - f1_score: 0.9940 - loss: 0.0175 - precision: 0.9940 - recall: 0.9943 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0022 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 675ms/step - accuracy: 0.9935 - auc: 0.9999 - f1_score: 0.9933 - loss: 0.0171 - precision: 0.9915 - recall: 0.9950 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.4547e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 677ms/step - accuracy: 0.9883 - auc: 0.9995 - f1_score: 0.9880 - loss: 0.0259 - precision: 0.9874 - recall: 0.9879 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0013 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 733ms/step - accuracy: 0.9934 - auc: 0.9990 - f1_score: 0.9917 - loss: 0.0197 - precision: 0.9901 - recall: 0.9964 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.6949e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 756ms/step - accuracy: 0.9976 - auc: 0.9996 - f1_score: 0.9974 - loss: 0.0156 - precision: 0.9980 - recall: 0.9972 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0012 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 662ms/step - accuracy: 0.9934 - auc: 0.9999 - f1_score: 0.9934 - loss: 0.0152 - precision: 0.9957 - recall: 0.9910 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.1185e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 677ms/step - accuracy: 0.9924 - auc: 0.9998 - f1_score: 0.9931 - loss: 0.0220 - precision: 0.9953 - recall: 0.9902 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.3612e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 702ms/step - accuracy: 0.9955 - auc: 0.9999 - f1_score: 0.9951 - loss: 0.0125 - precision: 0.9956 - recall: 0.9956 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.0589e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 774ms/step - accuracy: 0.9933 - auc: 0.9980 - f1_score: 0.9943 - loss: 0.0249 - precision: 0.9987 - recall: 0.9884 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.3901e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 675ms/step - accuracy: 0.9935 - auc: 0.9999 - f1_score: 0.9930 - loss: 0.0147 - precision: 0.9940 - recall: 0.9931 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.3811e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - accuracy: 0.9934 - auc: 0.9999 - f1_score: 0.9919 - loss: 0.0138 - precision: 0.9915 - recall: 0.9951\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 670ms/step - accuracy: 0.9934 - auc: 0.9999 - f1_score: 0.9920 - loss: 0.0137 - precision: 0.9915 - recall: 0.9951 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.2793e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Training time: 1102.37 seconds\n",
      "Evaluating ResNet50V2 on DeepFire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 535ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 538ms/step - accuracy: 0.6805 - auc: 0.6686 - f1_score: 0.4355 - loss: 1.9409 - precision: 0.5741 - recall: 0.7570\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.7151442170143127,\n",
      "                'auc': 0.7388205528259277,\n",
      "                'f1_score': 0.572641909122467,\n",
      "                'loss': 1.700905680656433,\n",
      "                'precision': 0.733686089515686,\n",
      "                'recall': 0.8286852836608887},\n",
      " 'history': {'accuracy': [0.9420230388641357,\n",
      "                          0.9765625,\n",
      "                          0.9831414222717285,\n",
      "                          0.984375,\n",
      "                          0.9884868264198303,\n",
      "                          0.9897204041481018,\n",
      "                          0.9884868264198303,\n",
      "                          0.9884868264198303,\n",
      "                          0.9909539222717285,\n",
      "                          0.9934210777282715,\n",
      "                          0.9962993264198303,\n",
      "                          0.9901315569877625,\n",
      "                          0.9909539222717285,\n",
      "                          0.9950658082962036,\n",
      "                          0.9930098652839661,\n",
      "                          0.9946545958518982,\n",
      "                          0.9946545958518982,\n",
      "                          0.9942434430122375,\n",
      "                          0.9946545958518982,\n",
      "                          0.9954769611358643],\n",
      "             'auc': [0.978486955165863,\n",
      "                     0.9970409274101257,\n",
      "                     0.9981133341789246,\n",
      "                     0.9987586140632629,\n",
      "                     0.9990968704223633,\n",
      "                     0.9996364712715149,\n",
      "                     0.9989165663719177,\n",
      "                     0.9986796379089355,\n",
      "                     0.9996127486228943,\n",
      "                     0.9989126920700073,\n",
      "                     0.9999381303787231,\n",
      "                     0.9996989965438843,\n",
      "                     0.9993307590484619,\n",
      "                     0.9993048310279846,\n",
      "                     0.9998584985733032,\n",
      "                     0.9998291730880737,\n",
      "                     0.9998988509178162,\n",
      "                     0.9994088411331177,\n",
      "                     0.9998986124992371,\n",
      "                     0.999954342842102],\n",
      "             'f1_score': [0.9403572082519531,\n",
      "                          0.974420964717865,\n",
      "                          0.981380045413971,\n",
      "                          0.9833728671073914,\n",
      "                          0.9885861277580261,\n",
      "                          0.9886764883995056,\n",
      "                          0.9870985746383667,\n",
      "                          0.9867554903030396,\n",
      "                          0.9911108613014221,\n",
      "                          0.9925681948661804,\n",
      "                          0.996420681476593,\n",
      "                          0.9902539253234863,\n",
      "                          0.9900901913642883,\n",
      "                          0.9948521852493286,\n",
      "                          0.9923323392868042,\n",
      "                          0.9947482943534851,\n",
      "                          0.9938521385192871,\n",
      "                          0.9947074055671692,\n",
      "                          0.9947115182876587,\n",
      "                          0.9945807456970215],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513],\n",
      "             'loss': [0.15357770025730133,\n",
      "                      0.06210578605532646,\n",
      "                      0.04431654140353203,\n",
      "                      0.03854711353778839,\n",
      "                      0.029186110943555832,\n",
      "                      0.02610222063958645,\n",
      "                      0.033678315579891205,\n",
      "                      0.02996334619820118,\n",
      "                      0.02464091219007969,\n",
      "                      0.02217976003885269,\n",
      "                      0.012015709653496742,\n",
      "                      0.02307542786002159,\n",
      "                      0.021907377988100052,\n",
      "                      0.021710336208343506,\n",
      "                      0.01767825521528721,\n",
      "                      0.016464387997984886,\n",
      "                      0.012897010892629623,\n",
      "                      0.018676603212952614,\n",
      "                      0.013958211056888103,\n",
      "                      0.00988306850194931],\n",
      "             'precision': [0.9303944110870361,\n",
      "                           0.9738134145736694,\n",
      "                           0.979457676410675,\n",
      "                           0.9843621253967285,\n",
      "                           0.9918500185012817,\n",
      "                           0.9876948595046997,\n",
      "                           0.9885151982307434,\n",
      "                           0.9868744611740112,\n",
      "                           0.9909613728523254,\n",
      "                           0.9925742745399475,\n",
      "                           0.9966832399368286,\n",
      "                           0.9925373196601868,\n",
      "                           0.9901071786880493,\n",
      "                           0.9958983063697815,\n",
      "                           0.9932829737663269,\n",
      "                           0.9951298832893372,\n",
      "                           0.9934372305870056,\n",
      "                           0.9967293739318848,\n",
      "                           0.995106041431427,\n",
      "                           0.9950535893440247],\n",
      "             'recall': [0.9358226656913757,\n",
      "                        0.9794238805770874,\n",
      "                        0.9867549538612366,\n",
      "                        0.9843621253967285,\n",
      "                        0.9854251146316528,\n",
      "                        0.9917627573013306,\n",
      "                        0.9885151982307434,\n",
      "                        0.990123450756073,\n",
      "                        0.9909613728523254,\n",
      "                        0.9942148923873901,\n",
      "                        0.9958574771881104,\n",
      "                        0.9876237511634827,\n",
      "                        0.9917423725128174,\n",
      "                        0.9942669868469238,\n",
      "                        0.9924496412277222,\n",
      "                        0.9943227767944336,\n",
      "                        0.9958881735801697,\n",
      "                        0.9918633103370667,\n",
      "                        0.9942950010299683,\n",
      "                        0.9958745837211609],\n",
      "             'val_accuracy': [0.9901315569877625,\n",
      "                              0.9917762875556946,\n",
      "                              0.9934210777282715,\n",
      "                              0.9983552694320679,\n",
      "                              0.9983552694320679,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9991992712020874,\n",
      "                         0.9998647570610046,\n",
      "                         0.9999457597732544,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.988594651222229,\n",
      "                              0.9918058514595032,\n",
      "                              0.9940685629844666,\n",
      "                              0.9981850981712341,\n",
      "                              0.9985775351524353,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.04004738852381706,\n",
      "                          0.026470042765140533,\n",
      "                          0.021535241976380348,\n",
      "                          0.00952516496181488,\n",
      "                          0.005683733616024256,\n",
      "                          0.003260433441027999,\n",
      "                          0.0019767272751778364,\n",
      "                          0.0017165675526484847,\n",
      "                          0.0012383206048980355,\n",
      "                          0.00215399032458663,\n",
      "                          0.0007454704609699547,\n",
      "                          0.0012804243015125394,\n",
      "                          0.0006694925832562149,\n",
      "                          0.0011792931472882628,\n",
      "                          0.0005118537228554487,\n",
      "                          0.0005361151415854692,\n",
      "                          0.0007058914052322507,\n",
      "                          0.000539009808562696,\n",
      "                          0.0005381092196330428,\n",
      "                          0.000527931610122323],\n",
      "             'val_precision': [0.9933554530143738,\n",
      "                               0.9966216087341309,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.9867987036705017,\n",
      "                            0.9866220951080322,\n",
      "                            0.9873816967010498,\n",
      "                            0.9967105388641357,\n",
      "                            0.9965986609458923,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.008332621306180954,\n",
      " 'train_counts': {'fire': 760, 'nofire': 760},\n",
      " 'train_dataset_size': 2432,\n",
      " 'training_time': 1102.366426706314,\n",
      " 'val_counts': {'fire': 0, 'nofire': 0},\n",
      " 'val_dataset_size': 608}\n",
      "Training model: ResNet50V2 on dataset: FIRE\n",
      "Epoch 1/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 754ms/step - accuracy: 0.8004 - auc: 0.8222 - f1_score: 0.6861 - loss: 0.5853 - precision: 0.6884 - recall: 0.8545 - val_accuracy: 0.9766 - val_auc: 0.9898 - val_f1_score: 0.9371 - val_loss: 0.0948 - val_precision: 0.9518 - val_recall: 0.9405 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 691ms/step - accuracy: 0.9273 - auc: 0.9900 - f1_score: 0.8549 - loss: 0.1871 - precision: 0.7737 - recall: 0.9774 - val_accuracy: 0.9844 - val_auc: 0.9952 - val_f1_score: 0.9628 - val_loss: 0.0542 - val_precision: 0.9892 - val_recall: 0.9485 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 671ms/step - accuracy: 0.9485 - auc: 0.9925 - f1_score: 0.8890 - loss: 0.1321 - precision: 0.8360 - recall: 0.9622 - val_accuracy: 0.9922 - val_auc: 0.9998 - val_f1_score: 0.9776 - val_loss: 0.0296 - val_precision: 1.0000 - val_recall: 0.9639 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 675ms/step - accuracy: 0.9757 - auc: 0.9971 - f1_score: 0.9481 - loss: 0.0732 - precision: 0.9272 - recall: 0.9775 - val_accuracy: 0.9974 - val_auc: 1.0000 - val_f1_score: 0.9951 - val_loss: 0.0186 - val_precision: 1.0000 - val_recall: 0.9897 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 696ms/step - accuracy: 0.9795 - auc: 0.9973 - f1_score: 0.9522 - loss: 0.0640 - precision: 0.9481 - recall: 0.9717 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0126 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 732ms/step - accuracy: 0.9762 - auc: 0.9971 - f1_score: 0.9436 - loss: 0.0686 - precision: 0.9347 - recall: 0.9754 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0102 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 781ms/step - accuracy: 0.9911 - auc: 0.9981 - f1_score: 0.9774 - loss: 0.0399 - precision: 0.9842 - recall: 0.9800 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0088 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 718ms/step - accuracy: 0.9809 - auc: 0.9977 - f1_score: 0.9470 - loss: 0.0542 - precision: 0.9456 - recall: 0.9775 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0045 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 662ms/step - accuracy: 0.9898 - auc: 0.9994 - f1_score: 0.9795 - loss: 0.0287 - precision: 0.9791 - recall: 0.9797 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0064 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 681ms/step - accuracy: 0.9825 - auc: 0.9984 - f1_score: 0.9494 - loss: 0.0479 - precision: 0.9376 - recall: 0.9904 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0025 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 690ms/step - accuracy: 0.9910 - auc: 0.9992 - f1_score: 0.9812 - loss: 0.0331 - precision: 0.9857 - recall: 0.9793 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 732ms/step - accuracy: 0.9925 - auc: 0.9988 - f1_score: 0.9835 - loss: 0.0319 - precision: 0.9842 - recall: 0.9876 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0031 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 771ms/step - accuracy: 0.9839 - auc: 0.9991 - f1_score: 0.9606 - loss: 0.0476 - precision: 0.9453 - recall: 0.9859 - val_accuracy: 0.9974 - val_auc: 1.0000 - val_f1_score: 0.9944 - val_loss: 0.0036 - val_precision: 1.0000 - val_recall: 0.9902 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 702ms/step - accuracy: 0.9905 - auc: 0.9995 - f1_score: 0.9748 - loss: 0.0261 - precision: 0.9806 - recall: 0.9805 - val_accuracy: 0.9974 - val_auc: 1.0000 - val_f1_score: 0.9960 - val_loss: 0.0052 - val_precision: 1.0000 - val_recall: 0.9906 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 681ms/step - accuracy: 0.9849 - auc: 0.9990 - f1_score: 0.9601 - loss: 0.0367 - precision: 0.9686 - recall: 0.9674 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0019 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 681ms/step - accuracy: 0.9909 - auc: 0.9990 - f1_score: 0.9804 - loss: 0.0335 - precision: 0.9864 - recall: 0.9791 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0014 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 679ms/step - accuracy: 0.9856 - auc: 0.9988 - f1_score: 0.9743 - loss: 0.0340 - precision: 0.9884 - recall: 0.9544 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 721ms/step - accuracy: 0.9902 - auc: 0.9991 - f1_score: 0.9778 - loss: 0.0299 - precision: 0.9831 - recall: 0.9764 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.5078e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 776ms/step - accuracy: 0.9927 - auc: 0.9998 - f1_score: 0.9787 - loss: 0.0186 - precision: 0.9794 - recall: 0.9918 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 722ms/step - accuracy: 0.9911 - auc: 0.9992 - f1_score: 0.9778 - loss: 0.0291 - precision: 0.9770 - recall: 0.9881 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.1788e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 666ms/step - accuracy: 0.9858 - auc: 0.9990 - f1_score: 0.9688 - loss: 0.0343 - precision: 0.9750 - recall: 0.9682 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.4076e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 695ms/step - accuracy: 0.9799 - auc: 0.9981 - f1_score: 0.9488 - loss: 0.0436 - precision: 0.9650 - recall: 0.9497 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0011 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 687ms/step - accuracy: 0.9934 - auc: 0.9999 - f1_score: 0.9824 - loss: 0.0175 - precision: 0.9774 - recall: 0.9952 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.1929e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 688ms/step - accuracy: 0.9945 - auc: 0.9986 - f1_score: 0.9872 - loss: 0.0201 - precision: 0.9906 - recall: 0.9871 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.3348e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9942 - auc: 0.9998 - f1_score: 0.9864 - loss: 0.0164 - precision: 0.9874 - recall: 0.9874\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 748ms/step - accuracy: 0.9943 - auc: 0.9998 - f1_score: 0.9864 - loss: 0.0164 - precision: 0.9874 - recall: 0.9874 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0013 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 785ms/step - accuracy: 0.9954 - auc: 0.9998 - f1_score: 0.9895 - loss: 0.0137 - precision: 0.9924 - recall: 0.9897 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0011 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Training time: 930.34 seconds\n",
      "Evaluating ResNet50V2 on FIRE...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 507ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 538ms/step - accuracy: 0.7112 - auc: 0.7096 - f1_score: 0.3993 - loss: 1.0878 - precision: 0.6257 - recall: 0.6404\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.703125,\n",
      "                'auc': 0.7823131680488586,\n",
      "                'f1_score': 0.5263406038284302,\n",
      "                'loss': 1.1685246229171753,\n",
      "                'precision': 0.7865168452262878,\n",
      "                'recall': 0.6972111463546753},\n",
      " 'history': {'accuracy': [0.8539540767669678,\n",
      "                          0.9387755393981934,\n",
      "                          0.9553571343421936,\n",
      "                          0.96875,\n",
      "                          0.9751275777816772,\n",
      "                          0.9744898080825806,\n",
      "                          0.9872449040412903,\n",
      "                          0.9815050959587097,\n",
      "                          0.9846938848495483,\n",
      "                          0.9904336929321289,\n",
      "                          0.9917091727256775,\n",
      "                          0.9917091727256775,\n",
      "                          0.9885203838348389,\n",
      "                          0.9910714030265808,\n",
      "                          0.9885203838348389,\n",
      "                          0.9891581535339355,\n",
      "                          0.9891581535339355,\n",
      "                          0.9917091727256775,\n",
      "                          0.9929847121238708,\n",
      "                          0.9923469424247742,\n",
      "                          0.9923469424247742,\n",
      "                          0.985331654548645,\n",
      "                          0.9948979616165161,\n",
      "                          0.9923469424247742,\n",
      "                          0.9948979616165161,\n",
      "                          0.9948979616165161],\n",
      "             'auc': [0.8732388615608215,\n",
      "                     0.9907441139221191,\n",
      "                     0.9896026849746704,\n",
      "                     0.9952324628829956,\n",
      "                     0.9964905381202698,\n",
      "                     0.9975499510765076,\n",
      "                     0.9963812232017517,\n",
      "                     0.9970670938491821,\n",
      "                     0.9988407492637634,\n",
      "                     0.9985659718513489,\n",
      "                     0.9993338584899902,\n",
      "                     0.9990312457084656,\n",
      "                     0.9991415143013,\n",
      "                     0.9994008541107178,\n",
      "                     0.9987454414367676,\n",
      "                     0.9987231492996216,\n",
      "                     0.9978414177894592,\n",
      "                     0.9991605281829834,\n",
      "                     0.9997468590736389,\n",
      "                     0.999355673789978,\n",
      "                     0.9995696544647217,\n",
      "                     0.9987694025039673,\n",
      "                     0.9998202323913574,\n",
      "                     0.9982132911682129,\n",
      "                     0.9998624920845032,\n",
      "                     0.9998254179954529],\n",
      "             'f1_score': [0.7516499161720276,\n",
      "                          0.8747974038124084,\n",
      "                          0.9012247920036316,\n",
      "                          0.932472288608551,\n",
      "                          0.9375605583190918,\n",
      "                          0.9351810812950134,\n",
      "                          0.9661219120025635,\n",
      "                          0.9530804753303528,\n",
      "                          0.9695557355880737,\n",
      "                          0.9754805564880371,\n",
      "                          0.9809325337409973,\n",
      "                          0.9808515310287476,\n",
      "                          0.970936119556427,\n",
      "                          0.975069522857666,\n",
      "                          0.9689480662345886,\n",
      "                          0.9727875590324402,\n",
      "                          0.9773256182670593,\n",
      "                          0.9817051291465759,\n",
      "                          0.9784253239631653,\n",
      "                          0.9810444712638855,\n",
      "                          0.9812250137329102,\n",
      "                          0.9622971415519714,\n",
      "                          0.9865679740905762,\n",
      "                          0.9793248176574707,\n",
      "                          0.9869493246078491,\n",
      "                          0.9864972233772278],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257],\n",
      "             'loss': [0.44149038195610046,\n",
      "                      0.16614429652690887,\n",
      "                      0.12603020668029785,\n",
      "                      0.08411385864019394,\n",
      "                      0.07074061781167984,\n",
      "                      0.06639618426561356,\n",
      "                      0.04848197102546692,\n",
      "                      0.0549754723906517,\n",
      "                      0.03865813836455345,\n",
      "                      0.03394298255443573,\n",
      "                      0.029162509366869926,\n",
      "                      0.032115109264850616,\n",
      "                      0.03517156094312668,\n",
      "                      0.027484430000185966,\n",
      "                      0.03392259404063225,\n",
      "                      0.03423115611076355,\n",
      "                      0.03376249969005585,\n",
      "                      0.02525945007801056,\n",
      "                      0.02038000524044037,\n",
      "                      0.026099279522895813,\n",
      "                      0.023432420566678047,\n",
      "                      0.035057131201028824,\n",
      "                      0.01660381816327572,\n",
      "                      0.024823440238833427,\n",
      "                      0.014515082351863384,\n",
      "                      0.015101183205842972],\n",
      "             'precision': [0.6883230805397034,\n",
      "                           0.8114035129547119,\n",
      "                           0.8723404407501221,\n",
      "                           0.9177377820014954,\n",
      "                           0.93638676404953,\n",
      "                           0.9234567880630493,\n",
      "                           0.9713541865348816,\n",
      "                           0.9530026316642761,\n",
      "                           0.9717223644256592,\n",
      "                           0.9740932583808899,\n",
      "                           0.9820051193237305,\n",
      "                           0.9782082438468933,\n",
      "                           0.9631578922271729,\n",
      "                           0.9764397740364075,\n",
      "                           0.9729729890823364,\n",
      "                           0.9717223644256592,\n",
      "                           0.981333315372467,\n",
      "                           0.9842932224273682,\n",
      "                           0.9770992398262024,\n",
      "                           0.9797468185424805,\n",
      "                           0.984415590763092,\n",
      "                           0.9737532734870911,\n",
      "                           0.9843342304229736,\n",
      "                           0.9842519760131836,\n",
      "                           0.9893333315849304,\n",
      "                           0.9870800971984863],\n",
      "             'recall': [0.875977635383606,\n",
      "                        0.9736841917037964,\n",
      "                        0.9584415555000305,\n",
      "                        0.9545454382896423,\n",
      "                        0.963350772857666,\n",
      "                        0.9765012860298157,\n",
      "                        0.9764397740364075,\n",
      "                        0.9707446694374084,\n",
      "                        0.9667519330978394,\n",
      "                        0.9868766665458679,\n",
      "                        0.9845361113548279,\n",
      "                        0.9901960492134094,\n",
      "                        0.9891892075538635,\n",
      "                        0.9867724776268005,\n",
      "                        0.97826087474823,\n",
      "                        0.984375,\n",
      "                        0.9735449552536011,\n",
      "                        0.9817232489585876,\n",
      "                        0.9948186278343201,\n",
      "                        0.9897698163986206,\n",
      "                        0.984415590763092,\n",
      "                        0.9661458134651184,\n",
      "                        0.9947229623794556,\n",
      "                        0.9842519760131836,\n",
      "                        0.9893333315849304,\n",
      "                        0.9922077655792236],\n",
      "             'val_accuracy': [0.9765625,\n",
      "                              0.984375,\n",
      "                              0.9921875,\n",
      "                              0.9973958134651184,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              0.9973958134651184,\n",
      "                              0.9973958134651184,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9897618889808655,\n",
      "                         0.9951865673065186,\n",
      "                         0.9997598528862,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.9370843768119812,\n",
      "                              0.9628027081489563,\n",
      "                              0.977637767791748,\n",
      "                              0.9950980544090271,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              0.9944444298744202,\n",
      "                              0.9960317611694336,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.09480920433998108,\n",
      "                          0.05421555042266846,\n",
      "                          0.029614349827170372,\n",
      "                          0.0186366755515337,\n",
      "                          0.012588396668434143,\n",
      "                          0.010181780904531479,\n",
      "                          0.008836345747113228,\n",
      "                          0.004494916647672653,\n",
      "                          0.006403778214007616,\n",
      "                          0.002509098034352064,\n",
      "                          0.002937673358246684,\n",
      "                          0.0030606857035309076,\n",
      "                          0.003566049737855792,\n",
      "                          0.005219282116740942,\n",
      "                          0.0019434812711551785,\n",
      "                          0.0014413759345188737,\n",
      "                          0.0028636271599680185,\n",
      "                          0.0009507842478342354,\n",
      "                          0.0029034458566457033,\n",
      "                          0.00081788026727736,\n",
      "                          0.000740756222512573,\n",
      "                          0.0010530207073315978,\n",
      "                          0.0008192880195565522,\n",
      "                          0.0009334798087365925,\n",
      "                          0.001272182329557836,\n",
      "                          0.0010991822928190231],\n",
      "             'val_precision': [0.9518072009086609,\n",
      "                               0.9892473220825195,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.9404761791229248,\n",
      "                            0.9484536051750183,\n",
      "                            0.9638554453849792,\n",
      "                            0.9896907210350037,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            0.9901960492134094,\n",
      "                            0.9905660152435303,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.3122466206550598,\n",
      " 'train_counts': {'fire': 755, 'nofire': 244},\n",
      " 'train_dataset_size': 1568,\n",
      " 'training_time': 930.3425323963165,\n",
      " 'val_counts': {'fire': 0, 'nofire': 0},\n",
      " 'val_dataset_size': 384}\n",
      "Training model: ResNet50V2 on dataset: Forest Fire\n",
      "Epoch 1/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 668ms/step - accuracy: 0.8998 - auc: 0.9253 - f1_score: 0.9035 - loss: 0.2504 - precision: 0.8875 - recall: 0.8547 - val_accuracy: 0.9797 - val_auc: 0.9977 - val_f1_score: 0.9810 - val_loss: 0.0636 - val_precision: 0.9773 - val_recall: 0.9861 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 724ms/step - accuracy: 0.9560 - auc: 0.9911 - f1_score: 0.9580 - loss: 0.1158 - precision: 0.9542 - recall: 0.9632 - val_accuracy: 0.9863 - val_auc: 0.9991 - val_f1_score: 0.9866 - val_loss: 0.0401 - val_precision: 0.9843 - val_recall: 0.9895 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 687ms/step - accuracy: 0.9671 - auc: 0.9934 - f1_score: 0.9690 - loss: 0.0908 - precision: 0.9691 - recall: 0.9706 - val_accuracy: 0.9951 - val_auc: 0.9998 - val_f1_score: 0.9953 - val_loss: 0.0261 - val_precision: 0.9959 - val_recall: 0.9949 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 701ms/step - accuracy: 0.9728 - auc: 0.9963 - f1_score: 0.9745 - loss: 0.0730 - precision: 0.9755 - recall: 0.9744 - val_accuracy: 0.9918 - val_auc: 0.9990 - val_f1_score: 0.9919 - val_loss: 0.0299 - val_precision: 0.9918 - val_recall: 0.9928 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 719ms/step - accuracy: 0.9736 - auc: 0.9950 - f1_score: 0.9757 - loss: 0.0780 - precision: 0.9775 - recall: 0.9741 - val_accuracy: 0.9923 - val_auc: 0.9998 - val_f1_score: 0.9937 - val_loss: 0.0218 - val_precision: 0.9879 - val_recall: 0.9980 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 708ms/step - accuracy: 0.9761 - auc: 0.9963 - f1_score: 0.9771 - loss: 0.0665 - precision: 0.9749 - recall: 0.9812 - val_accuracy: 0.9940 - val_auc: 0.9999 - val_f1_score: 0.9942 - val_loss: 0.0198 - val_precision: 0.9899 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 679ms/step - accuracy: 0.9780 - auc: 0.9974 - f1_score: 0.9794 - loss: 0.0552 - precision: 0.9802 - recall: 0.9793 - val_accuracy: 0.9962 - val_auc: 0.9999 - val_f1_score: 0.9966 - val_loss: 0.0161 - val_precision: 0.9940 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 703ms/step - accuracy: 0.9739 - auc: 0.9962 - f1_score: 0.9747 - loss: 0.0661 - precision: 0.9746 - recall: 0.9771 - val_accuracy: 0.9989 - val_auc: 0.9999 - val_f1_score: 0.9990 - val_loss: 0.0133 - val_precision: 0.9990 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 714ms/step - accuracy: 0.9801 - auc: 0.9975 - f1_score: 0.9815 - loss: 0.0553 - precision: 0.9833 - recall: 0.9804 - val_accuracy: 0.9962 - val_auc: 0.9999 - val_f1_score: 0.9960 - val_loss: 0.0138 - val_precision: 0.9949 - val_recall: 0.9979 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 694ms/step - accuracy: 0.9845 - auc: 0.9983 - f1_score: 0.9854 - loss: 0.0454 - precision: 0.9852 - recall: 0.9866 - val_accuracy: 0.9978 - val_auc: 1.0000 - val_f1_score: 0.9978 - val_loss: 0.0098 - val_precision: 0.9969 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 697ms/step - accuracy: 0.9822 - auc: 0.9982 - f1_score: 0.9826 - loss: 0.0494 - precision: 0.9798 - recall: 0.9878 - val_accuracy: 0.9984 - val_auc: 1.0000 - val_f1_score: 0.9986 - val_loss: 0.0092 - val_precision: 0.9990 - val_recall: 0.9980 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 745ms/step - accuracy: 0.9834 - auc: 0.9983 - f1_score: 0.9845 - loss: 0.0442 - precision: 0.9848 - recall: 0.9849 - val_accuracy: 0.9989 - val_auc: 1.0000 - val_f1_score: 0.9989 - val_loss: 0.0066 - val_precision: 0.9990 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 718ms/step - accuracy: 0.9846 - auc: 0.9991 - f1_score: 0.9853 - loss: 0.0364 - precision: 0.9851 - recall: 0.9867 - val_accuracy: 0.9995 - val_auc: 1.0000 - val_f1_score: 0.9996 - val_loss: 0.0067 - val_precision: 1.0000 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 711ms/step - accuracy: 0.9896 - auc: 0.9995 - f1_score: 0.9901 - loss: 0.0282 - precision: 0.9909 - recall: 0.9901 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0052 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 722ms/step - accuracy: 0.9884 - auc: 0.9991 - f1_score: 0.9887 - loss: 0.0334 - precision: 0.9889 - recall: 0.9895 - val_accuracy: 0.9989 - val_auc: 1.0000 - val_f1_score: 0.9987 - val_loss: 0.0084 - val_precision: 0.9990 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 733ms/step - accuracy: 0.9908 - auc: 0.9994 - f1_score: 0.9911 - loss: 0.0281 - precision: 0.9915 - recall: 0.9916 - val_accuracy: 0.9995 - val_auc: 1.0000 - val_f1_score: 0.9994 - val_loss: 0.0056 - val_precision: 1.0000 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 698ms/step - accuracy: 0.9894 - auc: 0.9990 - f1_score: 0.9901 - loss: 0.0318 - precision: 0.9898 - recall: 0.9906 - val_accuracy: 0.9989 - val_auc: 1.0000 - val_f1_score: 0.9991 - val_loss: 0.0065 - val_precision: 0.9981 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 727ms/step - accuracy: 0.9919 - auc: 0.9995 - f1_score: 0.9920 - loss: 0.0278 - precision: 0.9914 - recall: 0.9934 - val_accuracy: 0.9978 - val_auc: 1.0000 - val_f1_score: 0.9980 - val_loss: 0.0075 - val_precision: 0.9970 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 741ms/step - accuracy: 0.9895 - auc: 0.9992 - f1_score: 0.9892 - loss: 0.0283 - precision: 0.9889 - recall: 0.9918 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0033 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 721ms/step - accuracy: 0.9871 - auc: 0.9991 - f1_score: 0.9876 - loss: 0.0358 - precision: 0.9872 - recall: 0.9890 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0044 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 687ms/step - accuracy: 0.9866 - auc: 0.9990 - f1_score: 0.9867 - loss: 0.0348 - precision: 0.9888 - recall: 0.9868 - val_accuracy: 0.9995 - val_auc: 1.0000 - val_f1_score: 0.9995 - val_loss: 0.0047 - val_precision: 0.9990 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 708ms/step - accuracy: 0.9917 - auc: 0.9996 - f1_score: 0.9922 - loss: 0.0249 - precision: 0.9934 - recall: 0.9913 - val_accuracy: 0.9989 - val_auc: 1.0000 - val_f1_score: 0.9986 - val_loss: 0.0043 - val_precision: 0.9990 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 726ms/step - accuracy: 0.9902 - auc: 0.9993 - f1_score: 0.9899 - loss: 0.0301 - precision: 0.9894 - recall: 0.9925 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0047 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 683ms/step - accuracy: 0.9921 - auc: 0.9995 - f1_score: 0.9924 - loss: 0.0226 - precision: 0.9923 - recall: 0.9931 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0031 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 702ms/step - accuracy: 0.9929 - auc: 0.9996 - f1_score: 0.9931 - loss: 0.0200 - precision: 0.9926 - recall: 0.9944 - val_accuracy: 0.9995 - val_auc: 1.0000 - val_f1_score: 0.9995 - val_loss: 0.0038 - val_precision: 1.0000 - val_recall: 0.9990 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 714ms/step - accuracy: 0.9929 - auc: 0.9998 - f1_score: 0.9933 - loss: 0.0180 - precision: 0.9924 - recall: 0.9946 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0027 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 693ms/step - accuracy: 0.9902 - auc: 0.9989 - f1_score: 0.9901 - loss: 0.0314 - precision: 0.9911 - recall: 0.9907 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0031 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 697ms/step - accuracy: 0.9928 - auc: 0.9996 - f1_score: 0.9933 - loss: 0.0208 - precision: 0.9958 - recall: 0.9909 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0028 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 725ms/step - accuracy: 0.9909 - auc: 0.9993 - f1_score: 0.9909 - loss: 0.0252 - precision: 0.9909 - recall: 0.9922 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0025 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 746ms/step - accuracy: 0.9899 - auc: 0.9994 - f1_score: 0.9904 - loss: 0.0261 - precision: 0.9908 - recall: 0.9906 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0032 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 31/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 691ms/step - accuracy: 0.9861 - auc: 0.9986 - f1_score: 0.9857 - loss: 0.0358 - precision: 0.9833 - recall: 0.9906 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0040 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 32/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 705ms/step - accuracy: 0.9940 - auc: 0.9995 - f1_score: 0.9945 - loss: 0.0186 - precision: 0.9949 - recall: 0.9942 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0019 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 33/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 704ms/step - accuracy: 0.9925 - auc: 0.9990 - f1_score: 0.9919 - loss: 0.0221 - precision: 0.9903 - recall: 0.9957 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0028 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 34/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 719ms/step - accuracy: 0.9890 - auc: 0.9991 - f1_score: 0.9890 - loss: 0.0283 - precision: 0.9893 - recall: 0.9903 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0017 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 35/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 672ms/step - accuracy: 0.9955 - auc: 0.9998 - f1_score: 0.9957 - loss: 0.0164 - precision: 0.9958 - recall: 0.9959 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0019 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 36/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 715ms/step - accuracy: 0.9924 - auc: 0.9986 - f1_score: 0.9921 - loss: 0.0263 - precision: 0.9916 - recall: 0.9941 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0022 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 37/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 721ms/step - accuracy: 0.9923 - auc: 0.9997 - f1_score: 0.9932 - loss: 0.0211 - precision: 0.9948 - recall: 0.9912 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0015 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 38/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 678ms/step - accuracy: 0.9943 - auc: 0.9997 - f1_score: 0.9946 - loss: 0.0148 - precision: 0.9948 - recall: 0.9945 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0017 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 39/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 713ms/step - accuracy: 0.9931 - auc: 0.9993 - f1_score: 0.9938 - loss: 0.0212 - precision: 0.9945 - recall: 0.9929 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0017 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 40/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 719ms/step - accuracy: 0.9936 - auc: 0.9998 - f1_score: 0.9931 - loss: 0.0183 - precision: 0.9927 - recall: 0.9953 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0014 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 41/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 683ms/step - accuracy: 0.9931 - auc: 0.9996 - f1_score: 0.9926 - loss: 0.0208 - precision: 0.9931 - recall: 0.9939 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0021 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 42/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 724ms/step - accuracy: 0.9963 - auc: 0.9999 - f1_score: 0.9962 - loss: 0.0136 - precision: 0.9963 - recall: 0.9969 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0017 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 43/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 723ms/step - accuracy: 0.9944 - auc: 0.9998 - f1_score: 0.9943 - loss: 0.0141 - precision: 0.9956 - recall: 0.9941 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0023 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 44/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 666ms/step - accuracy: 0.9946 - auc: 0.9995 - f1_score: 0.9951 - loss: 0.0180 - precision: 0.9940 - recall: 0.9962 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0013 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 45/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 718ms/step - accuracy: 0.9941 - auc: 0.9998 - f1_score: 0.9943 - loss: 0.0179 - precision: 0.9956 - recall: 0.9935 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.5610e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 46/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 718ms/step - accuracy: 0.9943 - auc: 0.9997 - f1_score: 0.9942 - loss: 0.0154 - precision: 0.9932 - recall: 0.9963 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0016 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 47/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 682ms/step - accuracy: 0.9960 - auc: 0.9999 - f1_score: 0.9962 - loss: 0.0133 - precision: 0.9953 - recall: 0.9973 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0016 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 48/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 725ms/step - accuracy: 0.9934 - auc: 0.9994 - f1_score: 0.9935 - loss: 0.0204 - precision: 0.9941 - recall: 0.9937 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0010 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 49/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 738ms/step - accuracy: 0.9953 - auc: 0.9999 - f1_score: 0.9952 - loss: 0.0108 - precision: 0.9960 - recall: 0.9954 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0011 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 50/80\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553ms/step - accuracy: 0.9960 - auc: 0.9999 - f1_score: 0.9961 - loss: 0.0119 - precision: 0.9968 - recall: 0.9958\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 700ms/step - accuracy: 0.9960 - auc: 0.9999 - f1_score: 0.9961 - loss: 0.0119 - precision: 0.9968 - recall: 0.9958 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0019 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Training time: 8211.11 seconds\n",
      "Evaluating ResNet50V2 on Forest Fire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 602ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 624ms/step - accuracy: 0.7522 - auc: 0.7256 - f1_score: 0.4249 - loss: 1.1825 - precision: 0.6416 - recall: 0.7124\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.7596153616905212,\n",
      "                'auc': 0.8081552386283875,\n",
      "                'f1_score': 0.5632572770118713,\n",
      "                'loss': 1.1237133741378784,\n",
      "                'precision': 0.8081632852554321,\n",
      "                'recall': 0.788844645023346},\n",
      " 'history': {'accuracy': [0.9307065010070801,\n",
      "                          0.9627717137336731,\n",
      "                          0.9688858985900879,\n",
      "                          0.9722825884819031,\n",
      "                          0.972690224647522,\n",
      "                          0.975951075553894,\n",
      "                          0.9778532385826111,\n",
      "                          0.9758152365684509,\n",
      "                          0.981249988079071,\n",
      "                          0.982744574546814,\n",
      "                          0.9831521511077881,\n",
      "                          0.985461950302124,\n",
      "                          0.984375,\n",
      "                          0.9884510636329651,\n",
      "                          0.9870923757553101,\n",
      "                          0.9898098111152649,\n",
      "                          0.9873641133308411,\n",
      "                          0.9911684989929199,\n",
      "                          0.9887228012084961,\n",
      "                          0.989402174949646,\n",
      "                          0.988586962223053,\n",
      "                          0.99048912525177,\n",
      "                          0.9900815486907959,\n",
      "                          0.9906250238418579,\n",
      "                          0.989945650100708,\n",
      "                          0.9917119741439819,\n",
      "                          0.9906250238418579,\n",
      "                          0.992798924446106,\n",
      "                          0.9917119741439819,\n",
      "                          0.9898098111152649,\n",
      "                          0.990217387676239,\n",
      "                          0.9942934513092041,\n",
      "                          0.994157612323761,\n",
      "                          0.9911684989929199,\n",
      "                          0.993614137172699,\n",
      "                          0.993070662021637,\n",
      "                          0.994701087474823,\n",
      "                          0.9945651888847351,\n",
      "                          0.9919837117195129,\n",
      "                          0.9926630258560181,\n",
      "                          0.9929347634315491,\n",
      "                          0.9953804612159729,\n",
      "                          0.993342399597168,\n",
      "                          0.994157612323761,\n",
      "                          0.9951087236404419,\n",
      "                          0.9932065010070801,\n",
      "                          0.995788037776947,\n",
      "                          0.9929347634315491,\n",
      "                          0.9951087236404419,\n",
      "                          0.9948369860649109],\n",
      "             'auc': [0.9647053480148315,\n",
      "                     0.9921582937240601,\n",
      "                     0.9938141703605652,\n",
      "                     0.9955723881721497,\n",
      "                     0.9956545829772949,\n",
      "                     0.9964976906776428,\n",
      "                     0.9969956874847412,\n",
      "                     0.9969276189804077,\n",
      "                     0.9977572560310364,\n",
      "                     0.9981282949447632,\n",
      "                     0.9981804490089417,\n",
      "                     0.9986612796783447,\n",
      "                     0.998699963092804,\n",
      "                     0.9994202256202698,\n",
      "                     0.9989569187164307,\n",
      "                     0.999210774898529,\n",
      "                     0.9986850023269653,\n",
      "                     0.9994824528694153,\n",
      "                     0.9992142915725708,\n",
      "                     0.9988059997558594,\n",
      "                     0.9991514086723328,\n",
      "                     0.9993786811828613,\n",
      "                     0.9994176626205444,\n",
      "                     0.9994096159934998,\n",
      "                     0.9993348717689514,\n",
      "                     0.9997186660766602,\n",
      "                     0.9991050958633423,\n",
      "                     0.9996204972267151,\n",
      "                     0.9993738532066345,\n",
      "                     0.9990674257278442,\n",
      "                     0.9988515973091125,\n",
      "                     0.9994186758995056,\n",
      "                     0.9993511438369751,\n",
      "                     0.9989571571350098,\n",
      "                     0.9994411468505859,\n",
      "                     0.9990224242210388,\n",
      "                     0.9997869729995728,\n",
      "                     0.9997161626815796,\n",
      "                     0.9990028738975525,\n",
      "                     0.9997230172157288,\n",
      "                     0.9994277954101562,\n",
      "                     0.9997125267982483,\n",
      "                     0.9995750188827515,\n",
      "                     0.9994217157363892,\n",
      "                     0.999866783618927,\n",
      "                     0.9995040893554688,\n",
      "                     0.9997559785842896,\n",
      "                     0.9993628263473511,\n",
      "                     0.9997585415840149,\n",
      "                     0.9998672604560852],\n",
      "             'f1_score': [0.9347041845321655,\n",
      "                          0.9655035734176636,\n",
      "                          0.970020592212677,\n",
      "                          0.9733626246452332,\n",
      "                          0.9744235277175903,\n",
      "                          0.9773046374320984,\n",
      "                          0.9789646863937378,\n",
      "                          0.9766767621040344,\n",
      "                          0.9822817444801331,\n",
      "                          0.9835728406906128,\n",
      "                          0.9836369156837463,\n",
      "                          0.9862077236175537,\n",
      "                          0.9849616885185242,\n",
      "                          0.9889729619026184,\n",
      "                          0.9877411723136902,\n",
      "                          0.9903867244720459,\n",
      "                          0.9877789616584778,\n",
      "                          0.9914253950119019,\n",
      "                          0.9892046451568604,\n",
      "                          0.9896641373634338,\n",
      "                          0.9886000752449036,\n",
      "                          0.991087019443512,\n",
      "                          0.9901564121246338,\n",
      "                          0.9910848736763,\n",
      "                          0.9900203943252563,\n",
      "                          0.9919655323028564,\n",
      "                          0.9900059103965759,\n",
      "                          0.9929952025413513,\n",
      "                          0.9918117523193359,\n",
      "                          0.9904027581214905,\n",
      "                          0.9902466535568237,\n",
      "                          0.9946375489234924,\n",
      "                          0.9942028522491455,\n",
      "                          0.9913698434829712,\n",
      "                          0.993812084197998,\n",
      "                          0.9929901361465454,\n",
      "                          0.9950085282325745,\n",
      "                          0.9947820901870728,\n",
      "                          0.9926751255989075,\n",
      "                          0.9923276305198669,\n",
      "                          0.9929064512252808,\n",
      "                          0.995427668094635,\n",
      "                          0.9935100674629211,\n",
      "                          0.9945653080940247,\n",
      "                          0.9954149127006531,\n",
      "                          0.9928906559944153,\n",
      "                          0.9959098100662231,\n",
      "                          0.9930486083030701,\n",
      "                          0.9951391220092773,\n",
      "                          0.9948302507400513],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513],\n",
      "             'loss': [0.18495143949985504,\n",
      "                      0.10291757434606552,\n",
      "                      0.08927997201681137,\n",
      "                      0.07779732346534729,\n",
      "                      0.0758250504732132,\n",
      "                      0.06535297632217407,\n",
      "                      0.05993335694074631,\n",
      "                      0.06198135018348694,\n",
      "                      0.05218251422047615,\n",
      "                      0.04754660278558731,\n",
      "                      0.04654001444578171,\n",
      "                      0.0416821725666523,\n",
      "                      0.039386261254549026,\n",
      "                      0.0310800913721323,\n",
      "                      0.03696368634700775,\n",
      "                      0.0290585458278656,\n",
      "                      0.0363774374127388,\n",
      "                      0.027710260823369026,\n",
      "                      0.0294784102588892,\n",
      "                      0.03271901234984398,\n",
      "                      0.030833696946501732,\n",
      "                      0.02801154926419258,\n",
      "                      0.028877947479486465,\n",
      "                      0.026548458263278008,\n",
      "                      0.026070110499858856,\n",
      "                      0.020839111879467964,\n",
      "                      0.028584713116288185,\n",
      "                      0.02091684378683567,\n",
      "                      0.024222614243626595,\n",
      "                      0.029152285307645798,\n",
      "                      0.029553595930337906,\n",
      "                      0.018405143171548843,\n",
      "                      0.018972067162394524,\n",
      "                      0.025769710540771484,\n",
      "                      0.02097781002521515,\n",
      "                      0.02301497384905815,\n",
      "                      0.01691761054098606,\n",
      "                      0.015245229937136173,\n",
      "                      0.024841852486133575,\n",
      "                      0.020623544231057167,\n",
      "                      0.0214789230376482,\n",
      "                      0.014828801155090332,\n",
      "                      0.017876379191875458,\n",
      "                      0.01813204400241375,\n",
      "                      0.014010134153068066,\n",
      "                      0.019222436472773552,\n",
      "                      0.013468163087964058,\n",
      "                      0.01963297836482525,\n",
      "                      0.012412484735250473,\n",
      "                      0.014275805093348026],\n",
      "             'precision': [0.9213559031486511,\n",
      "                           0.9634692072868347,\n",
      "                           0.970924437046051,\n",
      "                           0.9727022051811218,\n",
      "                           0.9758646488189697,\n",
      "                           0.9762973785400391,\n",
      "                           0.9790576100349426,\n",
      "                           0.9764233827590942,\n",
      "                           0.9842618107795715,\n",
      "                           0.9833747148513794,\n",
      "                           0.9827413558959961,\n",
      "                           0.9864898920059204,\n",
      "                           0.9839276671409607,\n",
      "                           0.9896855354309082,\n",
      "                           0.9884913563728333,\n",
      "                           0.9907615184783936,\n",
      "                           0.9863911271095276,\n",
      "                           0.9914206266403198,\n",
      "                           0.9890655875205994,\n",
      "                           0.9899724125862122,\n",
      "                           0.9900299310684204,\n",
      "                           0.9922188520431519,\n",
      "                           0.9902864098548889,\n",
      "                           0.9909593462944031,\n",
      "                           0.9899699091911316,\n",
      "                           0.9915653467178345,\n",
      "                           0.990449845790863,\n",
      "                           0.9941757321357727,\n",
      "                           0.9919799566268921,\n",
      "                           0.9907453656196594,\n",
      "                           0.9910336136817932,\n",
      "                           0.9940387606620789,\n",
      "                           0.9947381615638733,\n",
      "                           0.9927300214767456,\n",
      "                           0.9935307502746582,\n",
      "                           0.9924356937408447,\n",
      "                           0.9959920048713684,\n",
      "                           0.9951935410499573,\n",
      "                           0.9929912686347961,\n",
      "                           0.9921538829803467,\n",
      "                           0.9934359788894653,\n",
      "                           0.9947302341461182,\n",
      "                           0.9949912428855896,\n",
      "                           0.9935048818588257,\n",
      "                           0.9962396621704102,\n",
      "                           0.9934574961662292,\n",
      "                           0.994988739490509,\n",
      "                           0.9934918880462646,\n",
      "                           0.9954830408096313,\n",
      "                           0.9959636926651001],\n",
      "             'recall': [0.9088274836540222,\n",
      "                        0.9682817459106445,\n",
      "                        0.9721323847770691,\n",
      "                        0.97612464427948,\n",
      "                        0.9741678833961487,\n",
      "                        0.9794743657112122,\n",
      "                        0.9802795648574829,\n",
      "                        0.9788785576820374,\n",
      "                        0.9813200235366821,\n",
      "                        0.9850857853889465,\n",
      "                        0.9861947894096375,\n",
      "                        0.9867367148399353,\n",
      "                        0.9871504306793213,\n",
      "                        0.9889391660690308,\n",
      "                        0.9877499938011169,\n",
      "                        0.9905142188072205,\n",
      "                        0.990134060382843,\n",
      "                        0.9921717047691345,\n",
      "                        0.9902960658073425,\n",
      "                        0.9904690384864807,\n",
      "                        0.9890438318252563,\n",
      "                        0.9902304410934448,\n",
      "                        0.9915211796760559,\n",
      "                        0.9917064309120178,\n",
      "                        0.9914615750312805,\n",
      "                        0.9932902455329895,\n",
      "                        0.9921953678131104,\n",
      "                        0.9924165606498718,\n",
      "                        0.9927263855934143,\n",
      "                        0.9904976487159729,\n",
      "                        0.9910336136817932,\n",
      "                        0.9955223798751831,\n",
      "                        0.9944889545440674,\n",
      "                        0.9909909963607788,\n",
      "                        0.9947683215141296,\n",
      "                        0.9946929216384888,\n",
      "                        0.9942485690116882,\n",
      "                        0.9946902394294739,\n",
      "                        0.992246150970459,\n",
      "                        0.9941668510437012,\n",
      "                        0.9934359788894653,\n",
      "                        0.9967312216758728,\n",
      "                        0.9927536249160767,\n",
      "                        0.9957436323165894,\n",
      "                        0.9947434067726135,\n",
      "                        0.9939576983451843,\n",
      "                        0.9972375631332397,\n",
      "                        0.9934918880462646,\n",
      "                        0.9954830408096313,\n",
      "                        0.9944584369659424],\n",
      "             'val_accuracy': [0.9797149300575256,\n",
      "                              0.9862938523292542,\n",
      "                              0.9950658082962036,\n",
      "                              0.9917762875556946,\n",
      "                              0.9923245906829834,\n",
      "                              0.9939693212509155,\n",
      "                              0.9961622953414917,\n",
      "                              0.9989035129547119,\n",
      "                              0.9961622953414917,\n",
      "                              0.9978070259094238,\n",
      "                              0.9983552694320679,\n",
      "                              0.9989035129547119,\n",
      "                              0.999451756477356,\n",
      "                              1.0,\n",
      "                              0.9989035129547119,\n",
      "                              0.999451756477356,\n",
      "                              0.9989035129547119,\n",
      "                              0.9978070259094238,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              0.999451756477356,\n",
      "                              0.9989035129547119,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              0.999451756477356,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9977450966835022,\n",
      "                         0.9990617632865906,\n",
      "                         0.9997835755348206,\n",
      "                         0.9989809989929199,\n",
      "                         0.9998109340667725,\n",
      "                         0.9998772740364075,\n",
      "                         0.9999333024024963,\n",
      "                         0.9998829960823059,\n",
      "                         0.9999462962150574,\n",
      "                         0.9999802112579346,\n",
      "                         0.9999963045120239,\n",
      "                         0.999997615814209,\n",
      "                         0.999997615814209,\n",
      "                         0.9999999403953552,\n",
      "                         0.9999818801879883,\n",
      "                         0.9999963641166687,\n",
      "                         0.9999809861183167,\n",
      "                         0.9999884963035583,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999986886978149,\n",
      "                         0.9999988079071045,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.98099684715271,\n",
      "                              0.986562967300415,\n",
      "                              0.9952812194824219,\n",
      "                              0.9919310212135315,\n",
      "                              0.9937328100204468,\n",
      "                              0.9941525459289551,\n",
      "                              0.9965612888336182,\n",
      "                              0.9989671111106873,\n",
      "                              0.9960427284240723,\n",
      "                              0.9977811574935913,\n",
      "                              0.9986165761947632,\n",
      "                              0.9989451766014099,\n",
      "                              0.9995501041412354,\n",
      "                              1.0,\n",
      "                              0.9986932873725891,\n",
      "                              0.9993950724601746,\n",
      "                              0.9990759491920471,\n",
      "                              0.998046338558197,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              0.999498724937439,\n",
      "                              0.9986329078674316,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              0.9994683265686035,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.06361635774374008,\n",
      "                          0.04009242728352547,\n",
      "                          0.026054613292217255,\n",
      "                          0.029895950108766556,\n",
      "                          0.02184460312128067,\n",
      "                          0.019763780757784843,\n",
      "                          0.016144365072250366,\n",
      "                          0.013322754763066769,\n",
      "                          0.013783954083919525,\n",
      "                          0.00981731154024601,\n",
      "                          0.009178858250379562,\n",
      "                          0.006551556754857302,\n",
      "                          0.006703950464725494,\n",
      "                          0.005150649230927229,\n",
      "                          0.008366190828382969,\n",
      "                          0.005559045821428299,\n",
      "                          0.006451996974647045,\n",
      "                          0.007513929158449173,\n",
      "                          0.0033393867779523134,\n",
      "                          0.004350061062723398,\n",
      "                          0.004677522461861372,\n",
      "                          0.004266789648681879,\n",
      "                          0.004742276854813099,\n",
      "                          0.0030789468437433243,\n",
      "                          0.0038064410910010338,\n",
      "                          0.0026686254423111677,\n",
      "                          0.0031329391058534384,\n",
      "                          0.002808230696246028,\n",
      "                          0.002490583574399352,\n",
      "                          0.0031552149448543787,\n",
      "                          0.003984102047979832,\n",
      "                          0.001937258173711598,\n",
      "                          0.002816281048581004,\n",
      "                          0.0017145774327218533,\n",
      "                          0.0018555145943537354,\n",
      "                          0.0021985406056046486,\n",
      "                          0.0015381634002551436,\n",
      "                          0.0017149270279332995,\n",
      "                          0.0016766201006248593,\n",
      "                          0.0013793958351016045,\n",
      "                          0.002065420849248767,\n",
      "                          0.001715514692477882,\n",
      "                          0.0022712259087711573,\n",
      "                          0.0012525562196969986,\n",
      "                          0.0008561041904613376,\n",
      "                          0.001576508628204465,\n",
      "                          0.0015659532509744167,\n",
      "                          0.0010263215517625213,\n",
      "                          0.001077195513062179,\n",
      "                          0.0018562981858849525],\n",
      "             'val_precision': [0.9773175716400146,\n",
      "                               0.9842932224273682,\n",
      "                               0.9959225058555603,\n",
      "                               0.9918367266654968,\n",
      "                               0.9878665208816528,\n",
      "                               0.9899294972419739,\n",
      "                               0.9939939975738525,\n",
      "                               0.9989929795265198,\n",
      "                               0.9948665499687195,\n",
      "                               0.9969072341918945,\n",
      "                               0.9990019798278809,\n",
      "                               0.9989827275276184,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               0.9989827275276184,\n",
      "                               1.0,\n",
      "                               0.998063862323761,\n",
      "                               0.9970208406448364,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               0.998971164226532,\n",
      "                               0.9989837408065796,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.9860696792602539,\n",
      "                            0.9894737005233765,\n",
      "                            0.994908332824707,\n",
      "                            0.9928498268127441,\n",
      "                            0.9979571104049683,\n",
      "                            0.9989837408065796,\n",
      "                            0.998993992805481,\n",
      "                            0.9989929795265198,\n",
      "                            0.9979402422904968,\n",
      "                            0.9989669322967529,\n",
      "                            0.9980059862136841,\n",
      "                            0.9989827275276184,\n",
      "                            0.9990167021751404,\n",
      "                            1.0,\n",
      "                            0.9989827275276184,\n",
      "                            0.9989701509475708,\n",
      "                            1.0,\n",
      "                            0.9990049600601196,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            0.9989837408065796,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            0.9989949464797974,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.6122586727142334,\n",
      " 'train_counts': {'fire': 2111, 'nofire': 2500},\n",
      " 'train_dataset_size': 7360,\n",
      " 'training_time': 8211.107058525085,\n",
      " 'val_counts': {'fire': 0, 'nofire': 0},\n",
      " 'val_dataset_size': 1824}\n",
      "Training model: ResNet50V2 on dataset: The Wildfire Dataset_DeepFire\n",
      "Epoch 1/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 683ms/step - accuracy: 0.7663 - auc: 0.8443 - f1_score: 0.7977 - loss: 0.5601 - precision: 0.8311 - recall: 0.7920 - val_accuracy: 0.9233 - val_auc: 0.9804 - val_f1_score: 0.9339 - val_loss: 0.2194 - val_precision: 0.9484 - val_recall: 0.9241 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 715ms/step - accuracy: 0.8769 - auc: 0.9466 - f1_score: 0.8996 - loss: 0.2881 - precision: 0.8912 - recall: 0.9112 - val_accuracy: 0.9631 - val_auc: 0.9954 - val_f1_score: 0.9685 - val_loss: 0.1308 - val_precision: 0.9777 - val_recall: 0.9618 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 666ms/step - accuracy: 0.8993 - auc: 0.9620 - f1_score: 0.9163 - loss: 0.2415 - precision: 0.9209 - recall: 0.9153 - val_accuracy: 0.9723 - val_auc: 0.9967 - val_f1_score: 0.9770 - val_loss: 0.1109 - val_precision: 0.9790 - val_recall: 0.9756 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 707ms/step - accuracy: 0.9158 - auc: 0.9742 - f1_score: 0.9314 - loss: 0.1997 - precision: 0.9361 - recall: 0.9280 - val_accuracy: 0.9886 - val_auc: 0.9992 - val_f1_score: 0.9907 - val_loss: 0.0749 - val_precision: 0.9942 - val_recall: 0.9873 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 697ms/step - accuracy: 0.9362 - auc: 0.9836 - f1_score: 0.9477 - loss: 0.1605 - precision: 0.9459 - recall: 0.9504 - val_accuracy: 0.9950 - val_auc: 1.0000 - val_f1_score: 0.9958 - val_loss: 0.0516 - val_precision: 0.9932 - val_recall: 0.9989 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 683ms/step - accuracy: 0.9352 - auc: 0.9856 - f1_score: 0.9465 - loss: 0.1512 - precision: 0.9418 - recall: 0.9529 - val_accuracy: 0.9979 - val_auc: 1.0000 - val_f1_score: 0.9981 - val_loss: 0.0433 - val_precision: 1.0000 - val_recall: 0.9965 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 730ms/step - accuracy: 0.9464 - auc: 0.9896 - f1_score: 0.9563 - loss: 0.1288 - precision: 0.9537 - recall: 0.9603 - val_accuracy: 0.9964 - val_auc: 1.0000 - val_f1_score: 0.9963 - val_loss: 0.0379 - val_precision: 0.9988 - val_recall: 0.9954 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 678ms/step - accuracy: 0.9548 - auc: 0.9920 - f1_score: 0.9623 - loss: 0.1140 - precision: 0.9622 - recall: 0.9638 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0305 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 724ms/step - accuracy: 0.9636 - auc: 0.9944 - f1_score: 0.9702 - loss: 0.0964 - precision: 0.9656 - recall: 0.9755 - val_accuracy: 0.9993 - val_auc: 1.0000 - val_f1_score: 0.9994 - val_loss: 0.0245 - val_precision: 0.9989 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 704ms/step - accuracy: 0.9620 - auc: 0.9947 - f1_score: 0.9685 - loss: 0.0936 - precision: 0.9694 - recall: 0.9685 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0269 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 678ms/step - accuracy: 0.9673 - auc: 0.9947 - f1_score: 0.9731 - loss: 0.0900 - precision: 0.9748 - recall: 0.9724 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0226 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 722ms/step - accuracy: 0.9695 - auc: 0.9945 - f1_score: 0.9747 - loss: 0.0881 - precision: 0.9766 - recall: 0.9739 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0178 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 660ms/step - accuracy: 0.9708 - auc: 0.9961 - f1_score: 0.9755 - loss: 0.0752 - precision: 0.9734 - recall: 0.9790 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0159 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 713ms/step - accuracy: 0.9757 - auc: 0.9973 - f1_score: 0.9798 - loss: 0.0675 - precision: 0.9823 - recall: 0.9778 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0161 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 684ms/step - accuracy: 0.9756 - auc: 0.9962 - f1_score: 0.9795 - loss: 0.0752 - precision: 0.9758 - recall: 0.9842 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0111 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 715ms/step - accuracy: 0.9705 - auc: 0.9965 - f1_score: 0.9757 - loss: 0.0733 - precision: 0.9756 - recall: 0.9764 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0122 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 686ms/step - accuracy: 0.9680 - auc: 0.9955 - f1_score: 0.9735 - loss: 0.0801 - precision: 0.9738 - recall: 0.9750 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0111 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 693ms/step - accuracy: 0.9699 - auc: 0.9961 - f1_score: 0.9749 - loss: 0.0750 - precision: 0.9738 - recall: 0.9769 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0127 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 709ms/step - accuracy: 0.9789 - auc: 0.9973 - f1_score: 0.9822 - loss: 0.0605 - precision: 0.9844 - recall: 0.9812 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0102 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 664ms/step - accuracy: 0.9779 - auc: 0.9970 - f1_score: 0.9812 - loss: 0.0639 - precision: 0.9834 - recall: 0.9803 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0115 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 728ms/step - accuracy: 0.9762 - auc: 0.9961 - f1_score: 0.9792 - loss: 0.0692 - precision: 0.9781 - recall: 0.9836 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0090 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 672ms/step - accuracy: 0.9808 - auc: 0.9982 - f1_score: 0.9835 - loss: 0.0525 - precision: 0.9816 - recall: 0.9871 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0076 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 722ms/step - accuracy: 0.9792 - auc: 0.9982 - f1_score: 0.9829 - loss: 0.0512 - precision: 0.9841 - recall: 0.9822 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0072 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 690ms/step - accuracy: 0.9773 - auc: 0.9976 - f1_score: 0.9810 - loss: 0.0547 - precision: 0.9806 - recall: 0.9824 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0083 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 708ms/step - accuracy: 0.9793 - auc: 0.9981 - f1_score: 0.9827 - loss: 0.0537 - precision: 0.9833 - recall: 0.9829 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0069 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 732ms/step - accuracy: 0.9806 - auc: 0.9982 - f1_score: 0.9838 - loss: 0.0468 - precision: 0.9841 - recall: 0.9844 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0070 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 674ms/step - accuracy: 0.9776 - auc: 0.9957 - f1_score: 0.9807 - loss: 0.0689 - precision: 0.9792 - recall: 0.9841 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0080 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 713ms/step - accuracy: 0.9798 - auc: 0.9979 - f1_score: 0.9836 - loss: 0.0568 - precision: 0.9891 - recall: 0.9784 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0066 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 661ms/step - accuracy: 0.9829 - auc: 0.9977 - f1_score: 0.9842 - loss: 0.0491 - precision: 0.9843 - recall: 0.9878 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0063 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 709ms/step - accuracy: 0.9859 - auc: 0.9987 - f1_score: 0.9884 - loss: 0.0429 - precision: 0.9885 - recall: 0.9885 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0059 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 31/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 683ms/step - accuracy: 0.9862 - auc: 0.9984 - f1_score: 0.9878 - loss: 0.0420 - precision: 0.9870 - recall: 0.9901 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0054 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 32/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 692ms/step - accuracy: 0.9777 - auc: 0.9979 - f1_score: 0.9814 - loss: 0.0568 - precision: 0.9812 - recall: 0.9825 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0055 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 33/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 696ms/step - accuracy: 0.9811 - auc: 0.9983 - f1_score: 0.9838 - loss: 0.0479 - precision: 0.9819 - recall: 0.9872 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0054 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 34/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 697ms/step - accuracy: 0.9850 - auc: 0.9984 - f1_score: 0.9881 - loss: 0.0465 - precision: 0.9883 - recall: 0.9873 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0061 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 35/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 733ms/step - accuracy: 0.9844 - auc: 0.9988 - f1_score: 0.9863 - loss: 0.0416 - precision: 0.9861 - recall: 0.9880 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0046 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 36/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 656ms/step - accuracy: 0.9855 - auc: 0.9988 - f1_score: 0.9879 - loss: 0.0387 - precision: 0.9874 - recall: 0.9886 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0045 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 37/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 711ms/step - accuracy: 0.9862 - auc: 0.9984 - f1_score: 0.9880 - loss: 0.0422 - precision: 0.9856 - recall: 0.9919 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0046 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 38/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 676ms/step - accuracy: 0.9858 - auc: 0.9987 - f1_score: 0.9878 - loss: 0.0415 - precision: 0.9886 - recall: 0.9879 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0040 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 39/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 696ms/step - accuracy: 0.9848 - auc: 0.9990 - f1_score: 0.9868 - loss: 0.0387 - precision: 0.9883 - recall: 0.9871 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0044 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 40/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 700ms/step - accuracy: 0.9859 - auc: 0.9986 - f1_score: 0.9878 - loss: 0.0412 - precision: 0.9882 - recall: 0.9891 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0032 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 41/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 680ms/step - accuracy: 0.9873 - auc: 0.9989 - f1_score: 0.9890 - loss: 0.0360 - precision: 0.9887 - recall: 0.9904 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0042 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 42/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 729ms/step - accuracy: 0.9866 - auc: 0.9988 - f1_score: 0.9889 - loss: 0.0381 - precision: 0.9891 - recall: 0.9893 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0035 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 43/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 673ms/step - accuracy: 0.9856 - auc: 0.9984 - f1_score: 0.9879 - loss: 0.0440 - precision: 0.9880 - recall: 0.9888 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 44/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 709ms/step - accuracy: 0.9852 - auc: 0.9989 - f1_score: 0.9876 - loss: 0.0384 - precision: 0.9888 - recall: 0.9874 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0038 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 45/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 693ms/step - accuracy: 0.9881 - auc: 0.9984 - f1_score: 0.9902 - loss: 0.0361 - precision: 0.9915 - recall: 0.9891 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0042 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 46/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 682ms/step - accuracy: 0.9875 - auc: 0.9992 - f1_score: 0.9891 - loss: 0.0311 - precision: 0.9879 - recall: 0.9918 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0038 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 47/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 714ms/step - accuracy: 0.9802 - auc: 0.9975 - f1_score: 0.9826 - loss: 0.0509 - precision: 0.9823 - recall: 0.9852 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0057 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 48/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549ms/step - accuracy: 0.9851 - auc: 0.9989 - f1_score: 0.9873 - loss: 0.0389 - precision: 0.9862 - recall: 0.9893\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 672ms/step - accuracy: 0.9850 - auc: 0.9989 - f1_score: 0.9873 - loss: 0.0390 - precision: 0.9862 - recall: 0.9893 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0042 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Training time: 6447.44 seconds\n",
      "Evaluating ResNet50V2 on The Wildfire Dataset_DeepFire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 563ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 641ms/step - accuracy: 0.8760 - auc: 0.8420 - f1_score: 0.4669 - loss: 0.3458 - precision: 0.7348 - recall: 0.8042\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.8846153616905212,\n",
      "                'auc': 0.948514997959137,\n",
      "                'f1_score': 0.6190789937973022,\n",
      "                'loss': 0.30841758847236633,\n",
      "                'precision': 0.8980392217636108,\n",
      "                'recall': 0.912350594997406},\n",
      " 'history': {'accuracy': [0.8183290362358093,\n",
      "                          0.8897344470024109,\n",
      "                          0.9007447957992554,\n",
      "                          0.9240608811378479,\n",
      "                          0.9347473978996277,\n",
      "                          0.9375,\n",
      "                          0.946891188621521,\n",
      "                          0.9553108811378479,\n",
      "                          0.959358811378479,\n",
      "                          0.9621114134788513,\n",
      "                          0.9672927260398865,\n",
      "                          0.9682642221450806,\n",
      "                          0.9716644883155823,\n",
      "                          0.9742552042007446,\n",
      "                          0.9739313721656799,\n",
      "                          0.9724740982055664,\n",
      "                          0.971988320350647,\n",
      "                          0.9755505323410034,\n",
      "                          0.978141188621521,\n",
      "                          0.9774935245513916,\n",
      "                          0.9768458604812622,\n",
      "                          0.981379508972168,\n",
      "                          0.9792746305465698,\n",
      "                          0.978141188621521,\n",
      "                          0.9794365167617798,\n",
      "                          0.9805699586868286,\n",
      "                          0.9789507985115051,\n",
      "                          0.981379508972168,\n",
      "                          0.984455943107605,\n",
      "                          0.9847797751426697,\n",
      "                          0.9863989353179932,\n",
      "                          0.9825129508972168,\n",
      "                          0.9838082790374756,\n",
      "                          0.9834844470024109,\n",
      "                          0.9846178889274597,\n",
      "                          0.9818652868270874,\n",
      "                          0.9829987287521362,\n",
      "                          0.9886658191680908,\n",
      "                          0.9854274392127991,\n",
      "                          0.9852655529975891,\n",
      "                          0.9868847131729126,\n",
      "                          0.9867228269577026,\n",
      "                          0.9847797751426697,\n",
      "                          0.9860751032829285,\n",
      "                          0.9886658191680908,\n",
      "                          0.9857512712478638,\n",
      "                          0.9820271730422974,\n",
      "                          0.9847797751426697],\n",
      "             'auc': [0.8830702900886536,\n",
      "                     0.953872561454773,\n",
      "                     0.9645121693611145,\n",
      "                     0.976007878780365,\n",
      "                     0.9836238026618958,\n",
      "                     0.9861404299736023,\n",
      "                     0.9890215396881104,\n",
      "                     0.9918001294136047,\n",
      "                     0.9929817914962769,\n",
      "                     0.9944275617599487,\n",
      "                     0.9947715997695923,\n",
      "                     0.9944924712181091,\n",
      "                     0.9961493611335754,\n",
      "                     0.9971150159835815,\n",
      "                     0.9957413077354431,\n",
      "                     0.9966618418693542,\n",
      "                     0.9960126280784607,\n",
      "                     0.9967362880706787,\n",
      "                     0.997053861618042,\n",
      "                     0.9972073435783386,\n",
      "                     0.9964373707771301,\n",
      "                     0.9980459213256836,\n",
      "                     0.9975823760032654,\n",
      "                     0.9974152445793152,\n",
      "                     0.997993528842926,\n",
      "                     0.997879683971405,\n",
      "                     0.9971956014633179,\n",
      "                     0.9981718063354492,\n",
      "                     0.9980274438858032,\n",
      "                     0.9986434578895569,\n",
      "                     0.998296320438385,\n",
      "                     0.9984692335128784,\n",
      "                     0.9979760050773621,\n",
      "                     0.9985126852989197,\n",
      "                     0.9988963007926941,\n",
      "                     0.9979915618896484,\n",
      "                     0.9975451231002808,\n",
      "                     0.9989400506019592,\n",
      "                     0.9991422891616821,\n",
      "                     0.9983699917793274,\n",
      "                     0.9988265037536621,\n",
      "                     0.9988007545471191,\n",
      "                     0.9978228211402893,\n",
      "                     0.9987203478813171,\n",
      "                     0.998361349105835,\n",
      "                     0.9983999729156494,\n",
      "                     0.9979811906814575,\n",
      "                     0.9987029433250427],\n",
      "             'f1_score': [0.8470090627670288,\n",
      "                          0.9093169569969177,\n",
      "                          0.9176660776138306,\n",
      "                          0.9373021721839905,\n",
      "                          0.9460577964782715,\n",
      "                          0.9480680823326111,\n",
      "                          0.9563941955566406,\n",
      "                          0.9627572298049927,\n",
      "                          0.9662546515464783,\n",
      "                          0.9688386917114258,\n",
      "                          0.9729052186012268,\n",
      "                          0.9734630584716797,\n",
      "                          0.9760299324989319,\n",
      "                          0.9784680008888245,\n",
      "                          0.9778178334236145,\n",
      "                          0.9769452214241028,\n",
      "                          0.9767405986785889,\n",
      "                          0.9795688986778259,\n",
      "                          0.9812304973602295,\n",
      "                          0.9809812903404236,\n",
      "                          0.9802795648574829,\n",
      "                          0.983966588973999,\n",
      "                          0.9828630089759827,\n",
      "                          0.9816887378692627,\n",
      "                          0.9828396439552307,\n",
      "                          0.9835941195487976,\n",
      "                          0.9818841814994812,\n",
      "                          0.9844943284988403,\n",
      "                          0.9857414364814758,\n",
      "                          0.9873003363609314,\n",
      "                          0.9882330894470215,\n",
      "                          0.9851563572883606,\n",
      "                          0.9865971803665161,\n",
      "                          0.9864286780357361,\n",
      "                          0.9869760870933533,\n",
      "                          0.9848986268043518,\n",
      "                          0.985213577747345,\n",
      "                          0.9904835820198059,\n",
      "                          0.9876013994216919,\n",
      "                          0.9875216484069824,\n",
      "                          0.9887781739234924,\n",
      "                          0.9888889193534851,\n",
      "                          0.9866548180580139,\n",
      "                          0.9884089231491089,\n",
      "                          0.9904999136924744,\n",
      "                          0.987779974937439,\n",
      "                          0.9847750663757324,\n",
      "                          0.987268328666687],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513],\n",
      "             'loss': [0.44225627183914185,\n",
      "                      0.2670528292655945,\n",
      "                      0.23426932096481323,\n",
      "                      0.1911790668964386,\n",
      "                      0.16072450578212738,\n",
      "                      0.1470527946949005,\n",
      "                      0.13000710308551788,\n",
      "                      0.1133175790309906,\n",
      "                      0.10517285764217377,\n",
      "                      0.09454783797264099,\n",
      "                      0.08810732513666153,\n",
      "                      0.0882255882024765,\n",
      "                      0.07443531602621078,\n",
      "                      0.06845898926258087,\n",
      "                      0.07747528702020645,\n",
      "                      0.07009046524763107,\n",
      "                      0.07560892403125763,\n",
      "                      0.06523329019546509,\n",
      "                      0.06299308687448502,\n",
      "                      0.062404975295066833,\n",
      "                      0.06714491546154022,\n",
      "                      0.05208105966448784,\n",
      "                      0.05563173070549965,\n",
      "                      0.05580507963895798,\n",
      "                      0.05392523109912872,\n",
      "                      0.05194159597158432,\n",
      "                      0.059241630136966705,\n",
      "                      0.050669245421886444,\n",
      "                      0.045445386320352554,\n",
      "                      0.043741848319768906,\n",
      "                      0.04219982028007507,\n",
      "                      0.047528982162475586,\n",
      "                      0.04509444907307625,\n",
      "                      0.04562279209494591,\n",
      "                      0.03963514789938927,\n",
      "                      0.04739735275506973,\n",
      "                      0.0494341142475605,\n",
      "                      0.035364001989364624,\n",
      "                      0.036998189985752106,\n",
      "                      0.0421147383749485,\n",
      "                      0.036917999386787415,\n",
      "                      0.03675742819905281,\n",
      "                      0.046375274658203125,\n",
      "                      0.03847406432032585,\n",
      "                      0.035860974341630936,\n",
      "                      0.03713807836174965,\n",
      "                      0.04557105898857117,\n",
      "                      0.040534961968660355],\n",
      "             'precision': [0.8573486804962158,\n",
      "                           0.9036113023757935,\n",
      "                           0.9175882339477539,\n",
      "                           0.9371383190155029,\n",
      "                           0.9444736838340759,\n",
      "                           0.9450405836105347,\n",
      "                           0.953902542591095,\n",
      "                           0.9637662172317505,\n",
      "                           0.9612463712692261,\n",
      "                           0.9693931341171265,\n",
      "                           0.9721784591674805,\n",
      "                           0.9729729890823364,\n",
      "                           0.9755456447601318,\n",
      "                           0.9796134233474731,\n",
      "                           0.9754422903060913,\n",
      "                           0.9765728116035461,\n",
      "                           0.9770811200141907,\n",
      "                           0.9801324605941772,\n",
      "                           0.9815400838851929,\n",
      "                           0.9835281372070312,\n",
      "                           0.9805365800857544,\n",
      "                           0.9831755757331848,\n",
      "                           0.9834035634994507,\n",
      "                           0.9812516570091248,\n",
      "                           0.9838752150535583,\n",
      "                           0.9836152195930481,\n",
      "                           0.9804232716560364,\n",
      "                           0.9863265752792358,\n",
      "                           0.9867934584617615,\n",
      "                           0.9873350858688354,\n",
      "                           0.9885972142219543,\n",
      "                           0.9849445223808289,\n",
      "                           0.9881141185760498,\n",
      "                           0.986250638961792,\n",
      "                           0.9875463843345642,\n",
      "                           0.9857407212257385,\n",
      "                           0.9840062856674194,\n",
      "                           0.9913089275360107,\n",
      "                           0.9876217842102051,\n",
      "                           0.9873450994491577,\n",
      "                           0.9886423945426941,\n",
      "                           0.9883874654769897,\n",
      "                           0.9863049983978271,\n",
      "                           0.9886901378631592,\n",
      "                           0.9904988408088684,\n",
      "                           0.9878467917442322,\n",
      "                           0.9860489368438721,\n",
      "                           0.9868282675743103],\n",
      "             'recall': [0.8306189179420471,\n",
      "                        0.9181626439094543,\n",
      "                        0.9207397699356079,\n",
      "                        0.9393619894981384,\n",
      "                        0.9492197632789612,\n",
      "                        0.9535252451896667,\n",
      "                        0.9599367380142212,\n",
      "                        0.9632566571235657,\n",
      "                        0.972707986831665,\n",
      "                        0.9688818454742432,\n",
      "                        0.9747368693351746,\n",
      "                        0.9755327701568604,\n",
      "                        0.9783755540847778,\n",
      "                        0.9783183336257935,\n",
      "                        0.9819245338439941,\n",
      "                        0.9786335825920105,\n",
      "                        0.9773386120796204,\n",
      "                        0.9798728823661804,\n",
      "                        0.9828360080718994,\n",
      "                        0.9796242117881775,\n",
      "                        0.9818277359008789,\n",
      "                        0.9865471124649048,\n",
      "                        0.9828857183456421,\n",
      "                        0.9830687642097473,\n",
      "                        0.9825765490531921,\n",
      "                        0.9846560955047607,\n",
      "                        0.9851142764091492,\n",
      "                        0.9834818840026855,\n",
      "                        0.9878371357917786,\n",
      "                        0.987856388092041,\n",
      "                        0.9891217947006226,\n",
      "                        0.9865079522132874,\n",
      "                        0.985511064529419,\n",
      "                        0.9867724776268005,\n",
      "                        0.987284779548645,\n",
      "                        0.984700620174408,\n",
      "                        0.9884119033813477,\n",
      "                        0.9902657270431519,\n",
      "                        0.9886633157730103,\n",
      "                        0.9886483550071716,\n",
      "                        0.9899497628211975,\n",
      "                        0.9899550676345825,\n",
      "                        0.9889094233512878,\n",
      "                        0.9886901378631592,\n",
      "                        0.9910219311714172,\n",
      "                        0.9888918399810791,\n",
      "                        0.984752893447876,\n",
      "                        0.9883905053138733],\n",
      "             'val_accuracy': [0.9232954382896423,\n",
      "                              0.9630681872367859,\n",
      "                              0.9723011255264282,\n",
      "                              0.9886363744735718,\n",
      "                              0.9950284361839294,\n",
      "                              0.9978693127632141,\n",
      "                              0.9964488744735718,\n",
      "                              1.0,\n",
      "                              0.9992897510528564,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9804375171661377,\n",
      "                         0.9954129457473755,\n",
      "                         0.9966813325881958,\n",
      "                         0.9992399215698242,\n",
      "                         0.9999678134918213,\n",
      "                         0.9999651312828064,\n",
      "                         0.9999871850013733,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999998807907104,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999998807907104,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.9339141845703125,\n",
      "                              0.9685302376747131,\n",
      "                              0.976970911026001,\n",
      "                              0.9907001256942749,\n",
      "                              0.9958276152610779,\n",
      "                              0.9981240630149841,\n",
      "                              0.9962847232818604,\n",
      "                              1.0,\n",
      "                              0.999417245388031,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.21935462951660156,\n",
      "                          0.13082893192768097,\n",
      "                          0.11089976131916046,\n",
      "                          0.07490332424640656,\n",
      "                          0.05157282575964928,\n",
      "                          0.04333562031388283,\n",
      "                          0.037932489067316055,\n",
      "                          0.030452381819486618,\n",
      "                          0.02452842704951763,\n",
      "                          0.026890097185969353,\n",
      "                          0.02256960980594158,\n",
      "                          0.017782477661967278,\n",
      "                          0.015891626477241516,\n",
      "                          0.01609891653060913,\n",
      "                          0.011101791635155678,\n",
      "                          0.012201440520584583,\n",
      "                          0.011066013015806675,\n",
      "                          0.012696048244833946,\n",
      "                          0.010158976539969444,\n",
      "                          0.0114580187946558,\n",
      "                          0.008978765457868576,\n",
      "                          0.007639144081622362,\n",
      "                          0.007231692783534527,\n",
      "                          0.008325225673615932,\n",
      "                          0.0068582575768232346,\n",
      "                          0.007046450860798359,\n",
      "                          0.008042337372899055,\n",
      "                          0.006552903447300196,\n",
      "                          0.006277875974774361,\n",
      "                          0.0059271338395774364,\n",
      "                          0.005403174087405205,\n",
      "                          0.005543696228414774,\n",
      "                          0.0054123736917972565,\n",
      "                          0.0060684336349368095,\n",
      "                          0.004614648409187794,\n",
      "                          0.004524024669080973,\n",
      "                          0.004620363004505634,\n",
      "                          0.003965419251471758,\n",
      "                          0.004389702342450619,\n",
      "                          0.003240360412746668,\n",
      "                          0.004204296972602606,\n",
      "                          0.003498817328363657,\n",
      "                          0.002905144589021802,\n",
      "                          0.003766718553379178,\n",
      "                          0.00417831027880311,\n",
      "                          0.003821099642664194,\n",
      "                          0.005705314688384533,\n",
      "                          0.004197176080197096],\n",
      "             'val_precision': [0.9484412670135498,\n",
      "                               0.977673351764679,\n",
      "                               0.9789965152740479,\n",
      "                               0.9941657185554504,\n",
      "                               0.9931818246841431,\n",
      "                               1.0,\n",
      "                               0.9988479018211365,\n",
      "                               1.0,\n",
      "                               0.9988505840301514,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.9240654110908508,\n",
      "                            0.9618496894836426,\n",
      "                            0.9755814075469971,\n",
      "                            0.9872537851333618,\n",
      "                            0.9988571405410767,\n",
      "                            0.9964747428894043,\n",
      "                            0.9954075813293457,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.8991925716400146,\n",
      " 'train_counts': {'fire': 1490, 'nofire': 1917},\n",
      " 'train_dataset_size': 6176,\n",
      " 'training_time': 6447.437012434006,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_dataset_size': 1408}\n",
      "Training model: ResNet50V2 on dataset: The Wildfire Dataset_FIRE\n",
      "Epoch 1/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 710ms/step - accuracy: 0.7597 - auc: 0.8890 - f1_score: 0.7896 - loss: 0.5983 - precision: 0.8567 - recall: 0.8228 - val_accuracy: 0.9265 - val_auc: 0.9830 - val_f1_score: 0.9391 - val_loss: 0.2139 - val_precision: 0.9515 - val_recall: 0.9295 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 679ms/step - accuracy: 0.8772 - auc: 0.9505 - f1_score: 0.8981 - loss: 0.2826 - precision: 0.8990 - recall: 0.8989 - val_accuracy: 0.9561 - val_auc: 0.9927 - val_f1_score: 0.9629 - val_loss: 0.1497 - val_precision: 0.9482 - val_recall: 0.9803 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 726ms/step - accuracy: 0.8964 - auc: 0.9606 - f1_score: 0.9147 - loss: 0.2459 - precision: 0.9097 - recall: 0.9228 - val_accuracy: 0.9747 - val_auc: 0.9979 - val_f1_score: 0.9795 - val_loss: 0.1044 - val_precision: 0.9690 - val_recall: 0.9904 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 658ms/step - accuracy: 0.9107 - auc: 0.9683 - f1_score: 0.9260 - loss: 0.2204 - precision: 0.9262 - recall: 0.9287 - val_accuracy: 0.9873 - val_auc: 0.9989 - val_f1_score: 0.9891 - val_loss: 0.0880 - val_precision: 0.9847 - val_recall: 0.9944 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 719ms/step - accuracy: 0.9199 - auc: 0.9736 - f1_score: 0.9346 - loss: 0.2016 - precision: 0.9327 - recall: 0.9395 - val_accuracy: 0.9924 - val_auc: 0.9997 - val_f1_score: 0.9937 - val_loss: 0.0661 - val_precision: 0.9932 - val_recall: 0.9945 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 666ms/step - accuracy: 0.9387 - auc: 0.9869 - f1_score: 0.9491 - loss: 0.1466 - precision: 0.9495 - recall: 0.9498 - val_accuracy: 0.9890 - val_auc: 0.9996 - val_f1_score: 0.9914 - val_loss: 0.0603 - val_precision: 0.9903 - val_recall: 0.9917 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 737ms/step - accuracy: 0.9441 - auc: 0.9867 - f1_score: 0.9537 - loss: 0.1439 - precision: 0.9469 - recall: 0.9626 - val_accuracy: 0.9949 - val_auc: 0.9999 - val_f1_score: 0.9959 - val_loss: 0.0451 - val_precision: 0.9959 - val_recall: 0.9959 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 657ms/step - accuracy: 0.9439 - auc: 0.9870 - f1_score: 0.9533 - loss: 0.1417 - precision: 0.9530 - recall: 0.9557 - val_accuracy: 0.9975 - val_auc: 1.0000 - val_f1_score: 0.9981 - val_loss: 0.0393 - val_precision: 1.0000 - val_recall: 0.9960 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 727ms/step - accuracy: 0.9638 - auc: 0.9918 - f1_score: 0.9696 - loss: 0.1083 - precision: 0.9668 - recall: 0.9733 - val_accuracy: 0.9975 - val_auc: 1.0000 - val_f1_score: 0.9978 - val_loss: 0.0353 - val_precision: 1.0000 - val_recall: 0.9959 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 670ms/step - accuracy: 0.9580 - auc: 0.9923 - f1_score: 0.9655 - loss: 0.1099 - precision: 0.9645 - recall: 0.9676 - val_accuracy: 0.9983 - val_auc: 1.0000 - val_f1_score: 0.9985 - val_loss: 0.0348 - val_precision: 1.0000 - val_recall: 0.9973 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 750ms/step - accuracy: 0.9667 - auc: 0.9943 - f1_score: 0.9724 - loss: 0.0954 - precision: 0.9764 - recall: 0.9695 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0258 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 675ms/step - accuracy: 0.9596 - auc: 0.9926 - f1_score: 0.9657 - loss: 0.1027 - precision: 0.9598 - recall: 0.9739 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0217 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 739ms/step - accuracy: 0.9666 - auc: 0.9954 - f1_score: 0.9721 - loss: 0.0871 - precision: 0.9713 - recall: 0.9741 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0238 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 663ms/step - accuracy: 0.9646 - auc: 0.9952 - f1_score: 0.9702 - loss: 0.0885 - precision: 0.9676 - recall: 0.9751 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0255 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 727ms/step - accuracy: 0.9714 - auc: 0.9954 - f1_score: 0.9762 - loss: 0.0796 - precision: 0.9767 - recall: 0.9770 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0165 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 659ms/step - accuracy: 0.9706 - auc: 0.9960 - f1_score: 0.9760 - loss: 0.0759 - precision: 0.9761 - recall: 0.9761 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0148 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 729ms/step - accuracy: 0.9645 - auc: 0.9948 - f1_score: 0.9702 - loss: 0.0906 - precision: 0.9675 - recall: 0.9738 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0157 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 661ms/step - accuracy: 0.9763 - auc: 0.9970 - f1_score: 0.9803 - loss: 0.0652 - precision: 0.9836 - recall: 0.9777 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0127 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 711ms/step - accuracy: 0.9755 - auc: 0.9975 - f1_score: 0.9788 - loss: 0.0652 - precision: 0.9763 - recall: 0.9830 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0103 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 676ms/step - accuracy: 0.9792 - auc: 0.9976 - f1_score: 0.9823 - loss: 0.0593 - precision: 0.9829 - recall: 0.9831 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0102 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 696ms/step - accuracy: 0.9765 - auc: 0.9962 - f1_score: 0.9806 - loss: 0.0684 - precision: 0.9798 - recall: 0.9823 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0106 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 706ms/step - accuracy: 0.9751 - auc: 0.9968 - f1_score: 0.9786 - loss: 0.0683 - precision: 0.9768 - recall: 0.9828 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0084 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 688ms/step - accuracy: 0.9769 - auc: 0.9972 - f1_score: 0.9802 - loss: 0.0636 - precision: 0.9814 - recall: 0.9802 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0103 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 717ms/step - accuracy: 0.9725 - auc: 0.9972 - f1_score: 0.9765 - loss: 0.0654 - precision: 0.9774 - recall: 0.9774 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0133 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 670ms/step - accuracy: 0.9691 - auc: 0.9941 - f1_score: 0.9740 - loss: 0.0825 - precision: 0.9712 - recall: 0.9787 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0106 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 743ms/step - accuracy: 0.9817 - auc: 0.9975 - f1_score: 0.9849 - loss: 0.0552 - precision: 0.9846 - recall: 0.9860 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0099 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 647ms/step - accuracy: 0.9769 - auc: 0.9958 - f1_score: 0.9801 - loss: 0.0647 - precision: 0.9785 - recall: 0.9833 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0073 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 728ms/step - accuracy: 0.9823 - auc: 0.9973 - f1_score: 0.9848 - loss: 0.0525 - precision: 0.9843 - recall: 0.9866 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0082 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 670ms/step - accuracy: 0.9833 - auc: 0.9982 - f1_score: 0.9857 - loss: 0.0482 - precision: 0.9866 - recall: 0.9861 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0074 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 715ms/step - accuracy: 0.9818 - auc: 0.9985 - f1_score: 0.9853 - loss: 0.0478 - precision: 0.9889 - recall: 0.9814 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0060 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 31/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 681ms/step - accuracy: 0.9836 - auc: 0.9989 - f1_score: 0.9864 - loss: 0.0422 - precision: 0.9861 - recall: 0.9870 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0068 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 32/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 728ms/step - accuracy: 0.9855 - auc: 0.9986 - f1_score: 0.9876 - loss: 0.0429 - precision: 0.9868 - recall: 0.9895 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0057 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 33/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 676ms/step - accuracy: 0.9838 - auc: 0.9988 - f1_score: 0.9860 - loss: 0.0420 - precision: 0.9845 - recall: 0.9884 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0054 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 34/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 708ms/step - accuracy: 0.9819 - auc: 0.9977 - f1_score: 0.9850 - loss: 0.0496 - precision: 0.9855 - recall: 0.9850 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0040 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 35/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 669ms/step - accuracy: 0.9854 - auc: 0.9980 - f1_score: 0.9878 - loss: 0.0472 - precision: 0.9903 - recall: 0.9857 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0038 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 36/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 715ms/step - accuracy: 0.9855 - auc: 0.9987 - f1_score: 0.9880 - loss: 0.0409 - precision: 0.9872 - recall: 0.9893 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0041 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 37/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 668ms/step - accuracy: 0.9801 - auc: 0.9985 - f1_score: 0.9835 - loss: 0.0488 - precision: 0.9873 - recall: 0.9804 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0039 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 38/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 713ms/step - accuracy: 0.9880 - auc: 0.9982 - f1_score: 0.9898 - loss: 0.0397 - precision: 0.9905 - recall: 0.9898 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0035 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 39/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 668ms/step - accuracy: 0.9867 - auc: 0.9980 - f1_score: 0.9885 - loss: 0.0387 - precision: 0.9916 - recall: 0.9869 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0037 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 40/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 711ms/step - accuracy: 0.9867 - auc: 0.9988 - f1_score: 0.9891 - loss: 0.0408 - precision: 0.9896 - recall: 0.9888 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0035 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 41/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 691ms/step - accuracy: 0.9829 - auc: 0.9984 - f1_score: 0.9858 - loss: 0.0435 - precision: 0.9882 - recall: 0.9842 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0046 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 42/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 725ms/step - accuracy: 0.9851 - auc: 0.9987 - f1_score: 0.9875 - loss: 0.0431 - precision: 0.9874 - recall: 0.9883 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0047 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 43/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 564ms/step - accuracy: 0.9849 - auc: 0.9986 - f1_score: 0.9878 - loss: 0.0421 - precision: 0.9903 - recall: 0.9854\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 684ms/step - accuracy: 0.9849 - auc: 0.9986 - f1_score: 0.9878 - loss: 0.0420 - precision: 0.9903 - recall: 0.9854 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0037 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Training time: 5001.18 seconds\n",
      "Evaluating ResNet50V2 on The Wildfire Dataset_FIRE...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 540ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 541ms/step - accuracy: 0.8841 - auc: 0.8414 - f1_score: 0.4656 - loss: 0.3736 - precision: 0.7458 - recall: 0.8022\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.8870192170143127,\n",
      "                'auc': 0.9474828243255615,\n",
      "                'f1_score': 0.6164953708648682,\n",
      "                'loss': 0.34649214148521423,\n",
      "                'precision': 0.9079999923706055,\n",
      "                'recall': 0.9043824672698975},\n",
      " 'history': {'accuracy': [0.81268709897995,\n",
      "                          0.8817365169525146,\n",
      "                          0.9041916131973267,\n",
      "                          0.9129865169525146,\n",
      "                          0.9229041934013367,\n",
      "                          0.933570384979248,\n",
      "                          0.942552387714386,\n",
      "                          0.9444236755371094,\n",
      "                          0.9580838084220886,\n",
      "                          0.95639967918396,\n",
      "                          0.965194582939148,\n",
      "                          0.9584580659866333,\n",
      "                          0.9659430980682373,\n",
      "                          0.9672529697418213,\n",
      "                          0.9693113565444946,\n",
      "                          0.96893709897995,\n",
      "                          0.9683757424354553,\n",
      "                          0.9739895462989807,\n",
      "                          0.9756736755371094,\n",
      "                          0.9771706461906433,\n",
      "                          0.9767963886260986,\n",
      "                          0.9779191613197327,\n",
      "                          0.9784805178642273,\n",
      "                          0.9743637442588806,\n",
      "                          0.9730538725852966,\n",
      "                          0.9807260632514954,\n",
      "                          0.9809131622314453,\n",
      "                          0.9803518056869507,\n",
      "                          0.982410192489624,\n",
      "                          0.983720064163208,\n",
      "                          0.9803518056869507,\n",
      "                          0.9844685792922974,\n",
      "                          0.9844685792922974,\n",
      "                          0.9852170944213867,\n",
      "                          0.9831587076187134,\n",
      "                          0.9855912923812866,\n",
      "                          0.982597291469574,\n",
      "                          0.988585352897644,\n",
      "                          0.986339807510376,\n",
      "                          0.9840943217277527,\n",
      "                          0.9796032905578613,\n",
      "                          0.9857784509658813,\n",
      "                          0.9852170944213867],\n",
      "             'auc': [0.8998134732246399,\n",
      "                     0.9516550302505493,\n",
      "                     0.9651572704315186,\n",
      "                     0.9727326035499573,\n",
      "                     0.9752082824707031,\n",
      "                     0.9850559234619141,\n",
      "                     0.9865030646324158,\n",
      "                     0.9871677160263062,\n",
      "                     0.9904049038887024,\n",
      "                     0.9907228946685791,\n",
      "                     0.9938048124313354,\n",
      "                     0.9918337464332581,\n",
      "                     0.9949397444725037,\n",
      "                     0.9955194592475891,\n",
      "                     0.9951654672622681,\n",
      "                     0.9956351518630981,\n",
      "                     0.9956784844398499,\n",
      "                     0.9966869950294495,\n",
      "                     0.9973772168159485,\n",
      "                     0.9973001480102539,\n",
      "                     0.9969109296798706,\n",
      "                     0.9968782663345337,\n",
      "                     0.9973329901695251,\n",
      "                     0.997092068195343,\n",
      "                     0.9958012700080872,\n",
      "                     0.997734546661377,\n",
      "                     0.9971641302108765,\n",
      "                     0.9975477457046509,\n",
      "                     0.9981849789619446,\n",
      "                     0.9986173510551453,\n",
      "                     0.9985824823379517,\n",
      "                     0.9984232187271118,\n",
      "                     0.9984397888183594,\n",
      "                     0.9985889792442322,\n",
      "                     0.9979836344718933,\n",
      "                     0.9987379312515259,\n",
      "                     0.9985464811325073,\n",
      "                     0.9984323382377625,\n",
      "                     0.9975181221961975,\n",
      "                     0.9987224340438843,\n",
      "                     0.9975554943084717,\n",
      "                     0.9990120530128479,\n",
      "                     0.9988531470298767],\n",
      "             'f1_score': [0.8418382406234741,\n",
      "                          0.903032660484314,\n",
      "                          0.9204970598220825,\n",
      "                          0.9282814264297485,\n",
      "                          0.9367551803588867,\n",
      "                          0.9449025988578796,\n",
      "                          0.9523466229438782,\n",
      "                          0.9536722898483276,\n",
      "                          0.9646064639091492,\n",
      "                          0.9632174372673035,\n",
      "                          0.9710094928741455,\n",
      "                          0.96522057056427,\n",
      "                          0.9717991352081299,\n",
      "                          0.9728160500526428,\n",
      "                          0.9744181632995605,\n",
      "                          0.9742056131362915,\n",
      "                          0.9740408658981323,\n",
      "                          0.9781996011734009,\n",
      "                          0.9794546961784363,\n",
      "                          0.9808221459388733,\n",
      "                          0.9811267256736755,\n",
      "                          0.9807890057563782,\n",
      "                          0.9815306663513184,\n",
      "                          0.9780867099761963,\n",
      "                          0.9769887328147888,\n",
      "                          0.9837612509727478,\n",
      "                          0.9839428067207336,\n",
      "                          0.9835078120231628,\n",
      "                          0.984946072101593,\n",
      "                          0.98649662733078,\n",
      "                          0.9837907552719116,\n",
      "                          0.9867798686027527,\n",
      "                          0.9867419600486755,\n",
      "                          0.9875498414039612,\n",
      "                          0.9859641194343567,\n",
      "                          0.9878860116004944,\n",
      "                          0.9852824211120605,\n",
      "                          0.990196168422699,\n",
      "                          0.9881811141967773,\n",
      "                          0.986506462097168,\n",
      "                          0.983031153678894,\n",
      "                          0.9880415201187134,\n",
      "                          0.9874982237815857],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513],\n",
      "             'loss': [0.46285951137542725,\n",
      "                      0.27465376257896423,\n",
      "                      0.2313738614320755,\n",
      "                      0.2044549137353897,\n",
      "                      0.19513005018234253,\n",
      "                      0.15428730845451355,\n",
      "                      0.14397086203098297,\n",
      "                      0.140729621052742,\n",
      "                      0.11856366693973541,\n",
      "                      0.11716622114181519,\n",
      "                      0.09696587920188904,\n",
      "                      0.10743599385023117,\n",
      "                      0.08943790197372437,\n",
      "                      0.0845227986574173,\n",
      "                      0.08346143364906311,\n",
      "                      0.08075252175331116,\n",
      "                      0.08077739924192429,\n",
      "                      0.06887727975845337,\n",
      "                      0.06412260234355927,\n",
      "                      0.062161121517419815,\n",
      "                      0.06251294910907745,\n",
      "                      0.06347163021564484,\n",
      "                      0.06023232638835907,\n",
      "                      0.06296857446432114,\n",
      "                      0.0715804174542427,\n",
      "                      0.05429105833172798,\n",
      "                      0.056648895144462585,\n",
      "                      0.05352924391627312,\n",
      "                      0.04935154318809509,\n",
      "                      0.04474307969212532,\n",
      "                      0.04739202558994293,\n",
      "                      0.045667827129364014,\n",
      "                      0.04254472628235817,\n",
      "                      0.04062740132212639,\n",
      "                      0.044767070561647415,\n",
      "                      0.041441358625888824,\n",
      "                      0.04487272724509239,\n",
      "                      0.037138063460588455,\n",
      "                      0.042385801672935486,\n",
      "                      0.04363388940691948,\n",
      "                      0.05309178680181503,\n",
      "                      0.03840833529829979,\n",
      "                      0.0385562963783741],\n",
      "             'precision': [0.8653005361557007,\n",
      "                           0.9026764035224915,\n",
      "                           0.9183549880981445,\n",
      "                           0.927875816822052,\n",
      "                           0.9329323172569275,\n",
      "                           0.9433444738388062,\n",
      "                           0.949455201625824,\n",
      "                           0.9521487355232239,\n",
      "                           0.961514949798584,\n",
      "                           0.9598051309585571,\n",
      "                           0.97512286901474,\n",
      "                           0.9632554054260254,\n",
      "                           0.9737244248390198,\n",
      "                           0.9717497229576111,\n",
      "                           0.9759878516197205,\n",
      "                           0.9748179316520691,\n",
      "                           0.9738044738769531,\n",
      "                           0.9781950116157532,\n",
      "                           0.9802955389022827,\n",
      "                           0.9820012450218201,\n",
      "                           0.9811492562294006,\n",
      "                           0.9805293679237366,\n",
      "                           0.983312726020813,\n",
      "                           0.9791794419288635,\n",
      "                           0.9762701392173767,\n",
      "                           0.9821752309799194,\n",
      "                           0.982827365398407,\n",
      "                           0.984375,\n",
      "                           0.9843606352806091,\n",
      "                           0.9874425530433655,\n",
      "                           0.9849785566329956,\n",
      "                           0.9853970408439636,\n",
      "                           0.985683798789978,\n",
      "                           0.9862343072891235,\n",
      "                           0.9862971901893616,\n",
      "                           0.9868541955947876,\n",
      "                           0.9868219494819641,\n",
      "                           0.9892703890800476,\n",
      "                           0.9893519878387451,\n",
      "                           0.9871402382850647,\n",
      "                           0.9841124415397644,\n",
      "                           0.9881386756896973,\n",
      "                           0.9881423115730286],\n",
      "             'recall': [0.8398302793502808,\n",
      "                        0.9048780202865601,\n",
      "                        0.9261969923973083,\n",
      "                        0.930424153804779,\n",
      "                        0.9425706267356873,\n",
      "                        0.9482547640800476,\n",
      "                        0.9572780132293701,\n",
      "                        0.9571078419685364,\n",
      "                        0.9698089957237244,\n",
      "                        0.9689517617225647,\n",
      "                        0.9679877758026123,\n",
      "                        0.9691414833068848,\n",
      "                        0.9707584381103516,\n",
      "                        0.9750075936317444,\n",
      "                        0.9742111563682556,\n",
      "                        0.9748179316520691,\n",
      "                        0.9746951460838318,\n",
      "                        0.9796785116195679,\n",
      "                        0.979692280292511,\n",
      "                        0.9808043837547302,\n",
      "                        0.9811492562294006,\n",
      "                        0.9835215210914612,\n",
      "                        0.9811902642250061,\n",
      "                        0.9788796901702881,\n",
      "                        0.9798473119735718,\n",
      "                        0.9866464138031006,\n",
      "                        0.9858505129814148,\n",
      "                        0.9834710955619812,\n",
      "                        0.9867814183235168,\n",
      "                        0.9859327077865601,\n",
      "                        0.9828693866729736,\n",
      "                        0.9893097281455994,\n",
      "                        0.9889975786209106,\n",
      "                        0.9895641207695007,\n",
      "                        0.9862971901893616,\n",
      "                        0.9895769357681274,\n",
      "                        0.9847095012664795,\n",
      "                        0.9920073747634888,\n",
      "                        0.9884498715400696,\n",
      "                        0.9868381023406982,\n",
      "                        0.982611358165741,\n",
      "                        0.988740086555481,\n",
      "                        0.9878419637680054],\n",
      "             'val_accuracy': [0.9265202879905701,\n",
      "                              0.9560810923576355,\n",
      "                              0.974662184715271,\n",
      "                              0.9873310923576355,\n",
      "                              0.9923986196517944,\n",
      "                              0.9890202879905701,\n",
      "                              0.9949324131011963,\n",
      "                              0.9974662065505981,\n",
      "                              0.9974662065505981,\n",
      "                              0.9983108043670654,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9830425977706909,\n",
      "                         0.9927006959915161,\n",
      "                         0.9978750944137573,\n",
      "                         0.9988721609115601,\n",
      "                         0.9997314810752869,\n",
      "                         0.9995707273483276,\n",
      "                         0.9999363422393799,\n",
      "                         1.0,\n",
      "                         0.9999970197677612,\n",
      "                         0.9999939203262329,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.9391185641288757,\n",
      "                              0.9628591537475586,\n",
      "                              0.9794628024101257,\n",
      "                              0.989066481590271,\n",
      "                              0.9937324523925781,\n",
      "                              0.9914241433143616,\n",
      "                              0.9958937168121338,\n",
      "                              0.9980521202087402,\n",
      "                              0.9978044033050537,\n",
      "                              0.9984995722770691,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.21391062438488007,\n",
      "                          0.14969657361507416,\n",
      "                          0.1044415682554245,\n",
      "                          0.08799796551465988,\n",
      "                          0.0660904198884964,\n",
      "                          0.06025315448641777,\n",
      "                          0.04514799267053604,\n",
      "                          0.039340801537036896,\n",
      "                          0.03534916788339615,\n",
      "                          0.03477902337908745,\n",
      "                          0.025801073759794235,\n",
      "                          0.02168053574860096,\n",
      "                          0.02382342889904976,\n",
      "                          0.025532573461532593,\n",
      "                          0.016479872167110443,\n",
      "                          0.014792208559811115,\n",
      "                          0.015677273273468018,\n",
      "                          0.012667899951338768,\n",
      "                          0.010257799178361893,\n",
      "                          0.010189712047576904,\n",
      "                          0.010587677359580994,\n",
      "                          0.008353443816304207,\n",
      "                          0.010328237898647785,\n",
      "                          0.013346021994948387,\n",
      "                          0.01064810436218977,\n",
      "                          0.009862580336630344,\n",
      "                          0.0073360251262784,\n",
      "                          0.00817918125540018,\n",
      "                          0.007425524760037661,\n",
      "                          0.0059614600613713264,\n",
      "                          0.006751192267984152,\n",
      "                          0.005677197128534317,\n",
      "                          0.005380305461585522,\n",
      "                          0.004048752598464489,\n",
      "                          0.0038493878673762083,\n",
      "                          0.0040894560515880585,\n",
      "                          0.0038815592415630817,\n",
      "                          0.0034854214172810316,\n",
      "                          0.0037205852568149567,\n",
      "                          0.0035265330225229263,\n",
      "                          0.00456080911681056,\n",
      "                          0.004655289929360151,\n",
      "                          0.003672960214316845],\n",
      "             'val_precision': [0.9514563083648682,\n",
      "                               0.9482288956642151,\n",
      "                               0.9690443873405457,\n",
      "                               0.9847009778022766,\n",
      "                               0.9931600689888,\n",
      "                               0.9902777671813965,\n",
      "                               0.9959239363670349,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.9295393228530884,\n",
      "                            0.9802817106246948,\n",
      "                            0.9903714060783386,\n",
      "                            0.9943820238113403,\n",
      "                            0.9945205450057983,\n",
      "                            0.9916550517082214,\n",
      "                            0.9959239363670349,\n",
      "                            0.9960370063781738,\n",
      "                            0.9958506226539612,\n",
      "                            0.9973261952400208,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.6397107243537903,\n",
      " 'train_counts': {'fire': 1485, 'nofire': 1401},\n",
      " 'train_dataset_size': 5344,\n",
      " 'training_time': 5001.182850122452,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_dataset_size': 1184}\n",
      "Training model: ResNet50V2 on dataset: The Wildfire Dataset_Forest Fire\n",
      "Epoch 1/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 712ms/step - accuracy: 0.8026 - auc: 0.9045 - f1_score: 0.8326 - loss: 0.4865 - precision: 0.8718 - recall: 0.8462 - val_accuracy: 0.9634 - val_auc: 0.9942 - val_f1_score: 0.9697 - val_loss: 0.1379 - val_precision: 0.9596 - val_recall: 0.9812 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 707ms/step - accuracy: 0.9113 - auc: 0.9670 - f1_score: 0.9273 - loss: 0.2245 - precision: 0.9236 - recall: 0.9333 - val_accuracy: 0.9855 - val_auc: 0.9989 - val_f1_score: 0.9878 - val_loss: 0.0764 - val_precision: 0.9853 - val_recall: 0.9914 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 703ms/step - accuracy: 0.9153 - auc: 0.9724 - f1_score: 0.9295 - loss: 0.2066 - precision: 0.9235 - recall: 0.9378 - val_accuracy: 0.9943 - val_auc: 1.0000 - val_f1_score: 0.9952 - val_loss: 0.0516 - val_precision: 0.9926 - val_recall: 0.9981 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 726ms/step - accuracy: 0.9438 - auc: 0.9852 - f1_score: 0.9536 - loss: 0.1494 - precision: 0.9506 - recall: 0.9585 - val_accuracy: 0.9992 - val_auc: 1.0000 - val_f1_score: 0.9994 - val_loss: 0.0357 - val_precision: 0.9994 - val_recall: 0.9994 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 705ms/step - accuracy: 0.9576 - auc: 0.9919 - f1_score: 0.9643 - loss: 0.1119 - precision: 0.9652 - recall: 0.9653 - val_accuracy: 0.9985 - val_auc: 1.0000 - val_f1_score: 0.9987 - val_loss: 0.0292 - val_precision: 0.9975 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 701ms/step - accuracy: 0.9641 - auc: 0.9936 - f1_score: 0.9697 - loss: 0.0961 - precision: 0.9686 - recall: 0.9731 - val_accuracy: 0.9992 - val_auc: 1.0000 - val_f1_score: 0.9995 - val_loss: 0.0217 - val_precision: 1.0000 - val_recall: 0.9988 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 709ms/step - accuracy: 0.9709 - auc: 0.9959 - f1_score: 0.9757 - loss: 0.0798 - precision: 0.9781 - recall: 0.9744 - val_accuracy: 0.9992 - val_auc: 1.0000 - val_f1_score: 0.9993 - val_loss: 0.0165 - val_precision: 1.0000 - val_recall: 0.9988 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 720ms/step - accuracy: 0.9704 - auc: 0.9954 - f1_score: 0.9756 - loss: 0.0816 - precision: 0.9757 - recall: 0.9764 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0161 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 708ms/step - accuracy: 0.9726 - auc: 0.9954 - f1_score: 0.9772 - loss: 0.0801 - precision: 0.9806 - recall: 0.9756 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0132 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 699ms/step - accuracy: 0.9742 - auc: 0.9962 - f1_score: 0.9777 - loss: 0.0749 - precision: 0.9759 - recall: 0.9819 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0128 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 700ms/step - accuracy: 0.9768 - auc: 0.9971 - f1_score: 0.9801 - loss: 0.0646 - precision: 0.9787 - recall: 0.9836 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0094 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 703ms/step - accuracy: 0.9774 - auc: 0.9974 - f1_score: 0.9810 - loss: 0.0583 - precision: 0.9797 - recall: 0.9833 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0095 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 732ms/step - accuracy: 0.9813 - auc: 0.9978 - f1_score: 0.9845 - loss: 0.0536 - precision: 0.9844 - recall: 0.9853 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0085 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 728ms/step - accuracy: 0.9805 - auc: 0.9981 - f1_score: 0.9840 - loss: 0.0534 - precision: 0.9839 - recall: 0.9840 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0063 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 719ms/step - accuracy: 0.9825 - auc: 0.9983 - f1_score: 0.9849 - loss: 0.0501 - precision: 0.9839 - recall: 0.9872 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0057 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 707ms/step - accuracy: 0.9835 - auc: 0.9983 - f1_score: 0.9861 - loss: 0.0473 - precision: 0.9888 - recall: 0.9843 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0065 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m243s\u001b[0m 698ms/step - accuracy: 0.9796 - auc: 0.9975 - f1_score: 0.9830 - loss: 0.0554 - precision: 0.9847 - recall: 0.9823 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0078 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 708ms/step - accuracy: 0.9829 - auc: 0.9982 - f1_score: 0.9858 - loss: 0.0478 - precision: 0.9881 - recall: 0.9842 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0041 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 702ms/step - accuracy: 0.9831 - auc: 0.9984 - f1_score: 0.9858 - loss: 0.0458 - precision: 0.9850 - recall: 0.9878 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0047 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 725ms/step - accuracy: 0.9859 - auc: 0.9989 - f1_score: 0.9882 - loss: 0.0370 - precision: 0.9879 - recall: 0.9891 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0054 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 704ms/step - accuracy: 0.9832 - auc: 0.9980 - f1_score: 0.9858 - loss: 0.0454 - precision: 0.9858 - recall: 0.9868 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0054 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 704ms/step - accuracy: 0.9849 - auc: 0.9984 - f1_score: 0.9869 - loss: 0.0425 - precision: 0.9876 - recall: 0.9879 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0055 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 705ms/step - accuracy: 0.9822 - auc: 0.9987 - f1_score: 0.9851 - loss: 0.0407 - precision: 0.9853 - recall: 0.9857 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0032 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 712ms/step - accuracy: 0.9854 - auc: 0.9987 - f1_score: 0.9875 - loss: 0.0377 - precision: 0.9874 - recall: 0.9889 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0034 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 708ms/step - accuracy: 0.9879 - auc: 0.9986 - f1_score: 0.9895 - loss: 0.0356 - precision: 0.9891 - recall: 0.9912 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0027 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 719ms/step - accuracy: 0.9865 - auc: 0.9990 - f1_score: 0.9883 - loss: 0.0372 - precision: 0.9885 - recall: 0.9892 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0032 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 709ms/step - accuracy: 0.9854 - auc: 0.9986 - f1_score: 0.9882 - loss: 0.0377 - precision: 0.9891 - recall: 0.9873 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 718ms/step - accuracy: 0.9894 - auc: 0.9989 - f1_score: 0.9909 - loss: 0.0332 - precision: 0.9895 - recall: 0.9932 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0027 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 709ms/step - accuracy: 0.9887 - auc: 0.9989 - f1_score: 0.9907 - loss: 0.0336 - precision: 0.9901 - recall: 0.9915 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0025 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 700ms/step - accuracy: 0.9876 - auc: 0.9983 - f1_score: 0.9895 - loss: 0.0358 - precision: 0.9905 - recall: 0.9894 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0021 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 31/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 705ms/step - accuracy: 0.9902 - auc: 0.9989 - f1_score: 0.9916 - loss: 0.0299 - precision: 0.9913 - recall: 0.9926 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0026 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 32/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 716ms/step - accuracy: 0.9881 - auc: 0.9984 - f1_score: 0.9897 - loss: 0.0366 - precision: 0.9900 - recall: 0.9907 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0031 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 33/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 716ms/step - accuracy: 0.9885 - auc: 0.9990 - f1_score: 0.9901 - loss: 0.0355 - precision: 0.9898 - recall: 0.9914 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0034 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 34/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 714ms/step - accuracy: 0.9895 - auc: 0.9993 - f1_score: 0.9911 - loss: 0.0291 - precision: 0.9908 - recall: 0.9920 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0019 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 35/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 715ms/step - accuracy: 0.9893 - auc: 0.9991 - f1_score: 0.9912 - loss: 0.0306 - precision: 0.9908 - recall: 0.9917 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 36/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 716ms/step - accuracy: 0.9890 - auc: 0.9991 - f1_score: 0.9904 - loss: 0.0311 - precision: 0.9904 - recall: 0.9917 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 37/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 712ms/step - accuracy: 0.9876 - auc: 0.9993 - f1_score: 0.9897 - loss: 0.0336 - precision: 0.9903 - recall: 0.9895 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0031 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 38/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 709ms/step - accuracy: 0.9888 - auc: 0.9989 - f1_score: 0.9898 - loss: 0.0317 - precision: 0.9903 - recall: 0.9914 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0022 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 39/80\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 576ms/step - accuracy: 0.9903 - auc: 0.9991 - f1_score: 0.9916 - loss: 0.0269 - precision: 0.9921 - recall: 0.9921\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m348/348\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 704ms/step - accuracy: 0.9903 - auc: 0.9991 - f1_score: 0.9916 - loss: 0.0269 - precision: 0.9921 - recall: 0.9921 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0030 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Training time: 9640.61 seconds\n",
      "Evaluating ResNet50V2 on The Wildfire Dataset_Forest Fire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 547ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 630ms/step - accuracy: 0.8765 - auc: 0.8392 - f1_score: 0.4676 - loss: 0.3952 - precision: 0.7332 - recall: 0.8139\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.8894230723381042,\n",
      "                'auc': 0.9465048909187317,\n",
      "                'f1_score': 0.6203575730323792,\n",
      "                'loss': 0.3469395041465759,\n",
      "                'precision': 0.8988326787948608,\n",
      "                'recall': 0.9203187227249146},\n",
      " 'history': {'accuracy': [0.8516523241996765,\n",
      "                          0.9109195470809937,\n",
      "                          0.9241199493408203,\n",
      "                          0.9480962753295898,\n",
      "                          0.9578843116760254,\n",
      "                          0.9619252681732178,\n",
      "                          0.970366358757019,\n",
      "                          0.9705459475517273,\n",
      "                          0.9725215435028076,\n",
      "                          0.9735991358757019,\n",
      "                          0.9766523241996765,\n",
      "                          0.9773706793785095,\n",
      "                          0.9790768623352051,\n",
      "                          0.9807830452919006,\n",
      "                          0.9823994040489197,\n",
      "                          0.9826688170433044,\n",
      "                          0.9801544547080994,\n",
      "                          0.9838362336158752,\n",
      "                          0.9825790524482727,\n",
      "                          0.985542356967926,\n",
      "                          0.9829382300376892,\n",
      "                          0.9851831793785095,\n",
      "                          0.9844648241996765,\n",
      "                          0.9860811829566956,\n",
      "                          0.9870689511299133,\n",
      "                          0.9861709475517273,\n",
      "                          0.9867995977401733,\n",
      "                          0.9882363677024841,\n",
      "                          0.9877873659133911,\n",
      "                          0.9878771305084229,\n",
      "                          0.9900323152542114,\n",
      "                          0.9876975417137146,\n",
      "                          0.9886853694915771,\n",
      "                          0.9876077771186829,\n",
      "                          0.9894935488700867,\n",
      "                          0.9885955452919006,\n",
      "                          0.9875179529190063,\n",
      "                          0.9885955452919006,\n",
      "                          0.9893139600753784],\n",
      "             'auc': [0.9250367879867554,\n",
      "                     0.9701245427131653,\n",
      "                     0.9766452312469482,\n",
      "                     0.9878721237182617,\n",
      "                     0.9924691915512085,\n",
      "                     0.9935205578804016,\n",
      "                     0.9956313967704773,\n",
      "                     0.9955729246139526,\n",
      "                     0.9951995015144348,\n",
      "                     0.996474027633667,\n",
      "                     0.9969928860664368,\n",
      "                     0.9970697164535522,\n",
      "                     0.9977545142173767,\n",
      "                     0.9980708360671997,\n",
      "                     0.9981018304824829,\n",
      "                     0.9977449178695679,\n",
      "                     0.9970096945762634,\n",
      "                     0.9981680512428284,\n",
      "                     0.9984576106071472,\n",
      "                     0.9988436698913574,\n",
      "                     0.9985135197639465,\n",
      "                     0.998289167881012,\n",
      "                     0.9985993504524231,\n",
      "                     0.998615026473999,\n",
      "                     0.99870365858078,\n",
      "                     0.9989518523216248,\n",
      "                     0.9989871978759766,\n",
      "                     0.9987621903419495,\n",
      "                     0.9989199638366699,\n",
      "                     0.9986273646354675,\n",
      "                     0.9988294243812561,\n",
      "                     0.998557984828949,\n",
      "                     0.9990359544754028,\n",
      "                     0.9989826679229736,\n",
      "                     0.9992193579673767,\n",
      "                     0.9990915656089783,\n",
      "                     0.9992530941963196,\n",
      "                     0.9988530278205872,\n",
      "                     0.9989410638809204],\n",
      "             'f1_score': [0.87685227394104,\n",
      "                          0.9267272353172302,\n",
      "                          0.9368719458580017,\n",
      "                          0.9572126269340515,\n",
      "                          0.9650294184684753,\n",
      "                          0.9680880904197693,\n",
      "                          0.9751678705215454,\n",
      "                          0.9752959609031677,\n",
      "                          0.9764421582221985,\n",
      "                          0.9775948524475098,\n",
      "                          0.9802605509757996,\n",
      "                          0.9809108376502991,\n",
      "                          0.9825210571289062,\n",
      "                          0.9838078022003174,\n",
      "                          0.9850882887840271,\n",
      "                          0.9854040145874023,\n",
      "                          0.9831464886665344,\n",
      "                          0.9863489270210266,\n",
      "                          0.9854391813278198,\n",
      "                          0.9880771636962891,\n",
      "                          0.9855340719223022,\n",
      "                          0.9870838522911072,\n",
      "                          0.9868637323379517,\n",
      "                          0.9882066249847412,\n",
      "                          0.9888865947723389,\n",
      "                          0.9881454110145569,\n",
      "                          0.9888429045677185,\n",
      "                          0.9901701807975769,\n",
      "                          0.9898374080657959,\n",
      "                          0.9898077249526978,\n",
      "                          0.9916973114013672,\n",
      "                          0.9894048571586609,\n",
      "                          0.9902634024620056,\n",
      "                          0.9894469976425171,\n",
      "                          0.9913177490234375,\n",
      "                          0.9901787638664246,\n",
      "                          0.989682674407959,\n",
      "                          0.990301787853241,\n",
      "                          0.9908636808395386],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513],\n",
      "             'loss': [0.36589694023132324,\n",
      "                      0.2144235372543335,\n",
      "                      0.18819139897823334,\n",
      "                      0.13712278008460999,\n",
      "                      0.10929962992668152,\n",
      "                      0.09871106594800949,\n",
      "                      0.08090901374816895,\n",
      "                      0.07987765967845917,\n",
      "                      0.07822855561971664,\n",
      "                      0.07219891995191574,\n",
      "                      0.06459350883960724,\n",
      "                      0.060939475893974304,\n",
      "                      0.05592941865324974,\n",
      "                      0.05169612541794777,\n",
      "                      0.05093172937631607,\n",
      "                      0.05011472851037979,\n",
      "                      0.056725502014160156,\n",
      "                      0.04690666124224663,\n",
      "                      0.04593605920672417,\n",
      "                      0.0388958603143692,\n",
      "                      0.04351270571351051,\n",
      "                      0.04296912997961044,\n",
      "                      0.03940977901220322,\n",
      "                      0.038288045674562454,\n",
      "                      0.036656029522418976,\n",
      "                      0.03735684975981712,\n",
      "                      0.034736473113298416,\n",
      "                      0.03521985933184624,\n",
      "                      0.03301038593053818,\n",
      "                      0.03450837731361389,\n",
      "                      0.0299520306289196,\n",
      "                      0.03567471355199814,\n",
      "                      0.0334455706179142,\n",
      "                      0.03461349010467529,\n",
      "                      0.029452962800860405,\n",
      "                      0.03280945494771004,\n",
      "                      0.03370508924126625,\n",
      "                      0.030837418511509895,\n",
      "                      0.030392691493034363],\n",
      "             'precision': [0.8854395747184753,\n",
      "                           0.9244953989982605,\n",
      "                           0.9349759221076965,\n",
      "                           0.9543604850769043,\n",
      "                           0.9658257365226746,\n",
      "                           0.9676664471626282,\n",
      "                           0.9760856628417969,\n",
      "                           0.9744563102722168,\n",
      "                           0.97743159532547,\n",
      "                           0.9773225784301758,\n",
      "                           0.9795141816139221,\n",
      "                           0.981176495552063,\n",
      "                           0.9831452369689941,\n",
      "                           0.9840081930160522,\n",
      "                           0.9844915866851807,\n",
      "                           0.9866353273391724,\n",
      "                           0.9836113452911377,\n",
      "                           0.9872713685035706,\n",
      "                           0.9855432510375977,\n",
      "                           0.9883126616477966,\n",
      "                           0.9855030179023743,\n",
      "                           0.9871363639831543,\n",
      "                           0.987410306930542,\n",
      "                           0.9887459874153137,\n",
      "                           0.9887113571166992,\n",
      "                           0.9885411858558655,\n",
      "                           0.9895955324172974,\n",
      "                           0.9900380969047546,\n",
      "                           0.9889164566993713,\n",
      "                           0.990776002407074,\n",
      "                           0.9917924404144287,\n",
      "                           0.9900541305541992,\n",
      "                           0.9907719492912292,\n",
      "                           0.9897705912590027,\n",
      "                           0.9913679361343384,\n",
      "                           0.9909104108810425,\n",
      "                           0.9903522729873657,\n",
      "                           0.9910570383071899,\n",
      "                           0.9913704991340637],\n",
      "             'recall': [0.8760532736778259,\n",
      "                        0.9309840798377991,\n",
      "                        0.9414268732070923,\n",
      "                        0.9613469839096069,\n",
      "                        0.9654009938240051,\n",
      "                        0.9702215194702148,\n",
      "                        0.975513219833374,\n",
      "                        0.9775955677032471,\n",
      "                        0.9780011773109436,\n",
      "                        0.9796158075332642,\n",
      "                        0.9823892116546631,\n",
      "                        0.981753945350647,\n",
      "                        0.9827131628990173,\n",
      "                        0.9845860004425049,\n",
      "                        0.9868015646934509,\n",
      "                        0.985044002532959,\n",
      "                        0.9840433597564697,\n",
      "                        0.9864054918289185,\n",
      "                        0.9861192107200623,\n",
      "                        0.9881682991981506,\n",
      "                        0.9866588711738586,\n",
      "                        0.9887261986732483,\n",
      "                        0.9872658252716064,\n",
      "                        0.9886015057563782,\n",
      "                        0.9901629686355591,\n",
      "                        0.9888317584991455,\n",
      "                        0.9888709783554077,\n",
      "                        0.9907638430595398,\n",
      "                        0.9912293553352356,\n",
      "                        0.9894721508026123,\n",
      "                        0.9919378757476807,\n",
      "                        0.9899093508720398,\n",
      "                        0.9907719492912292,\n",
      "                        0.9900599122047424,\n",
      "                        0.9915130138397217,\n",
      "                        0.9904748201370239,\n",
      "                        0.9893399477005005,\n",
      "                        0.9903311133384705,\n",
      "                        0.9912254810333252],\n",
      "             'val_accuracy': [0.9634146094322205,\n",
      "                              0.9855182766914368,\n",
      "                              0.9942835569381714,\n",
      "                              0.9992377758026123,\n",
      "                              0.9984756112098694,\n",
      "                              0.9992377758026123,\n",
      "                              0.9992377758026123,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.994194507598877,\n",
      "                         0.9989089369773865,\n",
      "                         0.9999521970748901,\n",
      "                         0.9999898672103882,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.969737708568573,\n",
      "                              0.987822949886322,\n",
      "                              0.99519944190979,\n",
      "                              0.999403715133667,\n",
      "                              0.9987102746963501,\n",
      "                              0.9994916319847107,\n",
      "                              0.9993388652801514,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.13794006407260895,\n",
      "                          0.07637766748666763,\n",
      "                          0.05164051055908203,\n",
      "                          0.03572051227092743,\n",
      "                          0.029209204018115997,\n",
      "                          0.02171194739639759,\n",
      "                          0.01650187559425831,\n",
      "                          0.01610562950372696,\n",
      "                          0.013153470121324062,\n",
      "                          0.012783206067979336,\n",
      "                          0.009438569657504559,\n",
      "                          0.009509650059044361,\n",
      "                          0.008524538949131966,\n",
      "                          0.006339936051517725,\n",
      "                          0.0057093678042292595,\n",
      "                          0.006486270576715469,\n",
      "                          0.00782078318297863,\n",
      "                          0.004083487670868635,\n",
      "                          0.0047075264155864716,\n",
      "                          0.005369032267481089,\n",
      "                          0.005394278559833765,\n",
      "                          0.005475408397614956,\n",
      "                          0.003235235344618559,\n",
      "                          0.003442318644374609,\n",
      "                          0.002669255482032895,\n",
      "                          0.0032366111408919096,\n",
      "                          0.0028786032926291227,\n",
      "                          0.0027029039338231087,\n",
      "                          0.0024902094155550003,\n",
      "                          0.0021138901356607676,\n",
      "                          0.002640375867486,\n",
      "                          0.003084399038925767,\n",
      "                          0.0034181380178779364,\n",
      "                          0.0019239247776567936,\n",
      "                          0.002947921631857753,\n",
      "                          0.002923237858340144,\n",
      "                          0.003109406679868698,\n",
      "                          0.0022328216582536697,\n",
      "                          0.003002204466611147],\n",
      "             'val_precision': [0.9595588445663452,\n",
      "                               0.9853300452232361,\n",
      "                               0.9925925731658936,\n",
      "                               0.9993800520896912,\n",
      "                               0.9975185990333557,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.981203019618988,\n",
      "                            0.9913899302482605,\n",
      "                            0.9981378316879272,\n",
      "                            0.9993800520896912,\n",
      "                            1.0,\n",
      "                            0.9987623691558838,\n",
      "                            0.9987601041793823,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.8164817094802856,\n",
      " 'train_counts': {'fire': 2841, 'nofire': 3657},\n",
      " 'train_dataset_size': 11136,\n",
      " 'training_time': 9640.607172966003,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_dataset_size': 2624}\n",
      "Training model: ResNet50V2 on dataset: DeepFire_FIRE\n",
      "Epoch 1/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 717ms/step - accuracy: 0.9184 - auc: 0.9699 - f1_score: 0.9147 - loss: 0.2098 - precision: 0.9215 - recall: 0.9309 - val_accuracy: 0.9909 - val_auc: 0.9997 - val_f1_score: 0.9911 - val_loss: 0.0323 - val_precision: 0.9941 - val_recall: 0.9882 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 688ms/step - accuracy: 0.9749 - auc: 0.9971 - f1_score: 0.9723 - loss: 0.0683 - precision: 0.9720 - recall: 0.9757 - val_accuracy: 0.9980 - val_auc: 1.0000 - val_f1_score: 0.9976 - val_loss: 0.0117 - val_precision: 0.9960 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 771ms/step - accuracy: 0.9900 - auc: 0.9996 - f1_score: 0.9892 - loss: 0.0257 - precision: 0.9880 - recall: 0.9920 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0050 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 683ms/step - accuracy: 0.9883 - auc: 0.9988 - f1_score: 0.9872 - loss: 0.0358 - precision: 0.9871 - recall: 0.9895 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0031 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 716ms/step - accuracy: 0.9912 - auc: 0.9997 - f1_score: 0.9908 - loss: 0.0222 - precision: 0.9930 - recall: 0.9893 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0022 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 757ms/step - accuracy: 0.9881 - auc: 0.9995 - f1_score: 0.9865 - loss: 0.0269 - precision: 0.9862 - recall: 0.9902 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0018 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 692ms/step - accuracy: 0.9901 - auc: 0.9988 - f1_score: 0.9889 - loss: 0.0271 - precision: 0.9905 - recall: 0.9897 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.2076e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 762ms/step - accuracy: 0.9965 - auc: 0.9999 - f1_score: 0.9963 - loss: 0.0132 - precision: 0.9962 - recall: 0.9967 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.1922e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 732ms/step - accuracy: 0.9949 - auc: 0.9997 - f1_score: 0.9951 - loss: 0.0185 - precision: 0.9959 - recall: 0.9934 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.4581e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 704ms/step - accuracy: 0.9966 - auc: 0.9998 - f1_score: 0.9963 - loss: 0.0130 - precision: 0.9970 - recall: 0.9962 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.4122e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 777ms/step - accuracy: 0.9941 - auc: 0.9998 - f1_score: 0.9936 - loss: 0.0169 - precision: 0.9939 - recall: 0.9943 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.9639e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 719ms/step - accuracy: 0.9969 - auc: 1.0000 - f1_score: 0.9965 - loss: 0.0106 - precision: 0.9958 - recall: 0.9980 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.8804e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 715ms/step - accuracy: 0.9951 - auc: 0.9992 - f1_score: 0.9945 - loss: 0.0183 - precision: 0.9941 - recall: 0.9959 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.3012e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 784ms/step - accuracy: 0.9946 - auc: 0.9999 - f1_score: 0.9931 - loss: 0.0153 - precision: 0.9912 - recall: 0.9979 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.3451e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 678ms/step - accuracy: 0.9931 - auc: 0.9994 - f1_score: 0.9926 - loss: 0.0193 - precision: 0.9936 - recall: 0.9926 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.8005e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 724ms/step - accuracy: 0.9941 - auc: 0.9996 - f1_score: 0.9943 - loss: 0.0137 - precision: 0.9972 - recall: 0.9915 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.0603e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628ms/step - accuracy: 0.9963 - auc: 0.9999 - f1_score: 0.9966 - loss: 0.0121 - precision: 0.9980 - recall: 0.9947\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 757ms/step - accuracy: 0.9963 - auc: 0.9999 - f1_score: 0.9966 - loss: 0.0121 - precision: 0.9980 - recall: 0.9947 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.0449e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 680ms/step - accuracy: 0.9953 - auc: 0.9999 - f1_score: 0.9952 - loss: 0.0105 - precision: 0.9964 - recall: 0.9945 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.3048e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 760ms/step - accuracy: 0.9993 - auc: 1.0000 - f1_score: 0.9992 - loss: 0.0037 - precision: 0.9990 - recall: 0.9996 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.8233e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 716ms/step - accuracy: 0.9961 - auc: 0.9996 - f1_score: 0.9965 - loss: 0.0139 - precision: 0.9980 - recall: 0.9943 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.4443e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 698ms/step - accuracy: 0.9954 - auc: 0.9996 - f1_score: 0.9940 - loss: 0.0117 - precision: 0.9940 - recall: 0.9969 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.5281e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 784ms/step - accuracy: 0.9962 - auc: 0.9999 - f1_score: 0.9968 - loss: 0.0112 - precision: 0.9983 - recall: 0.9944 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.9416e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 719ms/step - accuracy: 0.9983 - auc: 1.0000 - f1_score: 0.9979 - loss: 0.0043 - precision: 0.9978 - recall: 0.9988 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.8606e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.9988 - auc: 1.0000 - f1_score: 0.9988 - loss: 0.0056 - precision: 0.9991 - recall: 0.9985\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 697ms/step - accuracy: 0.9988 - auc: 1.0000 - f1_score: 0.9988 - loss: 0.0056 - precision: 0.9991 - recall: 0.9985 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2659e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 801ms/step - accuracy: 0.9972 - auc: 1.0000 - f1_score: 0.9973 - loss: 0.0061 - precision: 0.9984 - recall: 0.9962 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.8212e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 717ms/step - accuracy: 0.9961 - auc: 1.0000 - f1_score: 0.9964 - loss: 0.0088 - precision: 0.9987 - recall: 0.9936 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.1212e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 733ms/step - accuracy: 0.9982 - auc: 0.9999 - f1_score: 0.9984 - loss: 0.0074 - precision: 0.9995 - recall: 0.9969 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.1656e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 810ms/step - accuracy: 0.9972 - auc: 1.0000 - f1_score: 0.9967 - loss: 0.0081 - precision: 0.9961 - recall: 0.9984 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.9538e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546ms/step - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9974 - loss: 0.0058 - precision: 0.9975 - recall: 0.9977\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 683ms/step - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9974 - loss: 0.0058 - precision: 0.9975 - recall: 0.9978 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.4155e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 725ms/step - accuracy: 0.9964 - auc: 1.0000 - f1_score: 0.9965 - loss: 0.0073 - precision: 0.9963 - recall: 0.9966 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.1789e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 790ms/step - accuracy: 0.9964 - auc: 0.9999 - f1_score: 0.9966 - loss: 0.0109 - precision: 0.9975 - recall: 0.9954 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.0079e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 673ms/step - accuracy: 0.9986 - auc: 1.0000 - f1_score: 0.9983 - loss: 0.0066 - precision: 0.9987 - recall: 0.9986 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.5045e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 33/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 715ms/step - accuracy: 0.9993 - auc: 1.0000 - f1_score: 0.9990 - loss: 0.0048 - precision: 0.9987 - recall: 0.9999 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.2353e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 34/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 795ms/step - accuracy: 0.9975 - auc: 1.0000 - f1_score: 0.9978 - loss: 0.0063 - precision: 0.9993 - recall: 0.9957 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.8706e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 35/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530ms/step - accuracy: 0.9994 - auc: 1.0000 - f1_score: 0.9992 - loss: 0.0029 - precision: 0.9988 - recall: 1.0000\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 656ms/step - accuracy: 0.9994 - auc: 1.0000 - f1_score: 0.9992 - loss: 0.0029 - precision: 0.9988 - recall: 1.0000 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.8742e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 36/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 726ms/step - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9965 - loss: 0.0057 - precision: 0.9960 - recall: 0.9991 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.5575e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 37/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 775ms/step - accuracy: 0.9993 - auc: 1.0000 - f1_score: 0.9994 - loss: 0.0040 - precision: 0.9996 - recall: 0.9991 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.1324e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 38/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 692ms/step - accuracy: 0.9976 - auc: 0.9997 - f1_score: 0.9980 - loss: 0.0087 - precision: 0.9993 - recall: 0.9960 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.8545e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 39/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 708ms/step - accuracy: 0.9989 - auc: 1.0000 - f1_score: 0.9987 - loss: 0.0032 - precision: 0.9988 - recall: 0.9989 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.8081e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 40/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619ms/step - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9973 - loss: 0.0049 - precision: 0.9970 - recall: 0.9985\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 771ms/step - accuracy: 0.9978 - auc: 1.0000 - f1_score: 0.9973 - loss: 0.0049 - precision: 0.9970 - recall: 0.9985 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.1550e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 6.2500e-05\n",
      "Epoch 41/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 731ms/step - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9973 - loss: 0.0052 - precision: 0.9971 - recall: 0.9981 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.5074e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 42/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 680ms/step - accuracy: 0.9990 - auc: 1.0000 - f1_score: 0.9993 - loss: 0.0039 - precision: 1.0000 - recall: 0.9981 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.7035e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 43/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 757ms/step - accuracy: 0.9988 - auc: 1.0000 - f1_score: 0.9983 - loss: 0.0029 - precision: 0.9976 - recall: 0.9999 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.7963e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 44/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 800ms/step - accuracy: 0.9989 - auc: 1.0000 - f1_score: 0.9987 - loss: 0.0044 - precision: 0.9981 - recall: 0.9996 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.6396e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 45/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 510ms/step - accuracy: 0.9999 - auc: 1.0000 - f1_score: 0.9999 - loss: 0.0028 - precision: 1.0000 - recall: 0.9998\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 642ms/step - accuracy: 0.9999 - auc: 1.0000 - f1_score: 0.9999 - loss: 0.0028 - precision: 1.0000 - recall: 0.9998 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.6146e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 3.1250e-05\n",
      "Epoch 46/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 695ms/step - accuracy: 0.9985 - auc: 1.0000 - f1_score: 0.9985 - loss: 0.0065 - precision: 0.9990 - recall: 0.9981 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.5869e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
      "Epoch 47/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 779ms/step - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9977 - loss: 0.0062 - precision: 0.9985 - recall: 0.9968 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.8400e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
      "Epoch 48/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 738ms/step - accuracy: 0.9997 - auc: 1.0000 - f1_score: 0.9997 - loss: 0.0025 - precision: 0.9998 - recall: 0.9996 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.1703e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
      "Epoch 49/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 696ms/step - accuracy: 0.9984 - auc: 1.0000 - f1_score: 0.9982 - loss: 0.0056 - precision: 0.9980 - recall: 0.9988 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.7545e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.5625e-05\n",
      "Training time: 4486.89 seconds\n",
      "Evaluating ResNet50V2 on DeepFire_FIRE...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 610ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 641ms/step - accuracy: 0.6671 - auc: 0.6532 - f1_score: 0.4330 - loss: 2.1131 - precision: 0.5630 - recall: 0.7563\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.6959134340286255,\n",
      "                'auc': 0.7188397645950317,\n",
      "                'f1_score': 0.5668708682060242,\n",
      "                'loss': 1.8635714054107666,\n",
      "                'precision': 0.7165217399597168,\n",
      "                'recall': 0.8207171559333801},\n",
      " 'history': {'accuracy': [0.9605000019073486,\n",
      "                          0.9785000085830688,\n",
      "                          0.9904999732971191,\n",
      "                          0.9894999861717224,\n",
      "                          0.9887499809265137,\n",
      "                          0.9879999756813049,\n",
      "                          0.9907500147819519,\n",
      "                          0.9962499737739563,\n",
      "                          0.9950000047683716,\n",
      "                          0.9955000281333923,\n",
      "                          0.9940000176429749,\n",
      "                          0.9952499866485596,\n",
      "                          0.9957500100135803,\n",
      "                          0.9940000176429749,\n",
      "                          0.9940000176429749,\n",
      "                          0.9950000047683716,\n",
      "                          0.9950000047683716,\n",
      "                          0.9965000152587891,\n",
      "                          0.9987499713897705,\n",
      "                          0.9950000047683716,\n",
      "                          0.9955000281333923,\n",
      "                          0.9965000152587891,\n",
      "                          0.9977499842643738,\n",
      "                          0.9984999895095825,\n",
      "                          0.9984999895095825,\n",
      "                          0.9975000023841858,\n",
      "                          0.9977499842643738,\n",
      "                          0.9972500205039978,\n",
      "                          0.9990000128746033,\n",
      "                          0.9975000023841858,\n",
      "                          0.9959999918937683,\n",
      "                          0.9987499713897705,\n",
      "                          0.9977499842643738,\n",
      "                          0.9980000257492065,\n",
      "                          0.9984999895095825,\n",
      "                          0.9987499713897705,\n",
      "                          0.9990000128746033,\n",
      "                          0.9975000023841858,\n",
      "                          0.9987499713897705,\n",
      "                          0.9977499842643738,\n",
      "                          0.9990000128746033,\n",
      "                          0.9992499947547913,\n",
      "                          0.9987499713897705,\n",
      "                          0.9990000128746033,\n",
      "                          0.9992499947547913,\n",
      "                          0.9977499842643738,\n",
      "                          0.9977499842643738,\n",
      "                          0.9992499947547913,\n",
      "                          0.9980000257492065],\n",
      "             'auc': [0.9861586689949036,\n",
      "                     0.9978076219558716,\n",
      "                     0.9996126294136047,\n",
      "                     0.9991572499275208,\n",
      "                     0.9995400905609131,\n",
      "                     0.9995951652526855,\n",
      "                     0.9994264841079712,\n",
      "                     0.9998940825462341,\n",
      "                     0.9995362758636475,\n",
      "                     0.9996347427368164,\n",
      "                     0.9997978210449219,\n",
      "                     0.9999116063117981,\n",
      "                     0.9996405243873596,\n",
      "                     0.9998171925544739,\n",
      "                     0.99930340051651,\n",
      "                     0.9993792176246643,\n",
      "                     0.9996532201766968,\n",
      "                     0.999678373336792,\n",
      "                     0.9999884963035583,\n",
      "                     0.9996364712715149,\n",
      "                     0.9996768832206726,\n",
      "                     0.9999243021011353,\n",
      "                     0.9999884366989136,\n",
      "                     0.9999789595603943,\n",
      "                     0.9999896287918091,\n",
      "                     0.9999767541885376,\n",
      "                     0.9997087717056274,\n",
      "                     0.999972403049469,\n",
      "                     0.9999972581863403,\n",
      "                     0.9999808669090271,\n",
      "                     0.9999492764472961,\n",
      "                     0.9999823570251465,\n",
      "                     0.9999464154243469,\n",
      "                     0.9999797344207764,\n",
      "                     0.9999961853027344,\n",
      "                     0.9999887943267822,\n",
      "                     0.9999932646751404,\n",
      "                     0.999707043170929,\n",
      "                     0.9999799132347107,\n",
      "                     0.999973475933075,\n",
      "                     0.9999974966049194,\n",
      "                     0.9999949336051941,\n",
      "                     0.9999966025352478,\n",
      "                     0.9999949336051941,\n",
      "                     0.9999884366989136,\n",
      "                     0.9999635815620422,\n",
      "                     0.9999814629554749,\n",
      "                     0.9999817609786987,\n",
      "                     0.9999846816062927],\n",
      "             'f1_score': [0.958981454372406,\n",
      "                          0.9772402048110962,\n",
      "                          0.990307629108429,\n",
      "                          0.9888530373573303,\n",
      "                          0.9879469275474548,\n",
      "                          0.9866276979446411,\n",
      "                          0.9896169304847717,\n",
      "                          0.9960311055183411,\n",
      "                          0.9948049783706665,\n",
      "                          0.9950745105743408,\n",
      "                          0.9937167167663574,\n",
      "                          0.9951505661010742,\n",
      "                          0.9952079057693481,\n",
      "                          0.9928504824638367,\n",
      "                          0.9936015605926514,\n",
      "                          0.994505763053894,\n",
      "                          0.9947890043258667,\n",
      "                          0.9960448145866394,\n",
      "                          0.9985547661781311,\n",
      "                          0.9949674010276794,\n",
      "                          0.9943608045578003,\n",
      "                          0.9968903064727783,\n",
      "                          0.9972759485244751,\n",
      "                          0.9980724453926086,\n",
      "                          0.9983403086662292,\n",
      "                          0.9975636601448059,\n",
      "                          0.9976803064346313,\n",
      "                          0.9970710873603821,\n",
      "                          0.998734712600708,\n",
      "                          0.9976480603218079,\n",
      "                          0.9949787855148315,\n",
      "                          0.9985234141349792,\n",
      "                          0.9968476891517639,\n",
      "                          0.9981516003608704,\n",
      "                          0.9982056617736816,\n",
      "                          0.9985724091529846,\n",
      "                          0.9990530610084534,\n",
      "                          0.9978130459785461,\n",
      "                          0.9989079833030701,\n",
      "                          0.9975318312644958,\n",
      "                          0.9989994764328003,\n",
      "                          0.9994410276412964,\n",
      "                          0.9983540177345276,\n",
      "                          0.9988644123077393,\n",
      "                          0.9994585514068604,\n",
      "                          0.997282087802887,\n",
      "                          0.99773770570755,\n",
      "                          0.9991092085838318,\n",
      "                          0.9978607892990112],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               6.25000029685907e-05,\n",
      "                               6.25000029685907e-05,\n",
      "                               6.25000029685907e-05,\n",
      "                               6.25000029685907e-05,\n",
      "                               6.25000029685907e-05,\n",
      "                               3.125000148429535e-05,\n",
      "                               3.125000148429535e-05,\n",
      "                               3.125000148429535e-05,\n",
      "                               3.125000148429535e-05,\n",
      "                               3.125000148429535e-05,\n",
      "                               1.5625000742147677e-05,\n",
      "                               1.5625000742147677e-05,\n",
      "                               1.5625000742147677e-05,\n",
      "                               1.5625000742147677e-05],\n",
      "             'loss': [0.11086735129356384,\n",
      "                      0.057708676904439926,\n",
      "                      0.02576175332069397,\n",
      "                      0.03061416558921337,\n",
      "                      0.027912897989153862,\n",
      "                      0.025959180667996407,\n",
      "                      0.024385901167988777,\n",
      "                      0.012805667705833912,\n",
      "                      0.018303442746400833,\n",
      "                      0.01480946782976389,\n",
      "                      0.0175688024610281,\n",
      "                      0.013047444634139538,\n",
      "                      0.012974322773516178,\n",
      "                      0.016996227204799652,\n",
      "                      0.02005772478878498,\n",
      "                      0.015177885070443153,\n",
      "                      0.013560367748141289,\n",
      "                      0.011613089591264725,\n",
      "                      0.00529126450419426,\n",
      "                      0.015312162227928638,\n",
      "                      0.011271054856479168,\n",
      "                      0.010616840794682503,\n",
      "                      0.005028735846281052,\n",
      "                      0.005415423307567835,\n",
      "                      0.00460843788459897,\n",
      "                      0.006371160503476858,\n",
      "                      0.008081614039838314,\n",
      "                      0.007352324202656746,\n",
      "                      0.004135546740144491,\n",
      "                      0.006406606175005436,\n",
      "                      0.009553220123052597,\n",
      "                      0.004897776525467634,\n",
      "                      0.008439122699201107,\n",
      "                      0.005443865433335304,\n",
      "                      0.0038206749595701694,\n",
      "                      0.004201977048069239,\n",
      "                      0.004304154776036739,\n",
      "                      0.009094755165278912,\n",
      "                      0.004671237897127867,\n",
      "                      0.006224923301488161,\n",
      "                      0.003604111261665821,\n",
      "                      0.0034642317332327366,\n",
      "                      0.003559669479727745,\n",
      "                      0.0037925834767520428,\n",
      "                      0.004618237726390362,\n",
      "                      0.006314774043858051,\n",
      "                      0.0054936157539486885,\n",
      "                      0.004834119696170092,\n",
      "                      0.005176775623112917],\n",
      "             'precision': [0.9478918313980103,\n",
      "                           0.9768728017807007,\n",
      "                           0.9890710115432739,\n",
      "                           0.9900744557380676,\n",
      "                           0.9894683957099915,\n",
      "                           0.9860000014305115,\n",
      "                           0.9920159578323364,\n",
      "                           0.9970089793205261,\n",
      "                           0.9949672818183899,\n",
      "                           0.9959636926651001,\n",
      "                           0.9945082664489746,\n",
      "                           0.995517909526825,\n",
      "                           0.9949849843978882,\n",
      "                           0.9919678568840027,\n",
      "                           0.994450032711029,\n",
      "                           0.9954932332038879,\n",
      "                           0.9954909682273865,\n",
      "                           0.996536374092102,\n",
      "                           0.9980188012123108,\n",
      "                           0.9955112338066101,\n",
      "                           0.994997501373291,\n",
      "                           0.9980040192604065,\n",
      "                           0.9974849224090576,\n",
      "                           0.9975174069404602,\n",
      "                           0.9985097050666809,\n",
      "                           0.9984917044639587,\n",
      "                           0.9979879260063171,\n",
      "                           0.9969939589500427,\n",
      "                           0.9984962344169617,\n",
      "                           0.998497724533081,\n",
      "                           0.9950544238090515,\n",
      "                           0.998497724533081,\n",
      "                           0.9959595799446106,\n",
      "                           0.9990015029907227,\n",
      "                           0.9980019927024841,\n",
      "                           0.9989888668060303,\n",
      "                           0.9994984865188599,\n",
      "                           0.9989975094795227,\n",
      "                           0.9994980096817017,\n",
      "                           0.997519850730896,\n",
      "                           0.9994977116584778,\n",
      "                           1.0,\n",
      "                           0.9980069994926453,\n",
      "                           0.9984856247901917,\n",
      "                           1.0,\n",
      "                           0.9975161552429199,\n",
      "                           0.9984840750694275,\n",
      "                           0.9989979863166809,\n",
      "                           0.9980000257492065],\n",
      "             'recall': [0.9524380564689636,\n",
      "                        0.9798285365104675,\n",
      "                        0.9920278787612915,\n",
      "                        0.9890927076339722,\n",
      "                        0.9879819750785828,\n",
      "                        0.9899598360061646,\n",
      "                        0.9895470142364502,\n",
      "                        0.9955201745033264,\n",
      "                        0.9949672818183899,\n",
      "                        0.9949596524238586,\n",
      "                        0.993516206741333,\n",
      "                        0.9950224161148071,\n",
      "                        0.9964841604232788,\n",
      "                        0.9959677457809448,\n",
      "                        0.9934476017951965,\n",
      "                        0.9944972395896912,\n",
      "                        0.9944944977760315,\n",
      "                        0.996536374092102,\n",
      "                        0.9995039701461792,\n",
      "                        0.9945191740989685,\n",
      "                        0.995993971824646,\n",
      "                        0.9950248599052429,\n",
      "                        0.997986912727356,\n",
      "                        0.9995024800300598,\n",
      "                        0.9985097050666809,\n",
      "                        0.9964877367019653,\n",
      "                        0.9974861741065979,\n",
      "                        0.9974937438964844,\n",
      "                        0.9994982481002808,\n",
      "                        0.9965017437934875,\n",
      "                        0.9970267415046692,\n",
      "                        0.9989979863166809,\n",
      "                        0.9994931817054749,\n",
      "                        0.9970104694366455,\n",
      "                        0.9990000128746033,\n",
      "                        0.9984840750694275,\n",
      "                        0.9984970092773438,\n",
      "                        0.9960020184516907,\n",
      "                        0.9979949593544006,\n",
      "                        0.9980148673057556,\n",
      "                        0.9984947443008423,\n",
      "                        0.9985074400901794,\n",
      "                        0.9995009899139404,\n",
      "                        0.9994946718215942,\n",
      "                        0.998502254486084,\n",
      "                        0.9980119466781616,\n",
      "                        0.9969727396965027,\n",
      "                        0.999498724937439,\n",
      "                        0.9980000257492065],\n",
      "             'val_accuracy': [0.9909273982048035,\n",
      "                              0.9979838728904724,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9997497797012329,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.9911248087882996,\n",
      "                              0.9976199269294739,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.03232385590672493,\n",
      "                          0.011690382845699787,\n",
      "                          0.004999679978936911,\n",
      "                          0.003147380193695426,\n",
      "                          0.002165560144931078,\n",
      "                          0.0018102186731994152,\n",
      "                          0.00092076271539554,\n",
      "                          0.0008192200330086052,\n",
      "                          0.0006458141724579036,\n",
      "                          0.0005412225727923214,\n",
      "                          0.0005963902804069221,\n",
      "                          0.0002880432875826955,\n",
      "                          0.0002301197819178924,\n",
      "                          0.00023451294691767544,\n",
      "                          0.0004800485330633819,\n",
      "                          0.0002060285332845524,\n",
      "                          0.00030448968755081296,\n",
      "                          0.00023047720605973154,\n",
      "                          0.00018232574802823365,\n",
      "                          0.00014443081454373896,\n",
      "                          0.00015280609659384936,\n",
      "                          0.00019416485156398267,\n",
      "                          0.00018605544755700976,\n",
      "                          0.00012659373169299215,\n",
      "                          9.821169078350067e-05,\n",
      "                          9.12117466214113e-05,\n",
      "                          0.00011655785783659667,\n",
      "                          8.953818905865774e-05,\n",
      "                          9.415525710210204e-05,\n",
      "                          8.178907592082396e-05,\n",
      "                          8.007868746062741e-05,\n",
      "                          7.50453764339909e-05,\n",
      "                          7.235250814119354e-05,\n",
      "                          6.870595825603232e-05,\n",
      "                          6.874161772429943e-05,\n",
      "                          7.557458593510091e-05,\n",
      "                          8.132367656799033e-05,\n",
      "                          6.854464299976826e-05,\n",
      "                          6.808082980569452e-05,\n",
      "                          7.154997001634911e-05,\n",
      "                          7.507434202125296e-05,\n",
      "                          6.703466351609677e-05,\n",
      "                          5.7963025028584525e-05,\n",
      "                          5.639600567519665e-05,\n",
      "                          6.614626909140497e-05,\n",
      "                          7.586920401081443e-05,\n",
      "                          5.8399877161718905e-05,\n",
      "                          6.170282722450793e-05,\n",
      "                          6.754539936082438e-05],\n",
      "             'val_precision': [0.9940828680992126,\n",
      "                               0.9959595799446106,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.9882352948188782,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.0056848241947591305,\n",
      " 'train_counts': {'fire': 1515, 'nofire': 1004},\n",
      " 'train_dataset_size': 4000,\n",
      " 'training_time': 4486.886687994003,\n",
      " 'val_counts': {'fire': 0, 'nofire': 0},\n",
      " 'val_dataset_size': 992}\n",
      "Training model: ResNet50V2 on dataset: DeepFire_Forest Fire\n",
      "Epoch 1/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 727ms/step - accuracy: 0.9420 - auc: 0.9364 - f1_score: 0.9428 - loss: 0.1428 - precision: 0.8952 - recall: 0.9199 - val_accuracy: 0.9984 - val_auc: 1.0000 - val_f1_score: 0.9982 - val_loss: 0.0099 - val_precision: 0.9983 - val_recall: 0.9983 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 774ms/step - accuracy: 0.9889 - auc: 0.9989 - f1_score: 0.9885 - loss: 0.0313 - precision: 0.9890 - recall: 0.9886 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0018 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 761ms/step - accuracy: 0.9905 - auc: 0.9996 - f1_score: 0.9897 - loss: 0.0249 - precision: 0.9901 - recall: 0.9909 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.6958e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 747ms/step - accuracy: 0.9929 - auc: 0.9997 - f1_score: 0.9922 - loss: 0.0180 - precision: 0.9924 - recall: 0.9934 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.4766e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 740ms/step - accuracy: 0.9954 - auc: 0.9997 - f1_score: 0.9950 - loss: 0.0141 - precision: 0.9952 - recall: 0.9957 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.6415e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 748ms/step - accuracy: 0.9947 - auc: 0.9999 - f1_score: 0.9943 - loss: 0.0134 - precision: 0.9947 - recall: 0.9948 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.1600e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 712ms/step - accuracy: 0.9965 - auc: 0.9997 - f1_score: 0.9959 - loss: 0.0111 - precision: 0.9959 - recall: 0.9971 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.8921e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 721ms/step - accuracy: 0.9982 - auc: 0.9999 - f1_score: 0.9979 - loss: 0.0068 - precision: 0.9978 - recall: 0.9986 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.0466e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 726ms/step - accuracy: 0.9967 - auc: 0.9999 - f1_score: 0.9964 - loss: 0.0095 - precision: 0.9973 - recall: 0.9961 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2459e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 694ms/step - accuracy: 0.9983 - auc: 1.0000 - f1_score: 0.9980 - loss: 0.0055 - precision: 0.9984 - recall: 0.9982 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.5371e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m215s\u001b[0m 703ms/step - accuracy: 0.9982 - auc: 1.0000 - f1_score: 0.9981 - loss: 0.0061 - precision: 0.9978 - recall: 0.9987 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2792e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 719ms/step - accuracy: 0.9979 - auc: 1.0000 - f1_score: 0.9976 - loss: 0.0062 - precision: 0.9976 - recall: 0.9982 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.4640e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 732ms/step - accuracy: 0.9985 - auc: 1.0000 - f1_score: 0.9985 - loss: 0.0044 - precision: 0.9989 - recall: 0.9981 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2554e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 574ms/step - accuracy: 0.9985 - auc: 0.9998 - f1_score: 0.9984 - loss: 0.0060 - precision: 0.9990 - recall: 0.9980\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 723ms/step - accuracy: 0.9985 - auc: 0.9998 - f1_score: 0.9984 - loss: 0.0060 - precision: 0.9990 - recall: 0.9980 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.2448e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 688ms/step - accuracy: 0.9982 - auc: 0.9997 - f1_score: 0.9980 - loss: 0.0076 - precision: 0.9988 - recall: 0.9975 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.1688e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 710ms/step - accuracy: 0.9995 - auc: 1.0000 - f1_score: 0.9995 - loss: 0.0031 - precision: 0.9993 - recall: 0.9997 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.2400e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 767ms/step - accuracy: 0.9991 - auc: 1.0000 - f1_score: 0.9989 - loss: 0.0035 - precision: 0.9990 - recall: 0.9991 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.9110e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 897ms/step - accuracy: 0.9992 - auc: 1.0000 - f1_score: 0.9989 - loss: 0.0025 - precision: 0.9987 - recall: 0.9997 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.4579e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527ms/step - accuracy: 0.9979 - auc: 0.9996 - f1_score: 0.9974 - loss: 0.0078 - precision: 0.9974 - recall: 0.9982\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 673ms/step - accuracy: 0.9979 - auc: 0.9996 - f1_score: 0.9974 - loss: 0.0078 - precision: 0.9974 - recall: 0.9982 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.1402e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 717ms/step - accuracy: 0.9987 - auc: 1.0000 - f1_score: 0.9988 - loss: 0.0033 - precision: 0.9993 - recall: 0.9981 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.9749e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 738ms/step - accuracy: 0.9989 - auc: 1.0000 - f1_score: 0.9987 - loss: 0.0030 - precision: 0.9981 - recall: 0.9998 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.0472e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 768ms/step - accuracy: 0.9974 - auc: 0.9996 - f1_score: 0.9960 - loss: 0.0068 - precision: 0.9965 - recall: 0.9982 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.6633e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 723ms/step - accuracy: 0.9986 - auc: 0.9997 - f1_score: 0.9983 - loss: 0.0043 - precision: 0.9982 - recall: 0.9990 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.5372e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - accuracy: 0.9995 - auc: 1.0000 - f1_score: 0.9995 - loss: 0.0016 - precision: 0.9997 - recall: 0.9992\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 724ms/step - accuracy: 0.9995 - auc: 1.0000 - f1_score: 0.9995 - loss: 0.0016 - precision: 0.9997 - recall: 0.9992 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.7022e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 746ms/step - accuracy: 0.9990 - auc: 1.0000 - f1_score: 0.9989 - loss: 0.0035 - precision: 0.9994 - recall: 0.9985 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.5425e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 751ms/step - accuracy: 0.9997 - auc: 1.0000 - f1_score: 0.9997 - loss: 0.0019 - precision: 0.9996 - recall: 0.9997 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.3515e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 733ms/step - accuracy: 0.9993 - auc: 0.9999 - f1_score: 0.9988 - loss: 0.0022 - precision: 0.9989 - recall: 0.9997 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.6239e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 716ms/step - accuracy: 0.9990 - auc: 1.0000 - f1_score: 0.9990 - loss: 0.0029 - precision: 0.9992 - recall: 0.9989 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.5101e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 721ms/step - accuracy: 0.9989 - auc: 1.0000 - f1_score: 0.9991 - loss: 0.0027 - precision: 0.9995 - recall: 0.9984 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.4580e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 714ms/step - accuracy: 0.9988 - auc: 0.9997 - f1_score: 0.9988 - loss: 0.0042 - precision: 0.9987 - recall: 0.9989 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.9098e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 33/80\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.9990 - auc: 0.9999 - f1_score: 0.9987 - loss: 0.0030 - precision: 0.9987 - recall: 0.9993\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 723ms/step - accuracy: 0.9990 - auc: 0.9999 - f1_score: 0.9987 - loss: 0.0030 - precision: 0.9987 - recall: 0.9993 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.4604e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Training time: 7403.86 seconds\n",
      "Evaluating ResNet50V2 on DeepFire_Forest Fire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 598ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 631ms/step - accuracy: 0.6738 - auc: 0.6612 - f1_score: 0.4358 - loss: 2.2024 - precision: 0.5638 - recall: 0.7620\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.703125,\n",
      "                'auc': 0.7257152795791626,\n",
      "                'f1_score': 0.5732412338256836,\n",
      "                'loss': 1.9675979614257812,\n",
      "                'precision': 0.7179487347602844,\n",
      "                'recall': 0.8366534113883972},\n",
      " 'history': {'accuracy': [0.9730392098426819,\n",
      "                          0.9888684749603271,\n",
      "                          0.9921364188194275,\n",
      "                          0.9920343160629272,\n",
      "                          0.9947916865348816,\n",
      "                          0.9946895241737366,\n",
      "                          0.9953022599220276,\n",
      "                          0.9950980544090271,\n",
      "                          0.9962214231491089,\n",
      "                          0.9975489974021912,\n",
      "                          0.9973447918891907,\n",
      "                          0.9975489974021912,\n",
      "                          0.9977532625198364,\n",
      "                          0.9983659982681274,\n",
      "                          0.9984681606292725,\n",
      "                          0.9980596303939819,\n",
      "                          0.9978553652763367,\n",
      "                          0.999387264251709,\n",
      "                          0.998774528503418,\n",
      "                          0.9989787340164185,\n",
      "                          0.9988766312599182,\n",
      "                          0.9990808963775635,\n",
      "                          0.9991829991340637,\n",
      "                          0.9983659982681274,\n",
      "                          0.9988766312599182,\n",
      "                          0.999285101890564,\n",
      "                          0.9990808963775635,\n",
      "                          0.999285101890564,\n",
      "                          0.9990808963775635,\n",
      "                          0.9990808963775635,\n",
      "                          0.999387264251709,\n",
      "                          0.998774528503418,\n",
      "                          0.999285101890564],\n",
      "             'auc': [0.9799887537956238,\n",
      "                     0.999012291431427,\n",
      "                     0.9995855689048767,\n",
      "                     0.9996558427810669,\n",
      "                     0.9998299479484558,\n",
      "                     0.9995555281639099,\n",
      "                     0.9996717572212219,\n",
      "                     0.9998723268508911,\n",
      "                     0.9997288584709167,\n",
      "                     0.9998679757118225,\n",
      "                     0.9999540448188782,\n",
      "                     0.9997653961181641,\n",
      "                     0.9999678134918213,\n",
      "                     0.9999825358390808,\n",
      "                     0.9999894499778748,\n",
      "                     0.999770998954773,\n",
      "                     0.999748706817627,\n",
      "                     0.9999939203262329,\n",
      "                     0.9999930262565613,\n",
      "                     0.9999982118606567,\n",
      "                     0.9997820854187012,\n",
      "                     0.9999924302101135,\n",
      "                     0.9999962449073792,\n",
      "                     0.9998895525932312,\n",
      "                     0.9998926520347595,\n",
      "                     0.9999983906745911,\n",
      "                     0.9999938011169434,\n",
      "                     0.9999938607215881,\n",
      "                     0.9998945593833923,\n",
      "                     0.9999963045120239,\n",
      "                     0.9999989867210388,\n",
      "                     0.9997894763946533,\n",
      "                     0.9998936057090759],\n",
      "             'f1_score': [0.972350001335144,\n",
      "                          0.9883400797843933,\n",
      "                          0.9916627407073975,\n",
      "                          0.9912222027778625,\n",
      "                          0.9943845868110657,\n",
      "                          0.994557797908783,\n",
      "                          0.9949802756309509,\n",
      "                          0.9944361448287964,\n",
      "                          0.9954931735992432,\n",
      "                          0.9973222613334656,\n",
      "                          0.9970793128013611,\n",
      "                          0.9970664381980896,\n",
      "                          0.9975599646568298,\n",
      "                          0.9981621503829956,\n",
      "                          0.9984101057052612,\n",
      "                          0.9978798031806946,\n",
      "                          0.9975652694702148,\n",
      "                          0.9994035959243774,\n",
      "                          0.998725414276123,\n",
      "                          0.9986705183982849,\n",
      "                          0.9987409710884094,\n",
      "                          0.9991844296455383,\n",
      "                          0.9989910125732422,\n",
      "                          0.9980536699295044,\n",
      "                          0.9986787438392639,\n",
      "                          0.9993219375610352,\n",
      "                          0.9989548325538635,\n",
      "                          0.9993003606796265,\n",
      "                          0.998862087726593,\n",
      "                          0.9989113211631775,\n",
      "                          0.9993649125099182,\n",
      "                          0.9985641837120056,\n",
      "                          0.9990025162696838],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814],\n",
      "             'loss': [0.06851474940776825,\n",
      "                      0.029333095997571945,\n",
      "                      0.021929945796728134,\n",
      "                      0.020731670781970024,\n",
      "                      0.015739254653453827,\n",
      "                      0.01560138538479805,\n",
      "                      0.014895694330334663,\n",
      "                      0.013944815844297409,\n",
      "                      0.01101963222026825,\n",
      "                      0.00769603718072176,\n",
      "                      0.008361795917153358,\n",
      "                      0.007189793512225151,\n",
      "                      0.007072691805660725,\n",
      "                      0.005169034469872713,\n",
      "                      0.0045299590565264225,\n",
      "                      0.006511956453323364,\n",
      "                      0.008450526744127274,\n",
      "                      0.003302425378933549,\n",
      "                      0.003681701375171542,\n",
      "                      0.002595987170934677,\n",
      "                      0.004327727947384119,\n",
      "                      0.003147304756566882,\n",
      "                      0.00238783354870975,\n",
      "                      0.003928018733859062,\n",
      "                      0.003185985842719674,\n",
      "                      0.0018503412138670683,\n",
      "                      0.0032662355806678534,\n",
      "                      0.0028493015561252832,\n",
      "                      0.0025025568902492523,\n",
      "                      0.002804568037390709,\n",
      "                      0.0019302588189020753,\n",
      "                      0.004003819078207016,\n",
      "                      0.002801700262352824],\n",
      "             'precision': [0.9476373195648193,\n",
      "                           0.9885222315788269,\n",
      "                           0.9922338128089905,\n",
      "                           0.9914390444755554,\n",
      "                           0.9949031472206116,\n",
      "                           0.9953013062477112,\n",
      "                           0.995306134223938,\n",
      "                           0.9950889945030212,\n",
      "                           0.9957403540611267,\n",
      "                           0.9975379705429077,\n",
      "                           0.9977518916130066,\n",
      "                           0.9973469376564026,\n",
      "                           0.9975500106811523,\n",
      "                           0.9979600310325623,\n",
      "                           0.9985708594322205,\n",
      "                           0.9983640313148499,\n",
      "                           0.9981733560562134,\n",
      "                           0.9991828203201294,\n",
      "                           0.998773992061615,\n",
      "                           0.9985809922218323,\n",
      "                           0.9989739656448364,\n",
      "                           0.9995903968811035,\n",
      "                           0.9985755085945129,\n",
      "                           0.9985605478286743,\n",
      "                           0.9987764954566956,\n",
      "                           0.9995906949043274,\n",
      "                           0.9991786479949951,\n",
      "                           0.999387264251709,\n",
      "                           0.9991829991340637,\n",
      "                           0.998978316783905,\n",
      "                           0.9993875026702881,\n",
      "                           0.9983706474304199,\n",
      "                           0.998978316783905],\n",
      "             'recall': [0.9575958847999573,\n",
      "                        0.989130437374115,\n",
      "                        0.9920310378074646,\n",
      "                        0.9926530718803406,\n",
      "                        0.9947003722190857,\n",
      "                        0.9940828680992126,\n",
      "                        0.995306134223938,\n",
      "                        0.9950889945030212,\n",
      "                        0.9967512488365173,\n",
      "                        0.9975379705429077,\n",
      "                        0.9969369173049927,\n",
      "                        0.9977541565895081,\n",
      "                        0.9979575276374817,\n",
      "                        0.9987750053405762,\n",
      "                        0.9983670115470886,\n",
      "                        0.9977518916130066,\n",
      "                        0.9975659251213074,\n",
      "                        0.9995912313461304,\n",
      "                        0.998773992061615,\n",
      "                        0.9993913769721985,\n",
      "                        0.9987689852714539,\n",
      "                        0.9985679388046265,\n",
      "                        0.9997962713241577,\n",
      "                        0.9981500506401062,\n",
      "                        0.9989802241325378,\n",
      "                        0.9989773035049438,\n",
      "                        0.9989734888076782,\n",
      "                        0.999183177947998,\n",
      "                        0.9989789724349976,\n",
      "                        0.9991825222969055,\n",
      "                        0.9993875026702881,\n",
      "                        0.9991846680641174,\n",
      "                        0.9995911121368408],\n",
      "             'val_accuracy': [0.9983552694320679,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9999918937683105,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999998807907104,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.9982399344444275,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.009884754195809364,\n",
      "                          0.0017908541485667229,\n",
      "                          0.0007695796084590256,\n",
      "                          0.0006476595881395042,\n",
      "                          0.0003786909219343215,\n",
      "                          0.00027762618265114725,\n",
      "                          0.00026414511376060545,\n",
      "                          0.00031599574140273035,\n",
      "                          0.00018921407172456384,\n",
      "                          0.00020465611305553466,\n",
      "                          0.0001245886815013364,\n",
      "                          0.00025371331139467657,\n",
      "                          0.0001279228599742055,\n",
      "                          0.00014639760775025934,\n",
      "                          0.0001255434035556391,\n",
      "                          9.244790999218822e-05,\n",
      "                          9.16875505936332e-05,\n",
      "                          5.2400442655198276e-05,\n",
      "                          6.911037053214386e-05,\n",
      "                          4.457943941815756e-05,\n",
      "                          4.140166493016295e-05,\n",
      "                          3.974901119363494e-05,\n",
      "                          3.047219433938153e-05,\n",
      "                          2.663331360963639e-05,\n",
      "                          2.537237924116198e-05,\n",
      "                          2.7022446374758147e-05,\n",
      "                          2.5424984414712526e-05,\n",
      "                          2.351458533667028e-05,\n",
      "                          2.62385219684802e-05,\n",
      "                          2.510061858629342e-05,\n",
      "                          2.45795636146795e-05,\n",
      "                          2.909810427809134e-05,\n",
      "                          2.460438190610148e-05],\n",
      "             'val_precision': [0.9983319640159607,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.9983319640159607,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.9848630428314209,\n",
      " 'train_counts': {'fire': 2871, 'nofire': 3260},\n",
      " 'train_dataset_size': 9792,\n",
      " 'training_time': 7403.857415676117,\n",
      " 'val_counts': {'fire': 0, 'nofire': 0},\n",
      " 'val_dataset_size': 2432}\n",
      "Training model: ResNet50V2 on dataset: FIRE_Forest Fire\n",
      "Epoch 1/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 711ms/step - accuracy: 0.8881 - auc: 0.9135 - f1_score: 0.8058 - loss: 0.3032 - precision: 0.7388 - recall: 0.9025 - val_accuracy: 0.9960 - val_auc: 1.0000 - val_f1_score: 0.9909 - val_loss: 0.0165 - val_precision: 1.0000 - val_recall: 0.9828 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 723ms/step - accuracy: 0.9850 - auc: 0.9980 - f1_score: 0.9669 - loss: 0.0437 - precision: 0.9675 - recall: 0.9722 - val_accuracy: 0.9996 - val_auc: 1.0000 - val_f1_score: 0.9994 - val_loss: 0.0031 - val_precision: 1.0000 - val_recall: 0.9982 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 733ms/step - accuracy: 0.9910 - auc: 0.9992 - f1_score: 0.9764 - loss: 0.0284 - precision: 0.9812 - recall: 0.9825 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0016 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 733ms/step - accuracy: 0.9886 - auc: 0.9991 - f1_score: 0.9745 - loss: 0.0328 - precision: 0.9808 - recall: 0.9730 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.1469e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 738ms/step - accuracy: 0.9940 - auc: 0.9996 - f1_score: 0.9846 - loss: 0.0177 - precision: 0.9826 - recall: 0.9936 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.2357e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 712ms/step - accuracy: 0.9946 - auc: 0.9996 - f1_score: 0.9872 - loss: 0.0155 - precision: 0.9885 - recall: 0.9895 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.5613e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 721ms/step - accuracy: 0.9929 - auc: 0.9997 - f1_score: 0.9826 - loss: 0.0186 - precision: 0.9872 - recall: 0.9842 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.4218e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 728ms/step - accuracy: 0.9956 - auc: 0.9998 - f1_score: 0.9892 - loss: 0.0135 - precision: 0.9928 - recall: 0.9887 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.6125e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 729ms/step - accuracy: 0.9971 - auc: 0.9999 - f1_score: 0.9938 - loss: 0.0097 - precision: 0.9936 - recall: 0.9944 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.9252e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 740ms/step - accuracy: 0.9971 - auc: 0.9998 - f1_score: 0.9923 - loss: 0.0107 - precision: 0.9934 - recall: 0.9948 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.2637e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 713ms/step - accuracy: 0.9951 - auc: 0.9993 - f1_score: 0.9864 - loss: 0.0143 - precision: 0.9860 - recall: 0.9939 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2906e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 722ms/step - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9948 - loss: 0.0056 - precision: 0.9945 - recall: 0.9961 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.9110e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 724ms/step - accuracy: 0.9983 - auc: 0.9999 - f1_score: 0.9944 - loss: 0.0055 - precision: 0.9950 - recall: 0.9979 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 8.7240e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 732ms/step - accuracy: 0.9984 - auc: 1.0000 - f1_score: 0.9960 - loss: 0.0039 - precision: 0.9959 - recall: 0.9975 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.0280e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 740ms/step - accuracy: 0.9968 - auc: 0.9999 - f1_score: 0.9916 - loss: 0.0091 - precision: 0.9936 - recall: 0.9932 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.3063e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step - accuracy: 0.9982 - auc: 0.9999 - f1_score: 0.9956 - loss: 0.0074 - precision: 0.9961 - recall: 0.9966\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 706ms/step - accuracy: 0.9982 - auc: 0.9999 - f1_score: 0.9956 - loss: 0.0074 - precision: 0.9961 - recall: 0.9966 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.1259e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m280/280\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 707ms/step - accuracy: 0.9979 - auc: 1.0000 - f1_score: 0.9949 - loss: 0.0069 - precision: 0.9954 - recall: 0.9960 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 9.3335e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Training time: 3475.55 seconds\n",
      "Evaluating ResNet50V2 on FIRE_Forest Fire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 612ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 612ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 648ms/step - accuracy: 0.7096 - auc: 0.7181 - f1_score: 0.3989 - loss: 1.1542 - precision: 0.6286 - recall: 0.6320\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.7007211446762085,\n",
      "                'auc': 0.7943620085716248,\n",
      "                'f1_score': 0.5241321325302124,\n",
      "                'loss': 1.2371375560760498,\n",
      "                'precision': 0.7908046245574951,\n",
      "                'recall': 0.6852589845657349},\n",
      " 'history': {'accuracy': [0.9422991275787354,\n",
      "                          0.9867187738418579,\n",
      "                          0.9906250238418579,\n",
      "                          0.9911830425262451,\n",
      "                          0.9934151768684387,\n",
      "                          0.9940848350524902,\n",
      "                          0.9946428537368774,\n",
      "                          0.9949776530265808,\n",
      "                          0.9972098469734192,\n",
      "                          0.9964285492897034,\n",
      "                          0.9972098469734192,\n",
      "                          0.9973214268684387,\n",
      "                          0.9981026649475098,\n",
      "                          0.9975446462631226,\n",
      "                          0.9963169693946838,\n",
      "                          0.9977678656578064,\n",
      "                          0.9977678656578064],\n",
      "             'auc': [0.9635868668556213,\n",
      "                     0.9981797337532043,\n",
      "                     0.9988972544670105,\n",
      "                     0.9993535280227661,\n",
      "                     0.9994188547134399,\n",
      "                     0.999563455581665,\n",
      "                     0.9998310804367065,\n",
      "                     0.9998188018798828,\n",
      "                     0.9998598694801331,\n",
      "                     0.9996911287307739,\n",
      "                     0.9996959567070007,\n",
      "                     0.9999616146087646,\n",
      "                     0.9997351169586182,\n",
      "                     0.9997332096099854,\n",
      "                     0.9998505115509033,\n",
      "                     0.9999478459358215,\n",
      "                     0.9999600052833557],\n",
      "             'f1_score': [0.8837963342666626,\n",
      "                          0.9694053530693054,\n",
      "                          0.9750963449478149,\n",
      "                          0.9785944223403931,\n",
      "                          0.983214795589447,\n",
      "                          0.9850981831550598,\n",
      "                          0.9861329197883606,\n",
      "                          0.9877232313156128,\n",
      "                          0.9942107200622559,\n",
      "                          0.9915888905525208,\n",
      "                          0.9921858906745911,\n",
      "                          0.9932916760444641,\n",
      "                          0.9938886165618896,\n",
      "                          0.9940428733825684,\n",
      "                          0.9901661276817322,\n",
      "                          0.9947544932365417,\n",
      "                          0.994036078453064],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257],\n",
      "             'loss': [0.16412881016731262,\n",
      "                      0.039066243916749954,\n",
      "                      0.030404357239603996,\n",
      "                      0.026445012539625168,\n",
      "                      0.019402313977479935,\n",
      "                      0.016170382499694824,\n",
      "                      0.014711168594658375,\n",
      "                      0.014267952181398869,\n",
      "                      0.009483869187533855,\n",
      "                      0.011830329895019531,\n",
      "                      0.009829830378293991,\n",
      "                      0.007225584238767624,\n",
      "                      0.00637297285720706,\n",
      "                      0.006811865139752626,\n",
      "                      0.010084673762321472,\n",
      "                      0.007495405152440071,\n",
      "                      0.006853839848190546],\n",
      "             'precision': [0.8113936185836792,\n",
      "                           0.969188928604126,\n",
      "                           0.9781917333602905,\n",
      "                           0.9830973148345947,\n",
      "                           0.9815481305122375,\n",
      "                           0.9867941737174988,\n",
      "                           0.9890561103820801,\n",
      "                           0.9917279481887817,\n",
      "                           0.994965672492981,\n",
      "                           0.9922338724136353,\n",
      "                           0.9936014413833618,\n",
      "                           0.9940503239631653,\n",
      "                           0.9949794411659241,\n",
      "                           0.9949285387992859,\n",
      "                           0.993122398853302,\n",
      "                           0.99589604139328,\n",
      "                           0.9954296350479126],\n",
      "             'recall': [0.934049665927887,\n",
      "                        0.9767123460769653,\n",
      "                        0.9835541248321533,\n",
      "                        0.9808568954467773,\n",
      "                        0.9918144345283508,\n",
      "                        0.9890460968017578,\n",
      "                        0.9890561103820801,\n",
      "                        0.9876430034637451,\n",
      "                        0.9936014413833618,\n",
      "                        0.9931412935256958,\n",
      "                        0.994965672492981,\n",
      "                        0.9949610829353333,\n",
      "                        0.997255265712738,\n",
      "                        0.9949285387992859,\n",
      "                        0.9917582273483276,\n",
      "                        0.9949886202812195,\n",
      "                        0.9954296350479126],\n",
      "             'val_accuracy': [0.9959821701049805,\n",
      "                              0.9995535612106323,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9999933242797852,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.9909018278121948,\n",
      "                              0.9993788599967957,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.016456471756100655,\n",
      "                          0.003110031597316265,\n",
      "                          0.0015661489451304078,\n",
      "                          0.0008146936306729913,\n",
      "                          0.0009235743782483041,\n",
      "                          0.0007561323582194746,\n",
      "                          0.0005421838723123074,\n",
      "                          0.0002612522803246975,\n",
      "                          0.00019252183847129345,\n",
      "                          0.00032636572723276913,\n",
      "                          0.00012905710900668055,\n",
      "                          7.910968997748569e-05,\n",
      "                          8.724019426153973e-05,\n",
      "                          0.00010280265269102529,\n",
      "                          0.0001306292979279533,\n",
      "                          9.125863289227709e-05,\n",
      "                          9.33352202991955e-05],\n",
      "             'val_precision': [1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.9827916026115417,\n",
      "                            0.9981752038002014,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.054794974625110626,\n",
      " 'train_counts': {'fire': 2866, 'nofire': 2744},\n",
      " 'train_dataset_size': 8960,\n",
      " 'training_time': 3475.5530128479004,\n",
      " 'val_counts': {'fire': 0, 'nofire': 0},\n",
      " 'val_dataset_size': 2240}\n",
      "Training model: ResNet50V2 on dataset: The Wildfire Dataset_DeepFire_FIRE\n",
      "Epoch 1/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 701ms/step - accuracy: 0.7883 - auc: 0.8474 - f1_score: 0.8189 - loss: 0.5281 - precision: 0.8353 - recall: 0.7816 - val_accuracy: 0.9453 - val_auc: 0.9900 - val_f1_score: 0.9535 - val_loss: 0.1802 - val_precision: 0.9700 - val_recall: 0.9399 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 728ms/step - accuracy: 0.8917 - auc: 0.9578 - f1_score: 0.9116 - loss: 0.2590 - precision: 0.9173 - recall: 0.9078 - val_accuracy: 0.9754 - val_auc: 0.9981 - val_f1_score: 0.9787 - val_loss: 0.1102 - val_precision: 0.9916 - val_recall: 0.9680 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 710ms/step - accuracy: 0.9163 - auc: 0.9741 - f1_score: 0.9315 - loss: 0.1990 - precision: 0.9306 - recall: 0.9341 - val_accuracy: 0.9883 - val_auc: 0.9994 - val_f1_score: 0.9904 - val_loss: 0.0754 - val_precision: 0.9909 - val_recall: 0.9900 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 694ms/step - accuracy: 0.9249 - auc: 0.9786 - f1_score: 0.9371 - loss: 0.1814 - precision: 0.9377 - recall: 0.9399 - val_accuracy: 0.9961 - val_auc: 0.9999 - val_f1_score: 0.9967 - val_loss: 0.0559 - val_precision: 0.9981 - val_recall: 0.9954 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 723ms/step - accuracy: 0.9325 - auc: 0.9845 - f1_score: 0.9448 - loss: 0.1555 - precision: 0.9449 - recall: 0.9465 - val_accuracy: 0.9933 - val_auc: 0.9999 - val_f1_score: 0.9941 - val_loss: 0.0500 - val_precision: 0.9945 - val_recall: 0.9945 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 744ms/step - accuracy: 0.9551 - auc: 0.9920 - f1_score: 0.9628 - loss: 0.1136 - precision: 0.9628 - recall: 0.9647 - val_accuracy: 0.9972 - val_auc: 1.0000 - val_f1_score: 0.9978 - val_loss: 0.0327 - val_precision: 0.9991 - val_recall: 0.9963 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 727ms/step - accuracy: 0.9565 - auc: 0.9919 - f1_score: 0.9635 - loss: 0.1131 - precision: 0.9603 - recall: 0.9693 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0252 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 695ms/step - accuracy: 0.9585 - auc: 0.9929 - f1_score: 0.9661 - loss: 0.1057 - precision: 0.9665 - recall: 0.9659 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0205 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 744ms/step - accuracy: 0.9630 - auc: 0.9932 - f1_score: 0.9691 - loss: 0.0969 - precision: 0.9686 - recall: 0.9711 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0183 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 741ms/step - accuracy: 0.9697 - auc: 0.9943 - f1_score: 0.9745 - loss: 0.0868 - precision: 0.9730 - recall: 0.9775 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0163 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 693ms/step - accuracy: 0.9728 - auc: 0.9966 - f1_score: 0.9774 - loss: 0.0730 - precision: 0.9782 - recall: 0.9770 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0178 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 741ms/step - accuracy: 0.9769 - auc: 0.9974 - f1_score: 0.9807 - loss: 0.0637 - precision: 0.9794 - recall: 0.9830 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0134 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 718ms/step - accuracy: 0.9753 - auc: 0.9974 - f1_score: 0.9794 - loss: 0.0634 - precision: 0.9774 - recall: 0.9827 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0103 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 685ms/step - accuracy: 0.9788 - auc: 0.9969 - f1_score: 0.9818 - loss: 0.0621 - precision: 0.9820 - recall: 0.9832 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0121 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 711ms/step - accuracy: 0.9755 - auc: 0.9963 - f1_score: 0.9795 - loss: 0.0710 - precision: 0.9787 - recall: 0.9812 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0132 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 729ms/step - accuracy: 0.9780 - auc: 0.9977 - f1_score: 0.9817 - loss: 0.0597 - precision: 0.9804 - recall: 0.9833 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0072 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 691ms/step - accuracy: 0.9810 - auc: 0.9977 - f1_score: 0.9829 - loss: 0.0558 - precision: 0.9817 - recall: 0.9872 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0077 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 706ms/step - accuracy: 0.9795 - auc: 0.9976 - f1_score: 0.9822 - loss: 0.0562 - precision: 0.9803 - recall: 0.9865 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0085 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 722ms/step - accuracy: 0.9798 - auc: 0.9980 - f1_score: 0.9829 - loss: 0.0530 - precision: 0.9843 - recall: 0.9826 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0073 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 711ms/step - accuracy: 0.9821 - auc: 0.9979 - f1_score: 0.9856 - loss: 0.0498 - precision: 0.9862 - recall: 0.9848 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0082 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 691ms/step - accuracy: 0.9790 - auc: 0.9982 - f1_score: 0.9828 - loss: 0.0520 - precision: 0.9838 - recall: 0.9821 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0070 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 722ms/step - accuracy: 0.9818 - auc: 0.9978 - f1_score: 0.9843 - loss: 0.0514 - precision: 0.9846 - recall: 0.9856 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0064 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 713ms/step - accuracy: 0.9822 - auc: 0.9973 - f1_score: 0.9849 - loss: 0.0522 - precision: 0.9852 - recall: 0.9859 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0077 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 684ms/step - accuracy: 0.9811 - auc: 0.9980 - f1_score: 0.9831 - loss: 0.0522 - precision: 0.9833 - recall: 0.9857 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0062 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 725ms/step - accuracy: 0.9789 - auc: 0.9980 - f1_score: 0.9825 - loss: 0.0521 - precision: 0.9841 - recall: 0.9813 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0091 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 723ms/step - accuracy: 0.9864 - auc: 0.9985 - f1_score: 0.9886 - loss: 0.0449 - precision: 0.9902 - recall: 0.9875 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0047 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 688ms/step - accuracy: 0.9828 - auc: 0.9983 - f1_score: 0.9859 - loss: 0.0472 - precision: 0.9842 - recall: 0.9881 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0053 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 716ms/step - accuracy: 0.9848 - auc: 0.9971 - f1_score: 0.9875 - loss: 0.0482 - precision: 0.9887 - recall: 0.9868 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0049 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 740ms/step - accuracy: 0.9795 - auc: 0.9978 - f1_score: 0.9830 - loss: 0.0564 - precision: 0.9825 - recall: 0.9841 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0046 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 679ms/step - accuracy: 0.9794 - auc: 0.9984 - f1_score: 0.9827 - loss: 0.0507 - precision: 0.9837 - recall: 0.9822 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0041 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 31/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 722ms/step - accuracy: 0.9866 - auc: 0.9987 - f1_score: 0.9890 - loss: 0.0393 - precision: 0.9912 - recall: 0.9870 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0027 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 32/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 732ms/step - accuracy: 0.9887 - auc: 0.9990 - f1_score: 0.9910 - loss: 0.0354 - precision: 0.9926 - recall: 0.9890 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0032 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 33/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 690ms/step - accuracy: 0.9810 - auc: 0.9979 - f1_score: 0.9839 - loss: 0.0508 - precision: 0.9843 - recall: 0.9850 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0039 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 34/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 711ms/step - accuracy: 0.9872 - auc: 0.9990 - f1_score: 0.9892 - loss: 0.0336 - precision: 0.9880 - recall: 0.9910 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0046 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 35/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 733ms/step - accuracy: 0.9905 - auc: 0.9993 - f1_score: 0.9918 - loss: 0.0295 - precision: 0.9914 - recall: 0.9930 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0048 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 36/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 545ms/step - accuracy: 0.9883 - auc: 0.9980 - f1_score: 0.9900 - loss: 0.0382 - precision: 0.9889 - recall: 0.9921\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 678ms/step - accuracy: 0.9883 - auc: 0.9980 - f1_score: 0.9900 - loss: 0.0382 - precision: 0.9889 - recall: 0.9921 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0039 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Training time: 6236.29 seconds\n",
      "Evaluating ResNet50V2 on The Wildfire Dataset_DeepFire_FIRE...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 620ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 629ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 607ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 645ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 629ms/step - accuracy: 0.8540 - auc: 0.8333 - f1_score: 0.4651 - loss: 0.4117 - precision: 0.7143 - recall: 0.7992\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.870192289352417,\n",
      "                'auc': 0.9380176067352295,\n",
      "                'f1_score': 0.6167563199996948,\n",
      "                'loss': 0.37522050738334656,\n",
      "                'precision': 0.8803088665008545,\n",
      "                'recall': 0.9083665609359741},\n",
      " 'history': {'accuracy': [0.8311471343040466,\n",
      "                          0.898019552230835,\n",
      "                          0.9180812835693359,\n",
      "                          0.9305555820465088,\n",
      "                          0.9354423880577087,\n",
      "                          0.9538323283195496,\n",
      "                          0.9560185074806213,\n",
      "                          0.9643775820732117,\n",
      "                          0.9641203880310059,\n",
      "                          0.9711934328079224,\n",
      "                          0.9724794030189514,\n",
      "                          0.9747942090034485,\n",
      "                          0.9765946269035339,\n",
      "                          0.9763374328613281,\n",
      "                          0.9737654328346252,\n",
      "                          0.9792952537536621,\n",
      "                          0.9803240895271301,\n",
      "                          0.9798096418380737,\n",
      "                          0.979938268661499,\n",
      "                          0.9817386865615845,\n",
      "                          0.9803240895271301,\n",
      "                          0.9803240895271301,\n",
      "                          0.979938268661499,\n",
      "                          0.980967104434967,\n",
      "                          0.9822530746459961,\n",
      "                          0.9863682985305786,\n",
      "                          0.9832819104194641,\n",
      "                          0.9849537014961243,\n",
      "                          0.9841821193695068,\n",
      "                          0.9819958806037903,\n",
      "                          0.9866254925727844,\n",
      "                          0.9871399402618408,\n",
      "                          0.9812242984771729,\n",
      "                          0.9867541193962097,\n",
      "                          0.9863682985305786,\n",
      "                          0.9863682985305786],\n",
      "             'auc': [0.8899145126342773,\n",
      "                     0.9599893093109131,\n",
      "                     0.9754461646080017,\n",
      "                     0.9803200960159302,\n",
      "                     0.9847099781036377,\n",
      "                     0.991527795791626,\n",
      "                     0.9915527701377869,\n",
      "                     0.9947726726531982,\n",
      "                     0.9936396479606628,\n",
      "                     0.9954671859741211,\n",
      "                     0.996088981628418,\n",
      "                     0.9966633319854736,\n",
      "                     0.9973915815353394,\n",
      "                     0.9962359070777893,\n",
      "                     0.9969351887702942,\n",
      "                     0.997901976108551,\n",
      "                     0.9976219534873962,\n",
      "                     0.9977647662162781,\n",
      "                     0.9978647232055664,\n",
      "                     0.9980244636535645,\n",
      "                     0.9981024861335754,\n",
      "                     0.9976077079772949,\n",
      "                     0.9966133832931519,\n",
      "                     0.9975466132164001,\n",
      "                     0.9982419610023499,\n",
      "                     0.9988471865653992,\n",
      "                     0.9982627034187317,\n",
      "                     0.9977933764457703,\n",
      "                     0.998697817325592,\n",
      "                     0.9984699487686157,\n",
      "                     0.9982947111129761,\n",
      "                     0.9988602995872498,\n",
      "                     0.9979584217071533,\n",
      "                     0.9987271428108215,\n",
      "                     0.9988792538642883,\n",
      "                     0.9979764819145203],\n",
      "             'f1_score': [0.8588034510612488,\n",
      "                          0.9156736135482788,\n",
      "                          0.9326897859573364,\n",
      "                          0.9422314763069153,\n",
      "                          0.9466373324394226,\n",
      "                          0.9615347385406494,\n",
      "                          0.9631867408752441,\n",
      "                          0.970533013343811,\n",
      "                          0.9698601961135864,\n",
      "                          0.9761136770248413,\n",
      "                          0.9769192337989807,\n",
      "                          0.9790045619010925,\n",
      "                          0.9804750680923462,\n",
      "                          0.9799334406852722,\n",
      "                          0.9781750440597534,\n",
      "                          0.9828431010246277,\n",
      "                          0.9835748076438904,\n",
      "                          0.9826430082321167,\n",
      "                          0.9829795956611633,\n",
      "                          0.9848677515983582,\n",
      "                          0.9837602972984314,\n",
      "                          0.9832797050476074,\n",
      "                          0.9829434156417847,\n",
      "                          0.9837639927864075,\n",
      "                          0.9852489829063416,\n",
      "                          0.9887017607688904,\n",
      "                          0.9858834743499756,\n",
      "                          0.9874062538146973,\n",
      "                          0.9868419170379639,\n",
      "                          0.9847383499145508,\n",
      "                          0.9886190295219421,\n",
      "                          0.9896240830421448,\n",
      "                          0.983917772769928,\n",
      "                          0.9887521266937256,\n",
      "                          0.988479495048523,\n",
      "                          0.9884041547775269],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513],\n",
      "             'loss': [0.4148242473602295,\n",
      "                      0.24994538724422455,\n",
      "                      0.19394800066947937,\n",
      "                      0.17354944348335266,\n",
      "                      0.15297850966453552,\n",
      "                      0.11580204218626022,\n",
      "                      0.11385784298181534,\n",
      "                      0.09087616950273514,\n",
      "                      0.09425663948059082,\n",
      "                      0.08042501658201218,\n",
      "                      0.07562126964330673,\n",
      "                      0.07033563405275345,\n",
      "                      0.061127446591854095,\n",
      "                      0.06717651337385178,\n",
      "                      0.06739464402198792,\n",
      "                      0.05661836639046669,\n",
      "                      0.05502431467175484,\n",
      "                      0.05492193251848221,\n",
      "                      0.05482950434088707,\n",
      "                      0.049492597579956055,\n",
      "                      0.05189773812890053,\n",
      "                      0.05299382656812668,\n",
      "                      0.059212278574705124,\n",
      "                      0.05275271460413933,\n",
      "                      0.048234257847070694,\n",
      "                      0.04016676917672157,\n",
      "                      0.04693102836608887,\n",
      "                      0.044296346604824066,\n",
      "                      0.04381996765732765,\n",
      "                      0.04670270159840584,\n",
      "                      0.042126405984163284,\n",
      "                      0.03784896805882454,\n",
      "                      0.04808363318443298,\n",
      "                      0.03665757179260254,\n",
      "                      0.03831569850444794,\n",
      "                      0.0419805534183979],\n",
      "             'precision': [0.8603242635726929,\n",
      "                           0.9172601699829102,\n",
      "                           0.9304601550102234,\n",
      "                           0.9426298141479492,\n",
      "                           0.9448720812797546,\n",
      "                           0.9617874026298523,\n",
      "                           0.9613536596298218,\n",
      "                           0.9694879651069641,\n",
      "                           0.9688740372657776,\n",
      "                           0.9755229949951172,\n",
      "                           0.9772631525993347,\n",
      "                           0.9784473776817322,\n",
      "                           0.9793189764022827,\n",
      "                           0.9819517135620117,\n",
      "                           0.9784067273139954,\n",
      "                           0.9827948212623596,\n",
      "                           0.9836134314537048,\n",
      "                           0.9818333387374878,\n",
      "                           0.9840570688247681,\n",
      "                           0.9846638441085815,\n",
      "                           0.9852941036224365,\n",
      "                           0.9831649661064148,\n",
      "                           0.9842668175697327,\n",
      "                           0.9850746393203735,\n",
      "                           0.9849151372909546,\n",
      "                           0.9899095892906189,\n",
      "                           0.9845640659332275,\n",
      "                           0.9880302548408508,\n",
      "                           0.9862155318260193,\n",
      "                           0.9848068952560425,\n",
      "                           0.9901198148727417,\n",
      "                           0.99055415391922,\n",
      "                           0.9850996732711792,\n",
      "                           0.988452672958374,\n",
      "                           0.9894247055053711,\n",
      "                           0.9876310229301453],\n",
      "             'recall': [0.8386973738670349,\n",
      "                        0.916684091091156,\n",
      "                        0.936504602432251,\n",
      "                        0.9442114233970642,\n",
      "                        0.9504080414772034,\n",
      "                        0.9631953239440918,\n",
      "                        0.9670099020004272,\n",
      "                        0.9725366830825806,\n",
      "                        0.9727349281311035,\n",
      "                        0.9775681495666504,\n",
      "                        0.9776747822761536,\n",
      "                        0.9804990291595459,\n",
      "                        0.9826032519340515,\n",
      "                        0.979485034942627,\n",
      "                        0.9788171052932739,\n",
      "                        0.983413815498352,\n",
      "                        0.9842337369918823,\n",
      "                        0.985331118106842,\n",
      "                        0.9832320213317871,\n",
      "                        0.9854919910430908,\n",
      "                        0.9826105237007141,\n",
      "                        0.9846153855323792,\n",
      "                        0.9830295443534851,\n",
      "                        0.9838337302207947,\n",
      "                        0.9861547946929932,\n",
      "                        0.9878330230712891,\n",
      "                        0.9882746934890747,\n",
      "                        0.9874081611633301,\n",
      "                        0.9880728125572205,\n",
      "                        0.9856388568878174,\n",
      "                        0.9880427718162537,\n",
      "                        0.9884792566299438,\n",
      "                        0.9842734336853027,\n",
      "                        0.9899075031280518,\n",
      "                        0.9881706833839417,\n",
      "                        0.9901219010353088],\n",
      "             'val_accuracy': [0.9453125,\n",
      "                              0.9754464030265808,\n",
      "                              0.98828125,\n",
      "                              0.99609375,\n",
      "                              0.9933035969734192,\n",
      "                              0.9972098469734192,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.989983081817627,\n",
      "                         0.9981469511985779,\n",
      "                         0.9993530511856079,\n",
      "                         0.9999082684516907,\n",
      "                         0.9998573660850525,\n",
      "                         0.999983012676239,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999998807907104,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         0.9999999403953552],\n",
      "             'val_f1_score': [0.9534926414489746,\n",
      "                              0.9787160754203796,\n",
      "                              0.9904235005378723,\n",
      "                              0.9966523051261902,\n",
      "                              0.9940983653068542,\n",
      "                              0.9977507591247559,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.18024054169654846,\n",
      "                          0.11024240404367447,\n",
      "                          0.0753977969288826,\n",
      "                          0.05589044466614723,\n",
      "                          0.049988389015197754,\n",
      "                          0.03269822522997856,\n",
      "                          0.02524690516293049,\n",
      "                          0.020463287830352783,\n",
      "                          0.0183497816324234,\n",
      "                          0.016299748793244362,\n",
      "                          0.0177762433886528,\n",
      "                          0.013392155058681965,\n",
      "                          0.010327470488846302,\n",
      "                          0.012130136601626873,\n",
      "                          0.01319377776235342,\n",
      "                          0.007246074266731739,\n",
      "                          0.007717641536146402,\n",
      "                          0.008456112816929817,\n",
      "                          0.007347673177719116,\n",
      "                          0.008160778321325779,\n",
      "                          0.007023172918707132,\n",
      "                          0.006370633840560913,\n",
      "                          0.007701423484832048,\n",
      "                          0.0061504733748734,\n",
      "                          0.009114542976021767,\n",
      "                          0.004701248370110989,\n",
      "                          0.005251519847661257,\n",
      "                          0.004939664620906115,\n",
      "                          0.00455458601936698,\n",
      "                          0.0040574101731181145,\n",
      "                          0.002736397786065936,\n",
      "                          0.0032012031879276037,\n",
      "                          0.0038824088405817747,\n",
      "                          0.004565814044326544,\n",
      "                          0.004849706776440144,\n",
      "                          0.003915892913937569],\n",
      "             'val_precision': [0.9699530601501465,\n",
      "                               0.9915730357170105,\n",
      "                               0.9908842444419861,\n",
      "                               0.9981464147567749,\n",
      "                               0.9945105314254761,\n",
      "                               0.9990800619125366,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.9399453997612,\n",
      "                            0.9680073261260986,\n",
      "                            0.9899817705154419,\n",
      "                            0.9953789114952087,\n",
      "                            0.9945105314254761,\n",
      "                            0.9963302612304688,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.5925486087799072,\n",
      " 'train_counts': {'fire': 2245, 'nofire': 2161},\n",
      " 'train_dataset_size': 7776,\n",
      " 'training_time': 6236.287673711777,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_dataset_size': 1792}\n",
      "Training model: ResNet50V2 on dataset: The Wildfire Dataset_DeepFire_Forest Fire\n",
      "Epoch 1/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 713ms/step - accuracy: 0.8123 - auc: 0.9100 - f1_score: 0.8407 - loss: 0.4449 - precision: 0.8715 - recall: 0.8481 - val_accuracy: 0.9731 - val_auc: 0.9970 - val_f1_score: 0.9776 - val_loss: 0.1142 - val_precision: 0.9755 - val_recall: 0.9809 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 701ms/step - accuracy: 0.9108 - auc: 0.9708 - f1_score: 0.9264 - loss: 0.2134 - precision: 0.9222 - recall: 0.9324 - val_accuracy: 0.9913 - val_auc: 0.9997 - val_f1_score: 0.9931 - val_loss: 0.0624 - val_precision: 0.9890 - val_recall: 0.9970 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 703ms/step - accuracy: 0.9414 - auc: 0.9845 - f1_score: 0.9516 - loss: 0.1535 - precision: 0.9494 - recall: 0.9560 - val_accuracy: 0.9920 - val_auc: 1.0000 - val_f1_score: 0.9932 - val_loss: 0.0541 - val_precision: 1.0000 - val_recall: 0.9868 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 716ms/step - accuracy: 0.9538 - auc: 0.9900 - f1_score: 0.9619 - loss: 0.1232 - precision: 0.9630 - recall: 0.9618 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0260 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 731ms/step - accuracy: 0.9631 - auc: 0.9939 - f1_score: 0.9697 - loss: 0.0973 - precision: 0.9702 - recall: 0.9698 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0217 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 725ms/step - accuracy: 0.9682 - auc: 0.9956 - f1_score: 0.9734 - loss: 0.0819 - precision: 0.9702 - recall: 0.9779 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0141 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 713ms/step - accuracy: 0.9695 - auc: 0.9955 - f1_score: 0.9741 - loss: 0.0799 - precision: 0.9734 - recall: 0.9766 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0129 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 718ms/step - accuracy: 0.9774 - auc: 0.9972 - f1_score: 0.9809 - loss: 0.0641 - precision: 0.9805 - recall: 0.9828 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0106 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 728ms/step - accuracy: 0.9760 - auc: 0.9969 - f1_score: 0.9796 - loss: 0.0644 - precision: 0.9802 - recall: 0.9807 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0125 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 703ms/step - accuracy: 0.9762 - auc: 0.9968 - f1_score: 0.9799 - loss: 0.0651 - precision: 0.9805 - recall: 0.9807 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0078 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 720ms/step - accuracy: 0.9782 - auc: 0.9975 - f1_score: 0.9816 - loss: 0.0600 - precision: 0.9811 - recall: 0.9833 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0084 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 719ms/step - accuracy: 0.9816 - auc: 0.9976 - f1_score: 0.9849 - loss: 0.0501 - precision: 0.9859 - recall: 0.9839 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0050 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 697ms/step - accuracy: 0.9832 - auc: 0.9981 - f1_score: 0.9859 - loss: 0.0481 - precision: 0.9855 - recall: 0.9871 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0057 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 703ms/step - accuracy: 0.9793 - auc: 0.9976 - f1_score: 0.9825 - loss: 0.0553 - precision: 0.9823 - recall: 0.9839 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0050 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 711ms/step - accuracy: 0.9831 - auc: 0.9981 - f1_score: 0.9859 - loss: 0.0485 - precision: 0.9879 - recall: 0.9847 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0048 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 731ms/step - accuracy: 0.9839 - auc: 0.9975 - f1_score: 0.9869 - loss: 0.0480 - precision: 0.9867 - recall: 0.9873 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0049 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 706ms/step - accuracy: 0.9821 - auc: 0.9980 - f1_score: 0.9849 - loss: 0.0506 - precision: 0.9859 - recall: 0.9850 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0051 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 706ms/step - accuracy: 0.9868 - auc: 0.9983 - f1_score: 0.9890 - loss: 0.0392 - precision: 0.9891 - recall: 0.9893 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0039 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 707ms/step - accuracy: 0.9866 - auc: 0.9986 - f1_score: 0.9886 - loss: 0.0391 - precision: 0.9902 - recall: 0.9880 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0035 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 732ms/step - accuracy: 0.9858 - auc: 0.9987 - f1_score: 0.9881 - loss: 0.0394 - precision: 0.9897 - recall: 0.9871 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0036 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 709ms/step - accuracy: 0.9882 - auc: 0.9988 - f1_score: 0.9902 - loss: 0.0348 - precision: 0.9902 - recall: 0.9904 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0050 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 704ms/step - accuracy: 0.9856 - auc: 0.9987 - f1_score: 0.9881 - loss: 0.0416 - precision: 0.9882 - recall: 0.9883 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0039 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 713ms/step - accuracy: 0.9857 - auc: 0.9989 - f1_score: 0.9878 - loss: 0.0382 - precision: 0.9881 - recall: 0.9884 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 730ms/step - accuracy: 0.9898 - auc: 0.9992 - f1_score: 0.9913 - loss: 0.0296 - precision: 0.9914 - recall: 0.9919 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0027 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 707ms/step - accuracy: 0.9877 - auc: 0.9989 - f1_score: 0.9898 - loss: 0.0356 - precision: 0.9899 - recall: 0.9901 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0030 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 703ms/step - accuracy: 0.9854 - auc: 0.9990 - f1_score: 0.9876 - loss: 0.0378 - precision: 0.9865 - recall: 0.9899 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0037 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 703ms/step - accuracy: 0.9884 - auc: 0.9992 - f1_score: 0.9901 - loss: 0.0301 - precision: 0.9886 - recall: 0.9925 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0031 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 716ms/step - accuracy: 0.9863 - auc: 0.9991 - f1_score: 0.9887 - loss: 0.0342 - precision: 0.9893 - recall: 0.9883 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0026 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 705ms/step - accuracy: 0.9880 - auc: 0.9984 - f1_score: 0.9900 - loss: 0.0362 - precision: 0.9906 - recall: 0.9899 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0017 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 703ms/step - accuracy: 0.9900 - auc: 0.9991 - f1_score: 0.9914 - loss: 0.0278 - precision: 0.9930 - recall: 0.9906 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0020 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 31/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 712ms/step - accuracy: 0.9888 - auc: 0.9987 - f1_score: 0.9905 - loss: 0.0327 - precision: 0.9904 - recall: 0.9913 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0028 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 32/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 732ms/step - accuracy: 0.9891 - auc: 0.9990 - f1_score: 0.9910 - loss: 0.0311 - precision: 0.9905 - recall: 0.9918 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0021 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 33/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 708ms/step - accuracy: 0.9884 - auc: 0.9991 - f1_score: 0.9899 - loss: 0.0296 - precision: 0.9905 - recall: 0.9906 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0019 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 34/80\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573ms/step - accuracy: 0.9892 - auc: 0.9989 - f1_score: 0.9902 - loss: 0.0311 - precision: 0.9903 - recall: 0.9922\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 701ms/step - accuracy: 0.9893 - auc: 0.9989 - f1_score: 0.9902 - loss: 0.0311 - precision: 0.9903 - recall: 0.9922 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0025 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Training time: 10272.42 seconds\n",
      "Evaluating ResNet50V2 on The Wildfire Dataset_DeepFire_Forest Fire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 553ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 570ms/step - accuracy: 0.8656 - auc: 0.8311 - f1_score: 0.4665 - loss: 0.4663 - precision: 0.7164 - recall: 0.8210\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.8774038553237915,\n",
      "                'auc': 0.9381685256958008,\n",
      "                'f1_score': 0.6168261766433716,\n",
      "                'loss': 0.40280669927597046,\n",
      "                'precision': 0.8787878751754761,\n",
      "                'recall': 0.9243028163909912},\n",
      " 'history': {'accuracy': [0.8583431839942932,\n",
      "                          0.9178950190544128,\n",
      "                          0.9417010545730591,\n",
      "                          0.95703125,\n",
      "                          0.9610112309455872,\n",
      "                          0.9693396091461182,\n",
      "                          0.9730984568595886,\n",
      "                          0.9765625,\n",
      "                          0.9764150977134705,\n",
      "                          0.9764150977134705,\n",
      "                          0.9795106053352356,\n",
      "                          0.9825324416160583,\n",
      "                          0.981869101524353,\n",
      "                          0.9812057614326477,\n",
      "                          0.9828272461891174,\n",
      "                          0.9845224022865295,\n",
      "                          0.9831220507621765,\n",
      "                          0.9871020317077637,\n",
      "                          0.9862175583839417,\n",
      "                          0.9859227538108826,\n",
      "                          0.9875442385673523,\n",
      "                          0.9851857423782349,\n",
      "                          0.9861438870429993,\n",
      "                          0.9886497855186462,\n",
      "                          0.9874705076217651,\n",
      "                          0.9860701560974121,\n",
      "                          0.9879864454269409,\n",
      "                          0.9885023832321167,\n",
      "                          0.9883549809455872,\n",
      "                          0.9891656637191772,\n",
      "                          0.9884286522865295,\n",
      "                          0.9892393946647644,\n",
      "                          0.9894604682922363,\n",
      "                          0.9903449416160583],\n",
      "             'auc': [0.9328662157058716,\n",
      "                     0.9744777679443359,\n",
      "                     0.9857529997825623,\n",
      "                     0.9915925860404968,\n",
      "                     0.9934946298599243,\n",
      "                     0.9956367611885071,\n",
      "                     0.9963892102241516,\n",
      "                     0.9971153736114502,\n",
      "                     0.9971255660057068,\n",
      "                     0.9967858791351318,\n",
      "                     0.9975908398628235,\n",
      "                     0.9980432987213135,\n",
      "                     0.997764527797699,\n",
      "                     0.9977450966835022,\n",
      "                     0.9979479908943176,\n",
      "                     0.9979863166809082,\n",
      "                     0.9983144402503967,\n",
      "                     0.998211681842804,\n",
      "                     0.9982834458351135,\n",
      "                     0.9986722469329834,\n",
      "                     0.9987010955810547,\n",
      "                     0.9986787438392639,\n",
      "                     0.998749852180481,\n",
      "                     0.9989704489707947,\n",
      "                     0.9987735152244568,\n",
      "                     0.9989029169082642,\n",
      "                     0.999031126499176,\n",
      "                     0.9992492198944092,\n",
      "                     0.9984503984451294,\n",
      "                     0.9990540742874146,\n",
      "                     0.9986412525177002,\n",
      "                     0.9988202452659607,\n",
      "                     0.9990544319152832,\n",
      "                     0.9989409446716309],\n",
      "             'f1_score': [0.8818362951278687,\n",
      "                          0.9321656227111816,\n",
      "                          0.9517832398414612,\n",
      "                          0.9643256068229675,\n",
      "                          0.9677560925483704,\n",
      "                          0.9742775559425354,\n",
      "                          0.9774455428123474,\n",
      "                          0.9801038503646851,\n",
      "                          0.9799547791481018,\n",
      "                          0.9801920056343079,\n",
      "                          0.9826613664627075,\n",
      "                          0.9857326745986938,\n",
      "                          0.9848063588142395,\n",
      "                          0.9841110706329346,\n",
      "                          0.9856202006340027,\n",
      "                          0.9870878458023071,\n",
      "                          0.9858592748641968,\n",
      "                          0.9890760779380798,\n",
      "                          0.9883313179016113,\n",
      "                          0.9882004857063293,\n",
      "                          0.9896445870399475,\n",
      "                          0.9879181385040283,\n",
      "                          0.988333523273468,\n",
      "                          0.9903131127357483,\n",
      "                          0.9895623326301575,\n",
      "                          0.9882427453994751,\n",
      "                          0.989856481552124,\n",
      "                          0.9905397891998291,\n",
      "                          0.9902922511100769,\n",
      "                          0.9907543063163757,\n",
      "                          0.9901663661003113,\n",
      "                          0.9909089803695679,\n",
      "                          0.991092324256897,\n",
      "                          0.9916219711303711],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513],\n",
      "             'loss': [0.3365989625453949,\n",
      "                      0.19862714409828186,\n",
      "                      0.1481243222951889,\n",
      "                      0.11403463780879974,\n",
      "                      0.09926070272922516,\n",
      "                      0.08069423586130142,\n",
      "                      0.07232686132192612,\n",
      "                      0.06433504819869995,\n",
      "                      0.06408973783254623,\n",
      "                      0.0637686625123024,\n",
      "                      0.05579572170972824,\n",
      "                      0.047879572957754135,\n",
      "                      0.05180718004703522,\n",
      "                      0.05135054141283035,\n",
      "                      0.04851880669593811,\n",
      "                      0.045532796531915665,\n",
      "                      0.04758067801594734,\n",
      "                      0.04193733632564545,\n",
      "                      0.04106004163622856,\n",
      "                      0.03775191307067871,\n",
      "                      0.036311760544776917,\n",
      "                      0.039274100214242935,\n",
      "                      0.03867402300238609,\n",
      "                      0.0320916622877121,\n",
      "                      0.036924418061971664,\n",
      "                      0.03747706860303879,\n",
      "                      0.03193695470690727,\n",
      "                      0.030048811808228493,\n",
      "                      0.03477625548839569,\n",
      "                      0.02921164222061634,\n",
      "                      0.0330965593457222,\n",
      "                      0.0322905071079731,\n",
      "                      0.028217360377311707,\n",
      "                      0.02862420119345188],\n",
      "             'precision': [0.8887618780136108,\n",
      "                           0.9307203888893127,\n",
      "                           0.9499701261520386,\n",
      "                           0.9636276364326477,\n",
      "                           0.9670224189758301,\n",
      "                           0.9727654457092285,\n",
      "                           0.977242648601532,\n",
      "                           0.9794110655784607,\n",
      "                           0.9793443083763123,\n",
      "                           0.9803286790847778,\n",
      "                           0.982376217842102,\n",
      "                           0.9860442876815796,\n",
      "                           0.9846246242523193,\n",
      "                           0.9834035038948059,\n",
      "                           0.986878514289856,\n",
      "                           0.9866522550582886,\n",
      "                           0.9865449070930481,\n",
      "                           0.9887168407440186,\n",
      "                           0.9885954260826111,\n",
      "                           0.9889542460441589,\n",
      "                           0.9901157021522522,\n",
      "                           0.988550066947937,\n",
      "                           0.9893797039985657,\n",
      "                           0.9906125664710999,\n",
      "                           0.9897848963737488,\n",
      "                           0.9883258938789368,\n",
      "                           0.9892112016677856,\n",
      "                           0.9914478659629822,\n",
      "                           0.990620493888855,\n",
      "                           0.9918032884597778,\n",
      "                           0.990859866142273,\n",
      "                           0.9908763766288757,\n",
      "                           0.9915774464607239,\n",
      "                           0.9918200373649597],\n",
      "             'recall': [0.8803080320358276,\n",
      "                        0.9354294538497925,\n",
      "                        0.9553313851356506,\n",
      "                        0.9665186405181885,\n",
      "                        0.9694638252258301,\n",
      "                        0.9772206544876099,\n",
      "                        0.9787747263908386,\n",
      "                        0.9824687838554382,\n",
      "                        0.9821751117706299,\n",
      "                        0.9812702536582947,\n",
      "                        0.9842642545700073,\n",
      "                        0.9854514598846436,\n",
      "                        0.985808789730072,\n",
      "                        0.9858934283256531,\n",
      "                        0.985099732875824,\n",
      "                        0.9880780577659607,\n",
      "                        0.9859526753425598,\n",
      "                        0.9902620911598206,\n",
      "                        0.9889516234397888,\n",
      "                        0.9881237745285034,\n",
      "                        0.9895193576812744,\n",
      "                        0.9872412085533142,\n",
      "                        0.9879488945007324,\n",
      "                        0.990851104259491,\n",
      "                        0.9897848963737488,\n",
      "                        0.9889209866523743,\n",
      "                        0.9912312030792236,\n",
      "                        0.9897787570953369,\n",
      "                        0.9903823137283325,\n",
      "                        0.9904899597167969,\n",
      "                        0.9902644157409668,\n",
      "                        0.9915905594825745,\n",
      "                        0.9912196397781372,\n",
      "                        0.9924169182777405],\n",
      "             'val_accuracy': [0.9730817079544067,\n",
      "                              0.9913366436958313,\n",
      "                              0.9919554591178894,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.996986985206604,\n",
      "                         0.999740481376648,\n",
      "                         0.9999943971633911,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0000001192092896,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0000001192092896,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999998807907104],\n",
      "             'val_f1_score': [0.9775980710983276,\n",
      "                              0.9931334853172302,\n",
      "                              0.9931966066360474,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.11421561241149902,\n",
      "                          0.06236305832862854,\n",
      "                          0.0540856309235096,\n",
      "                          0.026005197316408157,\n",
      "                          0.021742435172200203,\n",
      "                          0.01414481457322836,\n",
      "                          0.012855606153607368,\n",
      "                          0.010626033879816532,\n",
      "                          0.012528005987405777,\n",
      "                          0.007844250649213791,\n",
      "                          0.00835662055760622,\n",
      "                          0.004980254918336868,\n",
      "                          0.005722010508179665,\n",
      "                          0.005032975692301989,\n",
      "                          0.004838813561946154,\n",
      "                          0.004931949079036713,\n",
      "                          0.005092578940093517,\n",
      "                          0.0038736118003726006,\n",
      "                          0.0034642957616597414,\n",
      "                          0.0036438729148358107,\n",
      "                          0.004957595840096474,\n",
      "                          0.003923971205949783,\n",
      "                          0.0029262849129736423,\n",
      "                          0.0027178728487342596,\n",
      "                          0.0030164963100105524,\n",
      "                          0.0036636157892644405,\n",
      "                          0.003142746863886714,\n",
      "                          0.0025729865301400423,\n",
      "                          0.001748609938658774,\n",
      "                          0.002022029832005501,\n",
      "                          0.0027718155179172754,\n",
      "                          0.002056462224572897,\n",
      "                          0.0018954065162688494,\n",
      "                          0.002459160750731826],\n",
      "             'val_precision': [0.9754999876022339,\n",
      "                               0.9889557957649231,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.980894923210144,\n",
      "                            0.9969635605812073,\n",
      "                            0.9867751598358154,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.8458356261253357,\n",
      " 'train_counts': {'fire': 3601, 'nofire': 4417},\n",
      " 'train_dataset_size': 13568,\n",
      " 'training_time': 10272.41883802414,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_dataset_size': 3232}\n",
      "Training model: ResNet50V2 on dataset: The Wildfire Dataset_FIRE_Forest Fire\n",
      "Epoch 1/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 719ms/step - accuracy: 0.8069 - auc: 0.9035 - f1_score: 0.8338 - loss: 0.4773 - precision: 0.8667 - recall: 0.8489 - val_accuracy: 0.9674 - val_auc: 0.9955 - val_f1_score: 0.9724 - val_loss: 0.1265 - val_precision: 0.9758 - val_recall: 0.9711 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 718ms/step - accuracy: 0.9125 - auc: 0.9711 - f1_score: 0.9280 - loss: 0.2113 - precision: 0.9289 - recall: 0.9298 - val_accuracy: 0.9891 - val_auc: 0.9996 - val_f1_score: 0.9908 - val_loss: 0.0675 - val_precision: 0.9962 - val_recall: 0.9861 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 714ms/step - accuracy: 0.9342 - auc: 0.9821 - f1_score: 0.9450 - loss: 0.1636 - precision: 0.9410 - recall: 0.9521 - val_accuracy: 0.9961 - val_auc: 1.0000 - val_f1_score: 0.9968 - val_loss: 0.0441 - val_precision: 0.9979 - val_recall: 0.9958 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 714ms/step - accuracy: 0.9501 - auc: 0.9885 - f1_score: 0.9588 - loss: 0.1300 - precision: 0.9602 - recall: 0.9589 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0336 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 715ms/step - accuracy: 0.9583 - auc: 0.9913 - f1_score: 0.9656 - loss: 0.1141 - precision: 0.9636 - recall: 0.9685 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0212 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 714ms/step - accuracy: 0.9617 - auc: 0.9931 - f1_score: 0.9684 - loss: 0.1013 - precision: 0.9667 - recall: 0.9709 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0206 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m286s\u001b[0m 718ms/step - accuracy: 0.9690 - auc: 0.9956 - f1_score: 0.9744 - loss: 0.0805 - precision: 0.9717 - recall: 0.9777 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0159 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 724ms/step - accuracy: 0.9785 - auc: 0.9975 - f1_score: 0.9821 - loss: 0.0615 - precision: 0.9821 - recall: 0.9826 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0121 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m324s\u001b[0m 815ms/step - accuracy: 0.9742 - auc: 0.9964 - f1_score: 0.9781 - loss: 0.0730 - precision: 0.9773 - recall: 0.9803 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0101 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 1s/step - accuracy: 0.9777 - auc: 0.9969 - f1_score: 0.9808 - loss: 0.0635 - precision: 0.9810 - recall: 0.9825 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0075 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 1s/step - accuracy: 0.9782 - auc: 0.9974 - f1_score: 0.9813 - loss: 0.0593 - precision: 0.9830 - recall: 0.9812 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0088 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 1s/step - accuracy: 0.9794 - auc: 0.9978 - f1_score: 0.9822 - loss: 0.0560 - precision: 0.9807 - recall: 0.9855 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0063 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 1s/step - accuracy: 0.9817 - auc: 0.9980 - f1_score: 0.9847 - loss: 0.0520 - precision: 0.9843 - recall: 0.9860 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0064 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 1s/step - accuracy: 0.9790 - auc: 0.9978 - f1_score: 0.9818 - loss: 0.0523 - precision: 0.9811 - recall: 0.9846 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0065 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 1s/step - accuracy: 0.9796 - auc: 0.9973 - f1_score: 0.9831 - loss: 0.0520 - precision: 0.9823 - recall: 0.9847 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0066 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 1s/step - accuracy: 0.9841 - auc: 0.9985 - f1_score: 0.9867 - loss: 0.0419 - precision: 0.9865 - recall: 0.9877 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0058 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 1s/step - accuracy: 0.9837 - auc: 0.9987 - f1_score: 0.9864 - loss: 0.0396 - precision: 0.9893 - recall: 0.9841 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0044 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 1s/step - accuracy: 0.9860 - auc: 0.9979 - f1_score: 0.9881 - loss: 0.0438 - precision: 0.9887 - recall: 0.9884 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0039 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 1s/step - accuracy: 0.9811 - auc: 0.9980 - f1_score: 0.9840 - loss: 0.0492 - precision: 0.9850 - recall: 0.9841 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0045 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 1s/step - accuracy: 0.9842 - auc: 0.9988 - f1_score: 0.9866 - loss: 0.0406 - precision: 0.9866 - recall: 0.9878 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0027 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 1s/step - accuracy: 0.9829 - auc: 0.9981 - f1_score: 0.9855 - loss: 0.0459 - precision: 0.9871 - recall: 0.9849 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0028 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m588s\u001b[0m 1s/step - accuracy: 0.9874 - auc: 0.9987 - f1_score: 0.9896 - loss: 0.0356 - precision: 0.9911 - recall: 0.9884 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0031 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m571s\u001b[0m 1s/step - accuracy: 0.9866 - auc: 0.9985 - f1_score: 0.9888 - loss: 0.0401 - precision: 0.9889 - recall: 0.9892 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0030 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 1s/step - accuracy: 0.9895 - auc: 0.9991 - f1_score: 0.9911 - loss: 0.0307 - precision: 0.9903 - recall: 0.9926 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0022 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 1s/step - accuracy: 0.9872 - auc: 0.9987 - f1_score: 0.9892 - loss: 0.0385 - precision: 0.9911 - recall: 0.9882 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0025 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 852ms/step - accuracy: 0.9873 - auc: 0.9984 - f1_score: 0.9897 - loss: 0.0381 - precision: 0.9905 - recall: 0.9890 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0026 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 825ms/step - accuracy: 0.9860 - auc: 0.9985 - f1_score: 0.9882 - loss: 0.0374 - precision: 0.9885 - recall: 0.9889 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0021 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 743ms/step - accuracy: 0.9847 - auc: 0.9976 - f1_score: 0.9873 - loss: 0.0485 - precision: 0.9885 - recall: 0.9868 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0031 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.9890 - auc: 0.9993 - f1_score: 0.9904 - loss: 0.0310 - precision: 0.9909 - recall: 0.9913\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 817ms/step - accuracy: 0.9890 - auc: 0.9993 - f1_score: 0.9904 - loss: 0.0310 - precision: 0.9909 - recall: 0.9913 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0026 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 758ms/step - accuracy: 0.9912 - auc: 0.9988 - f1_score: 0.9923 - loss: 0.0272 - precision: 0.9912 - recall: 0.9945 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0026 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 728ms/step - accuracy: 0.9904 - auc: 0.9985 - f1_score: 0.9918 - loss: 0.0323 - precision: 0.9917 - recall: 0.9927 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0026 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m398/398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 808ms/step - accuracy: 0.9889 - auc: 0.9985 - f1_score: 0.9905 - loss: 0.0327 - precision: 0.9896 - recall: 0.9922 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0022 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Training time: 13092.52 seconds\n",
      "Evaluating ResNet50V2 on The Wildfire Dataset_FIRE_Forest Fire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 649ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 670ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 658ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 656ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 659ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 646ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 686ms/step - accuracy: 0.8646 - auc: 0.8334 - f1_score: 0.4665 - loss: 0.4816 - precision: 0.7247 - recall: 0.8100\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.8822115659713745,\n",
      "                'auc': 0.940088152885437,\n",
      "                'f1_score': 0.6198199391365051,\n",
      "                'loss': 0.4196343421936035,\n",
      "                'precision': 0.8914728760719299,\n",
      "                'recall': 0.9163346886634827},\n",
      " 'history': {'accuracy': [0.8555276393890381,\n",
      "                          0.9170854091644287,\n",
      "                          0.9367148280143738,\n",
      "                          0.9506124258041382,\n",
      "                          0.9633322954177856,\n",
      "                          0.9640389680862427,\n",
      "                          0.970634400844574,\n",
      "                          0.9766802787780762,\n",
      "                          0.9744032621383667,\n",
      "                          0.9777795076370239,\n",
      "                          0.9781721234321594,\n",
      "                          0.9809202551841736,\n",
      "                          0.9815483689308167,\n",
      "                          0.981783926486969,\n",
      "                          0.9813128113746643,\n",
      "                          0.9838253855705261,\n",
      "                          0.9846105575561523,\n",
      "                          0.9855527877807617,\n",
      "                          0.9824120402336121,\n",
      "                          0.9855527877807617,\n",
      "                          0.984375,\n",
      "                          0.9868875741958618,\n",
      "                          0.9870445728302002,\n",
      "                          0.987672746181488,\n",
      "                          0.9877512454986572,\n",
      "                          0.9878297448158264,\n",
      "                          0.9867305159568787,\n",
      "                          0.9857097864151001,\n",
      "                          0.9884579181671143,\n",
      "                          0.992226779460907,\n",
      "                          0.9897927045822144,\n",
      "                          0.9897927045822144],\n",
      "             'auc': [0.9292072057723999,\n",
      "                     0.9739777445793152,\n",
      "                     0.9828739762306213,\n",
      "                     0.9891893267631531,\n",
      "                     0.9934591054916382,\n",
      "                     0.994178831577301,\n",
      "                     0.9954942464828491,\n",
      "                     0.9971009492874146,\n",
      "                     0.9964081048965454,\n",
      "                     0.9976203441619873,\n",
      "                     0.9970849752426147,\n",
      "                     0.9977685809135437,\n",
      "                     0.9980679750442505,\n",
      "                     0.9980071187019348,\n",
      "                     0.9978935718536377,\n",
      "                     0.998010516166687,\n",
      "                     0.9986591339111328,\n",
      "                     0.9981829524040222,\n",
      "                     0.9980253577232361,\n",
      "                     0.9986929297447205,\n",
      "                     0.9982405304908752,\n",
      "                     0.9987815618515015,\n",
      "                     0.9988160133361816,\n",
      "                     0.9987202882766724,\n",
      "                     0.9985260367393494,\n",
      "                     0.9985851645469666,\n",
      "                     0.9984370470046997,\n",
      "                     0.9981536269187927,\n",
      "                     0.9991450309753418,\n",
      "                     0.999198317527771,\n",
      "                     0.9985799193382263,\n",
      "                     0.9989484548568726],\n",
      "             'f1_score': [0.8785596489906311,\n",
      "                          0.931631326675415,\n",
      "                          0.9473305940628052,\n",
      "                          0.95906662940979,\n",
      "                          0.9693681001663208,\n",
      "                          0.9703575372695923,\n",
      "                          0.9754191637039185,\n",
      "                          0.9805981516838074,\n",
      "                          0.9785768985748291,\n",
      "                          0.9814465641975403,\n",
      "                          0.9815341830253601,\n",
      "                          0.9836907982826233,\n",
      "                          0.9844347834587097,\n",
      "                          0.9845317006111145,\n",
      "                          0.9842053651809692,\n",
      "                          0.9862906336784363,\n",
      "                          0.9871043562889099,\n",
      "                          0.9876832365989685,\n",
      "                          0.985102117061615,\n",
      "                          0.9877080321311951,\n",
      "                          0.9866359829902649,\n",
      "                          0.9890586137771606,\n",
      "                          0.989185631275177,\n",
      "                          0.9895278811454773,\n",
      "                          0.9896759986877441,\n",
      "                          0.9898906350135803,\n",
      "                          0.9887695908546448,\n",
      "                          0.9879249334335327,\n",
      "                          0.9901816248893738,\n",
      "                          0.9933758974075317,\n",
      "                          0.991435706615448,\n",
      "                          0.9912385940551758],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257],\n",
      "             'loss': [0.34977880120277405,\n",
      "                      0.19971083104610443,\n",
      "                      0.15973573923110962,\n",
      "                      0.127733051776886,\n",
      "                      0.09988915175199509,\n",
      "                      0.09362740069627762,\n",
      "                      0.07985405623912811,\n",
      "                      0.0645909309387207,\n",
      "                      0.07007633149623871,\n",
      "                      0.05844489485025406,\n",
      "                      0.061685580760240555,\n",
      "                      0.05378149077296257,\n",
      "                      0.05088076367974281,\n",
      "                      0.04887915030121803,\n",
      "                      0.04951063171029091,\n",
      "                      0.04534747824072838,\n",
      "                      0.04062294214963913,\n",
      "                      0.04133656620979309,\n",
      "                      0.04866771027445793,\n",
      "                      0.03772559389472008,\n",
      "                      0.04168768599629402,\n",
      "                      0.035739466547966,\n",
      "                      0.03623591735959053,\n",
      "                      0.03604480251669884,\n",
      "                      0.03678043559193611,\n",
      "                      0.03702761232852936,\n",
      "                      0.036473628133535385,\n",
      "                      0.04380359873175621,\n",
      "                      0.032524459064006805,\n",
      "                      0.02544657327234745,\n",
      "                      0.03194718062877655,\n",
      "                      0.030371613800525665],\n",
      "             'precision': [0.8856205344200134,\n",
      "                           0.9291418194770813,\n",
      "                           0.9443524479866028,\n",
      "                           0.9584342837333679,\n",
      "                           0.967384397983551,\n",
      "                           0.968502938747406,\n",
      "                           0.9750702977180481,\n",
      "                           0.9804472923278809,\n",
      "                           0.9790864586830139,\n",
      "                           0.9814364314079285,\n",
      "                           0.9820742607116699,\n",
      "                           0.9837179780006409,\n",
      "                           0.9841675162315369,\n",
      "                           0.984644889831543,\n",
      "                           0.9835794568061829,\n",
      "                           0.9863311052322388,\n",
      "                           0.9880707859992981,\n",
      "                           0.9878345727920532,\n",
      "                           0.9855350852012634,\n",
      "                           0.987709641456604,\n",
      "                           0.9868066906929016,\n",
      "                           0.9899974465370178,\n",
      "                           0.9896339774131775,\n",
      "                           0.9887266159057617,\n",
      "                           0.9902539253234863,\n",
      "                           0.9905237555503845,\n",
      "                           0.9886247515678406,\n",
      "                           0.9888561367988586,\n",
      "                           0.99094158411026,\n",
      "                           0.9930911064147949,\n",
      "                           0.9921994805335999,\n",
      "                           0.9910290837287903],\n",
      "             'recall': [0.8792083859443665,\n",
      "                        0.9365018606185913,\n",
      "                        0.9526011347770691,\n",
      "                        0.9612532258033752,\n",
      "                        0.9729625582695007,\n",
      "                        0.9729695320129395,\n",
      "                        0.9770689010620117,\n",
      "                        0.9815762639045715,\n",
      "                        0.9790864586830139,\n",
      "                        0.9823167324066162,\n",
      "                        0.9823257923126221,\n",
      "                        0.9851071834564209,\n",
      "                        0.9858037829399109,\n",
      "                        0.9856538772583008,\n",
      "                        0.986089825630188,\n",
      "                        0.9873401522636414,\n",
      "                        0.9868050217628479,\n",
      "                        0.988594114780426,\n",
      "                        0.9857874512672424,\n",
      "                        0.9887222647666931,\n",
      "                        0.9876922965049744,\n",
      "                        0.988602876663208,\n",
      "                        0.9892541766166687,\n",
      "                        0.9911390542984009,\n",
      "                        0.9897462129592896,\n",
      "                        0.9896366596221924,\n",
      "                        0.9897632598876953,\n",
      "                        0.9878438711166382,\n",
      "                        0.9903098344802856,\n",
      "                        0.9942359328269958,\n",
      "                        0.9911854863166809,\n",
      "                        0.992300808429718],\n",
      "             'val_accuracy': [0.9674342274665833,\n",
      "                              0.9891447424888611,\n",
      "                              0.996052622795105,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9954779744148254,\n",
      "                         0.9996219873428345,\n",
      "                         0.9999641180038452,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.9724072813987732,\n",
      "                              0.9907518029212952,\n",
      "                              0.9968183040618896,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.1265089362859726,\n",
      "                          0.06745366007089615,\n",
      "                          0.044087789952754974,\n",
      "                          0.03359740227460861,\n",
      "                          0.021236198022961617,\n",
      "                          0.020603658631443977,\n",
      "                          0.015912065282464027,\n",
      "                          0.012108872644603252,\n",
      "                          0.010095857083797455,\n",
      "                          0.0075191291980445385,\n",
      "                          0.008810359984636307,\n",
      "                          0.006322820670902729,\n",
      "                          0.0064461915753781796,\n",
      "                          0.006488461047410965,\n",
      "                          0.006629034876823425,\n",
      "                          0.005822105798870325,\n",
      "                          0.004413170274347067,\n",
      "                          0.003929393365979195,\n",
      "                          0.004509519785642624,\n",
      "                          0.0026536339428275824,\n",
      "                          0.0028356502298265696,\n",
      "                          0.003103043185546994,\n",
      "                          0.0030439167749136686,\n",
      "                          0.002227138727903366,\n",
      "                          0.0024806982837617397,\n",
      "                          0.0025714419316500425,\n",
      "                          0.0021455518435686827,\n",
      "                          0.0030568172223865986,\n",
      "                          0.0025887012016028166,\n",
      "                          0.002572550904005766,\n",
      "                          0.002568885451182723,\n",
      "                          0.002173644257709384],\n",
      "             'val_precision': [0.9757673740386963,\n",
      "                               0.9962304830551147,\n",
      "                               0.9978712201118469,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.971061110496521,\n",
      "                            0.9861407279968262,\n",
      "                            0.9957514405250549,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.7439208626747131,\n",
      " 'train_counts': {'fire': 3596, 'nofire': 3901},\n",
      " 'train_dataset_size': 12736,\n",
      " 'training_time': 13092.515852212906,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_dataset_size': 3040}\n",
      "Training model: ResNet50V2 on dataset: DeepFire_FIRE_Forest Fire\n",
      "Epoch 1/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 773ms/step - accuracy: 0.9449 - auc: 0.9833 - f1_score: 0.9419 - loss: 0.1315 - precision: 0.9440 - recall: 0.9463 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0053 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 818ms/step - accuracy: 0.9846 - auc: 0.9989 - f1_score: 0.9846 - loss: 0.0374 - precision: 0.9884 - recall: 0.9809 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0015 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 789ms/step - accuracy: 0.9938 - auc: 0.9998 - f1_score: 0.9928 - loss: 0.0170 - precision: 0.9920 - recall: 0.9954 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0013 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 829ms/step - accuracy: 0.9927 - auc: 0.9997 - f1_score: 0.9927 - loss: 0.0177 - precision: 0.9943 - recall: 0.9912 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.7639e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 751ms/step - accuracy: 0.9922 - auc: 0.9995 - f1_score: 0.9919 - loss: 0.0213 - precision: 0.9943 - recall: 0.9903 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.9942e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 734ms/step - accuracy: 0.9945 - auc: 0.9997 - f1_score: 0.9943 - loss: 0.0146 - precision: 0.9948 - recall: 0.9942 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.5762e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 748ms/step - accuracy: 0.9973 - auc: 1.0000 - f1_score: 0.9970 - loss: 0.0090 - precision: 0.9971 - recall: 0.9974 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.9460e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 788ms/step - accuracy: 0.9965 - auc: 1.0000 - f1_score: 0.9967 - loss: 0.0083 - precision: 0.9977 - recall: 0.9952 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2794e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 976ms/step - accuracy: 0.9970 - auc: 0.9997 - f1_score: 0.9964 - loss: 0.0091 - precision: 0.9965 - recall: 0.9974 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.8504e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 814ms/step - accuracy: 0.9963 - auc: 0.9996 - f1_score: 0.9956 - loss: 0.0116 - precision: 0.9961 - recall: 0.9965 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 2.0709e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 729ms/step - accuracy: 0.9968 - auc: 1.0000 - f1_score: 0.9966 - loss: 0.0083 - precision: 0.9968 - recall: 0.9968 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2739e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 918ms/step - accuracy: 0.9977 - auc: 1.0000 - f1_score: 0.9976 - loss: 0.0056 - precision: 0.9983 - recall: 0.9969 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.6875e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941ms/step - accuracy: 0.9983 - auc: 1.0000 - f1_score: 0.9984 - loss: 0.0049 - precision: 0.9987 - recall: 0.9980\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 1s/step - accuracy: 0.9983 - auc: 1.0000 - f1_score: 0.9984 - loss: 0.0049 - precision: 0.9987 - recall: 0.9980 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 1.2206e-04 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 993ms/step - accuracy: 0.9980 - auc: 0.9996 - f1_score: 0.9979 - loss: 0.0079 - precision: 0.9983 - recall: 0.9977 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.7393e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 716ms/step - accuracy: 0.9980 - auc: 1.0000 - f1_score: 0.9982 - loss: 0.0046 - precision: 0.9994 - recall: 0.9969 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 5.5312e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 16/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 1s/step - accuracy: 0.9987 - auc: 1.0000 - f1_score: 0.9984 - loss: 0.0036 - precision: 0.9983 - recall: 0.9991 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 7.9513e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 1s/step - accuracy: 0.9984 - auc: 1.0000 - f1_score: 0.9986 - loss: 0.0041 - precision: 0.9995 - recall: 0.9974 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 6.0319e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: 0.9996 - auc: 1.0000 - f1_score: 0.9994 - loss: 0.0024 - precision: 0.9993 - recall: 0.9998\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 892ms/step - accuracy: 0.9996 - auc: 1.0000 - f1_score: 0.9994 - loss: 0.0024 - precision: 0.9993 - recall: 0.9998 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.0594e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 898ms/step - accuracy: 0.9989 - auc: 1.0000 - f1_score: 0.9987 - loss: 0.0034 - precision: 0.9986 - recall: 0.9992 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.1636e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 908ms/step - accuracy: 0.9992 - auc: 0.9998 - f1_score: 0.9991 - loss: 0.0030 - precision: 0.9992 - recall: 0.9992 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.6522e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 1s/step - accuracy: 0.9982 - auc: 1.0000 - f1_score: 0.9976 - loss: 0.0040 - precision: 0.9978 - recall: 0.9985 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.9011e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 1s/step - accuracy: 0.9988 - auc: 1.0000 - f1_score: 0.9987 - loss: 0.0030 - precision: 0.9990 - recall: 0.9985 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.6213e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940ms/step - accuracy: 0.9994 - auc: 0.9998 - f1_score: 0.9995 - loss: 0.0038 - precision: 0.9997 - recall: 0.9991\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 1s/step - accuracy: 0.9994 - auc: 0.9998 - f1_score: 0.9995 - loss: 0.0038 - precision: 0.9997 - recall: 0.9991 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.3939e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.5000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 891ms/step - accuracy: 0.9993 - auc: 1.0000 - f1_score: 0.9993 - loss: 0.0025 - precision: 0.9992 - recall: 0.9995 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.8378e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 828ms/step - accuracy: 0.9988 - auc: 1.0000 - f1_score: 0.9988 - loss: 0.0031 - precision: 0.9988 - recall: 0.9989 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.7098e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 1s/step - accuracy: 0.9993 - auc: 1.0000 - f1_score: 0.9994 - loss: 0.0018 - precision: 0.9996 - recall: 0.9990 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.8218e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 898ms/step - accuracy: 0.9995 - auc: 1.0000 - f1_score: 0.9994 - loss: 0.0018 - precision: 0.9996 - recall: 0.9994 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 4.4820e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 557ms/step - accuracy: 0.9997 - auc: 1.0000 - f1_score: 0.9996 - loss: 0.0017 - precision: 0.9996 - recall: 0.9998\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 702ms/step - accuracy: 0.9997 - auc: 1.0000 - f1_score: 0.9996 - loss: 0.0017 - precision: 0.9996 - recall: 0.9998 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 3.7518e-05 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 1.2500e-04\n",
      "Training time: 9140.50 seconds\n",
      "Evaluating ResNet50V2 on DeepFire_FIRE_Forest Fire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 613ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 616ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 610ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 627ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 666ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 643ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 604ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 619ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 644ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 620ms/step - accuracy: 0.6502 - auc: 0.6412 - f1_score: 0.4359 - loss: 2.2921 - precision: 0.5516 - recall: 0.7665\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.6899038553237915,\n",
      "                'auc': 0.7110044956207275,\n",
      "                'f1_score': 0.5718502998352051,\n",
      "                'loss': 1.9627649784088135,\n",
      "                'precision': 0.7046979665756226,\n",
      "                'recall': 0.8366534113883972},\n",
      " 'history': {'accuracy': [0.9745435118675232,\n",
      "                          0.988500714302063,\n",
      "                          0.9932408928871155,\n",
      "                          0.9925386309623718,\n",
      "                          0.9931530952453613,\n",
      "                          0.9948209524154663,\n",
      "                          0.9961376190185547,\n",
      "                          0.9969276785850525,\n",
      "                          0.9964887499809265,\n",
      "                          0.9968398809432983,\n",
      "                          0.9966643452644348,\n",
      "                          0.9978932738304138,\n",
      "                          0.9982444047927856,\n",
      "                          0.9985077381134033,\n",
      "                          0.9988588690757751,\n",
      "                          0.998771071434021,\n",
      "                          0.9986832737922668,\n",
      "                          0.9988588690757751,\n",
      "                          0.9990344047546387,\n",
      "                          0.9991222023963928,\n",
      "                          0.9989466071128845,\n",
      "                          0.9990344047546387,\n",
      "                          0.9994733333587646,\n",
      "                          0.998771071434021,\n",
      "                          0.9989466071128845,\n",
      "                          0.9990344047546387,\n",
      "                          0.999561071395874,\n",
      "                          0.999561071395874],\n",
      "             'auc': [0.9944391250610352,\n",
      "                     0.999311625957489,\n",
      "                     0.9996223449707031,\n",
      "                     0.9996345043182373,\n",
      "                     0.999537467956543,\n",
      "                     0.999718427658081,\n",
      "                     0.9999373555183411,\n",
      "                     0.9999635815620422,\n",
      "                     0.9997634887695312,\n",
      "                     0.9998608827590942,\n",
      "                     0.9999353289604187,\n",
      "                     0.9999823570251465,\n",
      "                     0.999988317489624,\n",
      "                     0.999809741973877,\n",
      "                     0.9999905228614807,\n",
      "                     0.9999904036521912,\n",
      "                     0.9999904036521912,\n",
      "                     0.9999948740005493,\n",
      "                     0.9999938011169434,\n",
      "                     0.9999057650566101,\n",
      "                     0.9999951124191284,\n",
      "                     0.9999969601631165,\n",
      "                     0.9999068379402161,\n",
      "                     0.9999918937683105,\n",
      "                     0.9999948143959045,\n",
      "                     0.9999966025352478,\n",
      "                     0.9999986290931702,\n",
      "                     0.9999936819076538],\n",
      "             'f1_score': [0.9733759760856628,\n",
      "                          0.9881923794746399,\n",
      "                          0.9925640225410461,\n",
      "                          0.9921655654907227,\n",
      "                          0.9924721717834473,\n",
      "                          0.9945133328437805,\n",
      "                          0.9959656596183777,\n",
      "                          0.996920645236969,\n",
      "                          0.9958370923995972,\n",
      "                          0.9961089491844177,\n",
      "                          0.9964069128036499,\n",
      "                          0.9976562261581421,\n",
      "                          0.9982095956802368,\n",
      "                          0.9983569979667664,\n",
      "                          0.9987835884094238,\n",
      "                          0.9986509084701538,\n",
      "                          0.9987130165100098,\n",
      "                          0.9986695647239685,\n",
      "                          0.9988170862197876,\n",
      "                          0.9990991950035095,\n",
      "                          0.998723566532135,\n",
      "                          0.9988195896148682,\n",
      "                          0.9994479417800903,\n",
      "                          0.9985074400901794,\n",
      "                          0.9988313913345337,\n",
      "                          0.9989004135131836,\n",
      "                          0.9995626211166382,\n",
      "                          0.9992743730545044],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814],\n",
      "             'loss': [0.06815482676029205,\n",
      "                      0.02915610373020172,\n",
      "                      0.01858830265700817,\n",
      "                      0.01811744086444378,\n",
      "                      0.018873564898967743,\n",
      "                      0.013917416334152222,\n",
      "                      0.010394482873380184,\n",
      "                      0.007878893986344337,\n",
      "                      0.010271228849887848,\n",
      "                      0.009228820912539959,\n",
      "                      0.00943076517432928,\n",
      "                      0.005427315831184387,\n",
      "                      0.004813727922737598,\n",
      "                      0.005251256749033928,\n",
      "                      0.004002314060926437,\n",
      "                      0.003969368524849415,\n",
      "                      0.0038097952492535114,\n",
      "                      0.0032587051391601562,\n",
      "                      0.0032719557639211416,\n",
      "                      0.0032460519578307867,\n",
      "                      0.0030538616701960564,\n",
      "                      0.002414342015981674,\n",
      "                      0.003029831452295184,\n",
      "                      0.003367604920640588,\n",
      "                      0.0029951510950922966,\n",
      "                      0.0024403592105954885,\n",
      "                      0.002004204783588648,\n",
      "                      0.00225069560110569],\n",
      "             'precision': [0.967882513999939,\n",
      "                           0.990161657333374,\n",
      "                           0.9922521710395813,\n",
      "                           0.9929763078689575,\n",
      "                           0.9938639402389526,\n",
      "                           0.9949167370796204,\n",
      "                           0.9963047504425049,\n",
      "                           0.9971840977668762,\n",
      "                           0.9961349368095398,\n",
      "                           0.9964856505393982,\n",
      "                           0.9966701865196228,\n",
      "                           0.9980640411376953,\n",
      "                           0.9984254837036133,\n",
      "                           0.9984177350997925,\n",
      "                           0.999121904373169,\n",
      "                           0.9989442229270935,\n",
      "                           0.9989480972290039,\n",
      "                           0.9985986948013306,\n",
      "                           0.9985969662666321,\n",
      "                           0.9991223216056824,\n",
      "                           0.9989479184150696,\n",
      "                           0.9989472031593323,\n",
      "                           0.9994750022888184,\n",
      "                           0.9987693428993225,\n",
      "                           0.9987719058990479,\n",
      "                           0.9989464282989502,\n",
      "                           0.9998250007629395,\n",
      "                           0.9993010759353638],\n",
      "             'recall': [0.969447135925293,\n",
      "                        0.9868674278259277,\n",
      "                        0.9941778182983398,\n",
      "                        0.99210524559021,\n",
      "                        0.9924719929695129,\n",
      "                        0.9947423934936523,\n",
      "                        0.9959542751312256,\n",
      "                        0.9966578483581543,\n",
      "                        0.996835470199585,\n",
      "                        0.997186541557312,\n",
      "                        0.9966701865196228,\n",
      "                        0.9977128505706787,\n",
      "                        0.9980762600898743,\n",
      "                        0.998593270778656,\n",
      "                        0.9985957741737366,\n",
      "                        0.9985927939414978,\n",
      "                        0.9984229803085327,\n",
      "                        0.999123752117157,\n",
      "                        0.9994733929634094,\n",
      "                        0.9991223216056824,\n",
      "                        0.9989479184150696,\n",
      "                        0.9991225004196167,\n",
      "                        0.9994750022888184,\n",
      "                        0.9987693428993225,\n",
      "                        0.9991225004196167,\n",
      "                        0.999121904373169,\n",
      "                        0.999300479888916,\n",
      "                        0.9998251795768738],\n",
      "             'val_accuracy': [1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.005326918326318264,\n",
      "                          0.0014723454369232059,\n",
      "                          0.001315077068284154,\n",
      "                          0.00047639201511628926,\n",
      "                          0.00039942009607329965,\n",
      "                          0.00045761687215417624,\n",
      "                          0.00029459554934874177,\n",
      "                          0.00012793955102097243,\n",
      "                          0.00018504181934986264,\n",
      "                          0.00020709095406346023,\n",
      "                          0.00012738557416014373,\n",
      "                          0.00016875099390745163,\n",
      "                          0.00012206412793602794,\n",
      "                          5.7393401220906526e-05,\n",
      "                          5.531201168196276e-05,\n",
      "                          7.951292354846373e-05,\n",
      "                          6.031941302353516e-05,\n",
      "                          4.0594379242975265e-05,\n",
      "                          4.163613630225882e-05,\n",
      "                          3.652200393844396e-05,\n",
      "                          3.901114178006537e-05,\n",
      "                          3.621303403633647e-05,\n",
      "                          3.3938809792743996e-05,\n",
      "                          4.8377645725850016e-05,\n",
      "                          4.709803397418e-05,\n",
      "                          4.821836409973912e-05,\n",
      "                          4.482043732423335e-05,\n",
      "                          3.751785698113963e-05],\n",
      "             'val_precision': [1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.9851455688476562,\n",
      " 'train_counts': {'fire': 3626, 'nofire': 3504},\n",
      " 'train_dataset_size': 11392,\n",
      " 'training_time': 9140.50086426735,\n",
      " 'val_counts': {'fire': 0, 'nofire': 0},\n",
      " 'val_dataset_size': 2848}\n",
      "Training model: ResNet50V2 on dataset: The Wildfire Dataset_DeepFire_FIRE_Forest Fire\n",
      "Epoch 1/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 859ms/step - accuracy: 0.8136 - auc: 0.8581 - f1_score: 0.8386 - loss: 0.4555 - precision: 0.8390 - recall: 0.8351 - val_accuracy: 0.9792 - val_auc: 0.9969 - val_f1_score: 0.9827 - val_loss: 0.1083 - val_precision: 0.9840 - val_recall: 0.9823 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m542s\u001b[0m 1s/step - accuracy: 0.9169 - auc: 0.9740 - f1_score: 0.9314 - loss: 0.2006 - precision: 0.9321 - recall: 0.9325 - val_accuracy: 0.9893 - val_auc: 0.9996 - val_f1_score: 0.9911 - val_loss: 0.0602 - val_precision: 0.9884 - val_recall: 0.9942 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 1s/step - accuracy: 0.9393 - auc: 0.9856 - f1_score: 0.9500 - loss: 0.1496 - precision: 0.9493 - recall: 0.9521 - val_accuracy: 0.9986 - val_auc: 1.0000 - val_f1_score: 0.9988 - val_loss: 0.0333 - val_precision: 0.9986 - val_recall: 0.9991 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 864ms/step - accuracy: 0.9540 - auc: 0.9911 - f1_score: 0.9620 - loss: 0.1159 - precision: 0.9612 - recall: 0.9645 - val_accuracy: 0.9992 - val_auc: 1.0000 - val_f1_score: 0.9993 - val_loss: 0.0246 - val_precision: 0.9996 - val_recall: 0.9991 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m439s\u001b[0m 926ms/step - accuracy: 0.9651 - auc: 0.9952 - f1_score: 0.9706 - loss: 0.0887 - precision: 0.9702 - recall: 0.9728 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0159 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 980ms/step - accuracy: 0.9690 - auc: 0.9957 - f1_score: 0.9741 - loss: 0.0809 - precision: 0.9738 - recall: 0.9756 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0121 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 1s/step - accuracy: 0.9727 - auc: 0.9961 - f1_score: 0.9775 - loss: 0.0739 - precision: 0.9771 - recall: 0.9783 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0112 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 1s/step - accuracy: 0.9760 - auc: 0.9971 - f1_score: 0.9802 - loss: 0.0627 - precision: 0.9797 - recall: 0.9814 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0093 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 1s/step - accuracy: 0.9762 - auc: 0.9966 - f1_score: 0.9802 - loss: 0.0635 - precision: 0.9818 - recall: 0.9795 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0087 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m553s\u001b[0m 1s/step - accuracy: 0.9794 - auc: 0.9979 - f1_score: 0.9823 - loss: 0.0543 - precision: 0.9815 - recall: 0.9849 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0065 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 1s/step - accuracy: 0.9801 - auc: 0.9971 - f1_score: 0.9835 - loss: 0.0578 - precision: 0.9839 - recall: 0.9836 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0061 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m566s\u001b[0m 1s/step - accuracy: 0.9816 - auc: 0.9986 - f1_score: 0.9849 - loss: 0.0458 - precision: 0.9849 - recall: 0.9850 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0063 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 1s/step - accuracy: 0.9832 - auc: 0.9984 - f1_score: 0.9860 - loss: 0.0442 - precision: 0.9877 - recall: 0.9850 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0050 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 1s/step - accuracy: 0.9857 - auc: 0.9984 - f1_score: 0.9879 - loss: 0.0424 - precision: 0.9890 - recall: 0.9875 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0041 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 1s/step - accuracy: 0.9818 - auc: 0.9983 - f1_score: 0.9842 - loss: 0.0483 - precision: 0.9843 - recall: 0.9860 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0043 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 1s/step - accuracy: 0.9863 - auc: 0.9983 - f1_score: 0.9881 - loss: 0.0412 - precision: 0.9885 - recall: 0.9892 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0033 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 1s/step - accuracy: 0.9882 - auc: 0.9989 - f1_score: 0.9899 - loss: 0.0349 - precision: 0.9914 - recall: 0.9893 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0043 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m556s\u001b[0m 1s/step - accuracy: 0.9856 - auc: 0.9988 - f1_score: 0.9881 - loss: 0.0381 - precision: 0.9881 - recall: 0.9884 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0037 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 783ms/step - accuracy: 0.9872 - auc: 0.9989 - f1_score: 0.9892 - loss: 0.0363 - precision: 0.9900 - recall: 0.9891 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0023 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 709ms/step - accuracy: 0.9869 - auc: 0.9985 - f1_score: 0.9889 - loss: 0.0374 - precision: 0.9885 - recall: 0.9902 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0028 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 682ms/step - accuracy: 0.9876 - auc: 0.9986 - f1_score: 0.9894 - loss: 0.0364 - precision: 0.9888 - recall: 0.9910 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0033 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 668ms/step - accuracy: 0.9849 - auc: 0.9983 - f1_score: 0.9878 - loss: 0.0437 - precision: 0.9898 - recall: 0.9860 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0029 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 647ms/step - accuracy: 0.9856 - auc: 0.9989 - f1_score: 0.9880 - loss: 0.0368 - precision: 0.9891 - recall: 0.9875 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0027 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528ms/step - accuracy: 0.9854 - auc: 0.9988 - f1_score: 0.9879 - loss: 0.0392 - precision: 0.9890 - recall: 0.9872\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m474/474\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 652ms/step - accuracy: 0.9854 - auc: 0.9988 - f1_score: 0.9879 - loss: 0.0392 - precision: 0.9890 - recall: 0.9872 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_f1_score: 1.0000 - val_loss: 0.0036 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Training time: 11026.08 seconds\n",
      "Evaluating ResNet50V2 on The Wildfire Dataset_DeepFire_FIRE_Forest Fire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 480ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 506ms/step - accuracy: 0.8844 - auc: 0.8378 - f1_score: 0.4693 - loss: 0.3767 - precision: 0.7458 - recall: 0.8114\n",
      "Training results:\n",
      "{'evaluation': {'accuracy': 0.8966346383094788,\n",
      "                'auc': 0.9451647996902466,\n",
      "                'f1_score': 0.6223007440567017,\n",
      "                'loss': 0.34103286266326904,\n",
      "                'precision': 0.9094488024711609,\n",
      "                'recall': 0.9203187227249146},\n",
      " 'history': {'accuracy': [0.8615506291389465,\n",
      "                          0.9223365187644958,\n",
      "                          0.9460047483444214,\n",
      "                          0.9558939933776855,\n",
      "                          0.9663766026496887,\n",
      "                          0.9692115187644958,\n",
      "                          0.9752768874168396,\n",
      "                          0.9751450419425964,\n",
      "                          0.9780458807945251,\n",
      "                          0.981078565120697,\n",
      "                          0.981078565120697,\n",
      "                          0.9814082384109497,\n",
      "                          0.9826608896255493,\n",
      "                          0.9854958057403564,\n",
      "                          0.9833201766014099,\n",
      "                          0.986484706401825,\n",
      "                          0.987078070640564,\n",
      "                          0.9860891103744507,\n",
      "                          0.9866824746131897,\n",
      "                          0.9870121479034424,\n",
      "                          0.9871439933776855,\n",
      "                          0.9871439933776855,\n",
      "                          0.9872099161148071,\n",
      "                          0.9873417615890503],\n",
      "             'auc': [0.9165052175521851,\n",
      "                     0.9773512482643127,\n",
      "                     0.9877432584762573,\n",
      "                     0.9916338920593262,\n",
      "                     0.9954249858856201,\n",
      "                     0.9956169128417969,\n",
      "                     0.9964748024940491,\n",
      "                     0.9967149496078491,\n",
      "                     0.9969639182090759,\n",
      "                     0.9979490637779236,\n",
      "                     0.9973746538162231,\n",
      "                     0.9982922673225403,\n",
      "                     0.9982191324234009,\n",
      "                     0.998473584651947,\n",
      "                     0.9984099864959717,\n",
      "                     0.9984040260314941,\n",
      "                     0.9987474083900452,\n",
      "                     0.9987984895706177,\n",
      "                     0.9987868070602417,\n",
      "                     0.9986988306045532,\n",
      "                     0.9983165860176086,\n",
      "                     0.9987593293190002,\n",
      "                     0.9989487528800964,\n",
      "                     0.9989985823631287],\n",
      "             'f1_score': [0.8836725354194641,\n",
      "                          0.9357378482818604,\n",
      "                          0.9552313089370728,\n",
      "                          0.9632632732391357,\n",
      "                          0.9718586206436157,\n",
      "                          0.9741352200508118,\n",
      "                          0.9795413017272949,\n",
      "                          0.9793321490287781,\n",
      "                          0.9815647006034851,\n",
      "                          0.9840007424354553,\n",
      "                          0.9842166304588318,\n",
      "                          0.9845513701438904,\n",
      "                          0.9855016469955444,\n",
      "                          0.9878377318382263,\n",
      "                          0.9857959151268005,\n",
      "                          0.9882428646087646,\n",
      "                          0.9889432787895203,\n",
      "                          0.9884980916976929,\n",
      "                          0.988761305809021,\n",
      "                          0.9889845252037048,\n",
      "                          0.9889318943023682,\n",
      "                          0.9892825484275818,\n",
      "                          0.9891917705535889,\n",
      "                          0.9893919229507446],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513],\n",
      "             'loss': [0.3338364362716675,\n",
      "                      0.18681608140468597,\n",
      "                      0.13743633031845093,\n",
      "                      0.1129184439778328,\n",
      "                      0.08561570197343826,\n",
      "                      0.08072037994861603,\n",
      "                      0.06931442767381668,\n",
      "                      0.0659264475107193,\n",
      "                      0.05884380638599396,\n",
      "                      0.05250247195363045,\n",
      "                      0.05486614257097244,\n",
      "                      0.04803478717803955,\n",
      "                      0.046094100922346115,\n",
      "                      0.043764907866716385,\n",
      "                      0.04511897638440132,\n",
      "                      0.04121964052319527,\n",
      "                      0.03648184612393379,\n",
      "                      0.03767003118991852,\n",
      "                      0.03695179522037506,\n",
      "                      0.03702379763126373,\n",
      "                      0.038595058023929596,\n",
      "                      0.03648115321993828,\n",
      "                      0.035287678241729736,\n",
      "                      0.034697525203228],\n",
      "             'precision': [0.879725456237793,\n",
      "                           0.9354423880577087,\n",
      "                           0.9543702006340027,\n",
      "                           0.9621350169181824,\n",
      "                           0.9709383249282837,\n",
      "                           0.9747447371482849,\n",
      "                           0.979090690612793,\n",
      "                           0.9794601798057556,\n",
      "                           0.9822485446929932,\n",
      "                           0.9838709831237793,\n",
      "                           0.9847328066825867,\n",
      "                           0.9845178127288818,\n",
      "                           0.986438512802124,\n",
      "                           0.9884859323501587,\n",
      "                           0.9857127666473389,\n",
      "                           0.9887133240699768,\n",
      "                           0.9894883632659912,\n",
      "                           0.9888172149658203,\n",
      "                           0.9894623756408691,\n",
      "                           0.9892368912696838,\n",
      "                           0.9887254238128662,\n",
      "                           0.9892715215682983,\n",
      "                           0.989059329032898,\n",
      "                           0.9899978637695312],\n",
      "             'recall': [0.8788250684738159,\n",
      "                        0.9380578398704529,\n",
      "                        0.9577555656433105,\n",
      "                        0.9661654233932495,\n",
      "                        0.9742817282676697,\n",
      "                        0.9750591516494751,\n",
      "                        0.9806680083274841,\n",
      "                        0.9799870848655701,\n",
      "                        0.9819316267967224,\n",
      "                        0.9852482080459595,\n",
      "                        0.9844152927398682,\n",
      "                        0.985153317451477,\n",
      "                        0.9852719902992249,\n",
      "                        0.987848162651062,\n",
      "                        0.9870912432670593,\n",
      "                        0.9892449975013733,\n",
      "                        0.9894883632659912,\n",
      "                        0.988498330116272,\n",
      "                        0.9888244271278381,\n",
      "                        0.9895564317703247,\n",
      "                        0.9903205037117004,\n",
      "                        0.9898024797439575,\n",
      "                        0.9901213645935059,\n",
      "                        0.989359438419342],\n",
      "             'val_accuracy': [0.9791666865348816,\n",
      "                              0.9893091917037964,\n",
      "                              0.9986293911933899,\n",
      "                              0.9991776347160339,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_auc': [0.9968692660331726,\n",
      "                         0.9996309280395508,\n",
      "                         0.9999980926513672,\n",
      "                         0.9999986886978149,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0000001192092896,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         0.9999999403953552,\n",
      "                         1.0,\n",
      "                         1.0,\n",
      "                         1.0],\n",
      "             'val_f1_score': [0.9826786518096924,\n",
      "                              0.9910770654678345,\n",
      "                              0.9987940192222595,\n",
      "                              0.9993361830711365,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0,\n",
      "                              1.0],\n",
      "             'val_loss': [0.1083003506064415,\n",
      "                          0.060208991169929504,\n",
      "                          0.03334561735391617,\n",
      "                          0.02457759901881218,\n",
      "                          0.015945440158247948,\n",
      "                          0.012085768394172192,\n",
      "                          0.011161120608448982,\n",
      "                          0.009254622273147106,\n",
      "                          0.008748196065425873,\n",
      "                          0.006481311749666929,\n",
      "                          0.0060594831593334675,\n",
      "                          0.006303729023784399,\n",
      "                          0.004995913244783878,\n",
      "                          0.0041019851341843605,\n",
      "                          0.004294887650758028,\n",
      "                          0.0033174126874655485,\n",
      "                          0.004256447311490774,\n",
      "                          0.003658953821286559,\n",
      "                          0.002274642698466778,\n",
      "                          0.0027885902673006058,\n",
      "                          0.003316581016406417,\n",
      "                          0.0028542878571897745,\n",
      "                          0.0027230510022491217,\n",
      "                          0.003594096750020981],\n",
      "             'val_precision': [0.9840354919433594,\n",
      "                               0.9884341359138489,\n",
      "                               0.9986492395401001,\n",
      "                               0.9995543956756592,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0,\n",
      "                               1.0],\n",
      "             'val_recall': [0.9822930693626404,\n",
      "                            0.9941834211349487,\n",
      "                            0.99909907579422,\n",
      "                            0.999109148979187,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0]},\n",
      " 'optimal_threshold': 0.6961309909820557,\n",
      " 'train_counts': {'fire': 4356, 'nofire': 4661},\n",
      " 'train_dataset_size': 15168,\n",
      " 'training_time': 11026.081635475159,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_dataset_size': 3648}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"VGG19\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"VGG19\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,024,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ vgg19 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │    \u001b[38;5;34m20,024,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,159,041</span> (76.90 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,159,041\u001b[0m (76.90 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133,121</span> (520.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133,121\u001b[0m (520.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,025,920</span> (76.39 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20,025,920\u001b[0m (76.39 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MobileNetV3Small\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MobileNetV3Small\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MobileNetV3Small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MobileNetV3Small (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m)      │       \u001b[38;5;34m939,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m147,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,090,417</span> (4.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,090,417\u001b[0m (4.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">149,633</span> (584.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m149,633\u001b[0m (584.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">940,784</span> (3.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m940,784\u001b[0m (3.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MobileNetV2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MobileNetV2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │         \u001b[38;5;34m5,120\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,592,321</span> (9.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,592,321\u001b[0m (9.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331,265</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m331,265\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,261,056</span> (8.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,261,056\u001b[0m (8.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DenseNet121\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"DenseNet121\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │     \u001b[38;5;34m7,037,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m262,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,305,281</span> (27.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,305,281\u001b[0m (27.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">265,217</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m265,217\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,040,064</span> (26.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,040,064\u001b[0m (26.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"WildfireNet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"WildfireNet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m25,690,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,819,073</span> (98.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,819,073\u001b[0m (98.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,817,857</span> (98.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,817,857\u001b[0m (98.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> (4.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,216\u001b[0m (4.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_results = {}\n",
    "results_file = os.path.join(run_dir, 'training_results.json')\n",
    "\n",
    "for base_model, custom_bool in zip(all_models, is_custom_model):\n",
    "    model = generate_model(base_model, custom=custom_bool, run_dir=run_dir) # To display the model summary\n",
    "    model.summary()\n",
    "    model_dir = os.path.join(run_dir, model.name)\n",
    "    training_results[model.name] = {}\n",
    "    plot_model(model, show_shapes=True, show_layer_names=True, to_file=os.path.join(model_dir, f\"{model.name}_architecture.png\"))\n",
    "    for dataset_id, train_dataset, val_dataset, steps_per_epoch, validation_steps, train_counts_dict, val_counts_dict in training_params:\n",
    "        model = tf.keras.models.load_model(os.path.join(model_dir, f\"{model.name}_initial.keras\"))\n",
    "        print(f\"Training model: {model.name} on dataset: {dataset_id}\")\n",
    "        \n",
    "        # Record the start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Initial training of the model\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=val_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks_list\n",
    "        )\n",
    "\n",
    "        # Record the end time\n",
    "        end_time = time.time()\n",
    "        # Calculate the training time\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        model_ds_dir = os.path.join(run_dir, model.name, dataset_id)\n",
    "        os.makedirs(model_ds_dir, exist_ok=True)\n",
    "        # Save the model\n",
    "        model.save(os.path.join(model_ds_dir, f\"{model.name}_{dataset_id}.keras\"))\n",
    "\n",
    "        ### Evaluation stage ###\n",
    "        optimal_threshold = full_eval(model_ds_dir, history, model, dataset_id, test_dataset, true_labels, test_steps)\n",
    "        \n",
    "        training_results[model.name][dataset_id] = {\n",
    "            'history': history.history,\n",
    "            'training_time': training_time,\n",
    "            'optimal_threshold': float(optimal_threshold),\n",
    "            'train_dataset_size': steps_per_epoch * batch_size,\n",
    "            'val_dataset_size': validation_steps * batch_size,\n",
    "            'train_counts': train_counts_dict,\n",
    "            'val_counts': val_counts_dict,\n",
    "            \"evaluation\": model.evaluate(test_dataset, return_dict=True, steps=test_steps)\n",
    "        }\n",
    "        print(\"Training results:\")\n",
    "        pprint(training_results[model.name][dataset_id])\n",
    "        # Save the training results to a file after each iteration\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(training_results, f, indent=4)\n",
    "        \n",
    "        # model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list) # Reset the model for the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute force loop completed!\n",
      "All models and evaluations are available at: runs\\run_11\n"
     ]
    }
   ],
   "source": [
    "print(\"Brute force loop completed!\")\n",
    "print(f\"All models and evaluations are available at: {run_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1351460,
     "sourceId": 2247205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
