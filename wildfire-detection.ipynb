{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force Pipeline for Wildfire Detection - by Selman Tabet @ https://selman.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Dissertation\\Kaggle Data\\wildfire-detection\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaos\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "print(socket.gethostname())\n",
    "import os\n",
    "try: # for CUDA enviroment\n",
    "    os.system(\"nvidia-smi\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Data processing libraries\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "# ML libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Chart generating libraries\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from IPython import get_ipython\n",
    "from pprint import pprint\n",
    "\n",
    "# Custom helper libraries\n",
    "from default_params import *\n",
    "from wildfirenet import *\n",
    "from utils.img_processing import enforce_image_params\n",
    "from utils.dataset_processors import *\n",
    "from utils.plot_functions import *\n",
    "from utils.evaluator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES: None\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cuda_visible_devices = os.environ.get('CUDA_VISIBLE_DEVICES')\n",
    "print(f\"CUDA_VISIBLE_DEVICES: {cuda_visible_devices}\")\n",
    "print(tf.config.get_visible_devices())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse arguments from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Config Path: None\n",
      "No Python config file specified, using default config\n"
     ]
    }
   ],
   "source": [
    "# Detect if running in a Jupyter notebook\n",
    "def in_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        else:\n",
    "            return False  # Other type (terminal, etc.)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "    \n",
    "from_py = False\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Parse command line arguments\")\n",
    "parser.add_argument('--from-py-cfg', type=str,\n",
    "                    help='Path to the config Python file')\n",
    "if in_notebook():\n",
    "    args = parser.parse_args([])  # Ignore sys.argv\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "config_file_path = args.from_py_cfg\n",
    "print(f\"Python Config Path: {config_file_path}\")\n",
    "\n",
    "if config_file_path:\n",
    "    import importlib.util\n",
    "    spec = importlib.util.spec_from_file_location(\"config_module\", config_file_path)\n",
    "    config_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(config_module)\n",
    "    config = config_module.cfg\n",
    "    print(\"Loaded config from Python file:\")\n",
    "    pprint(config)\n",
    "    # Datasets, models, and hyperparameters are mandatory and must be processed now.\n",
    "    training_datasets = config.get('train', {})\n",
    "    if training_datasets is None or len(training_datasets) == 0:\n",
    "        raise ValueError(\"No train datasets defined in config.\")\n",
    "    full_test_dir = config.get('test')\n",
    "    base_models = config.get('keras_models', [])\n",
    "    custom_models = config.get('custom_models', [])\n",
    "    if base_models is None or len(base_models) == 0:\n",
    "        if custom_models is None or len(custom_models) == 0:\n",
    "            raise ValueError(\"No models defined in config.\")\n",
    "    \n",
    "    hyperparameters = config.get('hyperparameters')\n",
    "    default_hyperparameters = default_cfg.get('hyperparameters', {})\n",
    "    if hyperparameters is None or len(hyperparameters) == 0:\n",
    "        print(\"No training hyperparameters defined in config, using defaults.\")\n",
    "        hyperparameters = default_hyperparameters\n",
    "    else:\n",
    "        for key, value in default_hyperparameters.items():\n",
    "            if key not in hyperparameters:\n",
    "                print(f\"Missing parameter - falling back to default hyperparameter {key}:{default_hyperparameters[key]}\")\n",
    "                hyperparameters[key] = default_hyperparameters[key]\n",
    "    from_py = True # Successfully completed the import\n",
    "else:\n",
    "    print(\"No Python config file specified, using default config.\")\n",
    "    config = default_cfg\n",
    "    training_datasets = config.get('train', {})\n",
    "    base_models = config.get('keras_models', [])\n",
    "    custom_models = config.get('custom_models', [])\n",
    "    hyperparameters = config.get('hyperparameters')\n",
    "    full_test_dir = config.get('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models: [<function MobileNetV3Small at 0x00000290B3857BA0>, <Sequential name=WildfireNet, built=True>]\n",
      "Is custom model: [False, True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dirs = [training_datasets[ds].get('train') for ds in training_datasets]\n",
    "test_dirs = [training_datasets[ds].get('test') for ds in training_datasets]\n",
    "val_dirs = [training_datasets[ds].get('val') for ds in training_datasets]\n",
    "\n",
    "# Combine base_models and custom_models\n",
    "all_models = base_models + custom_models\n",
    "# Create a list to keep track of which models are custom\n",
    "is_custom_model = [False] * len(base_models) + [True] * len(custom_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if from_py:\n",
    "    epochs = hyperparameters.get('epochs')\n",
    "    batch_size = hyperparameters.get('batch_size')\n",
    "    img_height = config.get('image_height', default_cfg.get('image_height'))\n",
    "    img_width = config.get('image_width', default_cfg.get('image_width'))\n",
    "    optimizer_fn = config.get('optimizer', default_cfg.get('optimizer'))\n",
    "    loss_fn = config.get('loss', default_cfg.get('loss'))\n",
    "    callbacks_list = config.get('callbacks', default_cfg.get('callbacks'))\n",
    "    metrics_list = config.get('metrics', default_cfg.get('metrics'))\n",
    "    enforce_image_size = config.get('enforce_image_settings', default_cfg.get('enforce_image_settings'))\n",
    "else:\n",
    "    epochs = hyperparameters.get('epochs')\n",
    "    batch_size = hyperparameters.get('batch_size')\n",
    "    img_height = default_cfg.get('image_height')\n",
    "    img_width = default_cfg.get('image_width')\n",
    "    optimizer_fn = default_cfg.get('optimizer')\n",
    "    loss_fn = default_cfg.get('loss')\n",
    "    callbacks_list = default_cfg.get('callbacks')\n",
    "    metrics_list = default_cfg.get('metrics')\n",
    "    enforce_image_size = default_cfg.get('enforce_image_settings')\n",
    "\n",
    "checkpoint_path = os.path.join(\"checkpoint\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforce defined resolution and colour mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enforce_image_size:\n",
    "    all_dirs = train_dirs + test_dirs + val_dirs + [full_test_dir]\n",
    "    all_dirs = [d for d in all_dirs if d is not None]\n",
    "    for directory in all_dirs:\n",
    "        print(f\"Adjusting image properties in {directory}\")\n",
    "        enforce_image_params(directory, target_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: The Wildfire Dataset\n",
      "Augmenting The Wildfire Dataset\n",
      "Creating generators for training\n",
      "Found 1887 images belonging to 2 classes.\n",
      "Found 1887 images belonging to 2 classes.\n",
      "Creating generators for validation\n",
      "Found 402 images belonging to 2 classes.\n",
      "Found 402 images belonging to 2 classes.\n",
      "Number of samples in generator: 1887\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 730\n",
      "nofire: 1157\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 730\n",
      "nofire: 1157\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 1460\n",
      "nofire: 2314\n",
      "--------------------\n",
      "Processing: DeepFire\n",
      "Augmenting DeepFire\n",
      "Creating generators for training\n",
      "Found 1520 images belonging to 2 classes.\n",
      "Found 1520 images belonging to 2 classes.\n",
      "No validation set, splitting training set.\n",
      "Splitted dataset:\n",
      "Training dataset size: 2432 samples\n",
      "Validation dataset size: 608 samples\n",
      "Number of samples in generator: 1520\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 760\n",
      "nofire: 760\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 760\n",
      "nofire: 760\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 1520\n",
      "nofire: 1520\n",
      "--------------------\n",
      "Processing: FIRE\n",
      "Augmenting FIRE\n",
      "Creating generators for training\n",
      "Found 999 images belonging to 2 classes.\n",
      "Found 999 images belonging to 2 classes.\n",
      "No validation set, splitting training set.\n",
      "Splitted dataset:\n",
      "Training dataset size: 1599 samples\n",
      "Validation dataset size: 399 samples\n",
      "Number of samples in generator: 999\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 755\n",
      "nofire: 244\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 755\n",
      "nofire: 244\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 1510\n",
      "nofire: 488\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_names = []\n",
    "train_datasets = [] # [ (dataset_1_train, dataset_2_train), ... ]\n",
    "train_sizes = [] # [ (dataset_1_train_size, dataset_2_train_size), ... ]\n",
    "val_datasets = [] # [ (dataset_1_val, dataset_2_val), ... ]\n",
    "val_sizes = [] # [ (dataset_1_val_size, dataset_2_val_size), ... ]\n",
    "\n",
    "\n",
    "for d in training_datasets:\n",
    "    print(f\"Processing: {d}\")\n",
    "    train_dir = training_datasets[d].get('train')\n",
    "    augment = training_datasets[d].get('augment', True)\n",
    "    print(\"Augmenting\" if augment else \"Not augmenting\", d)\n",
    "    # Apply original and augmented data generators for training\n",
    "    print(\"Creating generators for training\")\n",
    "    train_generator, augmented_train_generator = create_generators(train_dir, batch_size=batch_size, augment=augment, img_width=img_width, img_height=img_height)\n",
    "    train_samples = samples_from_generators([train_generator, augmented_train_generator])  \n",
    "    train_dataset = generators_to_dataset([train_generator, augmented_train_generator], batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "    \n",
    "    # Apply original and augmented data generators for validation\n",
    "    if \"val\" in training_datasets[d]:\n",
    "        val_dir = training_datasets[d]['val']\n",
    "        print(\"Creating generators for validation\")\n",
    "        val_generator, augmented_val_generator = create_generators(val_dir, batch_size=batch_size, augment=augment, shuffle=False, img_width=img_width, img_height=img_height)\n",
    "        val_samples = samples_from_generators([val_generator, augmented_val_generator])\n",
    "        val_dataset = generators_to_dataset([train_generator, augmented_train_generator], batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "    else:\n",
    "        print(\"No validation set, splitting training set.\")\n",
    "        train_dataset, val_dataset, train_samples, val_samples = val_split(train_dataset, train_samples)\n",
    "        val_generator, augmented_val_generator = None, None\n",
    "    \n",
    "    # Calculate the number of samples for training and validation\n",
    "    train_sizes.append(train_samples)\n",
    "    val_sizes.append(val_samples)\n",
    "\n",
    "    show_counts_from_generators(train_generator, augmented_train_generator)\n",
    "\n",
    "    train_datasets.append(train_dataset)\n",
    "    val_datasets.append(val_dataset)\n",
    "    dataset_names.append(d)\n",
    "    \n",
    "# Ensure that the lengths are consistent across the board before continuing\n",
    "assert(len(train_sizes) == len(train_datasets) and len(train_sizes) == len(val_sizes) and len(val_sizes) == len(val_datasets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute Force Combinatorial Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_combos = [] # [(0,), (1,), (0, 1), ...] where 0, 1 are the indices of the datasets within their respective lists\n",
    "for r in range(1, len(dataset_names) + 1):\n",
    "    dataset_combos.extend(combinations(range(len(dataset_names)), r))\n",
    "combined_training_datasets = []\n",
    "combined_val_datasets = []\n",
    "combined_dataset_names = []\n",
    "steps_per_epoch_list = []\n",
    "validation_steps_list = []\n",
    "\n",
    "for combo in dataset_combos:\n",
    "    training_dataset = None\n",
    "    val_dataset = None\n",
    "    train_size = None\n",
    "    val_size = None\n",
    "    for idx in combo:\n",
    "        if training_dataset is None:\n",
    "            training_dataset = train_datasets[idx]\n",
    "            val_dataset = val_datasets[idx]\n",
    "            train_size = train_sizes[idx]\n",
    "            val_size = val_sizes[idx]\n",
    "        else:\n",
    "            training_dataset = training_dataset.concatenate(train_datasets[idx])\n",
    "            val_dataset = val_dataset.concatenate(val_datasets[idx])\n",
    "            train_size += train_sizes[idx]\n",
    "            val_size += val_sizes[idx]\n",
    "    combined_dataset_names.append(\"_\".join([dataset_names[idx] for idx in combo]))\n",
    "    combined_training_datasets.append(training_dataset)\n",
    "    combined_val_datasets.append(val_dataset)\n",
    "    steps_per_epoch_list.append(train_size // batch_size)\n",
    "    validation_steps_list.append(val_size // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 858 images belonging to 2 classes.\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "\n",
      "\n",
      "Test Dataset Class Counts:\n",
      "fire: 371\n",
      "nofire: 487\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if full_test_dir is None:\n",
    "    test_generators = []\n",
    "    print(\"No target test directory provided, merging all tests from provided datasets if available.\")\n",
    "    for d in test_dirs:\n",
    "        if d is not None:\n",
    "            test_generators.append(create_generators(d, batch_size=batch_size, augment=False, shuffle=False, img_height=img_height, img_width=img_width)[0]) # No augmentation/shuffle for testing\n",
    "    if len(test_generators) == 0:\n",
    "        raise ValueError(\"No tests found in the provided datasets.\")\n",
    "    true_labels = np.concatenate([gen.classes for gen in test_generators])\n",
    "    test_dataset = generators_to_dataset(test_generators, batch_size=batch_size)\n",
    "    test_steps = sum([gen.samples for gen in test_generators]) // batch_size\n",
    "    print(\"Test Dataset Class Counts:\")\n",
    "    for gen in test_generators:\n",
    "        print(\"Class indices:\", gen.class_indices)\n",
    "        for class_name, class_index in gen.class_indices.items():\n",
    "            print(f\"{class_name}: {sum(gen.classes == class_index)}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "else:\n",
    "    test_generator, augmented_test_generator = create_generators(full_test_dir, batch_size=batch_size, augment=False, shuffle=False, img_height=img_height, img_width=img_width) # No augmentation/shuffle for testing\n",
    "    test_dataset = create_dataset(test_generator, batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "    test_steps = test_generator.samples // batch_size\n",
    "    true_labels = test_generator.classes\n",
    "    print(\"Class indices:\", test_generator.class_indices)\n",
    "    print(\"\\n\")\n",
    "    print(\"Test Dataset Class Counts:\")\n",
    "    for class_name, class_index in test_generator.class_indices.items():\n",
    "        print(f\"{class_name}: {sum(test_generator.classes == class_index)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "true_labels = true_labels[: (len(true_labels) // batch_size) * batch_size] # Ensure that the true labels are divisible by the batch size to avoid size mismatch with predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_model(bm, custom=False):\n",
    "    if custom:\n",
    "        model = bm\n",
    "        model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list)\n",
    "        model.save_weights(os.path.join(checkpoint_path, f\"{model.name}_initial.weights.h5\"))    \n",
    "        return model\n",
    "    \n",
    "    base_model = bm(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(img_height, img_width, 3)\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create the model\n",
    "    inputs = Input(shape=(img_height, img_width, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=bm.__name__)\n",
    "    model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list)\n",
    "    model.save_weights(os.path.join(checkpoint_path, f\"{model.name}_initial.weights.h5\"))    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the models and combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "run_number = len([d for d in os.listdir(\"runs\") if os.path.isdir(os.path.join(\"runs\", d)) and d.startswith('run_')]) + 1\n",
    "run_dir = os.path.join(\"runs\", f\"run_{run_number}\")\n",
    "os.makedirs(run_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MobileNetV3Small\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MobileNetV3Small\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MobileNetV3Small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MobileNetV3Small (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m)      │       \u001b[38;5;34m939,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m147,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,090,417</span> (4.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,090,417\u001b[0m (4.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">149,633</span> (584.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m149,633\u001b[0m (584.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">940,784</span> (3.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m940,784\u001b[0m (3.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: MobileNetV3Small on dataset: The Wildfire Dataset\n",
      "Epoch 1/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 170ms/step - accuracy: 0.6149 - auc: 0.6826 - f1_score: 0.6429 - loss: 0.7686 - precision: 0.7215 - recall: 0.5944 - val_accuracy: 0.5987 - val_auc: 0.6427 - val_f1_score: 0.7453 - val_loss: 0.6687 - val_precision: 0.5987 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7151 - auc: 0.7761 - f1_score: 0.7654 - loss: 0.6004 - precision: 0.7753 - recall: 0.7611 - val_accuracy: 0.6037 - val_auc: 0.8335 - val_f1_score: 0.7501 - val_loss: 0.6549 - val_precision: 0.6037 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.7435 - auc: 0.8065 - f1_score: 0.7914 - loss: 0.5388 - precision: 0.7836 - recall: 0.8048 - val_accuracy: 0.5962 - val_auc: 0.8784 - val_f1_score: 0.7389 - val_loss: 0.6090 - val_precision: 0.5917 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.7416 - auc: 0.8143 - f1_score: 0.7910 - loss: 0.5220 - precision: 0.7881 - recall: 0.7983 - val_accuracy: 0.7387 - val_auc: 0.8688 - val_f1_score: 0.8060 - val_loss: 0.5499 - val_precision: 0.7075 - val_recall: 0.9514 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7557 - auc: 0.8265 - f1_score: 0.8046 - loss: 0.5009 - precision: 0.7924 - recall: 0.8199 - val_accuracy: 0.7812 - val_auc: 0.8789 - val_f1_score: 0.8386 - val_loss: 0.4932 - val_precision: 0.7607 - val_recall: 0.9389 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7480 - auc: 0.8326 - f1_score: 0.7963 - loss: 0.4920 - precision: 0.7771 - recall: 0.8215 - val_accuracy: 0.8225 - val_auc: 0.8953 - val_f1_score: 0.8511 - val_loss: 0.4389 - val_precision: 0.8528 - val_recall: 0.8598 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7640 - auc: 0.8415 - f1_score: 0.8074 - loss: 0.4792 - precision: 0.8005 - recall: 0.8194 - val_accuracy: 0.8150 - val_auc: 0.8877 - val_f1_score: 0.8488 - val_loss: 0.4252 - val_precision: 0.8509 - val_recall: 0.8543 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7594 - auc: 0.8387 - f1_score: 0.8049 - loss: 0.4828 - precision: 0.8002 - recall: 0.8126 - val_accuracy: 0.7987 - val_auc: 0.8787 - val_f1_score: 0.8318 - val_loss: 0.4363 - val_precision: 0.8544 - val_recall: 0.8149 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.7723 - auc: 0.8427 - f1_score: 0.8118 - loss: 0.4809 - precision: 0.7979 - recall: 0.8311 - val_accuracy: 0.8150 - val_auc: 0.8914 - val_f1_score: 0.8353 - val_loss: 0.4258 - val_precision: 0.8520 - val_recall: 0.8378 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.7829 - auc: 0.8586 - f1_score: 0.8265 - loss: 0.4522 - precision: 0.8363 - recall: 0.8208 - val_accuracy: 0.8200 - val_auc: 0.8942 - val_f1_score: 0.8540 - val_loss: 0.4164 - val_precision: 0.8676 - val_recall: 0.8436 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - accuracy: 0.7776 - auc: 0.8437 - f1_score: 0.8224 - loss: 0.4750 - precision: 0.8036 - recall: 0.8476 - val_accuracy: 0.8425 - val_auc: 0.9136 - val_f1_score: 0.8622 - val_loss: 0.3894 - val_precision: 0.8758 - val_recall: 0.8535 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.7774 - auc: 0.8478 - f1_score: 0.8179 - loss: 0.4695 - precision: 0.8124 - recall: 0.8268 - val_accuracy: 0.8325 - val_auc: 0.9171 - val_f1_score: 0.8595 - val_loss: 0.3784 - val_precision: 0.8787 - val_recall: 0.8468 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.7827 - auc: 0.8525 - f1_score: 0.8212 - loss: 0.4716 - precision: 0.8024 - recall: 0.8445 - val_accuracy: 0.8225 - val_auc: 0.9012 - val_f1_score: 0.8495 - val_loss: 0.4023 - val_precision: 0.8849 - val_recall: 0.8250 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.7773 - auc: 0.8469 - f1_score: 0.8190 - loss: 0.4743 - precision: 0.8148 - recall: 0.8258 - val_accuracy: 0.8225 - val_auc: 0.9074 - val_f1_score: 0.8552 - val_loss: 0.3915 - val_precision: 0.8373 - val_recall: 0.8786 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.7943 - auc: 0.8632 - f1_score: 0.8346 - loss: 0.4519 - precision: 0.8133 - recall: 0.8596 - val_accuracy: 0.8475 - val_auc: 0.9210 - val_f1_score: 0.8676 - val_loss: 0.3755 - val_precision: 0.8951 - val_recall: 0.8513 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7790 - auc: 0.8526 - f1_score: 0.8222 - loss: 0.4622 - precision: 0.8129 - recall: 0.8338 - val_accuracy: 0.8213 - val_auc: 0.9057 - val_f1_score: 0.8449 - val_loss: 0.3959 - val_precision: 0.8505 - val_recall: 0.8487 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 159ms/step - accuracy: 0.7839 - auc: 0.8625 - f1_score: 0.8250 - loss: 0.4445 - precision: 0.8279 - recall: 0.8249 - val_accuracy: 0.8500 - val_auc: 0.9298 - val_f1_score: 0.8764 - val_loss: 0.3537 - val_precision: 0.8778 - val_recall: 0.8813 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 160ms/step - accuracy: 0.7871 - auc: 0.8653 - f1_score: 0.8269 - loss: 0.4440 - precision: 0.8279 - recall: 0.8288 - val_accuracy: 0.8425 - val_auc: 0.9152 - val_f1_score: 0.8672 - val_loss: 0.3834 - val_precision: 0.9013 - val_recall: 0.8400 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 167ms/step - accuracy: 0.7884 - auc: 0.8711 - f1_score: 0.8257 - loss: 0.4342 - precision: 0.8268 - recall: 0.8260 - val_accuracy: 0.8537 - val_auc: 0.9273 - val_f1_score: 0.8819 - val_loss: 0.3576 - val_precision: 0.8902 - val_recall: 0.8780 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 161ms/step - accuracy: 0.7969 - auc: 0.8695 - f1_score: 0.8346 - loss: 0.4383 - precision: 0.8246 - recall: 0.8492 - val_accuracy: 0.8512 - val_auc: 0.9341 - val_f1_score: 0.8771 - val_loss: 0.3564 - val_precision: 0.8926 - val_recall: 0.8618 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 154ms/step - accuracy: 0.7887 - auc: 0.8648 - f1_score: 0.8277 - loss: 0.4476 - precision: 0.8188 - recall: 0.8404 - val_accuracy: 0.8438 - val_auc: 0.9204 - val_f1_score: 0.8639 - val_loss: 0.3642 - val_precision: 0.8982 - val_recall: 0.8371 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8053 - auc: 0.8790 - f1_score: 0.8445 - loss: 0.4217 - precision: 0.8328 - recall: 0.8590\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - accuracy: 0.8053 - auc: 0.8791 - f1_score: 0.8445 - loss: 0.4217 - precision: 0.8328 - recall: 0.8590 - val_accuracy: 0.8413 - val_auc: 0.9141 - val_f1_score: 0.8675 - val_loss: 0.3761 - val_precision: 0.8721 - val_recall: 0.8631 - learning_rate: 0.0010\n",
      "Training time: 326.69 seconds\n",
      "Evaluating MobileNetV3Small on The Wildfire Dataset...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "True labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True labels shape: (832,)\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step\n",
      "Predicted probabilities: [[0.37133127]\n",
      " [0.08147313]\n",
      " [0.49239337]\n",
      " [0.03901114]\n",
      " [0.3958896 ]\n",
      " [0.34476426]\n",
      " [0.14599554]\n",
      " [0.17370406]\n",
      " [0.16791557]\n",
      " [0.717523  ]\n",
      " [0.15882306]\n",
      " [0.16715723]\n",
      " [0.3412481 ]\n",
      " [0.31070116]\n",
      " [0.629024  ]\n",
      " [0.21325667]\n",
      " [0.39499864]\n",
      " [0.15607245]\n",
      " [0.28113517]\n",
      " [0.19815743]\n",
      " [0.144448  ]\n",
      " [0.28566143]\n",
      " [0.34877154]\n",
      " [0.32163405]\n",
      " [0.42024308]\n",
      " [0.16475132]\n",
      " [0.30145937]\n",
      " [0.3432974 ]\n",
      " [0.3547372 ]\n",
      " [0.4838977 ]\n",
      " [0.30383912]\n",
      " [0.24104662]\n",
      " [0.4473728 ]\n",
      " [0.17522007]\n",
      " [0.1232325 ]\n",
      " [0.33396927]\n",
      " [0.7169516 ]\n",
      " [0.5985515 ]\n",
      " [0.41428748]\n",
      " [0.27565828]\n",
      " [0.10175936]\n",
      " [0.4951103 ]\n",
      " [0.26732075]\n",
      " [0.5594921 ]\n",
      " [0.06256128]\n",
      " [0.4766828 ]\n",
      " [0.4393683 ]\n",
      " [0.21574023]\n",
      " [0.49971142]\n",
      " [0.5291053 ]\n",
      " [0.42244238]\n",
      " [0.25219867]\n",
      " [0.3682936 ]\n",
      " [0.569057  ]\n",
      " [0.13168034]\n",
      " [0.18411352]\n",
      " [0.37967   ]\n",
      " [0.5515802 ]\n",
      " [0.17827515]\n",
      " [0.0442994 ]\n",
      " [0.51330745]\n",
      " [0.18271099]\n",
      " [0.28728935]\n",
      " [0.0455754 ]\n",
      " [0.5097992 ]\n",
      " [0.18848357]\n",
      " [0.1994557 ]\n",
      " [0.09607655]\n",
      " [0.29684216]\n",
      " [0.32672936]\n",
      " [0.2645623 ]\n",
      " [0.11170469]\n",
      " [0.33835736]\n",
      " [0.88505465]\n",
      " [0.24982975]\n",
      " [0.47527158]\n",
      " [0.7307993 ]\n",
      " [0.13392007]\n",
      " [0.49130684]\n",
      " [0.7635033 ]\n",
      " [0.6326367 ]\n",
      " [0.74381673]\n",
      " [0.5263861 ]\n",
      " [0.15736328]\n",
      " [0.45977166]\n",
      " [0.18076636]\n",
      " [0.11188542]\n",
      " [0.5639475 ]\n",
      " [0.41646022]\n",
      " [0.08049357]\n",
      " [0.32082528]\n",
      " [0.28151852]\n",
      " [0.11742733]\n",
      " [0.35062304]\n",
      " [0.11329591]\n",
      " [0.27407956]\n",
      " [0.5113921 ]\n",
      " [0.65449166]\n",
      " [0.18738012]\n",
      " [0.47359905]\n",
      " [0.06270929]\n",
      " [0.816802  ]\n",
      " [0.16452652]\n",
      " [0.41610867]\n",
      " [0.17372702]\n",
      " [0.14790098]\n",
      " [0.2595411 ]\n",
      " [0.18928614]\n",
      " [0.79836243]\n",
      " [0.7474528 ]\n",
      " [0.2655858 ]\n",
      " [0.23568322]\n",
      " [0.0760878 ]\n",
      " [0.8568404 ]\n",
      " [0.16371307]\n",
      " [0.31112868]\n",
      " [0.67389613]\n",
      " [0.06310786]\n",
      " [0.44966042]\n",
      " [0.1507729 ]\n",
      " [0.9787356 ]\n",
      " [0.16950071]\n",
      " [0.6027163 ]\n",
      " [0.26758704]\n",
      " [0.1987538 ]\n",
      " [0.2664455 ]\n",
      " [0.3414959 ]\n",
      " [0.52275324]\n",
      " [0.167769  ]\n",
      " [0.170864  ]\n",
      " [0.28672582]\n",
      " [0.27728823]\n",
      " [0.21715587]\n",
      " [0.2512024 ]\n",
      " [0.8177931 ]\n",
      " [0.11566085]\n",
      " [0.5062809 ]\n",
      " [0.34159255]\n",
      " [0.21612369]\n",
      " [0.26119885]\n",
      " [0.9975343 ]\n",
      " [0.56786025]\n",
      " [0.47683704]\n",
      " [0.35677832]\n",
      " [0.09872777]\n",
      " [0.19198333]\n",
      " [0.5476823 ]\n",
      " [0.5054103 ]\n",
      " [0.42328057]\n",
      " [0.75647753]\n",
      " [0.334529  ]\n",
      " [0.10287725]\n",
      " [0.38285038]\n",
      " [0.29974353]\n",
      " [0.24530658]\n",
      " [0.3129036 ]\n",
      " [0.2571694 ]\n",
      " [0.6274106 ]\n",
      " [0.49750307]\n",
      " [0.52514946]\n",
      " [0.4963687 ]\n",
      " [0.5420116 ]\n",
      " [0.1250223 ]\n",
      " [0.7839452 ]\n",
      " [0.2655015 ]\n",
      " [0.18780506]\n",
      " [0.363202  ]\n",
      " [0.12715001]\n",
      " [0.47681957]\n",
      " [0.15983178]\n",
      " [0.5521555 ]\n",
      " [0.21016742]\n",
      " [0.8760797 ]\n",
      " [0.13519458]\n",
      " [0.49117368]\n",
      " [0.27530682]\n",
      " [0.36459368]\n",
      " [0.31803814]\n",
      " [0.45497227]\n",
      " [0.34122658]\n",
      " [0.3114442 ]\n",
      " [0.25483826]\n",
      " [0.44688186]\n",
      " [0.61408806]\n",
      " [0.34199807]\n",
      " [0.45089057]\n",
      " [0.23272768]\n",
      " [0.15173186]\n",
      " [0.6683078 ]\n",
      " [0.6502951 ]\n",
      " [0.25869116]\n",
      " [0.08788716]\n",
      " [0.40274048]\n",
      " [0.92774886]\n",
      " [0.37622288]\n",
      " [0.9536881 ]\n",
      " [0.94687223]\n",
      " [0.67481315]\n",
      " [0.6208175 ]\n",
      " [0.5593283 ]\n",
      " [0.97675616]\n",
      " [0.27869135]\n",
      " [0.39639953]\n",
      " [0.9269338 ]\n",
      " [0.329731  ]\n",
      " [0.43579647]\n",
      " [0.08494519]\n",
      " [0.40533012]\n",
      " [0.46732166]\n",
      " [0.36170554]\n",
      " [0.46087748]\n",
      " [0.4399985 ]\n",
      " [0.19441192]\n",
      " [0.5987451 ]\n",
      " [0.24699748]\n",
      " [0.792862  ]\n",
      " [0.27408963]\n",
      " [0.40499273]\n",
      " [0.11364098]\n",
      " [0.3612736 ]\n",
      " [0.21431388]\n",
      " [0.876     ]\n",
      " [0.23415317]\n",
      " [0.58301616]\n",
      " [0.0918361 ]\n",
      " [0.19816406]\n",
      " [0.29210478]\n",
      " [0.9114958 ]\n",
      " [0.14160588]\n",
      " [0.94864297]\n",
      " [0.18913977]\n",
      " [0.25890195]\n",
      " [0.33481878]\n",
      " [0.2944681 ]\n",
      " [0.62998474]\n",
      " [0.73466754]\n",
      " [0.568308  ]\n",
      " [0.5190259 ]\n",
      " [0.723222  ]\n",
      " [0.19231439]\n",
      " [0.3913272 ]\n",
      " [0.48724133]\n",
      " [0.5770391 ]\n",
      " [0.24873322]\n",
      " [0.34597346]\n",
      " [0.32086906]\n",
      " [0.76115066]\n",
      " [0.24038576]\n",
      " [0.24609369]\n",
      " [0.81760126]\n",
      " [0.78329605]\n",
      " [0.3663012 ]\n",
      " [0.7470156 ]\n",
      " [0.5821644 ]\n",
      " [0.7421942 ]\n",
      " [0.27037266]\n",
      " [0.29166174]\n",
      " [0.56779814]\n",
      " [0.11588905]\n",
      " [0.721708  ]\n",
      " [0.1890174 ]\n",
      " [0.15067962]\n",
      " [0.12551685]\n",
      " [0.26085576]\n",
      " [0.8042365 ]\n",
      " [0.1852707 ]\n",
      " [0.94347644]\n",
      " [0.80959994]\n",
      " [0.26035938]\n",
      " [0.06957106]\n",
      " [0.21636623]\n",
      " [0.9406143 ]\n",
      " [0.69761413]\n",
      " [0.456767  ]\n",
      " [0.70113325]\n",
      " [0.99842787]\n",
      " [0.26196742]\n",
      " [0.2472879 ]\n",
      " [0.52062243]\n",
      " [0.50455177]\n",
      " [0.73431504]\n",
      " [0.6029917 ]\n",
      " [0.9109469 ]\n",
      " [0.19483718]\n",
      " [0.17932154]\n",
      " [0.5129627 ]\n",
      " [0.14142554]\n",
      " [0.39292827]\n",
      " [0.10461182]\n",
      " [0.23840356]\n",
      " [0.27594212]\n",
      " [0.45258683]\n",
      " [0.5107776 ]\n",
      " [0.2328799 ]\n",
      " [0.25083905]\n",
      " [0.07521096]\n",
      " [0.45684838]\n",
      " [0.6886492 ]\n",
      " [0.45557448]\n",
      " [0.65532714]\n",
      " [0.8318383 ]\n",
      " [0.10537905]\n",
      " [0.5505593 ]\n",
      " [0.6042974 ]\n",
      " [0.4328428 ]\n",
      " [0.35867545]\n",
      " [0.38350672]\n",
      " [0.30237213]\n",
      " [0.2577913 ]\n",
      " [0.8386292 ]\n",
      " [0.9143437 ]\n",
      " [0.02993629]\n",
      " [0.57506216]\n",
      " [0.09925192]\n",
      " [0.24250461]\n",
      " [0.18349917]\n",
      " [0.5303083 ]\n",
      " [0.62420046]\n",
      " [0.20345186]\n",
      " [0.6171597 ]\n",
      " [0.23234953]\n",
      " [0.8346712 ]\n",
      " [0.50832236]\n",
      " [0.22824635]\n",
      " [0.60290587]\n",
      " [0.4594241 ]\n",
      " [0.1637229 ]\n",
      " [0.18944187]\n",
      " [0.33320737]\n",
      " [0.36573434]\n",
      " [0.22583272]\n",
      " [0.11535714]\n",
      " [0.15148717]\n",
      " [0.37750727]\n",
      " [0.5249275 ]\n",
      " [0.52031004]\n",
      " [0.2638801 ]\n",
      " [0.3110066 ]\n",
      " [0.22472818]\n",
      " [0.7965624 ]\n",
      " [0.13897371]\n",
      " [0.23957239]\n",
      " [0.50019217]\n",
      " [0.3188689 ]\n",
      " [0.63313293]\n",
      " [0.66516364]\n",
      " [0.62792325]\n",
      " [0.79872817]\n",
      " [0.5277048 ]\n",
      " [0.14343493]\n",
      " [0.9109362 ]\n",
      " [0.14095467]\n",
      " [0.9050109 ]\n",
      " [0.72987515]\n",
      " [0.43281445]\n",
      " [0.7875587 ]\n",
      " [0.8536885 ]\n",
      " [0.23026372]\n",
      " [0.9436746 ]\n",
      " [0.41936094]\n",
      " [0.62174356]\n",
      " [0.8670291 ]\n",
      " [0.5864543 ]\n",
      " [0.54566014]\n",
      " [0.81239235]\n",
      " [0.84778744]\n",
      " [0.9846255 ]\n",
      " [0.7088645 ]\n",
      " [0.8284263 ]\n",
      " [0.24592686]\n",
      " [0.91433936]\n",
      " [0.79957414]\n",
      " [0.70736074]\n",
      " [0.9670913 ]\n",
      " [0.7779979 ]\n",
      " [0.6803432 ]\n",
      " [0.7075047 ]\n",
      " [0.20055188]\n",
      " [0.67798233]\n",
      " [0.59566   ]\n",
      " [0.61788666]\n",
      " [0.41903633]\n",
      " [0.37827525]\n",
      " [0.90295196]\n",
      " [0.9588689 ]\n",
      " [0.15813035]\n",
      " [0.9728753 ]\n",
      " [0.6263224 ]\n",
      " [0.8633558 ]\n",
      " [0.98530596]\n",
      " [0.23828799]\n",
      " [0.5777656 ]\n",
      " [0.7512909 ]\n",
      " [0.5638845 ]\n",
      " [0.93118536]\n",
      " [0.70983255]\n",
      " [0.7050375 ]\n",
      " [0.4293752 ]\n",
      " [0.5473318 ]\n",
      " [0.3751992 ]\n",
      " [0.9117404 ]\n",
      " [0.8622406 ]\n",
      " [0.6362928 ]\n",
      " [0.9329613 ]\n",
      " [0.5772015 ]\n",
      " [0.60192996]\n",
      " [0.95903707]\n",
      " [0.8686807 ]\n",
      " [0.77475303]\n",
      " [0.6971638 ]\n",
      " [0.9710351 ]\n",
      " [0.67496276]\n",
      " [0.5539679 ]\n",
      " [0.8589814 ]\n",
      " [0.94640905]\n",
      " [0.9506726 ]\n",
      " [0.83879066]\n",
      " [0.9963282 ]\n",
      " [0.9813172 ]\n",
      " [0.9953793 ]\n",
      " [0.99274135]\n",
      " [0.6534359 ]\n",
      " [0.8584849 ]\n",
      " [0.3613609 ]\n",
      " [0.8326448 ]\n",
      " [0.4961865 ]\n",
      " [0.99478513]\n",
      " [0.56751597]\n",
      " [0.9031314 ]\n",
      " [0.9934519 ]\n",
      " [0.9960947 ]\n",
      " [0.767895  ]\n",
      " [0.57111615]\n",
      " [0.9081333 ]\n",
      " [0.83440167]\n",
      " [0.98967814]\n",
      " [0.9981784 ]\n",
      " [0.6831313 ]\n",
      " [0.7338557 ]\n",
      " [0.6724801 ]\n",
      " [0.9605514 ]\n",
      " [0.8220763 ]\n",
      " [0.86094487]\n",
      " [0.97387767]\n",
      " [0.8248624 ]\n",
      " [0.8316995 ]\n",
      " [0.27187923]\n",
      " [0.99060947]\n",
      " [0.37108627]\n",
      " [0.91489154]\n",
      " [0.8763078 ]\n",
      " [0.8889332 ]\n",
      " [0.13554397]\n",
      " [0.7507998 ]\n",
      " [0.4223856 ]\n",
      " [0.54893196]\n",
      " [0.9874485 ]\n",
      " [0.41917405]\n",
      " [0.971776  ]\n",
      " [0.82027996]\n",
      " [0.5516599 ]\n",
      " [0.6444473 ]\n",
      " [0.71618044]\n",
      " [0.9752824 ]\n",
      " [0.9770622 ]\n",
      " [0.23441346]\n",
      " [0.8863647 ]\n",
      " [0.93401754]\n",
      " [0.55408144]\n",
      " [0.8658985 ]\n",
      " [0.75578153]\n",
      " [0.91590506]\n",
      " [0.73130345]\n",
      " [0.9989894 ]\n",
      " [0.68638635]\n",
      " [0.62279296]\n",
      " [0.7109164 ]\n",
      " [0.9811301 ]\n",
      " [0.73627275]\n",
      " [0.98909444]\n",
      " [0.6403612 ]\n",
      " [0.37196723]\n",
      " [0.9231947 ]\n",
      " [0.911459  ]\n",
      " [0.86757606]\n",
      " [0.7734805 ]\n",
      " [0.9305682 ]\n",
      " [0.7652584 ]\n",
      " [0.61476827]\n",
      " [0.85080755]\n",
      " [0.56914115]\n",
      " [0.6868935 ]\n",
      " [0.9609339 ]\n",
      " [0.809554  ]\n",
      " [0.96511143]\n",
      " [0.9299906 ]\n",
      " [0.9777382 ]\n",
      " [0.57793033]\n",
      " [0.199634  ]\n",
      " [0.9612959 ]\n",
      " [0.47802585]\n",
      " [0.9024252 ]\n",
      " [0.9840036 ]\n",
      " [0.63066316]\n",
      " [0.6555544 ]\n",
      " [0.58900505]\n",
      " [0.9226748 ]\n",
      " [0.5208102 ]\n",
      " [0.8879838 ]\n",
      " [0.6209816 ]\n",
      " [0.83867425]\n",
      " [0.93693864]\n",
      " [0.83236885]\n",
      " [0.9107249 ]\n",
      " [0.9962475 ]\n",
      " [0.9901924 ]\n",
      " [0.9935629 ]\n",
      " [0.98729813]\n",
      " [0.5842619 ]\n",
      " [0.85166645]\n",
      " [0.9982944 ]\n",
      " [0.5211479 ]\n",
      " [0.326714  ]\n",
      " [0.58624375]\n",
      " [0.9700001 ]\n",
      " [0.36284602]\n",
      " [0.37223944]\n",
      " [0.932316  ]\n",
      " [0.92580235]\n",
      " [0.75989723]\n",
      " [0.9200017 ]\n",
      " [0.82451475]\n",
      " [0.5944903 ]\n",
      " [0.9546997 ]\n",
      " [0.78705674]\n",
      " [0.634406  ]\n",
      " [0.8532263 ]\n",
      " [0.59751403]\n",
      " [0.93987143]\n",
      " [0.9754579 ]\n",
      " [0.80962884]\n",
      " [0.6700494 ]\n",
      " [0.865617  ]\n",
      " [0.50640845]\n",
      " [0.82138157]\n",
      " [0.79458475]\n",
      " [0.5745981 ]\n",
      " [0.92631793]\n",
      " [0.74221957]\n",
      " [0.23026516]\n",
      " [0.9963107 ]\n",
      " [0.42552087]\n",
      " [0.9960817 ]\n",
      " [0.5705385 ]\n",
      " [0.51412225]\n",
      " [0.99368083]\n",
      " [0.4005286 ]\n",
      " [0.9884233 ]\n",
      " [0.8394106 ]\n",
      " [0.6657406 ]\n",
      " [0.82834226]\n",
      " [0.92680883]\n",
      " [0.9667872 ]\n",
      " [0.8710656 ]\n",
      " [0.98822224]\n",
      " [0.89323753]\n",
      " [0.9797515 ]\n",
      " [0.98805714]\n",
      " [0.9765586 ]\n",
      " [0.18528564]\n",
      " [0.3151058 ]\n",
      " [0.58658755]\n",
      " [0.9503848 ]\n",
      " [0.46928918]\n",
      " [0.1417376 ]\n",
      " [0.9285445 ]\n",
      " [0.95600057]\n",
      " [0.98038816]\n",
      " [0.44638556]\n",
      " [0.9394347 ]\n",
      " [0.2302638 ]\n",
      " [0.8713459 ]\n",
      " [0.92002034]\n",
      " [0.21152106]\n",
      " [0.77885836]\n",
      " [0.54363096]\n",
      " [0.95580614]\n",
      " [0.9495429 ]\n",
      " [0.8975839 ]\n",
      " [0.929645  ]\n",
      " [0.9235226 ]\n",
      " [0.8887849 ]\n",
      " [0.96894366]\n",
      " [0.9853311 ]\n",
      " [0.98830914]\n",
      " [0.9996954 ]\n",
      " [0.6841064 ]\n",
      " [0.96850795]\n",
      " [0.99687827]\n",
      " [0.7631023 ]\n",
      " [0.7777683 ]\n",
      " [0.99637794]\n",
      " [0.6882991 ]\n",
      " [0.9996349 ]\n",
      " [0.96014786]\n",
      " [0.9697614 ]\n",
      " [0.6053957 ]\n",
      " [0.989875  ]\n",
      " [0.9953453 ]\n",
      " [0.98942596]\n",
      " [0.9907309 ]\n",
      " [0.9397297 ]\n",
      " [0.9694096 ]\n",
      " [0.9829815 ]\n",
      " [0.99753237]\n",
      " [0.94498694]\n",
      " [0.78025615]\n",
      " [0.98561656]\n",
      " [0.9595692 ]\n",
      " [0.9269457 ]\n",
      " [0.80578905]\n",
      " [0.8029491 ]\n",
      " [0.9819133 ]\n",
      " [0.99636775]\n",
      " [0.9734428 ]\n",
      " [0.97474533]\n",
      " [0.9109529 ]\n",
      " [0.71818495]\n",
      " [0.9949181 ]\n",
      " [0.8878763 ]\n",
      " [0.57007873]\n",
      " [0.58627236]\n",
      " [0.88960636]\n",
      " [0.72987616]\n",
      " [0.8738614 ]\n",
      " [0.93280154]\n",
      " [0.4748368 ]\n",
      " [0.7981659 ]\n",
      " [0.82103735]\n",
      " [0.54323936]\n",
      " [0.23651527]\n",
      " [0.7916435 ]\n",
      " [0.7359916 ]\n",
      " [0.6410895 ]\n",
      " [0.841184  ]\n",
      " [0.81160367]\n",
      " [0.78073764]\n",
      " [0.87069964]\n",
      " [0.656868  ]\n",
      " [0.3163141 ]\n",
      " [0.9046155 ]\n",
      " [0.69209486]\n",
      " [0.9569417 ]\n",
      " [0.62688255]\n",
      " [0.2287077 ]\n",
      " [0.88580364]\n",
      " [0.44278538]\n",
      " [0.62555295]\n",
      " [0.5955645 ]\n",
      " [0.9653506 ]\n",
      " [0.9590193 ]\n",
      " [0.4946541 ]\n",
      " [0.9308674 ]\n",
      " [0.27179474]\n",
      " [0.7888298 ]\n",
      " [0.7257164 ]\n",
      " [0.85320306]\n",
      " [0.82420856]\n",
      " [0.70569414]\n",
      " [0.60853297]\n",
      " [0.04512684]\n",
      " [0.6875832 ]\n",
      " [0.6590787 ]\n",
      " [0.88742036]\n",
      " [0.9088348 ]\n",
      " [0.2669834 ]\n",
      " [0.5518998 ]\n",
      " [0.9308112 ]\n",
      " [0.6986018 ]\n",
      " [0.91343766]\n",
      " [0.63595265]\n",
      " [0.4710131 ]\n",
      " [0.9873669 ]\n",
      " [0.80842626]\n",
      " [0.32828125]\n",
      " [0.8696773 ]\n",
      " [0.74054635]\n",
      " [0.5075151 ]\n",
      " [0.6314443 ]\n",
      " [0.8507535 ]\n",
      " [0.22938974]\n",
      " [0.7477278 ]\n",
      " [0.9798676 ]\n",
      " [0.68700945]\n",
      " [0.9334255 ]\n",
      " [0.26419643]\n",
      " [0.86837244]\n",
      " [0.9784491 ]\n",
      " [0.8907173 ]\n",
      " [0.56681   ]\n",
      " [0.6098461 ]\n",
      " [0.8347765 ]\n",
      " [0.8780399 ]\n",
      " [0.69539225]\n",
      " [0.70535743]\n",
      " [0.43889025]\n",
      " [0.38588694]\n",
      " [0.98460364]\n",
      " [0.819403  ]\n",
      " [0.52110624]\n",
      " [0.6105627 ]\n",
      " [0.39191288]\n",
      " [0.42329827]\n",
      " [0.37705046]\n",
      " [0.8721029 ]\n",
      " [0.760341  ]\n",
      " [0.90323114]\n",
      " [0.5326524 ]\n",
      " [0.40187725]\n",
      " [0.89870447]\n",
      " [0.98279536]\n",
      " [0.99060476]\n",
      " [0.9791983 ]\n",
      " [0.42314756]\n",
      " [0.5672325 ]\n",
      " [0.93465686]\n",
      " [0.98821914]\n",
      " [0.43452892]\n",
      " [0.26767287]\n",
      " [0.90528893]\n",
      " [0.99161553]\n",
      " [0.9482148 ]\n",
      " [0.9959637 ]\n",
      " [0.9607168 ]\n",
      " [0.7907086 ]\n",
      " [0.9988144 ]\n",
      " [0.9140284 ]\n",
      " [0.97911036]\n",
      " [0.5123595 ]\n",
      " [0.90630734]\n",
      " [0.9440437 ]\n",
      " [0.81551796]\n",
      " [0.7138562 ]\n",
      " [0.826561  ]\n",
      " [0.7165689 ]\n",
      " [0.29709437]\n",
      " [0.54172826]\n",
      " [0.7728044 ]\n",
      " [0.6956384 ]\n",
      " [0.80674154]\n",
      " [0.22354424]\n",
      " [0.7680357 ]\n",
      " [0.9909539 ]\n",
      " [0.22547987]\n",
      " [0.32528424]\n",
      " [0.30675605]\n",
      " [0.6882393 ]\n",
      " [0.9546965 ]\n",
      " [0.6649793 ]\n",
      " [0.7731263 ]\n",
      " [0.3420325 ]\n",
      " [0.88046336]\n",
      " [0.9820428 ]\n",
      " [0.60379446]\n",
      " [0.6265582 ]\n",
      " [0.66324824]\n",
      " [0.97600895]\n",
      " [0.85758746]\n",
      " [0.937386  ]\n",
      " [0.9589882 ]\n",
      " [0.9988137 ]\n",
      " [0.9946059 ]\n",
      " [0.9723686 ]\n",
      " [0.98828596]\n",
      " [0.9791682 ]\n",
      " [0.92417884]\n",
      " [0.93009466]\n",
      " [0.9967992 ]\n",
      " [0.690225  ]\n",
      " [0.9592578 ]\n",
      " [0.9910502 ]\n",
      " [0.9005221 ]\n",
      " [0.9522238 ]\n",
      " [0.99080414]\n",
      " [0.9859844 ]\n",
      " [0.99034196]\n",
      " [0.4806935 ]\n",
      " [0.9510456 ]\n",
      " [0.98033756]\n",
      " [0.7799269 ]\n",
      " [0.837293  ]\n",
      " [0.58664   ]\n",
      " [0.67847157]\n",
      " [0.9776611 ]\n",
      " [0.9694921 ]\n",
      " [0.5266099 ]\n",
      " [0.8870091 ]\n",
      " [0.8742197 ]\n",
      " [0.9896847 ]\n",
      " [0.9577651 ]\n",
      " [0.96086127]\n",
      " [0.9754471 ]\n",
      " [0.37844044]\n",
      " [0.57928646]\n",
      " [0.6210152 ]\n",
      " [0.773803  ]\n",
      " [0.88380563]\n",
      " [0.73480594]\n",
      " [0.81624234]\n",
      " [0.8385529 ]\n",
      " [0.89188707]\n",
      " [0.81268233]\n",
      " [0.67259896]\n",
      " [0.99351346]\n",
      " [0.67072284]\n",
      " [0.9118961 ]\n",
      " [0.98010075]\n",
      " [0.88300145]\n",
      " [0.8969368 ]\n",
      " [0.45455652]\n",
      " [0.88095444]\n",
      " [0.9930525 ]\n",
      " [0.45754683]\n",
      " [0.2811244 ]\n",
      " [0.97924083]\n",
      " [0.5475157 ]\n",
      " [0.52502966]\n",
      " [0.19680865]\n",
      " [0.34981522]\n",
      " [0.19376732]\n",
      " [0.50833243]\n",
      " [0.3499256 ]]\n",
      "Predicted probabilities shape: (832, 1)\n",
      "Predicted labels: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0\n",
      " 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1\n",
      " 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0]\n",
      "Predicted labels shape: (832,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.8494 - auc: 0.4623 - f1_score: 0.7915 - loss: 0.3714 - precision: 0.9387 - recall: 0.8672\n",
      "Training model: MobileNetV3Small on dataset: DeepFire\n",
      "Epoch 1/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 118ms/step - accuracy: 0.6969 - auc: 0.8111 - f1_score: 0.6911 - loss: 0.6974 - precision: 0.7615 - recall: 0.7745 - val_accuracy: 0.4967 - val_auc: 0.8989 - val_f1_score: 0.6585 - val_loss: 0.7787 - val_precision: 0.4967 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - accuracy: 0.8105 - auc: 0.8931 - f1_score: 0.8051 - loss: 0.4449 - precision: 0.8337 - recall: 0.7849 - val_accuracy: 0.5115 - val_auc: 0.9189 - val_f1_score: 0.6697 - val_loss: 0.6879 - val_precision: 0.5107 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - accuracy: 0.8431 - auc: 0.9207 - f1_score: 0.8381 - loss: 0.3679 - precision: 0.8371 - recall: 0.8413 - val_accuracy: 0.4819 - val_auc: 0.9164 - val_f1_score: 0.6466 - val_loss: 0.7174 - val_precision: 0.4811 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8290 - auc: 0.9117 - f1_score: 0.8274 - loss: 0.3982 - precision: 0.8201 - recall: 0.8451 - val_accuracy: 0.5033 - val_auc: 0.9276 - val_f1_score: 0.6545 - val_loss: 0.6614 - val_precision: 0.4907 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8384 - auc: 0.9206 - f1_score: 0.8407 - loss: 0.3671 - precision: 0.8517 - recall: 0.8339 - val_accuracy: 0.6299 - val_auc: 0.9068 - val_f1_score: 0.7305 - val_loss: 0.5863 - val_precision: 0.5836 - val_recall: 0.9968 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8566 - auc: 0.9347 - f1_score: 0.8534 - loss: 0.3321 - precision: 0.8432 - recall: 0.8698 - val_accuracy: 0.7336 - val_auc: 0.9177 - val_f1_score: 0.7792 - val_loss: 0.5102 - val_precision: 0.6659 - val_recall: 0.9479 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.8572 - auc: 0.9279 - f1_score: 0.8560 - loss: 0.3521 - precision: 0.8782 - recall: 0.8365 - val_accuracy: 0.8224 - val_auc: 0.9454 - val_f1_score: 0.8276 - val_loss: 0.4231 - val_precision: 0.7493 - val_recall: 0.9373 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.8502 - auc: 0.9271 - f1_score: 0.8433 - loss: 0.3598 - precision: 0.8312 - recall: 0.8649 - val_accuracy: 0.9095 - val_auc: 0.9698 - val_f1_score: 0.9039 - val_loss: 0.3126 - val_precision: 0.8882 - val_recall: 0.9278 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.8734 - auc: 0.9437 - f1_score: 0.8755 - loss: 0.3088 - precision: 0.8757 - recall: 0.8772 - val_accuracy: 0.8964 - val_auc: 0.9689 - val_f1_score: 0.8934 - val_loss: 0.2748 - val_precision: 0.8594 - val_recall: 0.9386 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.8823 - auc: 0.9489 - f1_score: 0.8813 - loss: 0.2909 - precision: 0.8605 - recall: 0.9089 - val_accuracy: 0.9046 - val_auc: 0.9691 - val_f1_score: 0.8991 - val_loss: 0.2432 - val_precision: 0.9155 - val_recall: 0.8914 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8753 - auc: 0.9422 - f1_score: 0.8762 - loss: 0.3087 - precision: 0.8815 - recall: 0.8765 - val_accuracy: 0.9095 - val_auc: 0.9719 - val_f1_score: 0.9041 - val_loss: 0.2295 - val_precision: 0.9107 - val_recall: 0.9014 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8707 - auc: 0.9394 - f1_score: 0.8708 - loss: 0.3193 - precision: 0.8602 - recall: 0.8844 - val_accuracy: 0.9128 - val_auc: 0.9773 - val_f1_score: 0.9085 - val_loss: 0.2265 - val_precision: 0.8933 - val_recall: 0.9273 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.8695 - auc: 0.9440 - f1_score: 0.8666 - loss: 0.3099 - precision: 0.8820 - recall: 0.8649 - val_accuracy: 0.9079 - val_auc: 0.9679 - val_f1_score: 0.8991 - val_loss: 0.2346 - val_precision: 0.9041 - val_recall: 0.9041 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.8627 - auc: 0.9389 - f1_score: 0.8622 - loss: 0.3176 - precision: 0.8441 - recall: 0.8877 - val_accuracy: 0.8980 - val_auc: 0.9656 - val_f1_score: 0.8917 - val_loss: 0.2396 - val_precision: 0.8926 - val_recall: 0.8986 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.8876 - auc: 0.9566 - f1_score: 0.8893 - loss: 0.2708 - precision: 0.8759 - recall: 0.9039 - val_accuracy: 0.9260 - val_auc: 0.9807 - val_f1_score: 0.9236 - val_loss: 0.1944 - val_precision: 0.9306 - val_recall: 0.9147 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.8727 - auc: 0.9426 - f1_score: 0.8703 - loss: 0.3094 - precision: 0.8793 - recall: 0.8651 - val_accuracy: 0.9408 - val_auc: 0.9836 - val_f1_score: 0.9382 - val_loss: 0.1825 - val_precision: 0.9272 - val_recall: 0.9524 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.8837 - auc: 0.9493 - f1_score: 0.8855 - loss: 0.2908 - precision: 0.8828 - recall: 0.8913 - val_accuracy: 0.9161 - val_auc: 0.9753 - val_f1_score: 0.9115 - val_loss: 0.2134 - val_precision: 0.9333 - val_recall: 0.8926 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.8857 - auc: 0.9545 - f1_score: 0.8867 - loss: 0.2711 - precision: 0.8752 - recall: 0.9003 - val_accuracy: 0.9309 - val_auc: 0.9830 - val_f1_score: 0.9258 - val_loss: 0.1930 - val_precision: 0.9420 - val_recall: 0.9169 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.8633 - auc: 0.9368 - f1_score: 0.8598 - loss: 0.3240 - precision: 0.8624 - recall: 0.8621 - val_accuracy: 0.9227 - val_auc: 0.9821 - val_f1_score: 0.9216 - val_loss: 0.2015 - val_precision: 0.9444 - val_recall: 0.9060 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.8796 - auc: 0.9482 - f1_score: 0.8782 - loss: 0.2903 - precision: 0.8644 - recall: 0.8975 - val_accuracy: 0.9424 - val_auc: 0.9870 - val_f1_score: 0.9449 - val_loss: 0.1763 - val_precision: 0.9495 - val_recall: 0.9406 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.8751 - auc: 0.9462 - f1_score: 0.8750 - loss: 0.2990 - precision: 0.8689 - recall: 0.8834 - val_accuracy: 0.9391 - val_auc: 0.9891 - val_f1_score: 0.9375 - val_loss: 0.1789 - val_precision: 0.9388 - val_recall: 0.9356 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.8820 - auc: 0.9565 - f1_score: 0.8827 - loss: 0.2670 - precision: 0.8915 - recall: 0.8761 - val_accuracy: 0.9243 - val_auc: 0.9817 - val_f1_score: 0.9260 - val_loss: 0.1945 - val_precision: 0.9252 - val_recall: 0.9310 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.8770 - auc: 0.9478 - f1_score: 0.8724 - loss: 0.2935 - precision: 0.8654 - recall: 0.8887 - val_accuracy: 0.9194 - val_auc: 0.9774 - val_f1_score: 0.9152 - val_loss: 0.2132 - val_precision: 0.9416 - val_recall: 0.8954 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - accuracy: 0.8895 - auc: 0.9511 - f1_score: 0.8904 - loss: 0.2803 - precision: 0.8856 - recall: 0.8969 - val_accuracy: 0.9309 - val_auc: 0.9859 - val_f1_score: 0.9269 - val_loss: 0.1826 - val_precision: 0.9308 - val_recall: 0.9244 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8750 - auc: 0.9502 - f1_score: 0.8739 - loss: 0.2890 - precision: 0.8950 - recall: 0.8598\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.8751 - auc: 0.9503 - f1_score: 0.8741 - loss: 0.2887 - precision: 0.8950 - recall: 0.8601 - val_accuracy: 0.9112 - val_auc: 0.9772 - val_f1_score: 0.9093 - val_loss: 0.2065 - val_precision: 0.9269 - val_recall: 0.8971 - learning_rate: 0.0010\n",
      "Training time: 218.02 seconds\n",
      "Evaluating MobileNetV3Small on DeepFire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "True labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True labels shape: (832,)\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step\n",
      "Predicted probabilities: [[2.10390016e-01]\n",
      " [2.59840369e-01]\n",
      " [2.74937630e-01]\n",
      " [7.03783989e-01]\n",
      " [5.83900571e-01]\n",
      " [9.84591067e-01]\n",
      " [1.40473261e-01]\n",
      " [3.14362079e-01]\n",
      " [4.91290182e-01]\n",
      " [2.82938898e-01]\n",
      " [1.30559253e-02]\n",
      " [7.04681277e-01]\n",
      " [5.66160023e-01]\n",
      " [3.37308526e-01]\n",
      " [4.27452981e-01]\n",
      " [5.14225326e-02]\n",
      " [8.28712761e-01]\n",
      " [2.72678167e-01]\n",
      " [4.28229660e-01]\n",
      " [1.62239283e-01]\n",
      " [3.12621176e-01]\n",
      " [5.05404115e-01]\n",
      " [3.63858879e-01]\n",
      " [3.34740318e-02]\n",
      " [2.25469410e-01]\n",
      " [6.25373363e-01]\n",
      " [7.00529516e-01]\n",
      " [7.29019642e-02]\n",
      " [9.40707803e-01]\n",
      " [9.87184227e-01]\n",
      " [3.20356965e-01]\n",
      " [2.41076663e-01]\n",
      " [3.32629442e-01]\n",
      " [1.50394529e-01]\n",
      " [9.88187939e-02]\n",
      " [7.49940574e-01]\n",
      " [9.37912762e-01]\n",
      " [9.73030746e-01]\n",
      " [1.18653076e-02]\n",
      " [6.64285481e-01]\n",
      " [7.43052006e-01]\n",
      " [2.26994053e-01]\n",
      " [9.44420815e-01]\n",
      " [8.91780078e-01]\n",
      " [7.33341696e-03]\n",
      " [1.09175183e-01]\n",
      " [2.88489033e-02]\n",
      " [8.05145800e-01]\n",
      " [6.46848440e-01]\n",
      " [1.56561270e-01]\n",
      " [6.23680830e-01]\n",
      " [4.63416696e-01]\n",
      " [4.60072532e-02]\n",
      " [2.66221255e-01]\n",
      " [3.76764804e-01]\n",
      " [6.89530969e-01]\n",
      " [1.73966791e-02]\n",
      " [1.84183381e-02]\n",
      " [8.04309845e-02]\n",
      " [1.94305807e-01]\n",
      " [6.80195570e-01]\n",
      " [9.30675566e-01]\n",
      " [8.74522850e-02]\n",
      " [4.27923612e-02]\n",
      " [2.84411490e-01]\n",
      " [1.39519155e-01]\n",
      " [1.19502977e-01]\n",
      " [2.70334203e-02]\n",
      " [9.68774930e-02]\n",
      " [7.28123367e-01]\n",
      " [1.23506472e-01]\n",
      " [6.86260015e-02]\n",
      " [1.92458421e-01]\n",
      " [7.91441798e-01]\n",
      " [1.02321859e-02]\n",
      " [9.34043109e-01]\n",
      " [9.54326749e-01]\n",
      " [1.04407810e-01]\n",
      " [9.78807688e-01]\n",
      " [8.28080237e-01]\n",
      " [7.32075214e-01]\n",
      " [7.70919442e-01]\n",
      " [8.81168485e-01]\n",
      " [4.73937429e-02]\n",
      " [7.21659660e-01]\n",
      " [2.35980928e-01]\n",
      " [7.68305838e-01]\n",
      " [9.30952668e-01]\n",
      " [5.64315081e-01]\n",
      " [7.26453662e-01]\n",
      " [8.61038208e-01]\n",
      " [7.58530572e-02]\n",
      " [1.42317832e-01]\n",
      " [1.05784717e-03]\n",
      " [1.55112952e-01]\n",
      " [4.36197966e-01]\n",
      " [1.44820645e-01]\n",
      " [9.67160165e-01]\n",
      " [6.95446908e-01]\n",
      " [9.36667383e-01]\n",
      " [5.66343546e-01]\n",
      " [4.96600181e-01]\n",
      " [2.32666329e-01]\n",
      " [9.20652390e-01]\n",
      " [2.97353826e-02]\n",
      " [4.46782410e-01]\n",
      " [9.18617189e-01]\n",
      " [7.29471326e-01]\n",
      " [8.35793555e-01]\n",
      " [7.24719405e-01]\n",
      " [5.92474103e-01]\n",
      " [9.80198860e-01]\n",
      " [3.76244694e-01]\n",
      " [6.72117889e-01]\n",
      " [6.16657495e-01]\n",
      " [5.82994938e-01]\n",
      " [6.76841378e-01]\n",
      " [6.16752505e-01]\n",
      " [4.75322455e-01]\n",
      " [6.97603345e-01]\n",
      " [8.22889686e-01]\n",
      " [4.47977893e-02]\n",
      " [3.95409495e-01]\n",
      " [3.73695381e-02]\n",
      " [8.89023989e-02]\n",
      " [3.51748616e-01]\n",
      " [3.28229591e-02]\n",
      " [3.34562705e-04]\n",
      " [2.05305079e-03]\n",
      " [1.74804833e-02]\n",
      " [4.65267077e-02]\n",
      " [8.20125192e-02]\n",
      " [1.50378928e-01]\n",
      " [1.50810272e-01]\n",
      " [5.48238866e-02]\n",
      " [7.99507916e-01]\n",
      " [1.70010492e-01]\n",
      " [2.85500046e-02]\n",
      " [4.07564603e-02]\n",
      " [2.58967727e-01]\n",
      " [2.95802891e-01]\n",
      " [7.17136264e-02]\n",
      " [4.42303807e-01]\n",
      " [2.66817600e-01]\n",
      " [1.47486324e-04]\n",
      " [4.03610431e-03]\n",
      " [1.71940237e-01]\n",
      " [5.20206615e-02]\n",
      " [2.62846410e-01]\n",
      " [3.07991982e-01]\n",
      " [7.80962825e-01]\n",
      " [7.26153776e-02]\n",
      " [1.78050902e-02]\n",
      " [2.88037449e-01]\n",
      " [3.04262489e-02]\n",
      " [4.33000084e-03]\n",
      " [4.01317716e-01]\n",
      " [2.17982437e-02]\n",
      " [1.19397298e-01]\n",
      " [2.03799739e-01]\n",
      " [4.29124951e-01]\n",
      " [1.38729271e-02]\n",
      " [2.48243497e-03]\n",
      " [4.63718362e-03]\n",
      " [5.22204041e-01]\n",
      " [4.03824374e-02]\n",
      " [3.79895061e-01]\n",
      " [3.92164057e-03]\n",
      " [5.49072400e-02]\n",
      " [1.76208317e-02]\n",
      " [8.23145136e-02]\n",
      " [4.43637790e-03]\n",
      " [1.30512774e-01]\n",
      " [1.31821549e-02]\n",
      " [6.49809539e-02]\n",
      " [1.27922455e-02]\n",
      " [4.50199217e-01]\n",
      " [3.54118012e-02]\n",
      " [1.95433330e-02]\n",
      " [2.49650106e-02]\n",
      " [1.88521549e-01]\n",
      " [4.96664792e-01]\n",
      " [6.16227910e-02]\n",
      " [6.06965832e-03]\n",
      " [3.28924730e-02]\n",
      " [4.20054188e-03]\n",
      " [1.38119170e-02]\n",
      " [2.65675429e-02]\n",
      " [1.67905819e-02]\n",
      " [2.47440990e-02]\n",
      " [1.00815423e-01]\n",
      " [1.71858855e-02]\n",
      " [5.42969584e-01]\n",
      " [2.71578819e-01]\n",
      " [8.84550996e-03]\n",
      " [1.28265977e-01]\n",
      " [4.38730866e-01]\n",
      " [2.59278625e-01]\n",
      " [3.39631885e-01]\n",
      " [1.00452498e-01]\n",
      " [5.41577220e-01]\n",
      " [2.67382637e-02]\n",
      " [2.80275375e-01]\n",
      " [7.96468377e-01]\n",
      " [1.21677918e-02]\n",
      " [5.13827726e-02]\n",
      " [4.80690189e-02]\n",
      " [6.44533873e-01]\n",
      " [1.10263586e-01]\n",
      " [1.59135051e-02]\n",
      " [1.41702686e-02]\n",
      " [2.74813652e-01]\n",
      " [2.34865889e-01]\n",
      " [7.89520666e-02]\n",
      " [1.76694654e-02]\n",
      " [1.60129458e-01]\n",
      " [1.65665019e-02]\n",
      " [1.78840891e-01]\n",
      " [2.01839954e-02]\n",
      " [1.06453419e-01]\n",
      " [1.89444553e-02]\n",
      " [6.29987493e-02]\n",
      " [9.61123630e-02]\n",
      " [1.81174025e-01]\n",
      " [2.87911706e-02]\n",
      " [3.14895779e-01]\n",
      " [4.69945818e-02]\n",
      " [3.08086008e-01]\n",
      " [2.55884649e-03]\n",
      " [3.30123991e-01]\n",
      " [1.49373427e-01]\n",
      " [2.34639905e-02]\n",
      " [2.71586534e-02]\n",
      " [4.93066534e-02]\n",
      " [1.84368774e-01]\n",
      " [2.21091866e-01]\n",
      " [5.71518004e-01]\n",
      " [2.88685948e-01]\n",
      " [3.66522223e-02]\n",
      " [2.12529525e-01]\n",
      " [4.04095054e-01]\n",
      " [1.12823141e-03]\n",
      " [4.50710446e-01]\n",
      " [8.24779570e-02]\n",
      " [5.52184926e-03]\n",
      " [4.56982572e-03]\n",
      " [4.50185612e-02]\n",
      " [1.15039535e-02]\n",
      " [1.73196986e-01]\n",
      " [6.69347048e-02]\n",
      " [1.24781251e-01]\n",
      " [1.23437187e-02]\n",
      " [6.64702356e-02]\n",
      " [8.85778107e-03]\n",
      " [5.43321967e-01]\n",
      " [1.21570588e-03]\n",
      " [6.62446737e-01]\n",
      " [6.82553798e-02]\n",
      " [1.53385510e-03]\n",
      " [1.35404289e-01]\n",
      " [4.20516767e-02]\n",
      " [2.78385490e-01]\n",
      " [7.18627591e-03]\n",
      " [6.29456863e-02]\n",
      " [8.36667418e-03]\n",
      " [1.01100672e-02]\n",
      " [1.39143735e-01]\n",
      " [3.01933676e-01]\n",
      " [6.96111262e-01]\n",
      " [3.06836106e-02]\n",
      " [3.56435105e-02]\n",
      " [7.98610210e-01]\n",
      " [9.67709571e-02]\n",
      " [4.63066310e-01]\n",
      " [8.15236196e-03]\n",
      " [9.11587775e-01]\n",
      " [1.64400395e-02]\n",
      " [5.00090839e-03]\n",
      " [3.00024420e-01]\n",
      " [4.13363054e-03]\n",
      " [1.42791241e-01]\n",
      " [5.78336902e-02]\n",
      " [4.94598866e-01]\n",
      " [3.90744328e-01]\n",
      " [9.32725612e-03]\n",
      " [8.84232111e-03]\n",
      " [3.37657030e-03]\n",
      " [1.24211004e-02]\n",
      " [4.18751762e-04]\n",
      " [6.09615492e-03]\n",
      " [9.33806587e-04]\n",
      " [4.18205571e-04]\n",
      " [7.75306880e-01]\n",
      " [6.38977140e-02]\n",
      " [5.39007690e-03]\n",
      " [2.51053786e-03]\n",
      " [1.44001916e-01]\n",
      " [1.31607177e-02]\n",
      " [3.86930769e-04]\n",
      " [6.00719452e-01]\n",
      " [4.37666148e-01]\n",
      " [3.31553631e-03]\n",
      " [1.07414454e-01]\n",
      " [4.87234712e-01]\n",
      " [1.71709526e-02]\n",
      " [1.54347662e-02]\n",
      " [1.77411020e-01]\n",
      " [6.71208464e-03]\n",
      " [3.54947373e-02]\n",
      " [1.79528490e-01]\n",
      " [2.03110099e-01]\n",
      " [2.03883741e-02]\n",
      " [3.67000461e-01]\n",
      " [3.49114911e-04]\n",
      " [1.72629561e-02]\n",
      " [7.44853821e-03]\n",
      " [3.98800015e-01]\n",
      " [1.57154836e-02]\n",
      " [3.41908559e-02]\n",
      " [1.40003273e-02]\n",
      " [5.91488089e-03]\n",
      " [4.18237299e-01]\n",
      " [2.83896893e-01]\n",
      " [9.90232266e-03]\n",
      " [6.51259542e-01]\n",
      " [1.20585682e-02]\n",
      " [1.62705213e-01]\n",
      " [8.21051359e-01]\n",
      " [2.43892763e-02]\n",
      " [3.42520103e-02]\n",
      " [1.63872853e-01]\n",
      " [7.94006526e-01]\n",
      " [2.49416634e-01]\n",
      " [5.45157075e-01]\n",
      " [8.17212999e-01]\n",
      " [2.17039794e-01]\n",
      " [2.36081347e-01]\n",
      " [4.89343137e-01]\n",
      " [2.39316188e-02]\n",
      " [9.93501663e-01]\n",
      " [7.25273550e-01]\n",
      " [5.83620310e-01]\n",
      " [6.80957913e-01]\n",
      " [8.81670356e-01]\n",
      " [8.62766623e-01]\n",
      " [8.76652181e-01]\n",
      " [9.86911833e-01]\n",
      " [8.62005413e-01]\n",
      " [9.55433786e-01]\n",
      " [1.31370082e-01]\n",
      " [9.64327216e-01]\n",
      " [2.29308650e-01]\n",
      " [9.79982376e-01]\n",
      " [9.74645674e-01]\n",
      " [7.34273314e-01]\n",
      " [9.45347309e-01]\n",
      " [9.77418900e-01]\n",
      " [9.59344685e-01]\n",
      " [7.43886471e-01]\n",
      " [2.01768070e-01]\n",
      " [5.94621658e-01]\n",
      " [9.20858741e-01]\n",
      " [9.62423265e-01]\n",
      " [6.39551401e-01]\n",
      " [6.83032990e-01]\n",
      " [9.96713698e-01]\n",
      " [9.58068550e-01]\n",
      " [3.24636281e-01]\n",
      " [9.62512195e-01]\n",
      " [4.15873200e-01]\n",
      " [9.77630973e-01]\n",
      " [9.99224961e-01]\n",
      " [9.67321396e-01]\n",
      " [9.54119682e-01]\n",
      " [9.84383583e-01]\n",
      " [9.67589736e-01]\n",
      " [9.30903018e-01]\n",
      " [8.31818581e-01]\n",
      " [9.66607630e-01]\n",
      " [9.51003432e-01]\n",
      " [8.03624153e-01]\n",
      " [9.74275470e-01]\n",
      " [8.98065746e-01]\n",
      " [9.75513875e-01]\n",
      " [9.99520302e-01]\n",
      " [2.79524446e-01]\n",
      " [9.50624228e-01]\n",
      " [9.90356445e-01]\n",
      " [9.92180526e-01]\n",
      " [9.62144434e-01]\n",
      " [6.96783304e-01]\n",
      " [7.94139743e-01]\n",
      " [9.57787991e-01]\n",
      " [9.15952444e-01]\n",
      " [9.79919732e-01]\n",
      " [9.75327551e-01]\n",
      " [9.91226614e-01]\n",
      " [9.88292694e-01]\n",
      " [9.64479864e-01]\n",
      " [9.78306592e-01]\n",
      " [9.67472553e-01]\n",
      " [9.45263982e-01]\n",
      " [9.48572099e-01]\n",
      " [9.54638124e-01]\n",
      " [9.52667892e-01]\n",
      " [9.96675968e-01]\n",
      " [7.09720552e-01]\n",
      " [7.31913149e-01]\n",
      " [9.61892188e-01]\n",
      " [6.72392368e-01]\n",
      " [8.68980348e-01]\n",
      " [7.02162027e-01]\n",
      " [7.64647305e-01]\n",
      " [6.98467135e-01]\n",
      " [9.65319574e-01]\n",
      " [7.81442106e-01]\n",
      " [8.11831594e-01]\n",
      " [9.71953034e-01]\n",
      " [9.93497312e-01]\n",
      " [8.56179655e-01]\n",
      " [9.93301809e-01]\n",
      " [3.29634726e-01]\n",
      " [2.02666253e-01]\n",
      " [8.33106041e-01]\n",
      " [2.64235884e-01]\n",
      " [5.90247512e-01]\n",
      " [9.33044434e-01]\n",
      " [7.25237608e-01]\n",
      " [9.94003177e-01]\n",
      " [9.58314598e-01]\n",
      " [7.67917752e-01]\n",
      " [7.11222768e-01]\n",
      " [8.33724976e-01]\n",
      " [9.06889617e-01]\n",
      " [9.37542975e-01]\n",
      " [9.76900399e-01]\n",
      " [9.86671984e-01]\n",
      " [4.11194146e-01]\n",
      " [9.24956322e-01]\n",
      " [2.81230867e-01]\n",
      " [8.74924660e-01]\n",
      " [7.27021217e-01]\n",
      " [4.94581938e-01]\n",
      " [9.86841857e-01]\n",
      " [8.31168711e-01]\n",
      " [9.44987118e-01]\n",
      " [8.38584542e-01]\n",
      " [9.17770445e-01]\n",
      " [6.16814256e-01]\n",
      " [5.77054620e-01]\n",
      " [9.76496935e-01]\n",
      " [5.47036052e-01]\n",
      " [5.67007884e-02]\n",
      " [2.22828388e-01]\n",
      " [9.62166071e-01]\n",
      " [8.70235801e-01]\n",
      " [8.72685730e-01]\n",
      " [5.48708081e-01]\n",
      " [9.99677420e-01]\n",
      " [9.83507037e-01]\n",
      " [9.74473834e-01]\n",
      " [4.96243179e-01]\n",
      " [9.32731450e-01]\n",
      " [9.02175903e-01]\n",
      " [9.98149395e-01]\n",
      " [6.08097315e-01]\n",
      " [8.89005959e-01]\n",
      " [8.29884171e-01]\n",
      " [9.51323211e-01]\n",
      " [9.83518779e-01]\n",
      " [5.94499707e-01]\n",
      " [9.23128843e-01]\n",
      " [9.59116459e-01]\n",
      " [9.96724248e-01]\n",
      " [9.26804423e-01]\n",
      " [5.67867041e-01]\n",
      " [8.18893015e-01]\n",
      " [9.94908452e-01]\n",
      " [8.50362599e-01]\n",
      " [8.87668133e-01]\n",
      " [5.71844757e-01]\n",
      " [8.48902166e-01]\n",
      " [9.71774876e-01]\n",
      " [9.12611842e-01]\n",
      " [7.57330179e-01]\n",
      " [1.79629102e-01]\n",
      " [9.56437826e-01]\n",
      " [8.26028168e-01]\n",
      " [8.63842010e-01]\n",
      " [9.54084158e-01]\n",
      " [1.76762622e-02]\n",
      " [8.30304325e-01]\n",
      " [9.79087651e-01]\n",
      " [8.37539494e-01]\n",
      " [9.25744057e-01]\n",
      " [9.43247080e-01]\n",
      " [6.93672657e-01]\n",
      " [8.97415876e-01]\n",
      " [6.70029759e-01]\n",
      " [9.10682261e-01]\n",
      " [8.30820441e-01]\n",
      " [9.39223230e-01]\n",
      " [9.77388263e-01]\n",
      " [1.91818058e-01]\n",
      " [3.82964969e-01]\n",
      " [9.43141043e-01]\n",
      " [9.81325328e-01]\n",
      " [9.71433043e-01]\n",
      " [7.78414547e-01]\n",
      " [9.26029086e-01]\n",
      " [6.84473991e-01]\n",
      " [7.93542266e-01]\n",
      " [9.14394081e-01]\n",
      " [7.19146848e-01]\n",
      " [9.61733639e-01]\n",
      " [4.15228754e-01]\n",
      " [7.12311745e-01]\n",
      " [9.35885727e-01]\n",
      " [3.00323635e-01]\n",
      " [9.41579580e-01]\n",
      " [8.74478459e-01]\n",
      " [5.48265219e-01]\n",
      " [8.64856601e-01]\n",
      " [6.71738014e-02]\n",
      " [5.78594685e-01]\n",
      " [2.50281941e-04]\n",
      " [7.28784548e-03]\n",
      " [5.22199273e-01]\n",
      " [9.04843867e-01]\n",
      " [5.61123729e-01]\n",
      " [1.62219658e-01]\n",
      " [9.97568369e-01]\n",
      " [9.58752513e-01]\n",
      " [9.44578052e-01]\n",
      " [9.90599811e-01]\n",
      " [1.27527297e-01]\n",
      " [3.21357042e-01]\n",
      " [1.23078331e-01]\n",
      " [9.08212781e-01]\n",
      " [7.45912075e-01]\n",
      " [6.33196115e-01]\n",
      " [9.20620024e-01]\n",
      " [6.18992567e-01]\n",
      " [8.98177505e-01]\n",
      " [8.88367295e-01]\n",
      " [5.07801473e-02]\n",
      " [5.66271067e-01]\n",
      " [7.72673607e-01]\n",
      " [9.65520889e-02]\n",
      " [1.64951652e-01]\n",
      " [7.70217419e-01]\n",
      " [9.91012827e-02]\n",
      " [8.21934938e-01]\n",
      " [9.76460278e-01]\n",
      " [9.04417038e-01]\n",
      " [9.16600227e-01]\n",
      " [9.28425848e-01]\n",
      " [8.71797323e-01]\n",
      " [8.26634467e-01]\n",
      " [3.32823336e-01]\n",
      " [9.90586698e-01]\n",
      " [3.71680737e-01]\n",
      " [3.22138339e-01]\n",
      " [4.46958184e-01]\n",
      " [3.14557761e-01]\n",
      " [4.89712387e-01]\n",
      " [4.47611660e-01]\n",
      " [6.98238969e-01]\n",
      " [6.20332301e-01]\n",
      " [5.48252985e-02]\n",
      " [5.28719425e-01]\n",
      " [6.86186135e-01]\n",
      " [8.87399554e-01]\n",
      " [4.74938065e-01]\n",
      " [6.98645115e-02]\n",
      " [6.12546206e-01]\n",
      " [9.66281950e-01]\n",
      " [2.71680892e-01]\n",
      " [8.26901138e-01]\n",
      " [9.92607653e-01]\n",
      " [9.51098084e-01]\n",
      " [9.87065077e-01]\n",
      " [9.34004068e-01]\n",
      " [8.18841994e-01]\n",
      " [7.27462173e-01]\n",
      " [9.74159062e-01]\n",
      " [9.90478098e-01]\n",
      " [9.69780087e-01]\n",
      " [8.14626217e-01]\n",
      " [8.54389966e-01]\n",
      " [7.39368677e-01]\n",
      " [9.99662638e-01]\n",
      " [9.22990263e-01]\n",
      " [9.99119043e-01]\n",
      " [9.98993456e-01]\n",
      " [9.98033166e-01]\n",
      " [8.10297251e-01]\n",
      " [9.73183095e-01]\n",
      " [9.97815907e-01]\n",
      " [9.29947138e-01]\n",
      " [9.88933802e-01]\n",
      " [8.99485230e-01]\n",
      " [8.89324903e-01]\n",
      " [9.95975912e-01]\n",
      " [9.98019993e-01]\n",
      " [9.37478065e-01]\n",
      " [3.07846982e-02]\n",
      " [9.69458342e-01]\n",
      " [9.36510146e-01]\n",
      " [9.98954117e-01]\n",
      " [9.96696651e-01]\n",
      " [9.99079049e-01]\n",
      " [6.95814312e-01]\n",
      " [9.35731173e-01]\n",
      " [9.99145627e-01]\n",
      " [9.98392165e-01]\n",
      " [8.52383733e-01]\n",
      " [9.66017246e-01]\n",
      " [9.72859740e-01]\n",
      " [9.89011765e-01]\n",
      " [9.96774435e-01]\n",
      " [9.98922527e-01]\n",
      " [8.92008543e-01]\n",
      " [9.90510941e-01]\n",
      " [9.93569851e-01]\n",
      " [9.96500671e-01]\n",
      " [9.91137624e-01]\n",
      " [9.62529600e-01]\n",
      " [9.99891758e-01]\n",
      " [9.98107314e-01]\n",
      " [9.55594897e-01]\n",
      " [9.54132795e-01]\n",
      " [7.38932550e-01]\n",
      " [9.45215046e-01]\n",
      " [8.00100863e-01]\n",
      " [2.86459297e-01]\n",
      " [9.55525279e-01]\n",
      " [9.47477400e-01]\n",
      " [7.14663446e-01]\n",
      " [9.17990088e-01]\n",
      " [3.54781955e-01]\n",
      " [6.59268498e-01]\n",
      " [7.33543515e-01]\n",
      " [9.88594770e-01]\n",
      " [9.97207403e-01]\n",
      " [9.89934742e-01]\n",
      " [8.82306814e-01]\n",
      " [9.80532408e-01]\n",
      " [8.41959715e-01]\n",
      " [9.38307106e-01]\n",
      " [8.30621362e-01]\n",
      " [7.46824145e-01]\n",
      " [9.62117255e-01]\n",
      " [9.86585438e-01]\n",
      " [7.56842613e-01]\n",
      " [9.13920224e-01]\n",
      " [9.35213983e-01]\n",
      " [6.35150552e-01]\n",
      " [9.29501534e-01]\n",
      " [9.60406601e-01]\n",
      " [7.60210037e-01]\n",
      " [8.52623224e-01]\n",
      " [9.46388423e-01]\n",
      " [5.35301805e-01]\n",
      " [8.44702661e-01]\n",
      " [9.69502509e-01]\n",
      " [7.91368246e-01]\n",
      " [3.10827106e-01]\n",
      " [6.70784593e-01]\n",
      " [8.80515516e-01]\n",
      " [6.71614468e-01]\n",
      " [9.62249994e-01]\n",
      " [6.25575542e-01]\n",
      " [9.55402136e-01]\n",
      " [9.96767402e-01]\n",
      " [6.42885566e-01]\n",
      " [8.77199650e-01]\n",
      " [7.12241709e-01]\n",
      " [9.58116591e-01]\n",
      " [9.68692720e-01]\n",
      " [7.88704216e-01]\n",
      " [5.47891140e-01]\n",
      " [9.86807644e-01]\n",
      " [9.98074770e-01]\n",
      " [9.59438682e-01]\n",
      " [8.81357551e-01]\n",
      " [9.82184291e-01]\n",
      " [9.57470953e-01]\n",
      " [7.93777168e-01]\n",
      " [7.25269973e-01]\n",
      " [3.34602781e-02]\n",
      " [7.87739098e-01]\n",
      " [9.64125276e-01]\n",
      " [2.58546352e-01]\n",
      " [8.63296390e-01]\n",
      " [9.99073863e-01]\n",
      " [9.99076545e-01]\n",
      " [7.33111322e-01]\n",
      " [9.94634092e-01]\n",
      " [9.12758112e-01]\n",
      " [9.66951489e-01]\n",
      " [9.85656798e-01]\n",
      " [9.92058277e-01]\n",
      " [9.12034214e-01]\n",
      " [9.65825021e-01]\n",
      " [9.89275455e-01]\n",
      " [9.91954148e-01]\n",
      " [9.09592271e-01]\n",
      " [8.21666598e-01]\n",
      " [9.77011323e-01]\n",
      " [9.73953426e-01]\n",
      " [9.29244518e-01]\n",
      " [9.98615921e-01]\n",
      " [8.70001853e-01]\n",
      " [9.75330353e-01]\n",
      " [9.90234852e-01]\n",
      " [9.54780459e-01]\n",
      " [5.26365995e-01]\n",
      " [6.67660952e-01]\n",
      " [8.33361089e-01]\n",
      " [9.57907677e-01]\n",
      " [7.06041813e-01]\n",
      " [9.84244704e-01]\n",
      " [9.44768965e-01]\n",
      " [9.62248325e-01]\n",
      " [3.50503176e-01]\n",
      " [9.40055311e-01]\n",
      " [3.02278638e-01]\n",
      " [2.23755673e-01]\n",
      " [9.65131342e-01]\n",
      " [9.81057703e-01]\n",
      " [8.12721372e-01]\n",
      " [9.92274106e-01]\n",
      " [9.23558831e-01]\n",
      " [6.53186738e-01]\n",
      " [9.76395547e-01]\n",
      " [9.66124594e-01]\n",
      " [9.99133348e-01]\n",
      " [9.19849455e-01]\n",
      " [9.98780668e-01]\n",
      " [9.70216632e-01]\n",
      " [9.71396208e-01]\n",
      " [6.42579734e-01]\n",
      " [9.44323123e-01]\n",
      " [9.41494524e-01]\n",
      " [7.07276583e-01]\n",
      " [9.14635897e-01]\n",
      " [9.98172402e-01]\n",
      " [7.80806541e-01]\n",
      " [8.81028831e-01]\n",
      " [1.51882961e-01]\n",
      " [9.96382236e-01]\n",
      " [6.21514559e-01]\n",
      " [5.72544217e-01]\n",
      " [1.70853734e-01]\n",
      " [5.13179660e-01]\n",
      " [9.54400718e-01]\n",
      " [8.28485966e-01]\n",
      " [9.68865335e-01]\n",
      " [8.43930721e-01]\n",
      " [8.16805542e-01]\n",
      " [9.65895832e-01]\n",
      " [9.92175221e-01]\n",
      " [9.18180346e-01]\n",
      " [8.09514105e-01]\n",
      " [9.90385830e-01]\n",
      " [5.61734676e-01]\n",
      " [9.82260525e-01]\n",
      " [9.75120246e-01]\n",
      " [6.93114579e-01]\n",
      " [9.50967312e-01]\n",
      " [8.08226585e-01]\n",
      " [5.72444022e-01]\n",
      " [8.20485771e-01]\n",
      " [8.85888815e-01]\n",
      " [9.29564357e-01]\n",
      " [9.27501798e-01]\n",
      " [8.08345795e-01]\n",
      " [8.15362036e-01]\n",
      " [4.45371956e-01]\n",
      " [6.49965286e-01]\n",
      " [9.29233968e-01]\n",
      " [9.91260886e-01]\n",
      " [9.04530942e-01]\n",
      " [9.56366062e-01]\n",
      " [9.62039709e-01]\n",
      " [6.19822800e-01]\n",
      " [3.89633060e-01]\n",
      " [8.49130034e-01]\n",
      " [6.32734835e-01]\n",
      " [2.75651038e-01]\n",
      " [4.15672779e-01]\n",
      " [4.84053910e-01]\n",
      " [8.32671285e-01]\n",
      " [5.76889098e-01]\n",
      " [4.56061475e-02]\n",
      " [9.53304112e-01]\n",
      " [9.11201537e-01]\n",
      " [5.42822361e-01]\n",
      " [9.71255898e-01]\n",
      " [9.35711265e-01]\n",
      " [9.90529239e-01]\n",
      " [6.46786571e-01]\n",
      " [2.71873832e-01]\n",
      " [9.61115420e-01]\n",
      " [7.40867376e-01]\n",
      " [9.66820896e-01]\n",
      " [9.78073061e-01]\n",
      " [6.72117591e-01]\n",
      " [7.31522918e-01]\n",
      " [7.50921905e-01]\n",
      " [1.18427753e-01]\n",
      " [5.89601934e-01]\n",
      " [9.91745949e-01]\n",
      " [1.58908457e-01]\n",
      " [9.89870012e-01]\n",
      " [9.01204348e-01]\n",
      " [9.74855602e-01]\n",
      " [3.32585305e-01]\n",
      " [1.01524785e-01]\n",
      " [3.83959770e-01]\n",
      " [6.84689045e-01]\n",
      " [1.98695570e-01]\n",
      " [6.53669834e-01]\n",
      " [8.32130969e-01]\n",
      " [1.56195536e-01]\n",
      " [8.66027713e-01]\n",
      " [3.11305583e-01]\n",
      " [2.02229440e-01]\n",
      " [6.39671385e-01]\n",
      " [2.03805845e-02]\n",
      " [1.55242290e-02]]\n",
      "Predicted probabilities shape: (832, 1)\n",
      "Predicted labels: [0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1\n",
      " 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 0 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0\n",
      " 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 1 0 1 0 0 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1\n",
      " 1 1 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1\n",
      " 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 1 0 0]\n",
      "Predicted labels shape: (832,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.8380 - auc: 0.4344 - f1_score: 0.7863 - loss: 0.4153 - precision: 0.9290 - recall: 0.8633\n",
      "Training model: MobileNetV3Small on dataset: FIRE\n",
      "Epoch 1/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 145ms/step - accuracy: 0.7085 - auc: 0.8504 - f1_score: 0.5402 - loss: 0.7104 - precision: 0.6913 - recall: 0.8232 - val_accuracy: 0.7578 - val_auc: 0.9043 - val_f1_score: 0.0337 - val_loss: 0.6340 - val_precision: 1.0000 - val_recall: 0.0211 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.8297 - auc: 0.8710 - f1_score: 0.6989 - loss: 0.4554 - precision: 0.6731 - recall: 0.7330 - val_accuracy: 0.7474 - val_auc: 0.9036 - val_f1_score: 0.0000e+00 - val_loss: 0.5547 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.8593 - auc: 0.9041 - f1_score: 0.7067 - loss: 0.3585 - precision: 0.7002 - recall: 0.7206 - val_accuracy: 0.7760 - val_auc: 0.9064 - val_f1_score: 0.0000e+00 - val_loss: 0.5051 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.8433 - auc: 0.8861 - f1_score: 0.6824 - loss: 0.3749 - precision: 0.6803 - recall: 0.6986 - val_accuracy: 0.7708 - val_auc: 0.7970 - val_f1_score: 0.0000e+00 - val_loss: 0.5202 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - accuracy: 0.8658 - auc: 0.9051 - f1_score: 0.6839 - loss: 0.3403 - precision: 0.7088 - recall: 0.6960 - val_accuracy: 0.7578 - val_auc: 0.8119 - val_f1_score: 0.0000e+00 - val_loss: 0.5441 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 195ms/step - accuracy: 0.8636 - auc: 0.9052 - f1_score: 0.6939 - loss: 0.3464 - precision: 0.7385 - recall: 0.6825 - val_accuracy: 0.7474 - val_auc: 0.9092 - val_f1_score: 0.0000e+00 - val_loss: 0.5311 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 191ms/step - accuracy: 0.8767 - auc: 0.9060 - f1_score: 0.7176 - loss: 0.3199 - precision: 0.7297 - recall: 0.7227 - val_accuracy: 0.7917 - val_auc: 0.9376 - val_f1_score: 0.0000e+00 - val_loss: 0.4811 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 190ms/step - accuracy: 0.8809 - auc: 0.9246 - f1_score: 0.7511 - loss: 0.3158 - precision: 0.7939 - recall: 0.7268 - val_accuracy: 0.7708 - val_auc: 0.9418 - val_f1_score: 0.0000e+00 - val_loss: 0.4692 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 184ms/step - accuracy: 0.8645 - auc: 0.9203 - f1_score: 0.7228 - loss: 0.3195 - precision: 0.7858 - recall: 0.6779 - val_accuracy: 0.7578 - val_auc: 0.9404 - val_f1_score: 0.1009 - val_loss: 0.4776 - val_precision: 1.0000 - val_recall: 0.0510 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - accuracy: 0.8884 - auc: 0.9257 - f1_score: 0.7526 - loss: 0.2914 - precision: 0.7873 - recall: 0.7399 - val_accuracy: 0.7865 - val_auc: 0.9600 - val_f1_score: 0.2332 - val_loss: 0.4065 - val_precision: 1.0000 - val_recall: 0.1458 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 201ms/step - accuracy: 0.8742 - auc: 0.9147 - f1_score: 0.7040 - loss: 0.2976 - precision: 0.7412 - recall: 0.6968 - val_accuracy: 0.8411 - val_auc: 0.9686 - val_f1_score: 0.5247 - val_loss: 0.3163 - val_precision: 1.0000 - val_recall: 0.3441 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 189ms/step - accuracy: 0.8848 - auc: 0.9344 - f1_score: 0.7330 - loss: 0.2740 - precision: 0.7800 - recall: 0.7184 - val_accuracy: 0.8411 - val_auc: 0.9804 - val_f1_score: 0.4292 - val_loss: 0.2890 - val_precision: 1.0000 - val_recall: 0.3146 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 201ms/step - accuracy: 0.8691 - auc: 0.9144 - f1_score: 0.7218 - loss: 0.3185 - precision: 0.7561 - recall: 0.6908 - val_accuracy: 0.8750 - val_auc: 0.9597 - val_f1_score: 0.5965 - val_loss: 0.2640 - val_precision: 1.0000 - val_recall: 0.4419 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 190ms/step - accuracy: 0.8808 - auc: 0.9311 - f1_score: 0.7550 - loss: 0.2975 - precision: 0.8213 - recall: 0.7086 - val_accuracy: 0.9141 - val_auc: 0.9742 - val_f1_score: 0.7810 - val_loss: 0.2213 - val_precision: 0.9841 - val_recall: 0.6596 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - accuracy: 0.8787 - auc: 0.9329 - f1_score: 0.7374 - loss: 0.2844 - precision: 0.8002 - recall: 0.6918 - val_accuracy: 0.9010 - val_auc: 0.9664 - val_f1_score: 0.7622 - val_loss: 0.2319 - val_precision: 0.9265 - val_recall: 0.6562 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 210ms/step - accuracy: 0.8917 - auc: 0.9330 - f1_score: 0.7585 - loss: 0.2738 - precision: 0.8219 - recall: 0.7042 - val_accuracy: 0.9219 - val_auc: 0.9673 - val_f1_score: 0.8109 - val_loss: 0.2051 - val_precision: 0.9385 - val_recall: 0.7011 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - accuracy: 0.8996 - auc: 0.9432 - f1_score: 0.7823 - loss: 0.2546 - precision: 0.8516 - recall: 0.7300 - val_accuracy: 0.9479 - val_auc: 0.9853 - val_f1_score: 0.8647 - val_loss: 0.1507 - val_precision: 0.9481 - val_recall: 0.8202 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 193ms/step - accuracy: 0.8984 - auc: 0.9452 - f1_score: 0.7797 - loss: 0.2547 - precision: 0.8157 - recall: 0.7552 - val_accuracy: 0.9219 - val_auc: 0.9763 - val_f1_score: 0.8481 - val_loss: 0.1966 - val_precision: 0.9419 - val_recall: 0.7642 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 198ms/step - accuracy: 0.9054 - auc: 0.9483 - f1_score: 0.7755 - loss: 0.2397 - precision: 0.8107 - recall: 0.7615 - val_accuracy: 0.9167 - val_auc: 0.9715 - val_f1_score: 0.8182 - val_loss: 0.2090 - val_precision: 0.9250 - val_recall: 0.7400 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.9027 - auc: 0.9559 - f1_score: 0.7846 - loss: 0.2251 - precision: 0.8369 - recall: 0.7412 - val_accuracy: 0.9453 - val_auc: 0.9833 - val_f1_score: 0.8374 - val_loss: 0.1642 - val_precision: 0.9333 - val_recall: 0.8140 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 199ms/step - accuracy: 0.8816 - auc: 0.9338 - f1_score: 0.7536 - loss: 0.2838 - precision: 0.8339 - recall: 0.6913 - val_accuracy: 0.9219 - val_auc: 0.9747 - val_f1_score: 0.8063 - val_loss: 0.1974 - val_precision: 0.9692 - val_recall: 0.6923 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.8905 - auc: 0.9468 - f1_score: 0.7502 - loss: 0.2553 - precision: 0.8216 - recall: 0.7063\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - accuracy: 0.8905 - auc: 0.9469 - f1_score: 0.7503 - loss: 0.2552 - precision: 0.8215 - recall: 0.7066 - val_accuracy: 0.9141 - val_auc: 0.9713 - val_f1_score: 0.8226 - val_loss: 0.1955 - val_precision: 0.8929 - val_recall: 0.7576 - learning_rate: 0.0010\n",
      "Training time: 230.61 seconds\n",
      "Evaluating MobileNetV3Small on FIRE...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 982ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "True labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True labels shape: (832,)\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step\n",
      "Predicted probabilities: [[3.14644501e-02]\n",
      " [9.17020664e-02]\n",
      " [1.17908806e-01]\n",
      " [5.91756776e-02]\n",
      " [1.09227225e-01]\n",
      " [3.18349451e-01]\n",
      " [1.13920290e-02]\n",
      " [3.10413223e-02]\n",
      " [5.26377335e-02]\n",
      " [3.88835758e-01]\n",
      " [1.21122766e-02]\n",
      " [1.01316996e-01]\n",
      " [6.66066483e-02]\n",
      " [6.71306774e-02]\n",
      " [1.02462552e-01]\n",
      " [3.70228998e-02]\n",
      " [3.17604572e-01]\n",
      " [7.74441808e-02]\n",
      " [3.86248417e-02]\n",
      " [6.30452484e-02]\n",
      " [5.64412847e-02]\n",
      " [4.41059098e-02]\n",
      " [8.01508948e-02]\n",
      " [4.26943414e-02]\n",
      " [1.16169751e-01]\n",
      " [1.34196475e-01]\n",
      " [1.22326732e-01]\n",
      " [4.56266776e-02]\n",
      " [1.18829496e-01]\n",
      " [2.46283442e-01]\n",
      " [7.07527027e-02]\n",
      " [8.02958235e-02]\n",
      " [3.29608649e-01]\n",
      " [1.78406555e-02]\n",
      " [3.86860105e-03]\n",
      " [8.48233178e-02]\n",
      " [3.01875710e-01]\n",
      " [2.39774719e-01]\n",
      " [1.41279446e-02]\n",
      " [3.64443302e-01]\n",
      " [6.06905930e-02]\n",
      " [8.77825469e-02]\n",
      " [2.39428714e-01]\n",
      " [1.92337930e-01]\n",
      " [1.12471171e-02]\n",
      " [2.20330115e-02]\n",
      " [1.10397730e-02]\n",
      " [3.25765051e-02]\n",
      " [1.06388278e-01]\n",
      " [3.52188088e-02]\n",
      " [5.98368235e-02]\n",
      " [8.10315832e-02]\n",
      " [2.46043764e-02]\n",
      " [6.46223277e-02]\n",
      " [5.21312132e-02]\n",
      " [1.93156645e-01]\n",
      " [1.90363098e-02]\n",
      " [6.13609748e-03]\n",
      " [6.38309792e-02]\n",
      " [1.66444369e-02]\n",
      " [1.08648255e-01]\n",
      " [5.31598404e-02]\n",
      " [6.12950437e-02]\n",
      " [2.37831119e-02]\n",
      " [3.82055491e-02]\n",
      " [2.81142648e-02]\n",
      " [6.11416325e-02]\n",
      " [3.50939594e-02]\n",
      " [5.52379824e-02]\n",
      " [1.42231733e-01]\n",
      " [7.88749680e-02]\n",
      " [1.72512636e-01]\n",
      " [7.94417933e-02]\n",
      " [3.70129228e-01]\n",
      " [9.03170928e-03]\n",
      " [4.12246957e-02]\n",
      " [3.66231740e-01]\n",
      " [5.02127111e-02]\n",
      " [2.83306211e-01]\n",
      " [4.46408659e-01]\n",
      " [1.27734348e-01]\n",
      " [5.40629089e-01]\n",
      " [2.24259064e-01]\n",
      " [2.99375169e-02]\n",
      " [1.92606494e-01]\n",
      " [7.39190951e-02]\n",
      " [3.16468716e-01]\n",
      " [2.72945613e-01]\n",
      " [5.54202572e-02]\n",
      " [2.60663182e-02]\n",
      " [1.57315969e-01]\n",
      " [3.79034765e-02]\n",
      " [2.52956618e-02]\n",
      " [2.13752966e-03]\n",
      " [4.48874459e-02]\n",
      " [3.20035852e-02]\n",
      " [4.40166518e-02]\n",
      " [6.43530369e-01]\n",
      " [1.30181298e-01]\n",
      " [1.07233644e-01]\n",
      " [4.34475951e-02]\n",
      " [1.94310591e-01]\n",
      " [6.39824662e-03]\n",
      " [8.17176253e-02]\n",
      " [1.21274339e-02]\n",
      " [3.26731615e-02]\n",
      " [9.46066007e-02]\n",
      " [4.40955088e-02]\n",
      " [2.34338522e-01]\n",
      " [5.07508636e-01]\n",
      " [8.18864033e-02]\n",
      " [2.70478517e-01]\n",
      " [6.27613738e-02]\n",
      " [4.49604213e-01]\n",
      " [3.95433828e-02]\n",
      " [7.81693459e-02]\n",
      " [1.44391090e-01]\n",
      " [6.83155656e-02]\n",
      " [1.21587418e-01]\n",
      " [2.53476232e-01]\n",
      " [7.84309387e-01]\n",
      " [6.01016656e-02]\n",
      " [1.82095051e-01]\n",
      " [3.31623480e-02]\n",
      " [3.49262431e-02]\n",
      " [1.26812577e-01]\n",
      " [8.34503397e-03]\n",
      " [7.35901445e-02]\n",
      " [2.12871144e-03]\n",
      " [4.24197987e-02]\n",
      " [2.87792422e-02]\n",
      " [5.29427752e-02]\n",
      " [2.42432747e-02]\n",
      " [1.96357835e-02]\n",
      " [5.07057691e-03]\n",
      " [4.16156501e-02]\n",
      " [4.67659906e-02]\n",
      " [1.65427867e-02]\n",
      " [6.58559948e-02]\n",
      " [4.13581878e-02]\n",
      " [8.74742985e-01]\n",
      " [3.47880632e-01]\n",
      " [8.48479047e-02]\n",
      " [1.25218168e-01]\n",
      " [1.53511111e-03]\n",
      " [3.89084183e-02]\n",
      " [1.79959051e-02]\n",
      " [7.53453327e-03]\n",
      " [6.40773326e-02]\n",
      " [3.20371807e-01]\n",
      " [2.03611955e-01]\n",
      " [3.21728922e-02]\n",
      " [2.18097027e-03]\n",
      " [7.09763542e-02]\n",
      " [2.68503912e-02]\n",
      " [1.53729394e-01]\n",
      " [9.65183601e-02]\n",
      " [8.05971154e-04]\n",
      " [7.00660646e-02]\n",
      " [1.83745977e-02]\n",
      " [3.09717078e-02]\n",
      " [1.42871931e-01]\n",
      " [3.22703451e-01]\n",
      " [6.69727707e-03]\n",
      " [3.46180201e-02]\n",
      " [5.58037162e-02]\n",
      " [6.41083419e-02]\n",
      " [1.20757753e-02]\n",
      " [1.58919096e-02]\n",
      " [1.73428673e-02]\n",
      " [9.64991655e-03]\n",
      " [2.81969947e-03]\n",
      " [3.38788390e-01]\n",
      " [9.61580779e-03]\n",
      " [3.83433774e-02]\n",
      " [7.06248032e-03]\n",
      " [6.54297546e-02]\n",
      " [2.26021614e-02]\n",
      " [2.39284113e-02]\n",
      " [2.75674444e-02]\n",
      " [1.20208420e-01]\n",
      " [3.76597047e-02]\n",
      " [6.39374973e-03]\n",
      " [3.58552486e-02]\n",
      " [2.64455862e-02]\n",
      " [3.53615312e-03]\n",
      " [2.79535763e-02]\n",
      " [8.12067986e-02]\n",
      " [3.32080014e-02]\n",
      " [5.78480139e-02]\n",
      " [4.47897092e-02]\n",
      " [9.67294723e-03]\n",
      " [8.76391530e-02]\n",
      " [2.95026898e-01]\n",
      " [3.90037149e-02]\n",
      " [6.17010072e-02]\n",
      " [5.71283221e-01]\n",
      " [2.42670536e-01]\n",
      " [1.52199253e-01]\n",
      " [8.72835889e-02]\n",
      " [3.90396953e-01]\n",
      " [2.05899812e-02]\n",
      " [2.79935211e-01]\n",
      " [9.01101589e-01]\n",
      " [1.60616022e-02]\n",
      " [1.35200089e-02]\n",
      " [2.13333890e-02]\n",
      " [2.13253841e-01]\n",
      " [2.94101033e-02]\n",
      " [2.96143331e-02]\n",
      " [2.68718861e-02]\n",
      " [1.52760260e-02]\n",
      " [2.39714067e-02]\n",
      " [1.58799011e-02]\n",
      " [2.11754572e-02]\n",
      " [3.69304568e-01]\n",
      " [2.19349697e-01]\n",
      " [3.42239588e-02]\n",
      " [1.54868439e-02]\n",
      " [3.80087756e-02]\n",
      " [5.75133227e-03]\n",
      " [3.70784640e-01]\n",
      " [4.19016881e-03]\n",
      " [1.27944024e-02]\n",
      " [4.07600217e-02]\n",
      " [1.76418666e-02]\n",
      " [4.91837412e-02]\n",
      " [3.67958665e-01]\n",
      " [1.50678288e-02]\n",
      " [4.18638706e-01]\n",
      " [4.30087335e-02]\n",
      " [1.82786472e-02]\n",
      " [3.78756076e-02]\n",
      " [2.35729851e-02]\n",
      " [2.67689638e-02]\n",
      " [3.14581722e-01]\n",
      " [1.03017479e-01]\n",
      " [4.86933663e-02]\n",
      " [3.82841006e-03]\n",
      " [6.33135661e-02]\n",
      " [1.18976990e-02]\n",
      " [5.27444016e-03]\n",
      " [6.32025599e-02]\n",
      " [5.19141667e-02]\n",
      " [6.56844527e-02]\n",
      " [5.02024544e-03]\n",
      " [7.87448063e-02]\n",
      " [3.15536708e-02]\n",
      " [6.07024059e-02]\n",
      " [2.39092827e-01]\n",
      " [4.20623481e-01]\n",
      " [1.26034729e-02]\n",
      " [6.06178232e-02]\n",
      " [8.13101456e-02]\n",
      " [2.36519575e-01]\n",
      " [3.23273800e-03]\n",
      " [3.07270661e-02]\n",
      " [7.50174373e-02]\n",
      " [1.56992935e-02]\n",
      " [9.84868184e-02]\n",
      " [1.54260863e-02]\n",
      " [1.37600288e-01]\n",
      " [2.28182729e-02]\n",
      " [8.36307183e-02]\n",
      " [1.13399886e-03]\n",
      " [1.50450673e-02]\n",
      " [8.65121424e-01]\n",
      " [1.94543023e-02]\n",
      " [2.27864519e-01]\n",
      " [3.13670523e-02]\n",
      " [3.56387347e-02]\n",
      " [5.33260942e-01]\n",
      " [3.44638899e-02]\n",
      " [1.53744236e-01]\n",
      " [5.51769957e-02]\n",
      " [6.58962727e-01]\n",
      " [5.41091990e-03]\n",
      " [9.94465034e-03]\n",
      " [6.42367080e-02]\n",
      " [5.83317736e-03]\n",
      " [9.99446660e-02]\n",
      " [6.72333268e-03]\n",
      " [3.45100671e-01]\n",
      " [1.58724654e-02]\n",
      " [1.69953201e-02]\n",
      " [9.67182277e-04]\n",
      " [1.18960282e-02]\n",
      " [1.59165971e-02]\n",
      " [5.92092227e-04]\n",
      " [4.49003605e-03]\n",
      " [6.89490582e-04]\n",
      " [1.78306084e-03]\n",
      " [9.57024321e-02]\n",
      " [9.96787008e-03]\n",
      " [1.20355152e-02]\n",
      " [1.09611843e-02]\n",
      " [1.17953224e-02]\n",
      " [7.54099339e-03]\n",
      " [1.61650137e-03]\n",
      " [7.98728615e-02]\n",
      " [2.28241771e-01]\n",
      " [4.23413981e-03]\n",
      " [3.01664080e-02]\n",
      " [1.48362502e-01]\n",
      " [1.37500251e-02]\n",
      " [3.47911343e-02]\n",
      " [1.90905221e-02]\n",
      " [1.86394043e-02]\n",
      " [5.31789586e-02]\n",
      " [8.72778371e-02]\n",
      " [2.03937590e-01]\n",
      " [9.97312367e-03]\n",
      " [2.89002527e-02]\n",
      " [9.46329348e-03]\n",
      " [4.27346490e-02]\n",
      " [8.65239464e-03]\n",
      " [3.71537022e-02]\n",
      " [9.03587509e-03]\n",
      " [4.04934883e-02]\n",
      " [1.19683482e-02]\n",
      " [2.39147078e-02]\n",
      " [1.97997048e-01]\n",
      " [3.01979575e-02]\n",
      " [7.55622191e-03]\n",
      " [3.28491330e-01]\n",
      " [2.15681568e-02]\n",
      " [4.45330329e-02]\n",
      " [8.68001431e-02]\n",
      " [2.13817228e-02]\n",
      " [7.87241105e-03]\n",
      " [2.32095607e-02]\n",
      " [4.09465693e-02]\n",
      " [1.01397261e-01]\n",
      " [9.87225473e-02]\n",
      " [1.33177355e-01]\n",
      " [8.72289762e-02]\n",
      " [4.87578735e-02]\n",
      " [1.00620270e-01]\n",
      " [5.05373953e-03]\n",
      " [4.88157481e-01]\n",
      " [4.42800075e-02]\n",
      " [1.06246985e-01]\n",
      " [5.58882467e-02]\n",
      " [2.83152491e-01]\n",
      " [4.54002768e-01]\n",
      " [4.23907131e-01]\n",
      " [3.80907923e-01]\n",
      " [2.09550783e-01]\n",
      " [1.97898015e-01]\n",
      " [7.31820241e-02]\n",
      " [7.59209096e-01]\n",
      " [5.71957231e-02]\n",
      " [6.06552303e-01]\n",
      " [1.79314286e-01]\n",
      " [2.26326250e-02]\n",
      " [2.72892684e-01]\n",
      " [3.46062064e-01]\n",
      " [8.57013315e-02]\n",
      " [6.43506467e-01]\n",
      " [2.34651361e-02]\n",
      " [2.22936451e-01]\n",
      " [5.10844052e-01]\n",
      " [7.61991739e-01]\n",
      " [1.50103137e-01]\n",
      " [7.81741261e-01]\n",
      " [6.62361860e-01]\n",
      " [6.87680125e-01]\n",
      " [1.08970925e-01]\n",
      " [1.91114992e-01]\n",
      " [6.29892871e-02]\n",
      " [2.51452059e-01]\n",
      " [8.25271726e-01]\n",
      " [4.83355224e-01]\n",
      " [6.76515520e-01]\n",
      " [6.76598430e-01]\n",
      " [5.03595531e-01]\n",
      " [3.23506802e-01]\n",
      " [6.01309240e-02]\n",
      " [1.29805863e-01]\n",
      " [1.41562089e-01]\n",
      " [2.02265292e-01]\n",
      " [1.21176697e-01]\n",
      " [4.55229342e-01]\n",
      " [9.70373929e-01]\n",
      " [4.78726029e-01]\n",
      " [8.06389600e-02]\n",
      " [8.59424531e-01]\n",
      " [1.94458082e-01]\n",
      " [7.12335944e-01]\n",
      " [8.99417341e-01]\n",
      " [3.73940505e-02]\n",
      " [1.43190265e-01]\n",
      " [9.31707844e-02]\n",
      " [4.96903330e-01]\n",
      " [8.12321126e-01]\n",
      " [5.70086688e-02]\n",
      " [5.29037595e-01]\n",
      " [5.47629297e-01]\n",
      " [1.80934265e-01]\n",
      " [2.88937151e-01]\n",
      " [1.49630666e-01]\n",
      " [5.17404437e-01]\n",
      " [7.55624354e-01]\n",
      " [7.27276206e-01]\n",
      " [2.66872257e-01]\n",
      " [9.04076576e-01]\n",
      " [8.42240095e-01]\n",
      " [4.71342981e-01]\n",
      " [4.41371202e-01]\n",
      " [1.57232448e-01]\n",
      " [8.07589233e-01]\n",
      " [6.44228607e-02]\n",
      " [1.34220675e-01]\n",
      " [3.46018851e-01]\n",
      " [2.43941963e-01]\n",
      " [4.64018956e-02]\n",
      " [7.30302930e-02]\n",
      " [2.87481070e-01]\n",
      " [1.09883301e-01]\n",
      " [8.92049909e-01]\n",
      " [9.99529481e-01]\n",
      " [3.92226242e-02]\n",
      " [3.44363451e-01]\n",
      " [2.06951827e-01]\n",
      " [3.26528847e-01]\n",
      " [1.73562482e-01]\n",
      " [9.18616235e-01]\n",
      " [2.06419080e-01]\n",
      " [5.95219374e-01]\n",
      " [9.96392667e-01]\n",
      " [8.07559490e-01]\n",
      " [1.12880297e-01]\n",
      " [9.87075716e-02]\n",
      " [1.50254145e-01]\n",
      " [2.49463871e-01]\n",
      " [9.98216629e-01]\n",
      " [9.79295731e-01]\n",
      " [4.90821525e-02]\n",
      " [9.63090956e-02]\n",
      " [2.03945376e-02]\n",
      " [3.33681375e-01]\n",
      " [1.47625044e-01]\n",
      " [4.80429202e-01]\n",
      " [2.24561870e-01]\n",
      " [9.94770452e-02]\n",
      " [1.58978894e-01]\n",
      " [1.29278094e-01]\n",
      " [8.18975747e-01]\n",
      " [6.58101887e-02]\n",
      " [7.55492270e-01]\n",
      " [7.91495919e-01]\n",
      " [2.09099632e-02]\n",
      " [1.15988046e-01]\n",
      " [4.02211547e-02]\n",
      " [8.21062028e-02]\n",
      " [9.70965326e-02]\n",
      " [1.32591948e-01]\n",
      " [1.08771265e-01]\n",
      " [9.99032319e-01]\n",
      " [4.68972355e-01]\n",
      " [2.00820774e-01]\n",
      " [7.25034550e-02]\n",
      " [1.94334403e-01]\n",
      " [4.09801126e-01]\n",
      " [9.99292731e-01]\n",
      " [1.05632149e-01]\n",
      " [1.51073560e-01]\n",
      " [6.18258342e-02]\n",
      " [2.29539216e-01]\n",
      " [5.48024297e-01]\n",
      " [2.24057838e-01]\n",
      " [5.42237282e-01]\n",
      " [1.70657352e-01]\n",
      " [1.54365465e-01]\n",
      " [2.02540606e-01]\n",
      " [2.67386526e-01]\n",
      " [4.03604917e-02]\n",
      " [9.80548382e-01]\n",
      " [1.73869684e-01]\n",
      " [9.15245891e-01]\n",
      " [9.50532481e-02]\n",
      " [5.48057072e-02]\n",
      " [5.13889670e-01]\n",
      " [2.24515438e-01]\n",
      " [3.06574345e-01]\n",
      " [1.16260894e-01]\n",
      " [3.46453339e-01]\n",
      " [1.52908459e-01]\n",
      " [2.03825712e-01]\n",
      " [9.91686285e-02]\n",
      " [2.43293419e-02]\n",
      " [7.26059526e-02]\n",
      " [1.71813980e-01]\n",
      " [1.37662172e-01]\n",
      " [6.47407770e-01]\n",
      " [9.10940543e-02]\n",
      " [6.73898280e-01]\n",
      " [2.56659150e-01]\n",
      " [3.31241488e-02]\n",
      " [7.60199249e-01]\n",
      " [3.09916764e-01]\n",
      " [7.48230815e-02]\n",
      " [9.93659258e-01]\n",
      " [3.38282555e-01]\n",
      " [8.14247280e-02]\n",
      " [1.60336092e-01]\n",
      " [9.30404305e-01]\n",
      " [7.07672015e-02]\n",
      " [8.02675009e-01]\n",
      " [1.81569397e-01]\n",
      " [2.22190678e-01]\n",
      " [6.02591515e-01]\n",
      " [2.31577426e-01]\n",
      " [5.89425862e-01]\n",
      " [9.13894176e-01]\n",
      " [6.10576630e-01]\n",
      " [6.60431325e-01]\n",
      " [9.71245229e-01]\n",
      " [2.32463837e-01]\n",
      " [1.38880938e-01]\n",
      " [7.08933592e-01]\n",
      " [2.72499062e-02]\n",
      " [1.03107430e-01]\n",
      " [3.01781632e-02]\n",
      " [2.42551029e-01]\n",
      " [2.84901145e-03]\n",
      " [7.02006696e-03]\n",
      " [4.66718167e-01]\n",
      " [3.13620389e-01]\n",
      " [6.25023395e-02]\n",
      " [1.27230193e-02]\n",
      " [4.82850760e-01]\n",
      " [2.37858444e-01]\n",
      " [1.60113111e-01]\n",
      " [1.79260641e-01]\n",
      " [1.29548505e-01]\n",
      " [1.82876527e-01]\n",
      " [2.02972889e-02]\n",
      " [7.30907083e-01]\n",
      " [8.12054753e-01]\n",
      " [1.01454392e-01]\n",
      " [1.74952015e-01]\n",
      " [1.32089537e-02]\n",
      " [6.57357872e-02]\n",
      " [5.55571914e-01]\n",
      " [2.58057308e-03]\n",
      " [2.24917661e-02]\n",
      " [8.31591785e-02]\n",
      " [5.41645242e-03]\n",
      " [2.53645536e-02]\n",
      " [5.61873168e-02]\n",
      " [1.77402701e-02]\n",
      " [9.14210618e-01]\n",
      " [4.15449977e-01]\n",
      " [1.81357816e-01]\n",
      " [7.92226374e-01]\n",
      " [5.69699407e-01]\n",
      " [8.31678629e-01]\n",
      " [4.44175005e-01]\n",
      " [3.74421887e-02]\n",
      " [3.49063635e-01]\n",
      " [2.97214657e-01]\n",
      " [3.44322056e-01]\n",
      " [2.83254117e-01]\n",
      " [5.92074633e-01]\n",
      " [3.38203132e-01]\n",
      " [4.50996459e-01]\n",
      " [7.62843728e-01]\n",
      " [7.34358430e-01]\n",
      " [2.98633520e-02]\n",
      " [4.24732834e-01]\n",
      " [1.68614417e-01]\n",
      " [9.08388138e-01]\n",
      " [8.78744386e-03]\n",
      " [3.90828624e-02]\n",
      " [4.66627598e-01]\n",
      " [9.18993533e-01]\n",
      " [6.76638424e-01]\n",
      " [1.15429938e-01]\n",
      " [2.74320655e-02]\n",
      " [1.48436323e-01]\n",
      " [4.32978600e-01]\n",
      " [7.86618441e-02]\n",
      " [5.83991781e-02]\n",
      " [6.49510264e-01]\n",
      " [3.03150415e-01]\n",
      " [9.91614580e-01]\n",
      " [9.93044615e-01]\n",
      " [7.50296891e-01]\n",
      " [8.72084260e-01]\n",
      " [6.93300009e-01]\n",
      " [9.99779463e-01]\n",
      " [9.94115889e-01]\n",
      " [9.99966860e-01]\n",
      " [9.99392033e-01]\n",
      " [9.99577284e-01]\n",
      " [4.44132954e-01]\n",
      " [9.20735240e-01]\n",
      " [9.99862194e-01]\n",
      " [9.70182657e-01]\n",
      " [8.85456026e-01]\n",
      " [9.84637022e-01]\n",
      " [2.40151241e-01]\n",
      " [9.97493088e-01]\n",
      " [9.85276878e-01]\n",
      " [9.47089493e-01]\n",
      " [6.19588122e-02]\n",
      " [9.30546761e-01]\n",
      " [9.95091379e-01]\n",
      " [9.99872983e-01]\n",
      " [9.96090472e-01]\n",
      " [9.99538660e-01]\n",
      " [6.27868414e-01]\n",
      " [9.72998857e-01]\n",
      " [9.98486876e-01]\n",
      " [9.93211925e-01]\n",
      " [1.71943441e-01]\n",
      " [8.53834033e-01]\n",
      " [9.79459226e-01]\n",
      " [9.84763324e-01]\n",
      " [6.50287449e-01]\n",
      " [9.99707699e-01]\n",
      " [8.86847079e-01]\n",
      " [9.93676901e-01]\n",
      " [9.97215390e-01]\n",
      " [9.84504640e-01]\n",
      " [9.95444417e-01]\n",
      " [8.46506655e-01]\n",
      " [9.99897361e-01]\n",
      " [9.91640389e-01]\n",
      " [6.53681040e-01]\n",
      " [2.05173030e-01]\n",
      " [5.33435941e-01]\n",
      " [5.82973897e-01]\n",
      " [7.06588209e-01]\n",
      " [5.95977545e-01]\n",
      " [1.62919551e-01]\n",
      " [2.38732085e-01]\n",
      " [6.65991157e-02]\n",
      " [3.27889889e-01]\n",
      " [8.94624069e-02]\n",
      " [3.45625818e-01]\n",
      " [6.38314337e-02]\n",
      " [2.85030216e-01]\n",
      " [6.63281500e-01]\n",
      " [9.84160721e-01]\n",
      " [1.52976260e-01]\n",
      " [5.14979124e-01]\n",
      " [9.73423421e-02]\n",
      " [1.88880995e-01]\n",
      " [3.44993860e-01]\n",
      " [1.57025367e-01]\n",
      " [8.82416844e-01]\n",
      " [1.63504854e-01]\n",
      " [1.13127574e-01]\n",
      " [4.48906720e-01]\n",
      " [2.98847198e-01]\n",
      " [2.59903640e-01]\n",
      " [4.21859622e-01]\n",
      " [6.90467834e-01]\n",
      " [3.88816029e-01]\n",
      " [8.89564529e-02]\n",
      " [2.37948418e-01]\n",
      " [1.10051662e-01]\n",
      " [8.61821115e-01]\n",
      " [6.60293698e-01]\n",
      " [2.81849414e-01]\n",
      " [4.86970954e-02]\n",
      " [1.67277247e-01]\n",
      " [1.74194783e-01]\n",
      " [1.45759746e-01]\n",
      " [3.84364456e-01]\n",
      " [1.41470656e-02]\n",
      " [1.07322529e-01]\n",
      " [2.98749387e-01]\n",
      " [1.15239441e-01]\n",
      " [2.44113758e-01]\n",
      " [3.03070042e-02]\n",
      " [8.17618728e-01]\n",
      " [1.77044258e-01]\n",
      " [8.36853087e-02]\n",
      " [2.00862035e-01]\n",
      " [9.86011386e-01]\n",
      " [8.08788657e-01]\n",
      " [8.15720141e-01]\n",
      " [8.39299858e-01]\n",
      " [6.51070893e-01]\n",
      " [7.34280571e-02]\n",
      " [2.75807351e-01]\n",
      " [8.25872898e-01]\n",
      " [3.15162875e-02]\n",
      " [6.73366338e-02]\n",
      " [9.10332501e-01]\n",
      " [3.41513366e-01]\n",
      " [7.35956311e-01]\n",
      " [9.80844975e-01]\n",
      " [8.43801081e-01]\n",
      " [8.16660166e-01]\n",
      " [4.94731098e-01]\n",
      " [1.24265604e-01]\n",
      " [1.96753114e-01]\n",
      " [7.42336333e-01]\n",
      " [6.83673382e-01]\n",
      " [3.22942466e-01]\n",
      " [1.96743965e-01]\n",
      " [3.43077213e-01]\n",
      " [8.65001023e-01]\n",
      " [3.23498964e-01]\n",
      " [4.36170787e-01]\n",
      " [8.75321552e-02]\n",
      " [1.51793703e-01]\n",
      " [9.02826786e-02]\n",
      " [4.78359222e-01]\n",
      " [1.65579468e-01]\n",
      " [4.52956587e-01]\n",
      " [9.61604595e-01]\n",
      " [7.88245857e-01]\n",
      " [1.39311641e-01]\n",
      " [7.46022165e-02]\n",
      " [5.72659492e-01]\n",
      " [8.43144357e-01]\n",
      " [6.58346176e-01]\n",
      " [4.25983250e-01]\n",
      " [8.21795166e-02]\n",
      " [1.54888734e-01]\n",
      " [8.00323248e-01]\n",
      " [8.72016072e-01]\n",
      " [8.16975012e-02]\n",
      " [4.96175103e-02]\n",
      " [9.68467355e-01]\n",
      " [9.97925401e-01]\n",
      " [6.78223372e-01]\n",
      " [9.99241650e-01]\n",
      " [8.91405880e-01]\n",
      " [8.75932217e-01]\n",
      " [9.97962773e-01]\n",
      " [9.56975937e-01]\n",
      " [9.99835551e-01]\n",
      " [3.66006434e-01]\n",
      " [9.99352515e-01]\n",
      " [9.57556129e-01]\n",
      " [2.11129278e-01]\n",
      " [6.98607087e-01]\n",
      " [6.57320857e-01]\n",
      " [2.32243672e-01]\n",
      " [3.15502919e-02]\n",
      " [3.24892670e-01]\n",
      " [6.14203572e-01]\n",
      " [8.65690589e-01]\n",
      " [8.65351558e-01]\n",
      " [3.52637134e-02]\n",
      " [6.02221251e-01]\n",
      " [8.54265749e-01]\n",
      " [2.73343604e-02]\n",
      " [7.34882951e-02]\n",
      " [3.94090004e-02]\n",
      " [5.17030299e-01]\n",
      " [9.01660323e-01]\n",
      " [2.76089221e-01]\n",
      " [5.69052219e-01]\n",
      " [1.61654085e-01]\n",
      " [2.61803120e-01]\n",
      " [9.19900060e-01]\n",
      " [4.28453028e-01]\n",
      " [1.64818123e-01]\n",
      " [2.12299943e-01]\n",
      " [7.31855392e-01]\n",
      " [7.65973032e-02]\n",
      " [1.65572032e-01]\n",
      " [8.22564840e-01]\n",
      " [8.74886274e-01]\n",
      " [8.14410925e-01]\n",
      " [7.44920373e-01]\n",
      " [8.67154956e-01]\n",
      " [7.85640478e-01]\n",
      " [4.53950018e-01]\n",
      " [2.34513715e-01]\n",
      " [8.71107697e-01]\n",
      " [2.00681224e-01]\n",
      " [4.94049527e-02]\n",
      " [9.09590125e-01]\n",
      " [6.13869667e-01]\n",
      " [3.16201627e-01]\n",
      " [9.17867184e-01]\n",
      " [9.57507968e-01]\n",
      " [9.97620761e-01]\n",
      " [7.80357569e-02]\n",
      " [2.77363300e-01]\n",
      " [8.57102454e-01]\n",
      " [1.10389739e-01]\n",
      " [1.31771877e-01]\n",
      " [8.84145424e-02]\n",
      " [1.23523839e-01]\n",
      " [7.23971665e-01]\n",
      " [7.48912990e-01]\n",
      " [5.40078245e-02]\n",
      " [2.24339336e-01]\n",
      " [9.31910157e-01]\n",
      " [8.68746787e-02]\n",
      " [2.06753165e-01]\n",
      " [1.33130729e-01]\n",
      " [7.23043859e-01]\n",
      " [6.81193620e-02]\n",
      " [4.19485681e-02]\n",
      " [2.96046495e-01]\n",
      " [1.79537818e-01]\n",
      " [6.90199360e-02]\n",
      " [4.37028736e-01]\n",
      " [5.63665554e-02]\n",
      " [9.33780447e-02]\n",
      " [3.71825732e-02]\n",
      " [8.62897858e-02]\n",
      " [8.41166675e-02]\n",
      " [9.95539546e-01]\n",
      " [3.63972075e-02]\n",
      " [9.85584199e-01]\n",
      " [6.47829652e-01]\n",
      " [5.48242450e-01]\n",
      " [7.82069787e-02]\n",
      " [5.26590645e-02]\n",
      " [3.63847345e-01]\n",
      " [8.70172977e-01]\n",
      " [7.07411692e-02]\n",
      " [9.51357633e-02]\n",
      " [6.82253599e-01]\n",
      " [4.57986221e-02]\n",
      " [1.41424224e-01]\n",
      " [3.54290381e-02]\n",
      " [3.21656577e-02]\n",
      " [6.60529807e-02]\n",
      " [2.88398787e-02]\n",
      " [8.00193008e-03]]\n",
      "Predicted probabilities shape: (832, 1)\n",
      "Predicted labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0\n",
      " 0 1 0 1 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 1 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 1 1 0 0\n",
      " 1 0 0 1 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0]\n",
      "Predicted labels shape: (832,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.4637 - auc: 0.4309 - f1_score: 0.4465 - loss: 1.1752 - precision: 0.9858 - recall: 0.3756\n",
      "Training model: MobileNetV3Small on dataset: The Wildfire Dataset_DeepFire\n",
      "Epoch 1/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - accuracy: 0.6583 - auc: 0.7506 - f1_score: 0.6927 - loss: 0.7145 - precision: 0.7811 - recall: 0.6035 - val_accuracy: 0.6193 - val_auc: 0.8237 - val_f1_score: 0.7603 - val_loss: 0.6489 - val_precision: 0.6193 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.7553 - auc: 0.8207 - f1_score: 0.7989 - loss: 0.5257 - precision: 0.7896 - recall: 0.8132 - val_accuracy: 0.6697 - val_auc: 0.8649 - val_f1_score: 0.7787 - val_loss: 0.5865 - val_precision: 0.6476 - val_recall: 0.9894 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.7583 - auc: 0.8180 - f1_score: 0.8082 - loss: 0.5172 - precision: 0.7972 - recall: 0.8231 - val_accuracy: 0.8097 - val_auc: 0.8900 - val_f1_score: 0.8524 - val_loss: 0.4871 - val_precision: 0.8277 - val_recall: 0.8882 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.7569 - auc: 0.8316 - f1_score: 0.7989 - loss: 0.5034 - precision: 0.7792 - recall: 0.8232 - val_accuracy: 0.8146 - val_auc: 0.8885 - val_f1_score: 0.8464 - val_loss: 0.4352 - val_precision: 0.8624 - val_recall: 0.8316 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.7568 - auc: 0.8304 - f1_score: 0.8024 - loss: 0.4934 - precision: 0.7895 - recall: 0.8224 - val_accuracy: 0.8288 - val_auc: 0.9012 - val_f1_score: 0.8593 - val_loss: 0.4102 - val_precision: 0.8653 - val_recall: 0.8543 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.7731 - auc: 0.8441 - f1_score: 0.8163 - loss: 0.4740 - precision: 0.8029 - recall: 0.8349 - val_accuracy: 0.8011 - val_auc: 0.8946 - val_f1_score: 0.8240 - val_loss: 0.4187 - val_precision: 0.8724 - val_recall: 0.7890 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.7772 - auc: 0.8503 - f1_score: 0.8205 - loss: 0.4679 - precision: 0.8137 - recall: 0.8294 - val_accuracy: 0.7990 - val_auc: 0.8967 - val_f1_score: 0.8204 - val_loss: 0.4235 - val_precision: 0.9018 - val_recall: 0.7580 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - accuracy: 0.7803 - auc: 0.8518 - f1_score: 0.8211 - loss: 0.4650 - precision: 0.8163 - recall: 0.8287 - val_accuracy: 0.8381 - val_auc: 0.9125 - val_f1_score: 0.8698 - val_loss: 0.3827 - val_precision: 0.8573 - val_recall: 0.8920 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 173ms/step - accuracy: 0.7827 - auc: 0.8581 - f1_score: 0.8198 - loss: 0.4604 - precision: 0.8109 - recall: 0.8331 - val_accuracy: 0.8459 - val_auc: 0.9217 - val_f1_score: 0.8721 - val_loss: 0.3705 - val_precision: 0.8842 - val_recall: 0.8650 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 159ms/step - accuracy: 0.7811 - auc: 0.8547 - f1_score: 0.8226 - loss: 0.4603 - precision: 0.8121 - recall: 0.8375 - val_accuracy: 0.8317 - val_auc: 0.9099 - val_f1_score: 0.8542 - val_loss: 0.3856 - val_precision: 0.8834 - val_recall: 0.8327 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 150ms/step - accuracy: 0.7886 - auc: 0.8614 - f1_score: 0.8299 - loss: 0.4508 - precision: 0.8198 - recall: 0.8432 - val_accuracy: 0.8374 - val_auc: 0.9193 - val_f1_score: 0.8599 - val_loss: 0.3807 - val_precision: 0.8918 - val_recall: 0.8347 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 140ms/step - accuracy: 0.7934 - auc: 0.8680 - f1_score: 0.8333 - loss: 0.4400 - precision: 0.8252 - recall: 0.8444 - val_accuracy: 0.8402 - val_auc: 0.9163 - val_f1_score: 0.8651 - val_loss: 0.3664 - val_precision: 0.8653 - val_recall: 0.8724 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.7821 - auc: 0.8631 - f1_score: 0.8249 - loss: 0.4460 - precision: 0.8166 - recall: 0.8376 - val_accuracy: 0.8544 - val_auc: 0.9323 - val_f1_score: 0.8740 - val_loss: 0.3544 - val_precision: 0.9056 - val_recall: 0.8524 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.7994 - auc: 0.8769 - f1_score: 0.8366 - loss: 0.4244 - precision: 0.8326 - recall: 0.8458 - val_accuracy: 0.8388 - val_auc: 0.9200 - val_f1_score: 0.8590 - val_loss: 0.3695 - val_precision: 0.8965 - val_recall: 0.8331 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 90ms/step - accuracy: 0.7938 - auc: 0.8732 - f1_score: 0.8303 - loss: 0.4304 - precision: 0.8264 - recall: 0.8389 - val_accuracy: 0.8516 - val_auc: 0.9230 - val_f1_score: 0.8762 - val_loss: 0.3578 - val_precision: 0.8741 - val_recall: 0.8853 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.8005 - auc: 0.8730 - f1_score: 0.8393 - loss: 0.4322 - precision: 0.8299 - recall: 0.8522 - val_accuracy: 0.8523 - val_auc: 0.9307 - val_f1_score: 0.8724 - val_loss: 0.3509 - val_precision: 0.9140 - val_recall: 0.8406 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.7931 - auc: 0.8766 - f1_score: 0.8320 - loss: 0.4266 - precision: 0.8369 - recall: 0.8322 - val_accuracy: 0.8445 - val_auc: 0.9315 - val_f1_score: 0.8646 - val_loss: 0.3495 - val_precision: 0.9020 - val_recall: 0.8359 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8007 - auc: 0.8765 - f1_score: 0.8383 - loss: 0.4283 - precision: 0.8379 - recall: 0.8407 - val_accuracy: 0.8636 - val_auc: 0.9401 - val_f1_score: 0.8859 - val_loss: 0.3336 - val_precision: 0.8894 - val_recall: 0.8873 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 81ms/step - accuracy: 0.8083 - auc: 0.8829 - f1_score: 0.8449 - loss: 0.4174 - precision: 0.8358 - recall: 0.8569 - val_accuracy: 0.8558 - val_auc: 0.9348 - val_f1_score: 0.8775 - val_loss: 0.3439 - val_precision: 0.9019 - val_recall: 0.8593 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.7982 - auc: 0.8748 - f1_score: 0.8361 - loss: 0.4308 - precision: 0.8329 - recall: 0.8416 - val_accuracy: 0.8757 - val_auc: 0.9398 - val_f1_score: 0.8934 - val_loss: 0.3309 - val_precision: 0.9053 - val_recall: 0.8872 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.7996 - auc: 0.8783 - f1_score: 0.8343 - loss: 0.4230 - precision: 0.8337 - recall: 0.8397 - val_accuracy: 0.8494 - val_auc: 0.9302 - val_f1_score: 0.8772 - val_loss: 0.3465 - val_precision: 0.8661 - val_recall: 0.8903 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.8118 - auc: 0.8832 - f1_score: 0.8454 - loss: 0.4204 - precision: 0.8337 - recall: 0.8628 - val_accuracy: 0.8594 - val_auc: 0.9410 - val_f1_score: 0.8806 - val_loss: 0.3402 - val_precision: 0.9303 - val_recall: 0.8403 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 80ms/step - accuracy: 0.8104 - auc: 0.8878 - f1_score: 0.8426 - loss: 0.4098 - precision: 0.8440 - recall: 0.8455 - val_accuracy: 0.8743 - val_auc: 0.9462 - val_f1_score: 0.8941 - val_loss: 0.3152 - val_precision: 0.8995 - val_recall: 0.8921 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.8188 - auc: 0.8988 - f1_score: 0.8520 - loss: 0.3896 - precision: 0.8510 - recall: 0.8554 - val_accuracy: 0.8608 - val_auc: 0.9335 - val_f1_score: 0.8839 - val_loss: 0.3359 - val_precision: 0.8973 - val_recall: 0.8791 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - accuracy: 0.8089 - auc: 0.8842 - f1_score: 0.8450 - loss: 0.4143 - precision: 0.8368 - recall: 0.8575 - val_accuracy: 0.8722 - val_auc: 0.9433 - val_f1_score: 0.8933 - val_loss: 0.3157 - val_precision: 0.8931 - val_recall: 0.8993 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - accuracy: 0.8195 - auc: 0.8936 - f1_score: 0.8536 - loss: 0.3990 - precision: 0.8506 - recall: 0.8591 - val_accuracy: 0.8771 - val_auc: 0.9449 - val_f1_score: 0.8994 - val_loss: 0.3128 - val_precision: 0.8983 - val_recall: 0.9034 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.8267 - auc: 0.8995 - f1_score: 0.8575 - loss: 0.3882 - precision: 0.8616 - recall: 0.8563 - val_accuracy: 0.8743 - val_auc: 0.9505 - val_f1_score: 0.8907 - val_loss: 0.3122 - val_precision: 0.9176 - val_recall: 0.8715 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - accuracy: 0.8261 - auc: 0.9038 - f1_score: 0.8570 - loss: 0.3852 - precision: 0.8524 - recall: 0.8647 - val_accuracy: 0.8786 - val_auc: 0.9550 - val_f1_score: 0.8956 - val_loss: 0.3108 - val_precision: 0.9193 - val_recall: 0.8775 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 101ms/step - accuracy: 0.8180 - auc: 0.8937 - f1_score: 0.8490 - loss: 0.4028 - precision: 0.8433 - recall: 0.8590 - val_accuracy: 0.8722 - val_auc: 0.9518 - val_f1_score: 0.8916 - val_loss: 0.3068 - val_precision: 0.9119 - val_recall: 0.8808 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 100ms/step - accuracy: 0.8221 - auc: 0.9001 - f1_score: 0.8538 - loss: 0.3913 - precision: 0.8423 - recall: 0.8698 - val_accuracy: 0.8899 - val_auc: 0.9568 - val_f1_score: 0.9068 - val_loss: 0.2915 - val_precision: 0.9152 - val_recall: 0.9012 - learning_rate: 0.0010\n",
      "Epoch 31/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 103ms/step - accuracy: 0.8179 - auc: 0.8950 - f1_score: 0.8505 - loss: 0.3977 - precision: 0.8461 - recall: 0.8587 - val_accuracy: 0.8920 - val_auc: 0.9594 - val_f1_score: 0.9106 - val_loss: 0.2869 - val_precision: 0.9051 - val_recall: 0.9199 - learning_rate: 0.0010\n",
      "Epoch 32/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 100ms/step - accuracy: 0.8155 - auc: 0.8955 - f1_score: 0.8468 - loss: 0.3969 - precision: 0.8444 - recall: 0.8524 - val_accuracy: 0.8793 - val_auc: 0.9535 - val_f1_score: 0.8977 - val_loss: 0.3079 - val_precision: 0.9153 - val_recall: 0.8832 - learning_rate: 0.0010\n",
      "Epoch 33/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 89ms/step - accuracy: 0.8277 - auc: 0.9097 - f1_score: 0.8603 - loss: 0.3690 - precision: 0.8587 - recall: 0.8636 - val_accuracy: 0.8942 - val_auc: 0.9618 - val_f1_score: 0.9142 - val_loss: 0.2850 - val_precision: 0.9123 - val_recall: 0.9195 - learning_rate: 0.0010\n",
      "Epoch 34/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.8291 - auc: 0.9018 - f1_score: 0.8590 - loss: 0.3836 - precision: 0.8578 - recall: 0.8643 - val_accuracy: 0.8778 - val_auc: 0.9583 - val_f1_score: 0.8911 - val_loss: 0.2926 - val_precision: 0.9149 - val_recall: 0.8754 - learning_rate: 0.0010\n",
      "Epoch 35/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.8277 - auc: 0.9055 - f1_score: 0.8608 - loss: 0.3800 - precision: 0.8626 - recall: 0.8606 - val_accuracy: 0.8906 - val_auc: 0.9593 - val_f1_score: 0.9100 - val_loss: 0.2882 - val_precision: 0.8993 - val_recall: 0.9244 - learning_rate: 0.0010\n",
      "Epoch 36/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - accuracy: 0.8248 - auc: 0.9018 - f1_score: 0.8563 - loss: 0.3856 - precision: 0.8595 - recall: 0.8556 - val_accuracy: 0.8942 - val_auc: 0.9590 - val_f1_score: 0.9118 - val_loss: 0.2815 - val_precision: 0.9268 - val_recall: 0.9027 - learning_rate: 0.0010\n",
      "Epoch 37/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - accuracy: 0.8214 - auc: 0.9024 - f1_score: 0.8543 - loss: 0.3837 - precision: 0.8483 - recall: 0.8642 - val_accuracy: 0.8871 - val_auc: 0.9637 - val_f1_score: 0.9005 - val_loss: 0.2898 - val_precision: 0.9514 - val_recall: 0.8601 - learning_rate: 0.0010\n",
      "Epoch 38/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.8313 - auc: 0.9097 - f1_score: 0.8627 - loss: 0.3681 - precision: 0.8623 - recall: 0.8658 - val_accuracy: 0.8977 - val_auc: 0.9612 - val_f1_score: 0.9137 - val_loss: 0.2843 - val_precision: 0.9278 - val_recall: 0.9043 - learning_rate: 0.0010\n",
      "Epoch 39/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.8358 - auc: 0.9124 - f1_score: 0.8662 - loss: 0.3655 - precision: 0.8632 - recall: 0.8719 - val_accuracy: 0.8942 - val_auc: 0.9603 - val_f1_score: 0.9127 - val_loss: 0.2802 - val_precision: 0.9097 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 40/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.8269 - auc: 0.9037 - f1_score: 0.8589 - loss: 0.3807 - precision: 0.8554 - recall: 0.8668 - val_accuracy: 0.8963 - val_auc: 0.9588 - val_f1_score: 0.9175 - val_loss: 0.2881 - val_precision: 0.9086 - val_recall: 0.9272 - learning_rate: 0.0010\n",
      "Epoch 41/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 92ms/step - accuracy: 0.8185 - auc: 0.9013 - f1_score: 0.8521 - loss: 0.3835 - precision: 0.8512 - recall: 0.8557 - val_accuracy: 0.9062 - val_auc: 0.9663 - val_f1_score: 0.9187 - val_loss: 0.2757 - val_precision: 0.9469 - val_recall: 0.8991 - learning_rate: 0.0010\n",
      "Epoch 42/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 97ms/step - accuracy: 0.8282 - auc: 0.9097 - f1_score: 0.8590 - loss: 0.3675 - precision: 0.8577 - recall: 0.8639 - val_accuracy: 0.9169 - val_auc: 0.9685 - val_f1_score: 0.9284 - val_loss: 0.2572 - val_precision: 0.9453 - val_recall: 0.9152 - learning_rate: 0.0010\n",
      "Epoch 43/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 228ms/step - accuracy: 0.8303 - auc: 0.9089 - f1_score: 0.8606 - loss: 0.3703 - precision: 0.8644 - recall: 0.8598 - val_accuracy: 0.9134 - val_auc: 0.9752 - val_f1_score: 0.9267 - val_loss: 0.2521 - val_precision: 0.9350 - val_recall: 0.9243 - learning_rate: 0.0010\n",
      "Epoch 44/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 156ms/step - accuracy: 0.8250 - auc: 0.9041 - f1_score: 0.8555 - loss: 0.3803 - precision: 0.8527 - recall: 0.8619 - val_accuracy: 0.9091 - val_auc: 0.9722 - val_f1_score: 0.9215 - val_loss: 0.2590 - val_precision: 0.9470 - val_recall: 0.9005 - learning_rate: 0.0010\n",
      "Epoch 45/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 109ms/step - accuracy: 0.8400 - auc: 0.9112 - f1_score: 0.8714 - loss: 0.3671 - precision: 0.8748 - recall: 0.8702 - val_accuracy: 0.9077 - val_auc: 0.9710 - val_f1_score: 0.9226 - val_loss: 0.2538 - val_precision: 0.9539 - val_recall: 0.8952 - learning_rate: 0.0010\n",
      "Epoch 46/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 89ms/step - accuracy: 0.8369 - auc: 0.9115 - f1_score: 0.8678 - loss: 0.3655 - precision: 0.8694 - recall: 0.8687 - val_accuracy: 0.9190 - val_auc: 0.9733 - val_f1_score: 0.9303 - val_loss: 0.2492 - val_precision: 0.9442 - val_recall: 0.9223 - learning_rate: 0.0010\n",
      "Epoch 47/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.8334 - auc: 0.9073 - f1_score: 0.8632 - loss: 0.3749 - precision: 0.8547 - recall: 0.8753 - val_accuracy: 0.9155 - val_auc: 0.9685 - val_f1_score: 0.9304 - val_loss: 0.2591 - val_precision: 0.9332 - val_recall: 0.9277 - learning_rate: 0.0010\n",
      "Epoch 48/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 90ms/step - accuracy: 0.8334 - auc: 0.9108 - f1_score: 0.8620 - loss: 0.3703 - precision: 0.8566 - recall: 0.8718 - val_accuracy: 0.9134 - val_auc: 0.9706 - val_f1_score: 0.9265 - val_loss: 0.2492 - val_precision: 0.9430 - val_recall: 0.9173 - learning_rate: 0.0010\n",
      "Epoch 49/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 91ms/step - accuracy: 0.8417 - auc: 0.9211 - f1_score: 0.8697 - loss: 0.3459 - precision: 0.8686 - recall: 0.8738 - val_accuracy: 0.9290 - val_auc: 0.9774 - val_f1_score: 0.9403 - val_loss: 0.2378 - val_precision: 0.9483 - val_recall: 0.9351 - learning_rate: 0.0010\n",
      "Epoch 50/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 93ms/step - accuracy: 0.8366 - auc: 0.9133 - f1_score: 0.8657 - loss: 0.3637 - precision: 0.8550 - recall: 0.8807 - val_accuracy: 0.9190 - val_auc: 0.9765 - val_f1_score: 0.9308 - val_loss: 0.2411 - val_precision: 0.9200 - val_recall: 0.9444 - learning_rate: 0.0010\n",
      "Epoch 51/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 89ms/step - accuracy: 0.8359 - auc: 0.9182 - f1_score: 0.8642 - loss: 0.3529 - precision: 0.8623 - recall: 0.8704 - val_accuracy: 0.9183 - val_auc: 0.9784 - val_f1_score: 0.9316 - val_loss: 0.2421 - val_precision: 0.9306 - val_recall: 0.9339 - learning_rate: 0.0010\n",
      "Epoch 52/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 92ms/step - accuracy: 0.8468 - auc: 0.9236 - f1_score: 0.8763 - loss: 0.3415 - precision: 0.8772 - recall: 0.8782 - val_accuracy: 0.9183 - val_auc: 0.9745 - val_f1_score: 0.9315 - val_loss: 0.2463 - val_precision: 0.9319 - val_recall: 0.9351 - learning_rate: 0.0010\n",
      "Epoch 53/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 113ms/step - accuracy: 0.8505 - auc: 0.9253 - f1_score: 0.8760 - loss: 0.3387 - precision: 0.8751 - recall: 0.8803 - val_accuracy: 0.9112 - val_auc: 0.9722 - val_f1_score: 0.9236 - val_loss: 0.2510 - val_precision: 0.9481 - val_recall: 0.9025 - learning_rate: 0.0010\n",
      "Epoch 54/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 152ms/step - accuracy: 0.8399 - auc: 0.9129 - f1_score: 0.8700 - loss: 0.3636 - precision: 0.8699 - recall: 0.8728 - val_accuracy: 0.9212 - val_auc: 0.9779 - val_f1_score: 0.9347 - val_loss: 0.2364 - val_precision: 0.9244 - val_recall: 0.9472 - learning_rate: 0.0010\n",
      "Epoch 55/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 156ms/step - accuracy: 0.8433 - auc: 0.9217 - f1_score: 0.8716 - loss: 0.3452 - precision: 0.8729 - recall: 0.8743 - val_accuracy: 0.9382 - val_auc: 0.9806 - val_f1_score: 0.9472 - val_loss: 0.2283 - val_precision: 0.9469 - val_recall: 0.9503 - learning_rate: 0.0010\n",
      "Epoch 56/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 124ms/step - accuracy: 0.8348 - auc: 0.9152 - f1_score: 0.8654 - loss: 0.3580 - precision: 0.8639 - recall: 0.8704 - val_accuracy: 0.9361 - val_auc: 0.9795 - val_f1_score: 0.9451 - val_loss: 0.2335 - val_precision: 0.9660 - val_recall: 0.9277 - learning_rate: 0.0010\n",
      "Epoch 57/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 107ms/step - accuracy: 0.8467 - auc: 0.9191 - f1_score: 0.8766 - loss: 0.3503 - precision: 0.8767 - recall: 0.8772 - val_accuracy: 0.9197 - val_auc: 0.9760 - val_f1_score: 0.9320 - val_loss: 0.2483 - val_precision: 0.9483 - val_recall: 0.9156 - learning_rate: 0.0010\n",
      "Epoch 58/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 90ms/step - accuracy: 0.8489 - auc: 0.9256 - f1_score: 0.8765 - loss: 0.3357 - precision: 0.8724 - recall: 0.8836 - val_accuracy: 0.9432 - val_auc: 0.9838 - val_f1_score: 0.9517 - val_loss: 0.2151 - val_precision: 0.9548 - val_recall: 0.9525 - learning_rate: 0.0010\n",
      "Epoch 59/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 95ms/step - accuracy: 0.8490 - auc: 0.9217 - f1_score: 0.8751 - loss: 0.3461 - precision: 0.8738 - recall: 0.8804 - val_accuracy: 0.9219 - val_auc: 0.9787 - val_f1_score: 0.9324 - val_loss: 0.2359 - val_precision: 0.9615 - val_recall: 0.9075 - learning_rate: 0.0010\n",
      "Epoch 60/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 147ms/step - accuracy: 0.8433 - auc: 0.9157 - f1_score: 0.8714 - loss: 0.3591 - precision: 0.8714 - recall: 0.8739 - val_accuracy: 0.9339 - val_auc: 0.9826 - val_f1_score: 0.9436 - val_loss: 0.2241 - val_precision: 0.9586 - val_recall: 0.9332 - learning_rate: 0.0010\n",
      "Epoch 61/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 129ms/step - accuracy: 0.8378 - auc: 0.9178 - f1_score: 0.8667 - loss: 0.3532 - precision: 0.8638 - recall: 0.8723 - val_accuracy: 0.9233 - val_auc: 0.9771 - val_f1_score: 0.9371 - val_loss: 0.2318 - val_precision: 0.9191 - val_recall: 0.9562 - learning_rate: 0.0010\n",
      "Epoch 62/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 150ms/step - accuracy: 0.8526 - auc: 0.9244 - f1_score: 0.8795 - loss: 0.3398 - precision: 0.8771 - recall: 0.8843 - val_accuracy: 0.9254 - val_auc: 0.9826 - val_f1_score: 0.9364 - val_loss: 0.2301 - val_precision: 0.9636 - val_recall: 0.9138 - learning_rate: 0.0010\n",
      "Epoch 63/80\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.8442 - auc: 0.9237 - f1_score: 0.8729 - loss: 0.3395 - precision: 0.8685 - recall: 0.8800\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 159ms/step - accuracy: 0.8442 - auc: 0.9237 - f1_score: 0.8729 - loss: 0.3395 - precision: 0.8686 - recall: 0.8801 - val_accuracy: 0.9325 - val_auc: 0.9827 - val_f1_score: 0.9439 - val_loss: 0.2174 - val_precision: 0.9610 - val_recall: 0.9292 - learning_rate: 0.0010\n",
      "Training time: 1231.00 seconds\n",
      "Evaluating MobileNetV3Small on The Wildfire Dataset_DeepFire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "True labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True labels shape: (832,)\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step\n",
      "Predicted probabilities: [[5.77173352e-01]\n",
      " [1.78582311e-01]\n",
      " [9.72386241e-01]\n",
      " [6.65029764e-01]\n",
      " [9.04909492e-01]\n",
      " [9.46476400e-01]\n",
      " [2.10975911e-02]\n",
      " [5.42867959e-01]\n",
      " [7.44394660e-01]\n",
      " [3.04376245e-01]\n",
      " [9.00912642e-01]\n",
      " [5.74487567e-01]\n",
      " [3.87032062e-01]\n",
      " [5.52671611e-01]\n",
      " [5.85825980e-01]\n",
      " [2.34317839e-01]\n",
      " [9.32404757e-01]\n",
      " [9.62634146e-01]\n",
      " [5.82349539e-01]\n",
      " [8.90043139e-01]\n",
      " [2.99363703e-01]\n",
      " [6.12177968e-01]\n",
      " [9.50619161e-01]\n",
      " [8.80104840e-01]\n",
      " [7.01073408e-01]\n",
      " [7.10249662e-01]\n",
      " [9.90762174e-01]\n",
      " [7.55553901e-01]\n",
      " [5.32141566e-01]\n",
      " [9.81547952e-01]\n",
      " [9.93416071e-01]\n",
      " [9.89807606e-01]\n",
      " [8.87192607e-01]\n",
      " [9.99996662e-01]\n",
      " [9.97987032e-01]\n",
      " [9.97683406e-01]\n",
      " [9.85038400e-01]\n",
      " [7.45331049e-01]\n",
      " [9.93740201e-01]\n",
      " [4.02197629e-01]\n",
      " [9.44567502e-01]\n",
      " [5.74886560e-01]\n",
      " [9.98436809e-01]\n",
      " [6.80937588e-01]\n",
      " [8.56320381e-01]\n",
      " [9.83167052e-01]\n",
      " [9.98649299e-01]\n",
      " [7.60849297e-01]\n",
      " [8.23983014e-01]\n",
      " [9.86982226e-01]\n",
      " [9.31218028e-01]\n",
      " [9.77159858e-01]\n",
      " [9.99801934e-01]\n",
      " [9.02874827e-01]\n",
      " [9.12615895e-01]\n",
      " [8.67198706e-01]\n",
      " [9.99894500e-01]\n",
      " [9.08302248e-01]\n",
      " [8.26523364e-01]\n",
      " [9.98727798e-01]\n",
      " [9.23686624e-01]\n",
      " [9.41811740e-01]\n",
      " [2.22123638e-01]\n",
      " [9.92863774e-01]\n",
      " [6.42593503e-01]\n",
      " [9.33208466e-01]\n",
      " [9.49783504e-01]\n",
      " [9.56012130e-01]\n",
      " [1.08045362e-01]\n",
      " [7.55485177e-01]\n",
      " [8.80167782e-01]\n",
      " [5.17243266e-01]\n",
      " [9.87744927e-01]\n",
      " [4.45966572e-01]\n",
      " [9.77042198e-01]\n",
      " [7.80828774e-01]\n",
      " [2.66127348e-01]\n",
      " [6.79008603e-01]\n",
      " [8.39754105e-01]\n",
      " [9.97247875e-01]\n",
      " [9.71766233e-01]\n",
      " [8.10042441e-01]\n",
      " [9.57074940e-01]\n",
      " [9.87865269e-01]\n",
      " [3.60714018e-01]\n",
      " [9.76959705e-01]\n",
      " [9.27645624e-01]\n",
      " [8.61767232e-01]\n",
      " [8.78396749e-01]\n",
      " [9.99850035e-01]\n",
      " [7.05379963e-01]\n",
      " [3.57498586e-01]\n",
      " [8.58049572e-01]\n",
      " [9.94934857e-01]\n",
      " [8.27761114e-01]\n",
      " [9.88913238e-01]\n",
      " [8.25208902e-01]\n",
      " [1.83703691e-01]\n",
      " [9.91827846e-01]\n",
      " [9.32219446e-01]\n",
      " [8.03522527e-01]\n",
      " [8.41611028e-01]\n",
      " [8.31437051e-01]\n",
      " [8.96336496e-01]\n",
      " [6.83631778e-01]\n",
      " [9.28272843e-01]\n",
      " [6.33279622e-01]\n",
      " [7.31136560e-01]\n",
      " [9.79958832e-01]\n",
      " [9.23506439e-01]\n",
      " [9.62451279e-01]\n",
      " [9.92519081e-01]\n",
      " [9.86369669e-01]\n",
      " [9.07653987e-01]\n",
      " [1.48669958e-01]\n",
      " [9.36496615e-01]\n",
      " [8.54652226e-01]\n",
      " [9.26900148e-01]\n",
      " [9.65795815e-01]\n",
      " [9.27297652e-01]\n",
      " [6.90819919e-01]\n",
      " [6.43935323e-01]\n",
      " [9.03812706e-01]\n",
      " [3.90313685e-01]\n",
      " [9.75838900e-01]\n",
      " [7.99150646e-01]\n",
      " [7.89893508e-01]\n",
      " [9.41918731e-01]\n",
      " [9.48022723e-01]\n",
      " [9.83226359e-01]\n",
      " [9.98565674e-01]\n",
      " [9.98926699e-01]\n",
      " [9.97150958e-01]\n",
      " [9.88197029e-01]\n",
      " [7.94602990e-01]\n",
      " [8.94284904e-01]\n",
      " [9.98307586e-01]\n",
      " [6.98878050e-01]\n",
      " [2.68192500e-01]\n",
      " [4.74428058e-01]\n",
      " [9.89810288e-01]\n",
      " [2.84800470e-01]\n",
      " [4.08106565e-01]\n",
      " [9.20106888e-01]\n",
      " [9.90905762e-01]\n",
      " [5.44902861e-01]\n",
      " [9.91584539e-01]\n",
      " [8.86279941e-01]\n",
      " [6.28500223e-01]\n",
      " [9.94275630e-01]\n",
      " [8.16072404e-01]\n",
      " [9.94738698e-01]\n",
      " [9.63620782e-01]\n",
      " [9.74895239e-01]\n",
      " [9.57637787e-01]\n",
      " [9.99385178e-01]\n",
      " [9.00200307e-01]\n",
      " [7.74566412e-01]\n",
      " [9.78310943e-01]\n",
      " [5.41502118e-01]\n",
      " [8.48876655e-01]\n",
      " [9.43167508e-01]\n",
      " [1.91054836e-01]\n",
      " [9.63294089e-01]\n",
      " [8.00013483e-01]\n",
      " [1.60978928e-01]\n",
      " [9.99573767e-01]\n",
      " [4.67901558e-01]\n",
      " [9.93673921e-01]\n",
      " [6.37746096e-01]\n",
      " [6.12663448e-01]\n",
      " [9.97290194e-01]\n",
      " [1.99339673e-01]\n",
      " [9.98308182e-01]\n",
      " [9.17806983e-01]\n",
      " [6.93243027e-01]\n",
      " [9.03222501e-01]\n",
      " [9.88547206e-01]\n",
      " [9.78379905e-01]\n",
      " [9.02975559e-01]\n",
      " [9.93600965e-01]\n",
      " [8.74094486e-01]\n",
      " [9.92772460e-01]\n",
      " [9.97889042e-01]\n",
      " [9.79682088e-01]\n",
      " [3.38083237e-01]\n",
      " [1.12268761e-01]\n",
      " [4.13730860e-01]\n",
      " [8.92732024e-01]\n",
      " [2.64136374e-01]\n",
      " [4.57399577e-01]\n",
      " [9.31979179e-01]\n",
      " [9.68659818e-01]\n",
      " [9.96353030e-01]\n",
      " [7.48423457e-01]\n",
      " [9.38760400e-01]\n",
      " [1.77002668e-01]\n",
      " [9.17319417e-01]\n",
      " [8.86758387e-01]\n",
      " [4.19552803e-01]\n",
      " [7.77561069e-01]\n",
      " [4.78292912e-01]\n",
      " [9.20137763e-01]\n",
      " [9.36751127e-01]\n",
      " [9.50428605e-01]\n",
      " [9.72147405e-01]\n",
      " [9.76184905e-01]\n",
      " [9.57035482e-01]\n",
      " [9.39249039e-01]\n",
      " [9.63680983e-01]\n",
      " [9.73599970e-01]\n",
      " [9.99178290e-01]\n",
      " [8.27141762e-01]\n",
      " [9.73791182e-01]\n",
      " [9.95877326e-01]\n",
      " [9.50398564e-01]\n",
      " [5.46630025e-01]\n",
      " [9.93380427e-01]\n",
      " [7.87502527e-01]\n",
      " [9.99591529e-01]\n",
      " [8.10382366e-01]\n",
      " [9.55109060e-01]\n",
      " [6.44388914e-01]\n",
      " [9.96837616e-01]\n",
      " [9.91624355e-01]\n",
      " [9.77695882e-01]\n",
      " [9.70297158e-01]\n",
      " [2.92248905e-01]\n",
      " [8.86390448e-01]\n",
      " [9.82436538e-01]\n",
      " [9.46817517e-01]\n",
      " [8.93589616e-01]\n",
      " [7.78928816e-01]\n",
      " [9.37160015e-01]\n",
      " [9.26128566e-01]\n",
      " [9.28983271e-01]\n",
      " [8.55437398e-01]\n",
      " [3.98972392e-01]\n",
      " [9.73293304e-01]\n",
      " [9.92423296e-01]\n",
      " [8.54385257e-01]\n",
      " [9.53318775e-01]\n",
      " [5.40115833e-01]\n",
      " [4.28879976e-01]\n",
      " [9.94221151e-01]\n",
      " [9.53775287e-01]\n",
      " [3.54055554e-01]\n",
      " [4.77534652e-01]\n",
      " [9.13105011e-01]\n",
      " [6.18041337e-01]\n",
      " [7.84530401e-01]\n",
      " [9.91429448e-01]\n",
      " [4.89998788e-01]\n",
      " [9.08964813e-01]\n",
      " [8.20210159e-01]\n",
      " [5.49643278e-01]\n",
      " [3.97033602e-01]\n",
      " [8.94666016e-01]\n",
      " [7.13478386e-01]\n",
      " [6.82174623e-01]\n",
      " [8.58152092e-01]\n",
      " [7.75514066e-01]\n",
      " [7.62599528e-01]\n",
      " [9.53929186e-01]\n",
      " [8.60783577e-01]\n",
      " [2.80646443e-01]\n",
      " [9.62261856e-01]\n",
      " [8.39146376e-01]\n",
      " [9.31299925e-01]\n",
      " [2.27044597e-02]\n",
      " [2.84021437e-01]\n",
      " [7.51906812e-01]\n",
      " [8.03887174e-02]\n",
      " [2.37917811e-01]\n",
      " [3.03768396e-01]\n",
      " [9.61879253e-01]\n",
      " [9.79730725e-01]\n",
      " [4.75235283e-01]\n",
      " [9.18000281e-01]\n",
      " [8.20455030e-02]\n",
      " [5.60690045e-01]\n",
      " [8.15214157e-01]\n",
      " [7.14533627e-01]\n",
      " [8.64081502e-01]\n",
      " [8.07918191e-01]\n",
      " [5.50535440e-01]\n",
      " [1.23362324e-05]\n",
      " [5.50549865e-01]\n",
      " [7.46052980e-01]\n",
      " [9.77153778e-01]\n",
      " [9.87381458e-01]\n",
      " [2.83929825e-01]\n",
      " [2.86886096e-01]\n",
      " [9.87604380e-01]\n",
      " [2.59674340e-01]\n",
      " [9.37886357e-01]\n",
      " [5.40668249e-01]\n",
      " [6.84038639e-01]\n",
      " [9.90431905e-01]\n",
      " [9.23168182e-01]\n",
      " [1.90647423e-01]\n",
      " [8.07403803e-01]\n",
      " [9.14681077e-01]\n",
      " [3.89086932e-01]\n",
      " [6.28044724e-01]\n",
      " [8.41406882e-01]\n",
      " [2.55511224e-01]\n",
      " [7.83275545e-01]\n",
      " [9.79446292e-01]\n",
      " [4.33355570e-01]\n",
      " [9.68951464e-01]\n",
      " [1.49216220e-01]\n",
      " [9.90336418e-01]\n",
      " [9.90985751e-01]\n",
      " [8.43921304e-01]\n",
      " [4.69996065e-01]\n",
      " [6.12276375e-01]\n",
      " [7.84758866e-01]\n",
      " [8.48168969e-01]\n",
      " [7.73653865e-01]\n",
      " [6.81539059e-01]\n",
      " [2.30603874e-01]\n",
      " [1.19755022e-01]\n",
      " [9.99929130e-01]\n",
      " [8.09961438e-01]\n",
      " [3.00413251e-01]\n",
      " [3.16204727e-01]\n",
      " [4.27603155e-01]\n",
      " [2.46618763e-01]\n",
      " [2.48965189e-01]\n",
      " [7.22372174e-01]\n",
      " [4.26432312e-01]\n",
      " [9.60554838e-01]\n",
      " [3.36057812e-01]\n",
      " [2.73969322e-01]\n",
      " [9.49572444e-01]\n",
      " [9.99393165e-01]\n",
      " [9.95200992e-01]\n",
      " [9.62726951e-01]\n",
      " [1.29487827e-01]\n",
      " [4.96591717e-01]\n",
      " [9.80543911e-01]\n",
      " [9.67620075e-01]\n",
      " [2.79635638e-01]\n",
      " [6.28942922e-02]\n",
      " [9.07798827e-01]\n",
      " [9.75778282e-01]\n",
      " [9.51462984e-01]\n",
      " [9.92754340e-01]\n",
      " [9.80183482e-01]\n",
      " [5.77374220e-01]\n",
      " [9.92194533e-01]\n",
      " [8.64629328e-01]\n",
      " [9.76454854e-01]\n",
      " [4.44651306e-01]\n",
      " [7.05795646e-01]\n",
      " [8.49063754e-01]\n",
      " [7.14135289e-01]\n",
      " [7.89050519e-01]\n",
      " [8.63626361e-01]\n",
      " [8.58476520e-01]\n",
      " [4.06590477e-02]\n",
      " [7.34119058e-01]\n",
      " [9.58683968e-01]\n",
      " [3.92569005e-01]\n",
      " [8.13753128e-01]\n",
      " [3.22199792e-01]\n",
      " [9.79311883e-01]\n",
      " [9.93394136e-01]\n",
      " [7.21954927e-02]\n",
      " [4.01550502e-01]\n",
      " [5.07434487e-01]\n",
      " [3.97060633e-01]\n",
      " [9.84712183e-01]\n",
      " [5.01124024e-01]\n",
      " [6.91849828e-01]\n",
      " [3.21075082e-01]\n",
      " [8.32626522e-01]\n",
      " [9.98410106e-01]\n",
      " [5.60708582e-01]\n",
      " [5.85882008e-01]\n",
      " [6.48350477e-01]\n",
      " [9.70471263e-01]\n",
      " [7.29239404e-01]\n",
      " [9.66144502e-01]\n",
      " [9.49370444e-01]\n",
      " [9.99677300e-01]\n",
      " [9.99715984e-01]\n",
      " [9.18018997e-01]\n",
      " [9.99406159e-01]\n",
      " [9.96025145e-01]\n",
      " [9.90517557e-01]\n",
      " [9.85769689e-01]\n",
      " [9.99696612e-01]\n",
      " [8.61948848e-01]\n",
      " [9.99759853e-01]\n",
      " [9.95783985e-01]\n",
      " [8.88969898e-01]\n",
      " [9.68492985e-01]\n",
      " [9.97797549e-01]\n",
      " [9.85480070e-01]\n",
      " [9.73398328e-01]\n",
      " [3.01447749e-01]\n",
      " [9.96800601e-01]\n",
      " [9.88479495e-01]\n",
      " [8.71253312e-01]\n",
      " [9.19460893e-01]\n",
      " [6.23352647e-01]\n",
      " [8.45083058e-01]\n",
      " [9.68213677e-01]\n",
      " [9.57524478e-01]\n",
      " [6.48383021e-01]\n",
      " [9.86283660e-01]\n",
      " [8.63548219e-01]\n",
      " [9.96678174e-01]\n",
      " [9.92790818e-01]\n",
      " [9.84187663e-01]\n",
      " [9.98932660e-01]\n",
      " [3.11935067e-01]\n",
      " [7.84824789e-01]\n",
      " [6.60573959e-01]\n",
      " [8.76621723e-01]\n",
      " [7.77946234e-01]\n",
      " [6.90931857e-01]\n",
      " [7.63200223e-01]\n",
      " [9.13301110e-01]\n",
      " [9.47786748e-01]\n",
      " [9.41348791e-01]\n",
      " [7.09574223e-01]\n",
      " [9.86424267e-01]\n",
      " [6.36705160e-01]\n",
      " [7.43922114e-01]\n",
      " [9.81609285e-01]\n",
      " [8.63477111e-01]\n",
      " [8.15016627e-01]\n",
      " [4.87356424e-01]\n",
      " [9.59742010e-01]\n",
      " [9.98531580e-01]\n",
      " [3.96552950e-01]\n",
      " [2.36252189e-01]\n",
      " [9.29561615e-01]\n",
      " [5.54313779e-01]\n",
      " [4.69835699e-01]\n",
      " [1.60919309e-01]\n",
      " [7.28687763e-01]\n",
      " [1.23097725e-01]\n",
      " [3.13263834e-01]\n",
      " [3.45807999e-01]\n",
      " [2.68876076e-01]\n",
      " [5.28634749e-02]\n",
      " [4.41996694e-01]\n",
      " [2.77805954e-01]\n",
      " [1.81930419e-02]\n",
      " [2.20593259e-01]\n",
      " [1.88076809e-01]\n",
      " [3.36444825e-01]\n",
      " [3.91118109e-01]\n",
      " [2.04243347e-01]\n",
      " [2.45332681e-02]\n",
      " [1.99146956e-01]\n",
      " [1.25837639e-01]\n",
      " [1.82138069e-03]\n",
      " [7.60805428e-01]\n",
      " [2.26896062e-01]\n",
      " [3.23213845e-01]\n",
      " [2.59843767e-01]\n",
      " [2.46076230e-02]\n",
      " [6.47731423e-01]\n",
      " [3.79552841e-01]\n",
      " [7.02688098e-03]\n",
      " [6.10384822e-01]\n",
      " [8.43460679e-01]\n",
      " [1.52651533e-01]\n",
      " [2.86000445e-02]\n",
      " [2.68255651e-01]\n",
      " [6.49008453e-02]\n",
      " [5.02815843e-01]\n",
      " [3.03485952e-02]\n",
      " [4.39964414e-01]\n",
      " [5.46409488e-01]\n",
      " [2.87278682e-01]\n",
      " [1.44906923e-01]\n",
      " [1.24970637e-01]\n",
      " [7.65952349e-01]\n",
      " [9.52373296e-02]\n",
      " [1.46623999e-01]\n",
      " [2.65539497e-01]\n",
      " [2.64042467e-01]\n",
      " [6.14132524e-01]\n",
      " [2.29338497e-01]\n",
      " [2.75970340e-01]\n",
      " [9.60688516e-02]\n",
      " [3.27427834e-01]\n",
      " [3.34632307e-01]\n",
      " [1.95824221e-01]\n",
      " [3.19158345e-01]\n",
      " [2.94750988e-01]\n",
      " [3.61609638e-01]\n",
      " [5.89175463e-01]\n",
      " [6.46277005e-03]\n",
      " [1.30457163e-01]\n",
      " [3.01686704e-01]\n",
      " [2.17969507e-01]\n",
      " [3.75233680e-01]\n",
      " [3.52593780e-01]\n",
      " [1.74071565e-01]\n",
      " [7.90646732e-01]\n",
      " [1.95702866e-01]\n",
      " [4.75171916e-02]\n",
      " [2.27580860e-01]\n",
      " [7.01334417e-01]\n",
      " [2.00051263e-01]\n",
      " [4.85528857e-01]\n",
      " [2.67757416e-01]\n",
      " [6.62305653e-02]\n",
      " [4.47009027e-01]\n",
      " [2.55524665e-01]\n",
      " [5.54142475e-01]\n",
      " [3.34143192e-02]\n",
      " [2.56243795e-01]\n",
      " [4.88864928e-01]\n",
      " [2.85335004e-01]\n",
      " [6.67712569e-01]\n",
      " [7.16727257e-01]\n",
      " [3.20860863e-01]\n",
      " [3.99072617e-01]\n",
      " [3.34054410e-01]\n",
      " [6.49610043e-01]\n",
      " [2.27407143e-01]\n",
      " [4.13458534e-02]\n",
      " [5.00516415e-01]\n",
      " [4.36845511e-01]\n",
      " [2.08977252e-01]\n",
      " [1.27362562e-02]\n",
      " [4.37968403e-01]\n",
      " [7.08541274e-02]\n",
      " [3.23010862e-01]\n",
      " [4.68466282e-02]\n",
      " [3.81023943e-01]\n",
      " [1.96032956e-01]\n",
      " [2.36471102e-01]\n",
      " [8.40839073e-02]\n",
      " [2.55686820e-01]\n",
      " [2.45456740e-01]\n",
      " [2.52412647e-01]\n",
      " [1.55679926e-01]\n",
      " [2.38537744e-01]\n",
      " [6.10018075e-01]\n",
      " [2.31613085e-01]\n",
      " [5.49567342e-01]\n",
      " [4.83305037e-01]\n",
      " [1.16976842e-01]\n",
      " [5.12751877e-01]\n",
      " [6.41397536e-01]\n",
      " [6.13932192e-01]\n",
      " [7.65332699e-01]\n",
      " [4.80629414e-01]\n",
      " [1.09513663e-01]\n",
      " [2.69483864e-01]\n",
      " [1.74438387e-01]\n",
      " [1.41084660e-02]\n",
      " [4.45918947e-01]\n",
      " [2.30045840e-01]\n",
      " [5.16241305e-02]\n",
      " [4.59952712e-01]\n",
      " [4.34704959e-01]\n",
      " [2.91623361e-02]\n",
      " [2.04025641e-01]\n",
      " [1.06017053e-01]\n",
      " [1.22259520e-01]\n",
      " [6.51068449e-01]\n",
      " [5.96429467e-01]\n",
      " [1.79952681e-01]\n",
      " [4.20430340e-02]\n",
      " [1.61270443e-02]\n",
      " [7.16235161e-01]\n",
      " [8.84586871e-02]\n",
      " [3.60018998e-01]\n",
      " [5.84906816e-01]\n",
      " [7.33859614e-02]\n",
      " [1.38537899e-01]\n",
      " [9.67464000e-02]\n",
      " [9.01284218e-01]\n",
      " [5.97309828e-01]\n",
      " [2.82506227e-01]\n",
      " [2.88936228e-01]\n",
      " [5.97093180e-02]\n",
      " [8.51976514e-01]\n",
      " [4.21054736e-02]\n",
      " [2.36420870e-01]\n",
      " [8.02459896e-01]\n",
      " [1.55915199e-02]\n",
      " [3.88739258e-01]\n",
      " [3.43475401e-01]\n",
      " [9.65143800e-01]\n",
      " [2.33334243e-01]\n",
      " [5.83033860e-01]\n",
      " [2.21891284e-01]\n",
      " [3.85376394e-01]\n",
      " [5.29227614e-01]\n",
      " [3.57893735e-01]\n",
      " [6.64768457e-01]\n",
      " [1.10048264e-01]\n",
      " [2.41620734e-01]\n",
      " [2.98650354e-01]\n",
      " [4.50839818e-01]\n",
      " [1.32641435e-01]\n",
      " [1.46580130e-01]\n",
      " [8.86784196e-01]\n",
      " [4.73000333e-02]\n",
      " [5.27570009e-01]\n",
      " [3.92088860e-01]\n",
      " [4.28879172e-01]\n",
      " [2.65523434e-01]\n",
      " [9.91397500e-01]\n",
      " [3.21236253e-01]\n",
      " [5.00823736e-01]\n",
      " [2.70001292e-01]\n",
      " [2.54366826e-02]\n",
      " [4.58720148e-01]\n",
      " [5.87316036e-01]\n",
      " [6.66052103e-01]\n",
      " [5.89230895e-01]\n",
      " [6.51151121e-01]\n",
      " [1.93735480e-01]\n",
      " [2.07239687e-01]\n",
      " [5.60284734e-01]\n",
      " [2.38189295e-01]\n",
      " [2.84725279e-01]\n",
      " [8.57244134e-01]\n",
      " [1.55671507e-01]\n",
      " [7.04122961e-01]\n",
      " [4.77005064e-01]\n",
      " [7.12278545e-01]\n",
      " [7.69558191e-01]\n",
      " [6.28334165e-01]\n",
      " [8.59015882e-01]\n",
      " [6.11874104e-01]\n",
      " [3.25758100e-01]\n",
      " [4.39521223e-01]\n",
      " [4.01881635e-01]\n",
      " [5.60481884e-02]\n",
      " [4.14443225e-01]\n",
      " [1.02532603e-01]\n",
      " [3.70964140e-01]\n",
      " [1.12367608e-01]\n",
      " [7.77785897e-01]\n",
      " [1.29739061e-01]\n",
      " [2.55007327e-01]\n",
      " [2.28058830e-01]\n",
      " [5.11287510e-01]\n",
      " [2.61740416e-01]\n",
      " [1.60169721e-01]\n",
      " [3.29967707e-01]\n",
      " [2.48618722e-01]\n",
      " [8.90626758e-02]\n",
      " [4.32068706e-01]\n",
      " [7.23423600e-01]\n",
      " [2.89544851e-01]\n",
      " [7.88125694e-01]\n",
      " [6.56474158e-02]\n",
      " [5.32718062e-01]\n",
      " [8.05563390e-01]\n",
      " [6.28348172e-01]\n",
      " [2.93970317e-01]\n",
      " [1.23466976e-01]\n",
      " [3.38343024e-01]\n",
      " [9.23161864e-01]\n",
      " [1.49294347e-01]\n",
      " [9.97796953e-01]\n",
      " [9.80430424e-01]\n",
      " [5.44778287e-01]\n",
      " [6.31348372e-01]\n",
      " [6.18972540e-01]\n",
      " [9.96653557e-01]\n",
      " [2.53561735e-01]\n",
      " [3.86694223e-01]\n",
      " [7.69473314e-01]\n",
      " [1.79552183e-01]\n",
      " [6.77170992e-01]\n",
      " [8.95809680e-02]\n",
      " [2.67425984e-01]\n",
      " [3.80310625e-01]\n",
      " [2.86065757e-01]\n",
      " [1.47672221e-01]\n",
      " [2.83340096e-01]\n",
      " [2.01506659e-01]\n",
      " [7.38644361e-01]\n",
      " [3.56946379e-01]\n",
      " [3.53723973e-01]\n",
      " [8.82045031e-02]\n",
      " [4.25986201e-01]\n",
      " [2.60093138e-02]\n",
      " [1.80190787e-01]\n",
      " [2.62286037e-01]\n",
      " [5.71960747e-01]\n",
      " [2.15473518e-01]\n",
      " [5.88364959e-01]\n",
      " [3.72647971e-01]\n",
      " [1.38382256e-01]\n",
      " [1.62028134e-01]\n",
      " [8.01115870e-01]\n",
      " [3.51352692e-02]\n",
      " [8.98355603e-01]\n",
      " [3.41853440e-01]\n",
      " [3.09346974e-01]\n",
      " [2.66148418e-01]\n",
      " [3.06748450e-01]\n",
      " [5.82294106e-01]\n",
      " [3.56353313e-01]\n",
      " [6.13936186e-01]\n",
      " [4.85931605e-01]\n",
      " [5.46659589e-01]\n",
      " [2.08628833e-01]\n",
      " [2.34912738e-01]\n",
      " [4.97188359e-01]\n",
      " [7.21316814e-01]\n",
      " [2.28090227e-01]\n",
      " [6.12491369e-01]\n",
      " [3.72740060e-01]\n",
      " [6.16769373e-01]\n",
      " [9.48666632e-02]\n",
      " [2.43503198e-01]\n",
      " [9.39936459e-01]\n",
      " [6.37845635e-01]\n",
      " [3.96061182e-01]\n",
      " [9.74508822e-01]\n",
      " [9.32038903e-01]\n",
      " [6.20248675e-01]\n",
      " [3.34813178e-01]\n",
      " [3.29552621e-01]\n",
      " [6.52698576e-01]\n",
      " [4.00025584e-02]\n",
      " [8.21092546e-01]\n",
      " [2.31322065e-01]\n",
      " [5.20173982e-02]\n",
      " [7.02461228e-02]\n",
      " [7.06137061e-01]\n",
      " [9.80596423e-01]\n",
      " [2.09654659e-01]\n",
      " [6.72307730e-01]\n",
      " [6.57357395e-01]\n",
      " [2.89477825e-01]\n",
      " [2.38427259e-02]\n",
      " [3.51655841e-01]\n",
      " [9.45462048e-01]\n",
      " [7.17829108e-01]\n",
      " [3.51622164e-01]\n",
      " [5.37287056e-01]\n",
      " [9.99960244e-01]\n",
      " [2.90188223e-01]\n",
      " [7.71355331e-02]\n",
      " [2.72993058e-01]\n",
      " [5.35537124e-01]\n",
      " [7.87165940e-01]\n",
      " [8.08110774e-01]\n",
      " [9.82975543e-01]\n",
      " [7.71215782e-02]\n",
      " [1.40269846e-01]\n",
      " [8.84638965e-01]\n",
      " [1.95976689e-01]\n",
      " [2.71874398e-01]\n",
      " [7.54943816e-03]\n",
      " [1.96344033e-01]\n",
      " [4.00166214e-01]\n",
      " [1.80991322e-01]\n",
      " [8.28318119e-01]\n",
      " [1.74620569e-01]\n",
      " [7.61354864e-02]\n",
      " [1.96695048e-02]\n",
      " [5.60916543e-01]\n",
      " [6.24518752e-01]\n",
      " [2.51336664e-01]\n",
      " [4.38564956e-01]\n",
      " [8.04102659e-01]\n",
      " [4.01012093e-01]\n",
      " [3.16679388e-01]\n",
      " [7.24127293e-01]\n",
      " [3.84371430e-01]\n",
      " [6.73452616e-01]\n",
      " [4.55397010e-01]\n",
      " [1.55733317e-01]\n",
      " [3.65680993e-01]\n",
      " [8.03993702e-01]\n",
      " [8.47886205e-01]\n",
      " [2.22428031e-02]\n",
      " [6.89160109e-01]\n",
      " [5.57146668e-02]\n",
      " [2.42059410e-01]\n",
      " [2.82730341e-01]\n",
      " [7.92829335e-01]\n",
      " [8.27849269e-01]\n",
      " [1.63965106e-01]\n",
      " [5.15029430e-01]\n",
      " [2.29090787e-02]\n",
      " [9.45158780e-01]\n",
      " [5.15393317e-01]\n",
      " [6.63862303e-02]\n",
      " [5.57212353e-01]\n",
      " [5.43677926e-01]\n",
      " [1.75887898e-01]\n",
      " [2.14570746e-01]\n",
      " [4.24947560e-01]\n",
      " [3.67987573e-01]\n",
      " [1.30926162e-01]\n",
      " [4.80600484e-02]\n",
      " [1.02846585e-01]\n",
      " [1.39954478e-01]\n",
      " [5.68277061e-01]\n",
      " [5.15052497e-01]\n",
      " [2.61228710e-01]\n",
      " [3.47055942e-01]\n",
      " [4.23411369e-01]\n",
      " [2.96809524e-01]\n",
      " [1.39380455e-01]\n",
      " [2.38549829e-01]\n",
      " [4.53907043e-01]\n",
      " [1.97616130e-01]\n",
      " [4.21779126e-01]\n",
      " [5.08004189e-01]\n",
      " [7.22788930e-01]\n",
      " [6.99531436e-01]\n",
      " [4.49848473e-01]\n",
      " [1.81920379e-01]\n",
      " [9.44864631e-01]\n",
      " [3.12175870e-01]\n",
      " [9.39205825e-01]\n",
      " [6.74243450e-01]\n",
      " [3.13449413e-01]\n",
      " [8.17123294e-01]\n",
      " [7.53022194e-01]\n",
      " [5.19591151e-03]]\n",
      "Predicted probabilities shape: (832, 1)\n",
      "Predicted labels: [1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 1 0 0 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1\n",
      " 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1\n",
      " 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0\n",
      " 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 1 0\n",
      " 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0 0 1 1 1 1 0 0 1 0 0\n",
      " 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 1 1 1 0 0\n",
      " 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0\n",
      " 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0\n",
      " 1 0 1 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 0 0 1 0 1 1 0 1 1 0]\n",
      "Predicted labels shape: (832,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.7276 - auc: 0.4992 - f1_score: 0.2242 - loss: 0.5808 - precision: 0.3647 - recall: 0.4704\n",
      "Training model: MobileNetV3Small on dataset: The Wildfire Dataset_FIRE\n",
      "Epoch 1/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 91ms/step - accuracy: 0.6258 - auc: 0.7343 - f1_score: 0.6695 - loss: 0.7724 - precision: 0.7402 - recall: 0.6981 - val_accuracy: 0.6292 - val_auc: 0.7309 - val_f1_score: 0.7685 - val_loss: 0.6624 - val_precision: 0.6292 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 86ms/step - accuracy: 0.7258 - auc: 0.7949 - f1_score: 0.7761 - loss: 0.5593 - precision: 0.7693 - recall: 0.7907 - val_accuracy: 0.6225 - val_auc: 0.8167 - val_f1_score: 0.7636 - val_loss: 0.6141 - val_precision: 0.6225 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 86ms/step - accuracy: 0.7474 - auc: 0.8113 - f1_score: 0.7931 - loss: 0.5295 - precision: 0.7844 - recall: 0.8070 - val_accuracy: 0.7914 - val_auc: 0.8771 - val_f1_score: 0.8358 - val_loss: 0.5382 - val_precision: 0.7947 - val_recall: 0.8934 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 85ms/step - accuracy: 0.7586 - auc: 0.8250 - f1_score: 0.8046 - loss: 0.5101 - precision: 0.7856 - recall: 0.8312 - val_accuracy: 0.8041 - val_auc: 0.8796 - val_f1_score: 0.8391 - val_loss: 0.4500 - val_precision: 0.8311 - val_recall: 0.8496 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 86ms/step - accuracy: 0.7581 - auc: 0.8246 - f1_score: 0.8036 - loss: 0.5116 - precision: 0.7842 - recall: 0.8284 - val_accuracy: 0.8176 - val_auc: 0.8973 - val_f1_score: 0.8448 - val_loss: 0.4231 - val_precision: 0.8891 - val_recall: 0.8100 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 89ms/step - accuracy: 0.7664 - auc: 0.8446 - f1_score: 0.8089 - loss: 0.4748 - precision: 0.8027 - recall: 0.8175 - val_accuracy: 0.8277 - val_auc: 0.9038 - val_f1_score: 0.8621 - val_loss: 0.3991 - val_precision: 0.8450 - val_recall: 0.8862 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.7733 - auc: 0.8407 - f1_score: 0.8156 - loss: 0.4800 - precision: 0.8064 - recall: 0.8300 - val_accuracy: 0.8066 - val_auc: 0.8869 - val_f1_score: 0.8351 - val_loss: 0.4239 - val_precision: 0.8555 - val_recall: 0.8237 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 87ms/step - accuracy: 0.7903 - auc: 0.8627 - f1_score: 0.8279 - loss: 0.4499 - precision: 0.8190 - recall: 0.8403 - val_accuracy: 0.8336 - val_auc: 0.9054 - val_f1_score: 0.8623 - val_loss: 0.3987 - val_precision: 0.8864 - val_recall: 0.8449 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.7757 - auc: 0.8550 - f1_score: 0.8131 - loss: 0.4679 - precision: 0.7976 - recall: 0.8348 - val_accuracy: 0.8167 - val_auc: 0.8933 - val_f1_score: 0.8357 - val_loss: 0.4097 - val_precision: 0.8590 - val_recall: 0.8312 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 96ms/step - accuracy: 0.7874 - auc: 0.8616 - f1_score: 0.8292 - loss: 0.4495 - precision: 0.8187 - recall: 0.8426 - val_accuracy: 0.8294 - val_auc: 0.9103 - val_f1_score: 0.8566 - val_loss: 0.3822 - val_precision: 0.8468 - val_recall: 0.8774 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.7903 - auc: 0.8603 - f1_score: 0.8308 - loss: 0.4545 - precision: 0.8116 - recall: 0.8555 - val_accuracy: 0.8302 - val_auc: 0.9129 - val_f1_score: 0.8585 - val_loss: 0.3897 - val_precision: 0.9006 - val_recall: 0.8224 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.7886 - auc: 0.8595 - f1_score: 0.8269 - loss: 0.4550 - precision: 0.8215 - recall: 0.8348 - val_accuracy: 0.8277 - val_auc: 0.9137 - val_f1_score: 0.8566 - val_loss: 0.3828 - val_precision: 0.8713 - val_recall: 0.8450 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.7909 - auc: 0.8669 - f1_score: 0.8284 - loss: 0.4436 - precision: 0.8217 - recall: 0.8398 - val_accuracy: 0.8378 - val_auc: 0.9175 - val_f1_score: 0.8611 - val_loss: 0.3745 - val_precision: 0.8662 - val_recall: 0.8638 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.7870 - auc: 0.8654 - f1_score: 0.8279 - loss: 0.4423 - precision: 0.8137 - recall: 0.8467 - val_accuracy: 0.8539 - val_auc: 0.9234 - val_f1_score: 0.8782 - val_loss: 0.3683 - val_precision: 0.8607 - val_recall: 0.8987 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 88ms/step - accuracy: 0.7943 - auc: 0.8601 - f1_score: 0.8345 - loss: 0.4503 - precision: 0.8292 - recall: 0.8430 - val_accuracy: 0.8438 - val_auc: 0.9214 - val_f1_score: 0.8654 - val_loss: 0.3648 - val_precision: 0.8771 - val_recall: 0.8637 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.7952 - auc: 0.8732 - f1_score: 0.8333 - loss: 0.4331 - precision: 0.8316 - recall: 0.8376 - val_accuracy: 0.8463 - val_auc: 0.9230 - val_f1_score: 0.8731 - val_loss: 0.3600 - val_precision: 0.8856 - val_recall: 0.8639 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 96ms/step - accuracy: 0.7935 - auc: 0.8808 - f1_score: 0.8314 - loss: 0.4205 - precision: 0.8206 - recall: 0.8442 - val_accuracy: 0.8463 - val_auc: 0.9274 - val_f1_score: 0.8751 - val_loss: 0.3543 - val_precision: 0.8637 - val_recall: 0.8942 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.7925 - auc: 0.8703 - f1_score: 0.8309 - loss: 0.4411 - precision: 0.8181 - recall: 0.8475 - val_accuracy: 0.8370 - val_auc: 0.9199 - val_f1_score: 0.8623 - val_loss: 0.3762 - val_precision: 0.8804 - val_recall: 0.8474 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 87ms/step - accuracy: 0.8116 - auc: 0.8800 - f1_score: 0.8469 - loss: 0.4227 - precision: 0.8453 - recall: 0.8515 - val_accuracy: 0.8454 - val_auc: 0.9304 - val_f1_score: 0.8703 - val_loss: 0.3543 - val_precision: 0.8935 - val_recall: 0.8507 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.8001 - auc: 0.8728 - f1_score: 0.8372 - loss: 0.4355 - precision: 0.8274 - recall: 0.8511 - val_accuracy: 0.8488 - val_auc: 0.9238 - val_f1_score: 0.8719 - val_loss: 0.3618 - val_precision: 0.8999 - val_recall: 0.8523 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 88ms/step - accuracy: 0.7941 - auc: 0.8753 - f1_score: 0.8290 - loss: 0.4309 - precision: 0.8229 - recall: 0.8389 - val_accuracy: 0.8556 - val_auc: 0.9359 - val_f1_score: 0.8761 - val_loss: 0.3515 - val_precision: 0.9114 - val_recall: 0.8475 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.8057 - auc: 0.8883 - f1_score: 0.8379 - loss: 0.4091 - precision: 0.8299 - recall: 0.8503 - val_accuracy: 0.8801 - val_auc: 0.9491 - val_f1_score: 0.9002 - val_loss: 0.3151 - val_precision: 0.9001 - val_recall: 0.9098 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.8046 - auc: 0.8792 - f1_score: 0.8397 - loss: 0.4257 - precision: 0.8349 - recall: 0.8474 - val_accuracy: 0.8564 - val_auc: 0.9350 - val_f1_score: 0.8844 - val_loss: 0.3425 - val_precision: 0.8730 - val_recall: 0.8992 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.8061 - auc: 0.8883 - f1_score: 0.8395 - loss: 0.4079 - precision: 0.8391 - recall: 0.8432 - val_accuracy: 0.8632 - val_auc: 0.9381 - val_f1_score: 0.8837 - val_loss: 0.3361 - val_precision: 0.8977 - val_recall: 0.8725 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 94ms/step - accuracy: 0.8097 - auc: 0.8867 - f1_score: 0.8439 - loss: 0.4122 - precision: 0.8427 - recall: 0.8475 - val_accuracy: 0.8682 - val_auc: 0.9435 - val_f1_score: 0.8818 - val_loss: 0.3378 - val_precision: 0.9344 - val_recall: 0.8441 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.8110 - auc: 0.8875 - f1_score: 0.8466 - loss: 0.4089 - precision: 0.8436 - recall: 0.8524 - val_accuracy: 0.8674 - val_auc: 0.9436 - val_f1_score: 0.8865 - val_loss: 0.3275 - val_precision: 0.9140 - val_recall: 0.8648 - learning_rate: 0.0010\n",
      "Epoch 27/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.8146 - auc: 0.8865 - f1_score: 0.8508 - loss: 0.4110 - precision: 0.8385 - recall: 0.8660 - val_accuracy: 0.8944 - val_auc: 0.9509 - val_f1_score: 0.9150 - val_loss: 0.3092 - val_precision: 0.9059 - val_recall: 0.9246 - learning_rate: 0.0010\n",
      "Epoch 28/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.8100 - auc: 0.8851 - f1_score: 0.8429 - loss: 0.4164 - precision: 0.8403 - recall: 0.8499 - val_accuracy: 0.8818 - val_auc: 0.9455 - val_f1_score: 0.9007 - val_loss: 0.3185 - val_precision: 0.9070 - val_recall: 0.8969 - learning_rate: 0.0010\n",
      "Epoch 29/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 95ms/step - accuracy: 0.8194 - auc: 0.8939 - f1_score: 0.8538 - loss: 0.3973 - precision: 0.8507 - recall: 0.8596 - val_accuracy: 0.8767 - val_auc: 0.9443 - val_f1_score: 0.9020 - val_loss: 0.3157 - val_precision: 0.8901 - val_recall: 0.9143 - learning_rate: 0.0010\n",
      "Epoch 30/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 100ms/step - accuracy: 0.8070 - auc: 0.8916 - f1_score: 0.8398 - loss: 0.4036 - precision: 0.8328 - recall: 0.8509 - val_accuracy: 0.8632 - val_auc: 0.9382 - val_f1_score: 0.8855 - val_loss: 0.3305 - val_precision: 0.8964 - val_recall: 0.8791 - learning_rate: 0.0010\n",
      "Epoch 31/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 100ms/step - accuracy: 0.8130 - auc: 0.8948 - f1_score: 0.8456 - loss: 0.3998 - precision: 0.8389 - recall: 0.8554 - val_accuracy: 0.8851 - val_auc: 0.9549 - val_f1_score: 0.9030 - val_loss: 0.3034 - val_precision: 0.9105 - val_recall: 0.8978 - learning_rate: 0.0010\n",
      "Epoch 32/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.8137 - auc: 0.8886 - f1_score: 0.8476 - loss: 0.4083 - precision: 0.8407 - recall: 0.8593 - val_accuracy: 0.8834 - val_auc: 0.9514 - val_f1_score: 0.9020 - val_loss: 0.3154 - val_precision: 0.8974 - val_recall: 0.9100 - learning_rate: 0.0010\n",
      "Epoch 33/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.8041 - auc: 0.8907 - f1_score: 0.8397 - loss: 0.4032 - precision: 0.8334 - recall: 0.8494 - val_accuracy: 0.8944 - val_auc: 0.9590 - val_f1_score: 0.9126 - val_loss: 0.2954 - val_precision: 0.9240 - val_recall: 0.9053 - learning_rate: 0.0010\n",
      "Epoch 34/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.8167 - auc: 0.8981 - f1_score: 0.8501 - loss: 0.3902 - precision: 0.8459 - recall: 0.8585 - val_accuracy: 0.8877 - val_auc: 0.9601 - val_f1_score: 0.9071 - val_loss: 0.2904 - val_precision: 0.9131 - val_recall: 0.9044 - learning_rate: 0.0010\n",
      "Epoch 35/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.8124 - auc: 0.8874 - f1_score: 0.8467 - loss: 0.4102 - precision: 0.8355 - recall: 0.8635 - val_accuracy: 0.8961 - val_auc: 0.9579 - val_f1_score: 0.9140 - val_loss: 0.2944 - val_precision: 0.9137 - val_recall: 0.9175 - learning_rate: 0.0010\n",
      "Epoch 36/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.8260 - auc: 0.8997 - f1_score: 0.8582 - loss: 0.3905 - precision: 0.8653 - recall: 0.8542 - val_accuracy: 0.8860 - val_auc: 0.9568 - val_f1_score: 0.9054 - val_loss: 0.2961 - val_precision: 0.9041 - val_recall: 0.9151 - learning_rate: 0.0010\n",
      "Epoch 37/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.8211 - auc: 0.9011 - f1_score: 0.8517 - loss: 0.3885 - precision: 0.8494 - recall: 0.8574 - val_accuracy: 0.8944 - val_auc: 0.9557 - val_f1_score: 0.9141 - val_loss: 0.2814 - val_precision: 0.9202 - val_recall: 0.9090 - learning_rate: 0.0010\n",
      "Epoch 38/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.8251 - auc: 0.9015 - f1_score: 0.8541 - loss: 0.3863 - precision: 0.8538 - recall: 0.8575 - val_accuracy: 0.8944 - val_auc: 0.9622 - val_f1_score: 0.9136 - val_loss: 0.2755 - val_precision: 0.9043 - val_recall: 0.9277 - learning_rate: 0.0010\n",
      "Epoch 39/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 93ms/step - accuracy: 0.8170 - auc: 0.8980 - f1_score: 0.8496 - loss: 0.3917 - precision: 0.8417 - recall: 0.8621 - val_accuracy: 0.9139 - val_auc: 0.9665 - val_f1_score: 0.9238 - val_loss: 0.2764 - val_precision: 0.9346 - val_recall: 0.9186 - learning_rate: 0.0010\n",
      "Epoch 40/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 91ms/step - accuracy: 0.8162 - auc: 0.8950 - f1_score: 0.8516 - loss: 0.3945 - precision: 0.8461 - recall: 0.8619 - val_accuracy: 0.8894 - val_auc: 0.9575 - val_f1_score: 0.9031 - val_loss: 0.3051 - val_precision: 0.9195 - val_recall: 0.8920 - learning_rate: 0.0010\n",
      "Epoch 41/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 86ms/step - accuracy: 0.8347 - auc: 0.9104 - f1_score: 0.8658 - loss: 0.3673 - precision: 0.8635 - recall: 0.8720 - val_accuracy: 0.9088 - val_auc: 0.9657 - val_f1_score: 0.9225 - val_loss: 0.2633 - val_precision: 0.9287 - val_recall: 0.9236 - learning_rate: 0.0010\n",
      "Epoch 42/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.8188 - auc: 0.9009 - f1_score: 0.8515 - loss: 0.3860 - precision: 0.8518 - recall: 0.8523 - val_accuracy: 0.8936 - val_auc: 0.9560 - val_f1_score: 0.9105 - val_loss: 0.2867 - val_precision: 0.9095 - val_recall: 0.9170 - learning_rate: 0.0010\n",
      "Epoch 43/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.8303 - auc: 0.9049 - f1_score: 0.8604 - loss: 0.3802 - precision: 0.8587 - recall: 0.8654 - val_accuracy: 0.9003 - val_auc: 0.9590 - val_f1_score: 0.9163 - val_loss: 0.2900 - val_precision: 0.9330 - val_recall: 0.8990 - learning_rate: 0.0010\n",
      "Epoch 44/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 92ms/step - accuracy: 0.8249 - auc: 0.9042 - f1_score: 0.8546 - loss: 0.3821 - precision: 0.8523 - recall: 0.8601 - val_accuracy: 0.9003 - val_auc: 0.9655 - val_f1_score: 0.9151 - val_loss: 0.2693 - val_precision: 0.9397 - val_recall: 0.8960 - learning_rate: 0.0010\n",
      "Epoch 45/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.8220 - auc: 0.8999 - f1_score: 0.8548 - loss: 0.3841 - precision: 0.8592 - recall: 0.8535 - val_accuracy: 0.9206 - val_auc: 0.9725 - val_f1_score: 0.9324 - val_loss: 0.2679 - val_precision: 0.9595 - val_recall: 0.9095 - learning_rate: 0.0010\n",
      "Epoch 46/80\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8283 - auc: 0.9038 - f1_score: 0.8590 - loss: 0.3842 - precision: 0.8505 - recall: 0.8712\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 101ms/step - accuracy: 0.8283 - auc: 0.9038 - f1_score: 0.8591 - loss: 0.3841 - precision: 0.8506 - recall: 0.8712 - val_accuracy: 0.9122 - val_auc: 0.9700 - val_f1_score: 0.9277 - val_loss: 0.2695 - val_precision: 0.9414 - val_recall: 0.9159 - learning_rate: 0.0010\n",
      "Training time: 699.99 seconds\n",
      "Evaluating MobileNetV3Small on The Wildfire Dataset_FIRE...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "True labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True labels shape: (832,)\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step\n",
      "Predicted probabilities: [[9.14687097e-01]\n",
      " [2.13582247e-01]\n",
      " [9.79723513e-01]\n",
      " [8.26425493e-01]\n",
      " [8.81448507e-01]\n",
      " [9.60105062e-01]\n",
      " [1.01483151e-01]\n",
      " [5.36485672e-01]\n",
      " [6.61333561e-01]\n",
      " [4.16277677e-01]\n",
      " [8.27416480e-01]\n",
      " [7.98363924e-01]\n",
      " [5.79898715e-01]\n",
      " [7.58807123e-01]\n",
      " [6.18327737e-01]\n",
      " [4.44268674e-01]\n",
      " [9.36958730e-01]\n",
      " [9.67454851e-01]\n",
      " [7.96064556e-01]\n",
      " [7.98798203e-01]\n",
      " [2.26629809e-01]\n",
      " [5.12010217e-01]\n",
      " [9.53233600e-01]\n",
      " [9.37237918e-01]\n",
      " [6.48914933e-01]\n",
      " [6.62503481e-01]\n",
      " [9.88798976e-01]\n",
      " [7.41502583e-01]\n",
      " [5.37624002e-01]\n",
      " [9.69992399e-01]\n",
      " [9.93926764e-01]\n",
      " [9.86328363e-01]\n",
      " [8.94664586e-01]\n",
      " [9.99976397e-01]\n",
      " [9.96582925e-01]\n",
      " [9.97181773e-01]\n",
      " [9.93797243e-01]\n",
      " [7.66877472e-01]\n",
      " [9.38191533e-01]\n",
      " [3.86966169e-01]\n",
      " [9.48081493e-01]\n",
      " [5.79139829e-01]\n",
      " [9.98746753e-01]\n",
      " [6.44435048e-01]\n",
      " [8.73048306e-01]\n",
      " [9.86911774e-01]\n",
      " [9.99038875e-01]\n",
      " [8.63982677e-01]\n",
      " [7.43696392e-01]\n",
      " [9.89512026e-01]\n",
      " [9.27729189e-01]\n",
      " [9.87086594e-01]\n",
      " [9.99855459e-01]\n",
      " [8.70118260e-01]\n",
      " [8.85448515e-01]\n",
      " [8.48957956e-01]\n",
      " [9.97467995e-01]\n",
      " [9.07889307e-01]\n",
      " [8.08021903e-01]\n",
      " [9.97928083e-01]\n",
      " [9.30109441e-01]\n",
      " [8.87934327e-01]\n",
      " [2.09980950e-01]\n",
      " [9.94560361e-01]\n",
      " [7.13525951e-01]\n",
      " [9.42620635e-01]\n",
      " [9.64208424e-01]\n",
      " [9.51100171e-01]\n",
      " [1.04364410e-01]\n",
      " [8.32514942e-01]\n",
      " [7.92490840e-01]\n",
      " [5.41777611e-01]\n",
      " [9.90838885e-01]\n",
      " [3.65088463e-01]\n",
      " [9.88642633e-01]\n",
      " [8.17000926e-01]\n",
      " [3.78529698e-01]\n",
      " [7.49625981e-01]\n",
      " [7.75289893e-01]\n",
      " [9.97271955e-01]\n",
      " [9.81735528e-01]\n",
      " [4.55589265e-01]\n",
      " [9.56414819e-01]\n",
      " [9.87936556e-01]\n",
      " [4.93535966e-01]\n",
      " [9.74013984e-01]\n",
      " [8.75026643e-01]\n",
      " [9.02646720e-01]\n",
      " [8.63814116e-01]\n",
      " [9.99864638e-01]\n",
      " [7.40206122e-01]\n",
      " [5.00580847e-01]\n",
      " [7.58002460e-01]\n",
      " [9.95528281e-01]\n",
      " [8.26520026e-01]\n",
      " [9.92442608e-01]\n",
      " [7.01062918e-01]\n",
      " [3.38326812e-01]\n",
      " [9.97636378e-01]\n",
      " [9.18599665e-01]\n",
      " [7.15862989e-01]\n",
      " [8.73917520e-01]\n",
      " [8.97982061e-01]\n",
      " [8.98728967e-01]\n",
      " [6.10689998e-01]\n",
      " [9.30689991e-01]\n",
      " [7.02706575e-01]\n",
      " [7.26692319e-01]\n",
      " [9.90536690e-01]\n",
      " [9.18530881e-01]\n",
      " [9.53291953e-01]\n",
      " [9.88201618e-01]\n",
      " [9.83176827e-01]\n",
      " [8.03069234e-01]\n",
      " [1.90414041e-01]\n",
      " [9.36918616e-01]\n",
      " [8.36707354e-01]\n",
      " [9.18432236e-01]\n",
      " [9.78899300e-01]\n",
      " [8.88912141e-01]\n",
      " [6.44320726e-01]\n",
      " [5.67189395e-01]\n",
      " [9.00535643e-01]\n",
      " [4.81560409e-01]\n",
      " [9.51170802e-01]\n",
      " [7.17326522e-01]\n",
      " [7.51046181e-01]\n",
      " [8.76739025e-01]\n",
      " [9.43104148e-01]\n",
      " [9.94524360e-01]\n",
      " [9.99419868e-01]\n",
      " [9.99403596e-01]\n",
      " [9.97582197e-01]\n",
      " [9.84965444e-01]\n",
      " [7.67751575e-01]\n",
      " [9.08964872e-01]\n",
      " [9.99719679e-01]\n",
      " [5.85634112e-01]\n",
      " [5.43304324e-01]\n",
      " [5.93150496e-01]\n",
      " [9.93465662e-01]\n",
      " [4.60967392e-01]\n",
      " [2.98649400e-01]\n",
      " [9.22194123e-01]\n",
      " [9.88156974e-01]\n",
      " [7.90312648e-01]\n",
      " [9.77549613e-01]\n",
      " [9.31394935e-01]\n",
      " [6.28877342e-01]\n",
      " [9.92677271e-01]\n",
      " [8.67699265e-01]\n",
      " [9.49836373e-01]\n",
      " [9.62069809e-01]\n",
      " [8.33056152e-01]\n",
      " [9.42480206e-01]\n",
      " [9.98011351e-01]\n",
      " [8.53809834e-01]\n",
      " [6.99277639e-01]\n",
      " [9.50554669e-01]\n",
      " [6.08624876e-01]\n",
      " [8.16124737e-01]\n",
      " [9.22392309e-01]\n",
      " [1.56003371e-01]\n",
      " [9.79514778e-01]\n",
      " [7.36227512e-01]\n",
      " [1.28187522e-01]\n",
      " [9.99271333e-01]\n",
      " [4.92301583e-01]\n",
      " [9.92815673e-01]\n",
      " [5.43924093e-01]\n",
      " [5.46903312e-01]\n",
      " [9.98534262e-01]\n",
      " [3.87488842e-01]\n",
      " [9.98891830e-01]\n",
      " [9.06181693e-01]\n",
      " [6.36838019e-01]\n",
      " [9.12190318e-01]\n",
      " [9.83814061e-01]\n",
      " [9.82355773e-01]\n",
      " [8.88155818e-01]\n",
      " [9.96583283e-01]\n",
      " [9.15132463e-01]\n",
      " [9.96119916e-01]\n",
      " [9.97555315e-01]\n",
      " [9.77871060e-01]\n",
      " [1.81190416e-01]\n",
      " [2.22812757e-01]\n",
      " [5.07774353e-01]\n",
      " [9.07698274e-01]\n",
      " [3.47929537e-01]\n",
      " [2.80073553e-01]\n",
      " [9.42872822e-01]\n",
      " [9.81785536e-01]\n",
      " [9.96773601e-01]\n",
      " [7.18704581e-01]\n",
      " [9.76133704e-01]\n",
      " [3.14219803e-01]\n",
      " [9.03225124e-01]\n",
      " [9.23694730e-01]\n",
      " [3.19511294e-01]\n",
      " [9.16931033e-01]\n",
      " [5.99282861e-01]\n",
      " [9.86839652e-01]\n",
      " [9.40969944e-01]\n",
      " [9.09049869e-01]\n",
      " [9.18164968e-01]\n",
      " [9.32799459e-01]\n",
      " [9.54032660e-01]\n",
      " [9.26449060e-01]\n",
      " [9.82696831e-01]\n",
      " [9.77757156e-01]\n",
      " [9.99949038e-01]\n",
      " [7.19142139e-01]\n",
      " [9.88988638e-01]\n",
      " [9.99394119e-01]\n",
      " [9.31444764e-01]\n",
      " [5.33418536e-01]\n",
      " [9.97041285e-01]\n",
      " [7.66677260e-01]\n",
      " [9.99933064e-01]\n",
      " [9.66420293e-01]\n",
      " [9.61060643e-01]\n",
      " [7.58176029e-01]\n",
      " [9.93608356e-01]\n",
      " [9.81288612e-01]\n",
      " [9.98421192e-01]\n",
      " [9.65943456e-01]\n",
      " [5.24124503e-01]\n",
      " [9.83258963e-01]\n",
      " [9.75628614e-01]\n",
      " [9.77061808e-01]\n",
      " [9.14092243e-01]\n",
      " [7.74918795e-01]\n",
      " [9.54323590e-01]\n",
      " [9.79387641e-01]\n",
      " [8.32296193e-01]\n",
      " [7.75144935e-01]\n",
      " [5.76128960e-01]\n",
      " [9.77262795e-01]\n",
      " [9.97628987e-01]\n",
      " [9.71087396e-01]\n",
      " [9.00172353e-01]\n",
      " [6.08902454e-01]\n",
      " [7.73552179e-01]\n",
      " [9.97976601e-01]\n",
      " [9.50925231e-01]\n",
      " [4.42439169e-01]\n",
      " [4.62648004e-01]\n",
      " [7.98858404e-01]\n",
      " [5.28801560e-01]\n",
      " [8.36293817e-01]\n",
      " [9.94193316e-01]\n",
      " [4.63473111e-01]\n",
      " [9.07403111e-01]\n",
      " [8.02897215e-01]\n",
      " [5.02597213e-01]\n",
      " [3.45033824e-01]\n",
      " [8.77915382e-01]\n",
      " [8.35409403e-01]\n",
      " [6.14994586e-01]\n",
      " [8.85543346e-01]\n",
      " [7.77646005e-01]\n",
      " [8.95824730e-01]\n",
      " [9.45403457e-01]\n",
      " [7.81546593e-01]\n",
      " [2.51763463e-01]\n",
      " [9.67638552e-01]\n",
      " [8.20735812e-01]\n",
      " [9.02217746e-01]\n",
      " [3.07217270e-01]\n",
      " [2.55621493e-01]\n",
      " [6.63808465e-01]\n",
      " [5.69523931e-01]\n",
      " [4.34824556e-01]\n",
      " [4.88333076e-01]\n",
      " [9.41908479e-01]\n",
      " [9.79352772e-01]\n",
      " [4.35915440e-01]\n",
      " [9.14913833e-01]\n",
      " [1.23564132e-01]\n",
      " [6.93880796e-01]\n",
      " [7.49547243e-01]\n",
      " [8.23836446e-01]\n",
      " [8.94824386e-01]\n",
      " [7.13893414e-01]\n",
      " [6.79202795e-01]\n",
      " [3.77618126e-04]\n",
      " [6.39284968e-01]\n",
      " [7.33260989e-01]\n",
      " [9.47391391e-01]\n",
      " [9.85989988e-01]\n",
      " [2.60626376e-01]\n",
      " [4.51555550e-01]\n",
      " [9.80596542e-01]\n",
      " [2.90116966e-01]\n",
      " [9.12422001e-01]\n",
      " [5.68558872e-01]\n",
      " [5.39350867e-01]\n",
      " [9.80572462e-01]\n",
      " [9.55889106e-01]\n",
      " [3.65046382e-01]\n",
      " [7.56728530e-01]\n",
      " [9.15077567e-01]\n",
      " [8.17983270e-01]\n",
      " [5.69474399e-01]\n",
      " [7.00305820e-01]\n",
      " [1.23540007e-01]\n",
      " [8.48097563e-01]\n",
      " [9.80244935e-01]\n",
      " [6.98135376e-01]\n",
      " [9.60187197e-01]\n",
      " [3.20609063e-01]\n",
      " [9.78377461e-01]\n",
      " [9.87205982e-01]\n",
      " [9.04372931e-01]\n",
      " [5.26028514e-01]\n",
      " [5.81659853e-01]\n",
      " [7.83573866e-01]\n",
      " [8.30999613e-01]\n",
      " [7.65396476e-01]\n",
      " [7.45324969e-01]\n",
      " [3.40036184e-01]\n",
      " [3.16215008e-01]\n",
      " [9.98932302e-01]\n",
      " [8.68866444e-01]\n",
      " [3.99659306e-01]\n",
      " [7.01618314e-01]\n",
      " [3.27226043e-01]\n",
      " [5.07464588e-01]\n",
      " [3.12106609e-01]\n",
      " [6.90099716e-01]\n",
      " [6.92727447e-01]\n",
      " [9.63232577e-01]\n",
      " [4.87088114e-01]\n",
      " [5.16863048e-01]\n",
      " [9.71436441e-01]\n",
      " [9.98619556e-01]\n",
      " [9.97298300e-01]\n",
      " [9.74518716e-01]\n",
      " [2.14324981e-01]\n",
      " [3.89180958e-01]\n",
      " [9.70576167e-01]\n",
      " [9.72656071e-01]\n",
      " [3.69637907e-01]\n",
      " [1.39876068e-01]\n",
      " [8.94034445e-01]\n",
      " [9.83713269e-01]\n",
      " [9.46707904e-01]\n",
      " [9.96292233e-01]\n",
      " [9.84337032e-01]\n",
      " [8.40166628e-01]\n",
      " [9.99394655e-01]\n",
      " [7.45239377e-01]\n",
      " [9.93775368e-01]\n",
      " [5.19019485e-01]\n",
      " [7.48236179e-01]\n",
      " [8.73428226e-01]\n",
      " [8.84284139e-01]\n",
      " [7.43888736e-01]\n",
      " [8.65811825e-01]\n",
      " [8.16559792e-01]\n",
      " [4.74176183e-02]\n",
      " [6.74139857e-01]\n",
      " [9.47188735e-01]\n",
      " [7.17598438e-01]\n",
      " [8.54013622e-01]\n",
      " [4.30093974e-01]\n",
      " [9.56586301e-01]\n",
      " [9.76637959e-01]\n",
      " [1.15661018e-01]\n",
      " [2.81559020e-01]\n",
      " [3.87881368e-01]\n",
      " [4.56959516e-01]\n",
      " [9.80836272e-01]\n",
      " [6.15356326e-01]\n",
      " [7.26418734e-01]\n",
      " [5.03276467e-01]\n",
      " [8.38487625e-01]\n",
      " [9.98366892e-01]\n",
      " [5.78870714e-01]\n",
      " [5.78195214e-01]\n",
      " [8.35771441e-01]\n",
      " [9.84217823e-01]\n",
      " [9.24932003e-01]\n",
      " [9.66217399e-01]\n",
      " [9.51863885e-01]\n",
      " [9.99919832e-01]\n",
      " [9.99742627e-01]\n",
      " [8.02921772e-01]\n",
      " [9.98815536e-01]\n",
      " [9.94780838e-01]\n",
      " [9.89053071e-01]\n",
      " [9.84592199e-01]\n",
      " [9.99732792e-01]\n",
      " [8.42151046e-01]\n",
      " [9.97947395e-01]\n",
      " [9.97881532e-01]\n",
      " [9.46394980e-01]\n",
      " [9.72696483e-01]\n",
      " [9.97620165e-01]\n",
      " [9.52304661e-01]\n",
      " [9.82445836e-01]\n",
      " [4.12799984e-01]\n",
      " [9.93330657e-01]\n",
      " [9.86803114e-01]\n",
      " [8.13084364e-01]\n",
      " [9.26231503e-01]\n",
      " [5.33995509e-01]\n",
      " [7.98681319e-01]\n",
      " [9.61744308e-01]\n",
      " [9.67750132e-01]\n",
      " [6.49897039e-01]\n",
      " [9.71837521e-01]\n",
      " [8.60299647e-01]\n",
      " [9.99055982e-01]\n",
      " [9.90552425e-01]\n",
      " [9.79552984e-01]\n",
      " [9.96963203e-01]\n",
      " [3.06573212e-01]\n",
      " [6.29248381e-01]\n",
      " [4.42079365e-01]\n",
      " [8.55277538e-01]\n",
      " [8.79775345e-01]\n",
      " [6.69497907e-01]\n",
      " [6.99990034e-01]\n",
      " [8.68233562e-01]\n",
      " [8.63523781e-01]\n",
      " [9.21157360e-01]\n",
      " [6.02485716e-01]\n",
      " [9.92784202e-01]\n",
      " [6.66438937e-01]\n",
      " [8.30427051e-01]\n",
      " [9.66909349e-01]\n",
      " [8.91212225e-01]\n",
      " [8.45224619e-01]\n",
      " [3.56186658e-01]\n",
      " [9.69064891e-01]\n",
      " [9.98873413e-01]\n",
      " [3.74270856e-01]\n",
      " [3.11497301e-01]\n",
      " [9.70335007e-01]\n",
      " [4.76936072e-01]\n",
      " [4.63930577e-01]\n",
      " [1.18388481e-01]\n",
      " [6.05914593e-01]\n",
      " [2.67750025e-01]\n",
      " [2.74208546e-01]\n",
      " [2.91142523e-01]\n",
      " [5.46128392e-01]\n",
      " [6.22986034e-02]\n",
      " [6.10977709e-01]\n",
      " [3.09531540e-01]\n",
      " [2.39226278e-02]\n",
      " [3.74955416e-01]\n",
      " [1.43405259e-01]\n",
      " [4.23153698e-01]\n",
      " [3.84869754e-01]\n",
      " [3.12634647e-01]\n",
      " [2.55152974e-02]\n",
      " [1.71394959e-01]\n",
      " [1.18641913e-01]\n",
      " [4.42166626e-03]\n",
      " [6.41791761e-01]\n",
      " [2.88305342e-01]\n",
      " [3.01766962e-01]\n",
      " [2.82797217e-01]\n",
      " [2.84098946e-02]\n",
      " [6.13125205e-01]\n",
      " [4.19537157e-01]\n",
      " [7.63249956e-03]\n",
      " [5.15894949e-01]\n",
      " [8.83501649e-01]\n",
      " [2.26048380e-01]\n",
      " [3.85932401e-02]\n",
      " [2.45219231e-01]\n",
      " [7.50101730e-02]\n",
      " [4.96984392e-01]\n",
      " [3.19273248e-02]\n",
      " [4.15058553e-01]\n",
      " [3.16939682e-01]\n",
      " [1.46817863e-01]\n",
      " [1.55718550e-01]\n",
      " [1.34878919e-01]\n",
      " [8.17554712e-01]\n",
      " [1.40491039e-01]\n",
      " [1.52054057e-01]\n",
      " [2.44132906e-01]\n",
      " [2.80797094e-01]\n",
      " [4.37929153e-01]\n",
      " [1.67757720e-01]\n",
      " [2.59043336e-01]\n",
      " [1.13592409e-01]\n",
      " [2.83249736e-01]\n",
      " [2.16837049e-01]\n",
      " [1.57064214e-01]\n",
      " [3.65336835e-01]\n",
      " [3.03658009e-01]\n",
      " [2.83592314e-01]\n",
      " [4.65182334e-01]\n",
      " [3.40540372e-02]\n",
      " [1.85778931e-01]\n",
      " [3.13995570e-01]\n",
      " [2.47323826e-01]\n",
      " [4.75169688e-01]\n",
      " [2.81914085e-01]\n",
      " [1.44424051e-01]\n",
      " [6.36560559e-01]\n",
      " [2.50688434e-01]\n",
      " [6.57202229e-02]\n",
      " [2.78844237e-01]\n",
      " [7.65639365e-01]\n",
      " [3.71027768e-01]\n",
      " [5.39361119e-01]\n",
      " [2.90034473e-01]\n",
      " [9.47052687e-02]\n",
      " [3.76404256e-01]\n",
      " [2.77273446e-01]\n",
      " [5.75028658e-01]\n",
      " [4.97118458e-02]\n",
      " [3.93153548e-01]\n",
      " [5.34735799e-01]\n",
      " [1.91299647e-01]\n",
      " [6.67040765e-01]\n",
      " [6.55938566e-01]\n",
      " [5.11572242e-01]\n",
      " [2.72355855e-01]\n",
      " [2.41934359e-01]\n",
      " [7.22093463e-01]\n",
      " [2.40274832e-01]\n",
      " [5.52210510e-02]\n",
      " [4.24847335e-01]\n",
      " [1.71489805e-01]\n",
      " [1.61335081e-01]\n",
      " [9.75580979e-03]\n",
      " [5.22039771e-01]\n",
      " [7.62084797e-02]\n",
      " [2.79107630e-01]\n",
      " [4.50220220e-02]\n",
      " [5.27362227e-01]\n",
      " [1.28175497e-01]\n",
      " [2.42649600e-01]\n",
      " [7.76429996e-02]\n",
      " [2.00488493e-01]\n",
      " [2.43511409e-01]\n",
      " [3.04629862e-01]\n",
      " [2.05366760e-01]\n",
      " [2.63086379e-01]\n",
      " [7.42323041e-01]\n",
      " [2.23794386e-01]\n",
      " [6.66296482e-01]\n",
      " [5.72835922e-01]\n",
      " [8.73898491e-02]\n",
      " [4.37043935e-01]\n",
      " [7.02493250e-01]\n",
      " [6.17602706e-01]\n",
      " [5.65366209e-01]\n",
      " [4.40506876e-01]\n",
      " [9.61666778e-02]\n",
      " [5.35857558e-01]\n",
      " [1.93795279e-01]\n",
      " [5.17406538e-02]\n",
      " [3.83105725e-01]\n",
      " [2.14460611e-01]\n",
      " [7.75204897e-02]\n",
      " [4.75124240e-01]\n",
      " [2.43512854e-01]\n",
      " [2.95347571e-02]\n",
      " [2.15057865e-01]\n",
      " [1.21635586e-01]\n",
      " [1.05732217e-01]\n",
      " [5.04084170e-01]\n",
      " [7.66726136e-01]\n",
      " [1.50144413e-01]\n",
      " [1.03689022e-01]\n",
      " [2.51918454e-02]\n",
      " [6.42705917e-01]\n",
      " [2.48308003e-01]\n",
      " [2.87543237e-01]\n",
      " [2.38689721e-01]\n",
      " [7.02939406e-02]\n",
      " [1.33454219e-01]\n",
      " [1.00667499e-01]\n",
      " [8.95662665e-01]\n",
      " [6.94722891e-01]\n",
      " [2.84347355e-01]\n",
      " [1.44722298e-01]\n",
      " [5.15661351e-02]\n",
      " [7.72575021e-01]\n",
      " [1.19409874e-01]\n",
      " [2.20437139e-01]\n",
      " [7.97645569e-01]\n",
      " [2.85954848e-02]\n",
      " [3.69696826e-01]\n",
      " [3.32558483e-01]\n",
      " [9.81794715e-01]\n",
      " [1.24997027e-01]\n",
      " [5.97366750e-01]\n",
      " [2.04069808e-01]\n",
      " [3.02573711e-01]\n",
      " [3.58448982e-01]\n",
      " [3.48523974e-01]\n",
      " [5.48871160e-01]\n",
      " [1.14175610e-01]\n",
      " [1.14482082e-01]\n",
      " [2.03742459e-01]\n",
      " [3.47400904e-01]\n",
      " [1.00486301e-01]\n",
      " [1.20875463e-01]\n",
      " [8.77069175e-01]\n",
      " [7.86301121e-02]\n",
      " [3.86632472e-01]\n",
      " [2.86973417e-01]\n",
      " [3.30720276e-01]\n",
      " [3.57962221e-01]\n",
      " [9.95388031e-01]\n",
      " [4.30810958e-01]\n",
      " [5.46662688e-01]\n",
      " [3.39916825e-01]\n",
      " [3.64102423e-02]\n",
      " [4.57361430e-01]\n",
      " [6.51005864e-01]\n",
      " [5.80676794e-01]\n",
      " [4.77816433e-01]\n",
      " [7.31675386e-01]\n",
      " [1.85241073e-01]\n",
      " [1.24544106e-01]\n",
      " [3.58271658e-01]\n",
      " [2.79051960e-01]\n",
      " [2.63754725e-01]\n",
      " [7.54263759e-01]\n",
      " [1.75678596e-01]\n",
      " [7.06734061e-01]\n",
      " [3.56542856e-01]\n",
      " [5.14413834e-01]\n",
      " [7.15905547e-01]\n",
      " [8.06015849e-01]\n",
      " [8.88341427e-01]\n",
      " [7.56988883e-01]\n",
      " [3.08274627e-01]\n",
      " [2.28591725e-01]\n",
      " [4.45380300e-01]\n",
      " [6.44844249e-02]\n",
      " [4.15202975e-01]\n",
      " [5.75432330e-02]\n",
      " [6.62736356e-01]\n",
      " [8.25086683e-02]\n",
      " [8.82182360e-01]\n",
      " [7.12415054e-02]\n",
      " [2.22214907e-01]\n",
      " [1.88186705e-01]\n",
      " [4.61814880e-01]\n",
      " [3.44732493e-01]\n",
      " [4.42186236e-01]\n",
      " [3.54022980e-01]\n",
      " [1.81273535e-01]\n",
      " [1.28054276e-01]\n",
      " [4.05881763e-01]\n",
      " [3.90993476e-01]\n",
      " [3.67110938e-01]\n",
      " [8.66776705e-01]\n",
      " [6.52621761e-02]\n",
      " [5.41475415e-01]\n",
      " [7.91170180e-01]\n",
      " [7.08859086e-01]\n",
      " [2.80362517e-01]\n",
      " [6.85107186e-02]\n",
      " [4.11371738e-01]\n",
      " [9.64292884e-01]\n",
      " [1.66867897e-01]\n",
      " [9.98408020e-01]\n",
      " [9.28069770e-01]\n",
      " [5.35486460e-01]\n",
      " [8.35305274e-01]\n",
      " [5.29398382e-01]\n",
      " [9.96022761e-01]\n",
      " [2.45919809e-01]\n",
      " [3.78882229e-01]\n",
      " [7.21061349e-01]\n",
      " [2.13221297e-01]\n",
      " [5.36126614e-01]\n",
      " [1.26066044e-01]\n",
      " [3.24266225e-01]\n",
      " [4.34159160e-01]\n",
      " [3.91113371e-01]\n",
      " [4.41428453e-01]\n",
      " [3.02686065e-01]\n",
      " [2.09942102e-01]\n",
      " [7.81482995e-01]\n",
      " [3.05207074e-01]\n",
      " [8.00077438e-01]\n",
      " [1.28591195e-01]\n",
      " [4.03986424e-01]\n",
      " [6.03513680e-02]\n",
      " [3.18895400e-01]\n",
      " [3.65080833e-01]\n",
      " [7.17753410e-01]\n",
      " [1.87238768e-01]\n",
      " [5.69140732e-01]\n",
      " [3.89840633e-01]\n",
      " [1.69874385e-01]\n",
      " [1.48315161e-01]\n",
      " [8.16610515e-01]\n",
      " [7.19065219e-02]\n",
      " [9.69579816e-01]\n",
      " [4.05985594e-01]\n",
      " [2.64947236e-01]\n",
      " [2.47672886e-01]\n",
      " [1.40243202e-01]\n",
      " [5.89720726e-01]\n",
      " [5.26534796e-01]\n",
      " [5.89137495e-01]\n",
      " [4.85374510e-01]\n",
      " [8.01095366e-01]\n",
      " [1.53749794e-01]\n",
      " [3.63228887e-01]\n",
      " [6.00503922e-01]\n",
      " [6.51717186e-01]\n",
      " [2.07596347e-01]\n",
      " [5.53700566e-01]\n",
      " [3.36377114e-01]\n",
      " [6.66104794e-01]\n",
      " [1.61255807e-01]\n",
      " [1.81892008e-01]\n",
      " [9.46007967e-01]\n",
      " [8.22075367e-01]\n",
      " [5.50234616e-01]\n",
      " [9.39929426e-01]\n",
      " [9.35682058e-01]\n",
      " [6.75757408e-01]\n",
      " [2.03059524e-01]\n",
      " [3.16426635e-01]\n",
      " [5.53412914e-01]\n",
      " [6.22828938e-02]\n",
      " [7.20949173e-01]\n",
      " [1.94746822e-01]\n",
      " [1.11586437e-01]\n",
      " [5.75223528e-02]\n",
      " [5.16504526e-01]\n",
      " [9.82116938e-01]\n",
      " [2.04092577e-01]\n",
      " [8.97965670e-01]\n",
      " [7.17353046e-01]\n",
      " [2.37059370e-01]\n",
      " [2.67887730e-02]\n",
      " [2.24687725e-01]\n",
      " [9.01738882e-01]\n",
      " [6.47651672e-01]\n",
      " [4.30301040e-01]\n",
      " [6.33643866e-01]\n",
      " [9.99934852e-01]\n",
      " [3.87542665e-01]\n",
      " [1.74272925e-01]\n",
      " [3.64578962e-01]\n",
      " [6.95682645e-01]\n",
      " [8.78160596e-01]\n",
      " [9.27371204e-01]\n",
      " [9.74920213e-01]\n",
      " [1.56904191e-01]\n",
      " [1.24181718e-01]\n",
      " [7.59126365e-01]\n",
      " [1.90420493e-01]\n",
      " [3.99236321e-01]\n",
      " [3.60874422e-02]\n",
      " [1.77851230e-01]\n",
      " [1.65542960e-01]\n",
      " [4.06896561e-01]\n",
      " [7.15513945e-01]\n",
      " [2.61041433e-01]\n",
      " [1.61377579e-01]\n",
      " [2.84482036e-02]\n",
      " [5.03131509e-01]\n",
      " [6.99165225e-01]\n",
      " [2.74734110e-01]\n",
      " [4.86668944e-01]\n",
      " [7.43655086e-01]\n",
      " [7.72992373e-02]\n",
      " [4.33001995e-01]\n",
      " [7.28312254e-01]\n",
      " [5.01942635e-01]\n",
      " [8.17195117e-01]\n",
      " [5.12867570e-01]\n",
      " [1.87514484e-01]\n",
      " [3.02942365e-01]\n",
      " [9.32954073e-01]\n",
      " [8.46128166e-01]\n",
      " [1.67016946e-02]\n",
      " [6.22939527e-01]\n",
      " [4.78588343e-02]\n",
      " [1.53311059e-01]\n",
      " [3.05752993e-01]\n",
      " [5.81013441e-01]\n",
      " [8.57906222e-01]\n",
      " [1.86816081e-01]\n",
      " [6.15035892e-01]\n",
      " [7.53825083e-02]\n",
      " [9.02008772e-01]\n",
      " [5.70172906e-01]\n",
      " [2.84557968e-01]\n",
      " [5.46617568e-01]\n",
      " [7.06086695e-01]\n",
      " [1.35034174e-01]\n",
      " [1.60802886e-01]\n",
      " [2.84744143e-01]\n",
      " [3.63030791e-01]\n",
      " [1.04186662e-01]\n",
      " [7.78560042e-02]\n",
      " [8.95119831e-02]\n",
      " [5.71995735e-01]\n",
      " [6.45958900e-01]\n",
      " [4.23627794e-01]\n",
      " [1.95535645e-01]\n",
      " [2.79274881e-01]\n",
      " [3.62610817e-01]\n",
      " [4.57039565e-01]\n",
      " [8.99258107e-02]\n",
      " [2.04986066e-01]\n",
      " [5.76341510e-01]\n",
      " [5.30547976e-01]\n",
      " [5.57408631e-01]\n",
      " [4.77890223e-01]\n",
      " [7.36683011e-01]\n",
      " [6.85293913e-01]\n",
      " [5.70321500e-01]\n",
      " [1.34237856e-01]\n",
      " [9.16800737e-01]\n",
      " [2.38561958e-01]\n",
      " [9.29116011e-01]\n",
      " [7.55531907e-01]\n",
      " [3.61808300e-01]\n",
      " [8.73401523e-01]\n",
      " [8.74187827e-01]\n",
      " [1.66217715e-01]]\n",
      "Predicted probabilities shape: (832, 1)\n",
      "Predicted labels: [1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0\n",
      " 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1\n",
      " 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 1\n",
      " 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0\n",
      " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 0\n",
      " 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1\n",
      " 0 0 1 0 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0\n",
      " 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0\n",
      " 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0\n",
      " 0 1 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
      " 1 0 0 0 0 1 1 1 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 0\n",
      " 1 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0\n",
      " 1 1 1 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      " 0 0 1 1 1 0 1 1 1 0 1 0 1 1 0 1 1 0]\n",
      "Predicted labels shape: (832,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.7442 - auc: 0.5125 - f1_score: 0.2351 - loss: 0.5668 - precision: 0.3706 - recall: 0.5022\n",
      "Training model: MobileNetV3Small on dataset: DeepFire_FIRE\n",
      "Epoch 1/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 111ms/step - accuracy: 0.7002 - auc: 0.8156 - f1_score: 0.6971 - loss: 0.6671 - precision: 0.7568 - recall: 0.7606 - val_accuracy: 0.4980 - val_auc: 0.9158 - val_f1_score: 0.6604 - val_loss: 0.7135 - val_precision: 0.4980 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.8289 - auc: 0.9064 - f1_score: 0.8299 - loss: 0.4028 - precision: 0.8320 - recall: 0.8300 - val_accuracy: 0.4869 - val_auc: 0.9326 - val_f1_score: 0.6480 - val_loss: 0.6630 - val_precision: 0.4859 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.8379 - auc: 0.9162 - f1_score: 0.8384 - loss: 0.3844 - precision: 0.8386 - recall: 0.8413 - val_accuracy: 0.7389 - val_auc: 0.9503 - val_f1_score: 0.7838 - val_loss: 0.5410 - val_precision: 0.6552 - val_recall: 0.9835 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 99ms/step - accuracy: 0.8547 - auc: 0.9226 - f1_score: 0.8531 - loss: 0.3651 - precision: 0.8483 - recall: 0.8626 - val_accuracy: 0.8619 - val_auc: 0.9642 - val_f1_score: 0.8734 - val_loss: 0.4059 - val_precision: 0.7945 - val_recall: 0.9779 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.8693 - auc: 0.9385 - f1_score: 0.8672 - loss: 0.3214 - precision: 0.8569 - recall: 0.8814 - val_accuracy: 0.9052 - val_auc: 0.9672 - val_f1_score: 0.9107 - val_loss: 0.3004 - val_precision: 0.8858 - val_recall: 0.9376 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 107ms/step - accuracy: 0.8587 - auc: 0.9329 - f1_score: 0.8558 - loss: 0.3344 - precision: 0.8664 - recall: 0.8513 - val_accuracy: 0.9052 - val_auc: 0.9729 - val_f1_score: 0.9059 - val_loss: 0.2393 - val_precision: 0.9053 - val_recall: 0.9089 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 107ms/step - accuracy: 0.8690 - auc: 0.9407 - f1_score: 0.8655 - loss: 0.3129 - precision: 0.8765 - recall: 0.8596 - val_accuracy: 0.9153 - val_auc: 0.9777 - val_f1_score: 0.9117 - val_loss: 0.2108 - val_precision: 0.9210 - val_recall: 0.9059 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.8719 - auc: 0.9431 - f1_score: 0.8708 - loss: 0.3097 - precision: 0.8582 - recall: 0.8887 - val_accuracy: 0.9234 - val_auc: 0.9797 - val_f1_score: 0.9210 - val_loss: 0.2067 - val_precision: 0.9303 - val_recall: 0.9153 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 120ms/step - accuracy: 0.8719 - auc: 0.9463 - f1_score: 0.8699 - loss: 0.2962 - precision: 0.8672 - recall: 0.8792 - val_accuracy: 0.9173 - val_auc: 0.9744 - val_f1_score: 0.9141 - val_loss: 0.2180 - val_precision: 0.9393 - val_recall: 0.8944 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 104ms/step - accuracy: 0.8751 - auc: 0.9471 - f1_score: 0.8702 - loss: 0.2942 - precision: 0.8620 - recall: 0.8843 - val_accuracy: 0.9304 - val_auc: 0.9814 - val_f1_score: 0.9251 - val_loss: 0.1951 - val_precision: 0.9311 - val_recall: 0.9253 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.8731 - auc: 0.9442 - f1_score: 0.8741 - loss: 0.3034 - precision: 0.8679 - recall: 0.8828 - val_accuracy: 0.9204 - val_auc: 0.9747 - val_f1_score: 0.9221 - val_loss: 0.2181 - val_precision: 0.9439 - val_recall: 0.9023 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 94ms/step - accuracy: 0.8830 - auc: 0.9505 - f1_score: 0.8796 - loss: 0.2837 - precision: 0.8779 - recall: 0.8873 - val_accuracy: 0.9325 - val_auc: 0.9809 - val_f1_score: 0.9272 - val_loss: 0.2039 - val_precision: 0.9165 - val_recall: 0.9454 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 93ms/step - accuracy: 0.8763 - auc: 0.9458 - f1_score: 0.8762 - loss: 0.2996 - precision: 0.8851 - recall: 0.8716 - val_accuracy: 0.9304 - val_auc: 0.9825 - val_f1_score: 0.9282 - val_loss: 0.1920 - val_precision: 0.9485 - val_recall: 0.9127 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 96ms/step - accuracy: 0.8737 - auc: 0.9504 - f1_score: 0.8716 - loss: 0.2842 - precision: 0.8623 - recall: 0.8843 - val_accuracy: 0.9194 - val_auc: 0.9786 - val_f1_score: 0.9117 - val_loss: 0.2035 - val_precision: 0.9414 - val_recall: 0.8912 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 102ms/step - accuracy: 0.8879 - auc: 0.9555 - f1_score: 0.8849 - loss: 0.2691 - precision: 0.8792 - recall: 0.8947 - val_accuracy: 0.9375 - val_auc: 0.9851 - val_f1_score: 0.9366 - val_loss: 0.1817 - val_precision: 0.9348 - val_recall: 0.9422 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 95ms/step - accuracy: 0.8911 - auc: 0.9546 - f1_score: 0.8890 - loss: 0.2732 - precision: 0.8923 - recall: 0.8923 - val_accuracy: 0.9385 - val_auc: 0.9832 - val_f1_score: 0.9366 - val_loss: 0.1770 - val_precision: 0.9319 - val_recall: 0.9485 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 121ms/step - accuracy: 0.8815 - auc: 0.9482 - f1_score: 0.8808 - loss: 0.2948 - precision: 0.8819 - recall: 0.8795 - val_accuracy: 0.9345 - val_auc: 0.9874 - val_f1_score: 0.9314 - val_loss: 0.1753 - val_precision: 0.9451 - val_recall: 0.9245 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - accuracy: 0.8849 - auc: 0.9539 - f1_score: 0.8818 - loss: 0.2737 - precision: 0.8851 - recall: 0.8847 - val_accuracy: 0.9415 - val_auc: 0.9873 - val_f1_score: 0.9387 - val_loss: 0.1709 - val_precision: 0.9432 - val_recall: 0.9394 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 103ms/step - accuracy: 0.9009 - auc: 0.9621 - f1_score: 0.8980 - loss: 0.2489 - precision: 0.9044 - recall: 0.8960 - val_accuracy: 0.9345 - val_auc: 0.9859 - val_f1_score: 0.9318 - val_loss: 0.1804 - val_precision: 0.9378 - val_recall: 0.9321 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 143ms/step - accuracy: 0.8936 - auc: 0.9600 - f1_score: 0.8922 - loss: 0.2561 - precision: 0.8948 - recall: 0.8936 - val_accuracy: 0.9375 - val_auc: 0.9868 - val_f1_score: 0.9380 - val_loss: 0.1728 - val_precision: 0.9341 - val_recall: 0.9416 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 163ms/step - accuracy: 0.8957 - auc: 0.9561 - f1_score: 0.8934 - loss: 0.2702 - precision: 0.8829 - recall: 0.9096 - val_accuracy: 0.9506 - val_auc: 0.9908 - val_f1_score: 0.9456 - val_loss: 0.1508 - val_precision: 0.9571 - val_recall: 0.9437 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 161ms/step - accuracy: 0.8827 - auc: 0.9541 - f1_score: 0.8837 - loss: 0.2754 - precision: 0.8906 - recall: 0.8775 - val_accuracy: 0.9466 - val_auc: 0.9909 - val_f1_score: 0.9424 - val_loss: 0.1564 - val_precision: 0.9563 - val_recall: 0.9348 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 139ms/step - accuracy: 0.8916 - auc: 0.9567 - f1_score: 0.8896 - loss: 0.2666 - precision: 0.8832 - recall: 0.8975 - val_accuracy: 0.9355 - val_auc: 0.9869 - val_f1_score: 0.9309 - val_loss: 0.1628 - val_precision: 0.9335 - val_recall: 0.9335 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 113ms/step - accuracy: 0.8961 - auc: 0.9579 - f1_score: 0.8958 - loss: 0.2614 - precision: 0.8937 - recall: 0.9014 - val_accuracy: 0.9345 - val_auc: 0.9869 - val_f1_score: 0.9324 - val_loss: 0.1649 - val_precision: 0.9296 - val_recall: 0.9390 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 107ms/step - accuracy: 0.8919 - auc: 0.9590 - f1_score: 0.8886 - loss: 0.2581 - precision: 0.8927 - recall: 0.8891 - val_accuracy: 0.9385 - val_auc: 0.9839 - val_f1_score: 0.9321 - val_loss: 0.1719 - val_precision: 0.9535 - val_recall: 0.9151 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8865 - auc: 0.9559 - f1_score: 0.8854 - loss: 0.2703 - precision: 0.8796 - recall: 0.8951\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 111ms/step - accuracy: 0.8866 - auc: 0.9559 - f1_score: 0.8854 - loss: 0.2703 - precision: 0.8797 - recall: 0.8951 - val_accuracy: 0.9315 - val_auc: 0.9865 - val_f1_score: 0.9274 - val_loss: 0.1701 - val_precision: 0.9464 - val_recall: 0.9208 - learning_rate: 0.0010\n",
      "Training time: 408.12 seconds\n",
      "Evaluating MobileNetV3Small on DeepFire_FIRE...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 906ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "True labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True labels shape: (832,)\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step\n",
      "Predicted probabilities: [[9.99704182e-01]\n",
      " [3.69662106e-01]\n",
      " [9.66421783e-01]\n",
      " [9.93964195e-01]\n",
      " [9.92984056e-01]\n",
      " [9.47528422e-01]\n",
      " [8.00684750e-01]\n",
      " [6.61939502e-01]\n",
      " [9.82250929e-01]\n",
      " [8.75226557e-01]\n",
      " [9.79016244e-01]\n",
      " [9.96177316e-01]\n",
      " [9.95524585e-01]\n",
      " [9.57325220e-01]\n",
      " [9.71153617e-01]\n",
      " [9.88556087e-01]\n",
      " [9.66904402e-01]\n",
      " [9.31358337e-01]\n",
      " [9.48363245e-01]\n",
      " [9.69561219e-01]\n",
      " [9.64583218e-01]\n",
      " [9.98798311e-01]\n",
      " [6.62636757e-01]\n",
      " [8.40509832e-01]\n",
      " [9.46885943e-01]\n",
      " [5.43017149e-01]\n",
      " [8.30055237e-01]\n",
      " [5.90440214e-01]\n",
      " [6.55516982e-01]\n",
      " [5.75395107e-01]\n",
      " [9.40067530e-01]\n",
      " [7.05415130e-01]\n",
      " [6.72772110e-01]\n",
      " [9.81105685e-01]\n",
      " [9.84252691e-01]\n",
      " [8.37958932e-01]\n",
      " [9.62396026e-01]\n",
      " [3.49626660e-01]\n",
      " [9.88636017e-02]\n",
      " [7.50099063e-01]\n",
      " [1.94566101e-01]\n",
      " [4.15485084e-01]\n",
      " [9.46163535e-01]\n",
      " [6.74582720e-01]\n",
      " [9.96413946e-01]\n",
      " [8.76110077e-01]\n",
      " [7.71272898e-01]\n",
      " [6.55740976e-01]\n",
      " [8.11413705e-01]\n",
      " [8.59712005e-01]\n",
      " [9.15769339e-01]\n",
      " [9.40821230e-01]\n",
      " [9.88623500e-01]\n",
      " [3.43180805e-01]\n",
      " [9.23900962e-01]\n",
      " [2.13560671e-01]\n",
      " [9.00594413e-01]\n",
      " [5.68741918e-01]\n",
      " [4.67870831e-01]\n",
      " [9.82717693e-01]\n",
      " [7.66813338e-01]\n",
      " [9.41692889e-01]\n",
      " [7.96029449e-01]\n",
      " [8.92105699e-01]\n",
      " [4.26145494e-01]\n",
      " [4.64860827e-01]\n",
      " [9.72449541e-01]\n",
      " [3.32861602e-01]\n",
      " [2.28877999e-02]\n",
      " [2.07611188e-01]\n",
      " [9.53708589e-01]\n",
      " [7.84272552e-01]\n",
      " [7.93301105e-01]\n",
      " [5.02312124e-01]\n",
      " [9.99180436e-01]\n",
      " [9.84998882e-01]\n",
      " [9.93614018e-01]\n",
      " [3.17398697e-01]\n",
      " [8.84833515e-01]\n",
      " [8.89974236e-01]\n",
      " [9.93289948e-01]\n",
      " [3.71961981e-01]\n",
      " [8.39503288e-01]\n",
      " [7.02591956e-01]\n",
      " [9.21294391e-01]\n",
      " [9.78509068e-01]\n",
      " [5.38934469e-01]\n",
      " [9.15242493e-01]\n",
      " [9.40504670e-01]\n",
      " [9.94940877e-01]\n",
      " [9.17164028e-01]\n",
      " [4.49763209e-01]\n",
      " [7.67959654e-01]\n",
      " [9.71363962e-01]\n",
      " [7.74088979e-01]\n",
      " [8.45325828e-01]\n",
      " [4.51486230e-01]\n",
      " [8.12809169e-01]\n",
      " [9.72409189e-01]\n",
      " [8.61342788e-01]\n",
      " [7.53911078e-01]\n",
      " [1.07952751e-01]\n",
      " [9.31861937e-01]\n",
      " [7.29030013e-01]\n",
      " [7.88259268e-01]\n",
      " [9.49073553e-01]\n",
      " [5.86060854e-03]\n",
      " [7.86689401e-01]\n",
      " [9.59873378e-01]\n",
      " [7.71625280e-01]\n",
      " [9.50174689e-01]\n",
      " [9.50760484e-01]\n",
      " [6.45789266e-01]\n",
      " [8.35286677e-01]\n",
      " [5.82929671e-01]\n",
      " [9.47400510e-01]\n",
      " [7.69656360e-01]\n",
      " [8.84059191e-01]\n",
      " [9.08181787e-01]\n",
      " [1.13523386e-01]\n",
      " [2.48774961e-01]\n",
      " [9.24917638e-01]\n",
      " [9.36018229e-01]\n",
      " [9.82266486e-01]\n",
      " [7.82308757e-01]\n",
      " [9.11573946e-01]\n",
      " [7.04649627e-01]\n",
      " [6.82806969e-01]\n",
      " [8.94234657e-01]\n",
      " [5.31958282e-01]\n",
      " [9.68025446e-01]\n",
      " [3.00094873e-01]\n",
      " [7.47516990e-01]\n",
      " [8.65894437e-01]\n",
      " [1.32077143e-01]\n",
      " [8.92931521e-01]\n",
      " [9.24664617e-01]\n",
      " [4.80949372e-01]\n",
      " [9.39141631e-01]\n",
      " [3.67659070e-02]\n",
      " [2.46778890e-01]\n",
      " [3.57581215e-04]\n",
      " [4.53326385e-03]\n",
      " [5.54279625e-01]\n",
      " [9.22133088e-01]\n",
      " [4.26517010e-01]\n",
      " [1.50803134e-01]\n",
      " [9.98380840e-01]\n",
      " [9.47559893e-01]\n",
      " [9.06891227e-01]\n",
      " [9.85490859e-01]\n",
      " [9.62143540e-02]\n",
      " [1.83249742e-01]\n",
      " [7.94067383e-02]\n",
      " [9.01273370e-01]\n",
      " [7.72698104e-01]\n",
      " [4.91158724e-01]\n",
      " [8.95623207e-01]\n",
      " [5.52310824e-01]\n",
      " [8.62928927e-01]\n",
      " [8.38118374e-01]\n",
      " [7.69994706e-02]\n",
      " [8.13783884e-01]\n",
      " [6.84398890e-01]\n",
      " [1.27211586e-01]\n",
      " [9.00259688e-02]\n",
      " [8.07410717e-01]\n",
      " [4.71538752e-02]\n",
      " [8.54705453e-01]\n",
      " [9.70668912e-01]\n",
      " [8.61843944e-01]\n",
      " [9.17672873e-01]\n",
      " [8.86177361e-01]\n",
      " [8.38588595e-01]\n",
      " [6.71519876e-01]\n",
      " [3.01801801e-01]\n",
      " [9.90130126e-01]\n",
      " [2.15467378e-01]\n",
      " [2.83645719e-01]\n",
      " [3.59389007e-01]\n",
      " [2.13076025e-01]\n",
      " [4.66299891e-01]\n",
      " [3.59696895e-01]\n",
      " [5.78597546e-01]\n",
      " [5.84284902e-01]\n",
      " [2.30303481e-02]\n",
      " [2.72696406e-01]\n",
      " [6.14068031e-01]\n",
      " [7.22625434e-01]\n",
      " [4.33218122e-01]\n",
      " [3.42864767e-02]\n",
      " [4.93845254e-01]\n",
      " [9.38310862e-01]\n",
      " [2.01359183e-01]\n",
      " [7.49760151e-01]\n",
      " [9.88636374e-01]\n",
      " [9.77693200e-01]\n",
      " [9.92749453e-01]\n",
      " [9.59890842e-01]\n",
      " [7.82127261e-01]\n",
      " [6.77422166e-01]\n",
      " [9.75638688e-01]\n",
      " [9.76986051e-01]\n",
      " [9.29864109e-01]\n",
      " [7.59386599e-01]\n",
      " [8.14101994e-01]\n",
      " [6.69534326e-01]\n",
      " [9.99007404e-01]\n",
      " [8.48659158e-01]\n",
      " [9.96292233e-01]\n",
      " [9.95655239e-01]\n",
      " [9.92134035e-01]\n",
      " [6.93888783e-01]\n",
      " [9.73163962e-01]\n",
      " [9.91238415e-01]\n",
      " [8.43507946e-01]\n",
      " [9.83407974e-01]\n",
      " [8.13992381e-01]\n",
      " [8.48429680e-01]\n",
      " [9.79407907e-01]\n",
      " [9.95230258e-01]\n",
      " [8.75978410e-01]\n",
      " [5.12930229e-02]\n",
      " [9.63509262e-01]\n",
      " [8.95019233e-01]\n",
      " [9.94939089e-01]\n",
      " [9.90482509e-01]\n",
      " [9.95365798e-01]\n",
      " [5.93607426e-01]\n",
      " [9.00096416e-01]\n",
      " [9.96404767e-01]\n",
      " [9.97133255e-01]\n",
      " [8.21643353e-01]\n",
      " [9.26433623e-01]\n",
      " [8.84277225e-01]\n",
      " [9.73942399e-01]\n",
      " [9.98445690e-01]\n",
      " [9.97859061e-01]\n",
      " [8.65930796e-01]\n",
      " [9.50118840e-01]\n",
      " [9.66578662e-01]\n",
      " [9.96507883e-01]\n",
      " [9.80732381e-01]\n",
      " [9.55573976e-01]\n",
      " [9.99430418e-01]\n",
      " [9.92375374e-01]\n",
      " [9.72459435e-01]\n",
      " [9.57380235e-01]\n",
      " [7.35463500e-01]\n",
      " [9.42833304e-01]\n",
      " [7.16931939e-01]\n",
      " [1.97073340e-01]\n",
      " [9.33719754e-01]\n",
      " [9.34738636e-01]\n",
      " [7.02256262e-01]\n",
      " [9.14209783e-01]\n",
      " [3.90958756e-01]\n",
      " [5.30407071e-01]\n",
      " [6.06502354e-01]\n",
      " [9.89993989e-01]\n",
      " [9.98046219e-01]\n",
      " [9.86702502e-01]\n",
      " [9.14186954e-01]\n",
      " [9.78915691e-01]\n",
      " [8.24480534e-01]\n",
      " [8.84808064e-01]\n",
      " [8.22254241e-01]\n",
      " [6.24506176e-01]\n",
      " [9.51898575e-01]\n",
      " [9.89604354e-01]\n",
      " [5.85333288e-01]\n",
      " [8.76660585e-01]\n",
      " [9.01347220e-01]\n",
      " [7.21220374e-01]\n",
      " [9.41258967e-01]\n",
      " [9.39396739e-01]\n",
      " [8.01473022e-01]\n",
      " [8.58915031e-01]\n",
      " [9.33178723e-01]\n",
      " [3.78489554e-01]\n",
      " [7.86565781e-01]\n",
      " [9.84898090e-01]\n",
      " [7.38462329e-01]\n",
      " [3.94725293e-01]\n",
      " [7.00069010e-01]\n",
      " [7.54583359e-01]\n",
      " [8.59685659e-01]\n",
      " [9.45547819e-01]\n",
      " [7.07041681e-01]\n",
      " [9.57989931e-01]\n",
      " [9.96610999e-01]\n",
      " [5.49318731e-01]\n",
      " [8.12483132e-01]\n",
      " [7.06236601e-01]\n",
      " [8.58081758e-01]\n",
      " [9.76172030e-01]\n",
      " [8.20536256e-01]\n",
      " [3.56379479e-01]\n",
      " [9.87718821e-01]\n",
      " [9.98344481e-01]\n",
      " [9.76249278e-01]\n",
      " [8.27002048e-01]\n",
      " [9.78650391e-01]\n",
      " [9.40461338e-01]\n",
      " [8.11740458e-01]\n",
      " [5.23343205e-01]\n",
      " [8.96185916e-03]\n",
      " [7.40550816e-01]\n",
      " [9.46117043e-01]\n",
      " [1.54666796e-01]\n",
      " [8.03359151e-01]\n",
      " [9.98866498e-01]\n",
      " [9.99508262e-01]\n",
      " [7.52925575e-01]\n",
      " [9.91444170e-01]\n",
      " [9.09388900e-01]\n",
      " [9.67746854e-01]\n",
      " [9.91229653e-01]\n",
      " [9.94117558e-01]\n",
      " [8.64988983e-01]\n",
      " [9.37404275e-01]\n",
      " [9.95099425e-01]\n",
      " [9.96726215e-01]\n",
      " [9.71996784e-01]\n",
      " [7.29610443e-01]\n",
      " [9.75982666e-01]\n",
      " [9.93787467e-01]\n",
      " [9.32951927e-01]\n",
      " [9.99714196e-01]\n",
      " [8.51508617e-01]\n",
      " [9.91724372e-01]\n",
      " [9.88998294e-01]\n",
      " [9.37731981e-01]\n",
      " [6.02749228e-01]\n",
      " [6.85809612e-01]\n",
      " [7.80411422e-01]\n",
      " [9.68235195e-01]\n",
      " [7.27972269e-01]\n",
      " [9.82968390e-01]\n",
      " [9.71033275e-01]\n",
      " [9.53219116e-01]\n",
      " [3.07901889e-01]\n",
      " [9.61792886e-01]\n",
      " [1.50223523e-01]\n",
      " [3.07193488e-01]\n",
      " [9.30562437e-01]\n",
      " [9.77600276e-01]\n",
      " [7.54917800e-01]\n",
      " [9.77793157e-01]\n",
      " [8.71778131e-01]\n",
      " [3.68039668e-01]\n",
      " [9.02852893e-01]\n",
      " [9.15676832e-01]\n",
      " [9.96525288e-01]\n",
      " [9.30603266e-01]\n",
      " [9.88468289e-01]\n",
      " [9.74807441e-01]\n",
      " [9.61961865e-01]\n",
      " [6.50159240e-01]\n",
      " [9.54680741e-01]\n",
      " [9.32531118e-01]\n",
      " [7.69536257e-01]\n",
      " [9.09931123e-01]\n",
      " [9.98676777e-01]\n",
      " [4.39111263e-01]\n",
      " [8.06225896e-01]\n",
      " [5.19793779e-02]\n",
      " [9.97726083e-01]\n",
      " [4.46153015e-01]\n",
      " [5.13587356e-01]\n",
      " [1.49014577e-01]\n",
      " [4.62146044e-01]\n",
      " [9.59837615e-01]\n",
      " [6.77982330e-01]\n",
      " [9.65621650e-01]\n",
      " [8.20619941e-01]\n",
      " [7.86266506e-01]\n",
      " [9.72456515e-01]\n",
      " [9.98006403e-01]\n",
      " [8.55246484e-01]\n",
      " [7.01724172e-01]\n",
      " [9.94588971e-01]\n",
      " [5.11397302e-01]\n",
      " [9.97479081e-01]\n",
      " [9.76545155e-01]\n",
      " [6.55741811e-01]\n",
      " [9.76124287e-01]\n",
      " [7.56068945e-01]\n",
      " [5.88740349e-01]\n",
      " [7.33306766e-01]\n",
      " [8.54160666e-01]\n",
      " [9.36018527e-01]\n",
      " [8.91172349e-01]\n",
      " [7.91050911e-01]\n",
      " [7.28295565e-01]\n",
      " [3.09651643e-01]\n",
      " [4.88200814e-01]\n",
      " [9.69856441e-01]\n",
      " [9.87474382e-01]\n",
      " [8.85089278e-01]\n",
      " [9.28818464e-01]\n",
      " [8.31913054e-01]\n",
      " [5.13090909e-01]\n",
      " [2.43528917e-01]\n",
      " [8.43468189e-01]\n",
      " [4.80595291e-01]\n",
      " [1.74493909e-01]\n",
      " [2.93773562e-01]\n",
      " [2.92684525e-01]\n",
      " [8.37653995e-01]\n",
      " [5.61334968e-01]\n",
      " [2.92866677e-02]\n",
      " [9.30371046e-01]\n",
      " [8.50160956e-01]\n",
      " [6.98234916e-01]\n",
      " [9.70737696e-01]\n",
      " [9.02018905e-01]\n",
      " [9.91849542e-01]\n",
      " [4.88297105e-01]\n",
      " [1.59225389e-01]\n",
      " [9.60345566e-01]\n",
      " [5.44357061e-01]\n",
      " [9.53756332e-01]\n",
      " [9.64962065e-01]\n",
      " [4.43370134e-01]\n",
      " [6.94506526e-01]\n",
      " [7.37370014e-01]\n",
      " [1.01364471e-01]\n",
      " [5.75858474e-01]\n",
      " [9.74362493e-01]\n",
      " [6.63437620e-02]\n",
      " [9.86713648e-01]\n",
      " [7.95518398e-01]\n",
      " [9.76704597e-01]\n",
      " [2.31421873e-01]\n",
      " [3.19564454e-02]\n",
      " [2.42380112e-01]\n",
      " [6.21403933e-01]\n",
      " [1.10889673e-01]\n",
      " [3.96017611e-01]\n",
      " [7.90708899e-01]\n",
      " [8.31276104e-02]\n",
      " [7.86672533e-01]\n",
      " [1.96273014e-01]\n",
      " [2.62020737e-01]\n",
      " [5.76317906e-01]\n",
      " [5.04998164e-03]\n",
      " [3.83073627e-03]\n",
      " [8.41696262e-01]\n",
      " [4.44102138e-02]\n",
      " [9.78624344e-01]\n",
      " [1.25075877e-01]\n",
      " [4.69971597e-01]\n",
      " [5.24947643e-01]\n",
      " [8.24241117e-02]\n",
      " [9.75897372e-01]\n",
      " [5.14531314e-01]\n",
      " [9.77482677e-01]\n",
      " [1.38255758e-02]\n",
      " [8.86531472e-01]\n",
      " [1.70192257e-01]\n",
      " [2.55317776e-03]\n",
      " [8.26141834e-02]\n",
      " [3.30494225e-01]\n",
      " [2.57783711e-01]\n",
      " [1.71043992e-01]\n",
      " [2.59514689e-01]\n",
      " [5.12294710e-01]\n",
      " [3.55212063e-01]\n",
      " [2.16483518e-01]\n",
      " [5.97544372e-01]\n",
      " [3.27449322e-01]\n",
      " [5.23691654e-01]\n",
      " [8.62491488e-01]\n",
      " [1.09753758e-01]\n",
      " [6.78248778e-02]\n",
      " [1.57331064e-01]\n",
      " [4.65062737e-01]\n",
      " [4.05662090e-01]\n",
      " [9.84345555e-01]\n",
      " [4.16461006e-02]\n",
      " [1.60693049e-01]\n",
      " [3.81077468e-01]\n",
      " [1.93576366e-01]\n",
      " [5.13559487e-03]\n",
      " [5.13975501e-01]\n",
      " [6.92367315e-01]\n",
      " [3.64434242e-01]\n",
      " [3.46452683e-01]\n",
      " [2.28529051e-02]\n",
      " [6.78296685e-01]\n",
      " [1.40340254e-01]\n",
      " [2.26956457e-01]\n",
      " [6.40828460e-02]\n",
      " [1.72559425e-01]\n",
      " [3.74406964e-01]\n",
      " [3.32157999e-01]\n",
      " [1.29782259e-02]\n",
      " [1.10709459e-01]\n",
      " [7.10633934e-01]\n",
      " [5.85099816e-01]\n",
      " [2.70287301e-02]\n",
      " [9.23259914e-01]\n",
      " [9.83952940e-01]\n",
      " [2.18219861e-01]\n",
      " [1.13048457e-01]\n",
      " [1.82062060e-01]\n",
      " [1.37522414e-01]\n",
      " [2.23259658e-01]\n",
      " [5.72411418e-01]\n",
      " [9.04699683e-01]\n",
      " [9.84991908e-01]\n",
      " [4.57461085e-03]\n",
      " [5.23816705e-01]\n",
      " [5.90077877e-01]\n",
      " [1.09428972e-01]\n",
      " [8.97135615e-01]\n",
      " [8.34852695e-01]\n",
      " [3.15118744e-03]\n",
      " [7.18341544e-02]\n",
      " [1.94661617e-02]\n",
      " [8.17373753e-01]\n",
      " [6.48568749e-01]\n",
      " [1.14419930e-01]\n",
      " [4.38664794e-01]\n",
      " [2.62020737e-01]\n",
      " [1.82707347e-02]\n",
      " [1.29311204e-01]\n",
      " [2.47157976e-01]\n",
      " [5.81882477e-01]\n",
      " [8.42955709e-03]\n",
      " [2.52209492e-02]\n",
      " [2.98998859e-02]\n",
      " [5.88792525e-02]\n",
      " [6.71398759e-01]\n",
      " [9.59061742e-01]\n",
      " [5.48387282e-02]\n",
      " [1.15465252e-02]\n",
      " [2.03701004e-01]\n",
      " [8.63235593e-02]\n",
      " [8.65188390e-02]\n",
      " [9.27812420e-03]\n",
      " [3.63565348e-02]\n",
      " [4.83756274e-01]\n",
      " [3.91308106e-02]\n",
      " [1.73473787e-02]\n",
      " [1.37059405e-01]\n",
      " [7.13570595e-01]\n",
      " [1.18739717e-02]\n",
      " [8.84757221e-01]\n",
      " [9.21609938e-01]\n",
      " [4.21120636e-02]\n",
      " [9.70949233e-01]\n",
      " [7.48450756e-01]\n",
      " [6.82389021e-01]\n",
      " [8.07471752e-01]\n",
      " [8.86517167e-01]\n",
      " [1.32521577e-02]\n",
      " [7.61834383e-01]\n",
      " [1.01311184e-01]\n",
      " [6.29035115e-01]\n",
      " [9.25585389e-01]\n",
      " [5.76303363e-01]\n",
      " [6.64617240e-01]\n",
      " [7.91237950e-01]\n",
      " [3.80288288e-02]\n",
      " [1.89665988e-01]\n",
      " [3.49562732e-04]\n",
      " [9.44191292e-02]\n",
      " [4.34004307e-01]\n",
      " [6.37810975e-02]\n",
      " [9.37790453e-01]\n",
      " [5.66116214e-01]\n",
      " [9.51529801e-01]\n",
      " [6.02191567e-01]\n",
      " [3.20023924e-01]\n",
      " [1.09716371e-01]\n",
      " [9.54874456e-01]\n",
      " [1.58933867e-02]\n",
      " [4.50650632e-01]\n",
      " [9.37041521e-01]\n",
      " [5.79807818e-01]\n",
      " [7.10147023e-01]\n",
      " [6.11679077e-01]\n",
      " [3.63486826e-01]\n",
      " [9.85482931e-01]\n",
      " [2.18846455e-01]\n",
      " [5.71977735e-01]\n",
      " [4.28669035e-01]\n",
      " [4.08931673e-01]\n",
      " [5.03942132e-01]\n",
      " [4.36025441e-01]\n",
      " [2.36372396e-01]\n",
      " [4.92788941e-01]\n",
      " [8.62737417e-01]\n",
      " [1.48239173e-02]\n",
      " [2.76926130e-01]\n",
      " [1.28718624e-02]\n",
      " [6.19231388e-02]\n",
      " [1.71147376e-01]\n",
      " [1.69553924e-02]\n",
      " [8.65183683e-05]\n",
      " [1.66323909e-03]\n",
      " [3.76144517e-03]\n",
      " [1.91949494e-02]\n",
      " [2.50157937e-02]\n",
      " [8.80997553e-02]\n",
      " [1.10537529e-01]\n",
      " [3.40870507e-02]\n",
      " [8.30322981e-01]\n",
      " [7.25811571e-02]\n",
      " [1.26527008e-02]\n",
      " [1.33319879e-02]\n",
      " [1.59229070e-01]\n",
      " [2.53252506e-01]\n",
      " [4.40014713e-02]\n",
      " [2.21861929e-01]\n",
      " [2.14089543e-01]\n",
      " [4.73155669e-05]\n",
      " [1.39966689e-03]\n",
      " [1.36633590e-01]\n",
      " [5.12282029e-02]\n",
      " [2.21110404e-01]\n",
      " [1.66559070e-01]\n",
      " [7.86431968e-01]\n",
      " [2.98028477e-02]\n",
      " [3.36040594e-02]\n",
      " [1.38319001e-01]\n",
      " [1.13869430e-02]\n",
      " [5.80336340e-03]\n",
      " [4.58992451e-01]\n",
      " [2.47707330e-02]\n",
      " [5.21557964e-02]\n",
      " [1.94280133e-01]\n",
      " [3.06973100e-01]\n",
      " [6.06339565e-03]\n",
      " [2.01689266e-03]\n",
      " [2.02184636e-03]\n",
      " [3.72487754e-01]\n",
      " [1.30208815e-02]\n",
      " [2.36903653e-01]\n",
      " [2.00013048e-03]\n",
      " [2.24223230e-02]\n",
      " [5.59859909e-03]\n",
      " [7.86889121e-02]\n",
      " [1.19189976e-03]\n",
      " [9.43769887e-02]\n",
      " [5.22221159e-03]\n",
      " [3.20065245e-02]\n",
      " [5.20166196e-03]\n",
      " [4.03189361e-01]\n",
      " [2.69258581e-02]\n",
      " [1.16692241e-02]\n",
      " [1.93718579e-02]\n",
      " [5.91273680e-02]\n",
      " [4.86008704e-01]\n",
      " [7.09240362e-02]\n",
      " [1.69552944e-03]\n",
      " [2.23179422e-02]\n",
      " [2.14578584e-03]\n",
      " [5.65960864e-03]\n",
      " [6.34353375e-03]\n",
      " [1.04159601e-02]\n",
      " [1.22584682e-02]\n",
      " [5.28841838e-02]\n",
      " [4.99915518e-03]\n",
      " [3.94956470e-01]\n",
      " [2.22721383e-01]\n",
      " [5.95113961e-03]\n",
      " [1.42377868e-01]\n",
      " [2.42148980e-01]\n",
      " [2.18491986e-01]\n",
      " [1.69691250e-01]\n",
      " [9.36185569e-02]\n",
      " [4.14108396e-01]\n",
      " [7.65584828e-03]\n",
      " [1.60503760e-01]\n",
      " [7.01062560e-01]\n",
      " [1.03830770e-02]\n",
      " [4.33898829e-02]\n",
      " [1.46578206e-02]\n",
      " [6.78179622e-01]\n",
      " [6.44719005e-02]\n",
      " [9.23454296e-03]\n",
      " [9.58342105e-03]\n",
      " [3.55544358e-01]\n",
      " [1.99886411e-01]\n",
      " [4.14040573e-02]\n",
      " [1.06672151e-02]\n",
      " [1.37192503e-01]\n",
      " [2.28050817e-03]\n",
      " [1.07214786e-01]\n",
      " [7.55401980e-03]\n",
      " [7.29453564e-02]\n",
      " [1.53006706e-02]\n",
      " [2.51582190e-02]\n",
      " [3.89966890e-02]\n",
      " [1.10766508e-01]\n",
      " [6.22471282e-03]\n",
      " [2.08333626e-01]\n",
      " [1.26250377e-02]\n",
      " [2.02809975e-01]\n",
      " [1.08878361e-03]\n",
      " [1.90185532e-01]\n",
      " [2.27129847e-01]\n",
      " [1.50698759e-02]\n",
      " [7.90456776e-03]\n",
      " [8.05473030e-02]\n",
      " [1.16234004e-01]\n",
      " [1.67316139e-01]\n",
      " [3.88309240e-01]\n",
      " [3.00148636e-01]\n",
      " [1.28117427e-02]\n",
      " [1.02787733e-01]\n",
      " [1.68100387e-01]\n",
      " [4.53588495e-04]\n",
      " [3.42292368e-01]\n",
      " [4.64263074e-02]\n",
      " [1.85957190e-03]\n",
      " [3.79681424e-03]\n",
      " [1.73103120e-02]\n",
      " [2.14626384e-03]\n",
      " [7.17319474e-02]\n",
      " [5.97446784e-02]\n",
      " [4.76728342e-02]\n",
      " [9.00516380e-03]\n",
      " [1.00295976e-01]\n",
      " [6.66216481e-03]\n",
      " [1.82084113e-01]\n",
      " [9.99737415e-04]\n",
      " [5.92763305e-01]\n",
      " [2.34781895e-02]\n",
      " [1.55561219e-03]\n",
      " [1.26885831e-01]\n",
      " [2.37498265e-02]\n",
      " [1.42081618e-01]\n",
      " [4.47358796e-03]\n",
      " [2.00221930e-02]\n",
      " [6.41057175e-03]\n",
      " [2.86634243e-03]\n",
      " [4.33585495e-02]\n",
      " [2.14079633e-01]\n",
      " [5.61791301e-01]\n",
      " [7.62260985e-03]\n",
      " [1.28144184e-02]\n",
      " [6.90522432e-01]\n",
      " [4.94463295e-02]\n",
      " [2.93380499e-01]\n",
      " [9.72271245e-03]\n",
      " [9.05408382e-01]\n",
      " [1.91870201e-02]\n",
      " [4.44901036e-03]\n",
      " [1.68663576e-01]\n",
      " [2.50939932e-03]\n",
      " [8.03260803e-02]\n",
      " [7.25594684e-02]\n",
      " [3.13099146e-01]\n",
      " [8.01566988e-02]\n",
      " [3.26995202e-03]\n",
      " [1.21720172e-02]\n",
      " [1.18164311e-03]\n",
      " [1.04083847e-02]\n",
      " [1.84898236e-05]\n",
      " [4.88503044e-03]\n",
      " [1.53642090e-04]\n",
      " [8.53478923e-05]\n",
      " [7.32315779e-01]\n",
      " [1.52668124e-02]\n",
      " [2.00108555e-03]\n",
      " [1.08030066e-03]\n",
      " [2.09964156e-01]\n",
      " [1.50550548e-02]\n",
      " [1.37788316e-04]\n",
      " [5.38691282e-01]\n",
      " [3.44286352e-01]\n",
      " [1.04528922e-03]\n",
      " [5.36328368e-02]\n",
      " [4.81626928e-01]\n",
      " [8.33841134e-03]\n",
      " [3.03330226e-03]\n",
      " [2.46221468e-01]\n",
      " [1.89186574e-03]\n",
      " [4.04791124e-02]\n",
      " [1.76155075e-01]\n",
      " [1.86837360e-01]\n",
      " [8.03687051e-03]\n",
      " [2.22970560e-01]\n",
      " [9.84772996e-05]\n",
      " [6.08366635e-03]\n",
      " [5.64401224e-03]\n",
      " [2.96224385e-01]\n",
      " [2.64279768e-02]\n",
      " [1.42182223e-02]\n",
      " [6.90004323e-03]\n",
      " [3.52276023e-03]\n",
      " [3.37705493e-01]\n",
      " [2.32169479e-01]\n",
      " [7.01623224e-03]\n",
      " [5.07459283e-01]\n",
      " [5.03805000e-03]\n",
      " [6.91607669e-02]\n",
      " [7.56042123e-01]\n",
      " [1.10955080e-02]\n",
      " [1.85700394e-02]\n",
      " [9.49350893e-02]\n",
      " [8.25509071e-01]\n",
      " [1.15076959e-01]\n",
      " [3.00015956e-01]\n",
      " [7.15150774e-01]\n",
      " [1.25404552e-01]\n",
      " [1.37213275e-01]\n",
      " [3.43076527e-01]\n",
      " [2.29929704e-02]\n",
      " [9.96042192e-01]\n",
      " [6.84830785e-01]\n",
      " [4.53744859e-01]\n",
      " [6.60252929e-01]\n",
      " [8.94892573e-01]\n",
      " [8.66097331e-01]\n",
      " [7.72149205e-01]\n",
      " [9.82828379e-01]\n",
      " [8.68943810e-01]\n",
      " [9.43837225e-01]\n",
      " [8.39577019e-02]\n",
      " [9.65914607e-01]\n",
      " [1.57329082e-01]\n",
      " [9.86856997e-01]\n",
      " [9.67844129e-01]\n",
      " [7.87828982e-01]\n",
      " [8.39915752e-01]\n",
      " [9.91428792e-01]\n",
      " [9.63813901e-01]]\n",
      "Predicted probabilities shape: (832, 1)\n",
      "Predicted labels: [1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1\n",
      " 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1\n",
      " 1 1 1 0 0 0 1 1 0 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 0\n",
      " 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 0 1 0 0 1 0 1 0\n",
      " 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 1 0\n",
      " 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 1 1 1 0 1 1 0 1 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 1 1\n",
      " 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 1 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1\n",
      " 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1]\n",
      "Predicted labels shape: (832,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.7874 - auc: 0.5646 - f1_score: 0.2377 - loss: 0.4894 - precision: 0.4445 - recall: 0.5148\n",
      "Training model: MobileNetV3Small on dataset: The Wildfire Dataset_DeepFire_FIRE\n",
      "Epoch 1/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 86ms/step - accuracy: 0.6624 - auc: 0.7752 - f1_score: 0.7039 - loss: 0.7250 - precision: 0.7785 - recall: 0.7189 - val_accuracy: 0.6200 - val_auc: 0.7484 - val_f1_score: 0.7620 - val_loss: 0.6443 - val_precision: 0.6198 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 85ms/step - accuracy: 0.7382 - auc: 0.8047 - f1_score: 0.7845 - loss: 0.5434 - precision: 0.7716 - recall: 0.8040 - val_accuracy: 0.7695 - val_auc: 0.8365 - val_f1_score: 0.8242 - val_loss: 0.5329 - val_precision: 0.7747 - val_recall: 0.8868 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 86ms/step - accuracy: 0.7523 - auc: 0.8250 - f1_score: 0.7965 - loss: 0.5110 - precision: 0.7816 - recall: 0.8189 - val_accuracy: 0.8013 - val_auc: 0.8814 - val_f1_score: 0.8286 - val_loss: 0.4440 - val_precision: 0.8588 - val_recall: 0.8087 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 83ms/step - accuracy: 0.7586 - auc: 0.8341 - f1_score: 0.8033 - loss: 0.4910 - precision: 0.7962 - recall: 0.8167 - val_accuracy: 0.8069 - val_auc: 0.8904 - val_f1_score: 0.8271 - val_loss: 0.4308 - val_precision: 0.8857 - val_recall: 0.7831 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 88ms/step - accuracy: 0.7737 - auc: 0.8470 - f1_score: 0.8153 - loss: 0.4735 - precision: 0.8144 - recall: 0.8226 - val_accuracy: 0.7963 - val_auc: 0.8980 - val_f1_score: 0.8192 - val_loss: 0.4207 - val_precision: 0.9033 - val_recall: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 88ms/step - accuracy: 0.7797 - auc: 0.8544 - f1_score: 0.8224 - loss: 0.4575 - precision: 0.8155 - recall: 0.8328 - val_accuracy: 0.8265 - val_auc: 0.9047 - val_f1_score: 0.8540 - val_loss: 0.3922 - val_precision: 0.8627 - val_recall: 0.8525 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - accuracy: 0.7809 - auc: 0.8481 - f1_score: 0.8222 - loss: 0.4672 - precision: 0.8107 - recall: 0.8393 - val_accuracy: 0.8237 - val_auc: 0.9126 - val_f1_score: 0.8519 - val_loss: 0.3800 - val_precision: 0.8570 - val_recall: 0.8555 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - accuracy: 0.7815 - auc: 0.8604 - f1_score: 0.8207 - loss: 0.4559 - precision: 0.8059 - recall: 0.8404 - val_accuracy: 0.8309 - val_auc: 0.9143 - val_f1_score: 0.8538 - val_loss: 0.3802 - val_precision: 0.8882 - val_recall: 0.8294 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - accuracy: 0.7939 - auc: 0.8693 - f1_score: 0.8325 - loss: 0.4383 - precision: 0.8292 - recall: 0.8391 - val_accuracy: 0.8231 - val_auc: 0.9152 - val_f1_score: 0.8419 - val_loss: 0.3926 - val_precision: 0.9071 - val_recall: 0.7922 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 89ms/step - accuracy: 0.7892 - auc: 0.8688 - f1_score: 0.8284 - loss: 0.4388 - precision: 0.8240 - recall: 0.8348 - val_accuracy: 0.8404 - val_auc: 0.9235 - val_f1_score: 0.8639 - val_loss: 0.3620 - val_precision: 0.8755 - val_recall: 0.8627 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 90ms/step - accuracy: 0.7849 - auc: 0.8668 - f1_score: 0.8240 - loss: 0.4397 - precision: 0.8255 - recall: 0.8262 - val_accuracy: 0.8454 - val_auc: 0.9255 - val_f1_score: 0.8729 - val_loss: 0.3604 - val_precision: 0.8722 - val_recall: 0.8761 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 90ms/step - accuracy: 0.8006 - auc: 0.8805 - f1_score: 0.8363 - loss: 0.4246 - precision: 0.8272 - recall: 0.8484 - val_accuracy: 0.8571 - val_auc: 0.9264 - val_f1_score: 0.8809 - val_loss: 0.3506 - val_precision: 0.8810 - val_recall: 0.8874 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 90ms/step - accuracy: 0.7959 - auc: 0.8730 - f1_score: 0.8350 - loss: 0.4308 - precision: 0.8278 - recall: 0.8475 - val_accuracy: 0.8376 - val_auc: 0.9279 - val_f1_score: 0.8583 - val_loss: 0.3652 - val_precision: 0.9214 - val_recall: 0.8110 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 91ms/step - accuracy: 0.7936 - auc: 0.8728 - f1_score: 0.8302 - loss: 0.4326 - precision: 0.8288 - recall: 0.8355 - val_accuracy: 0.8666 - val_auc: 0.9419 - val_f1_score: 0.8861 - val_loss: 0.3389 - val_precision: 0.9115 - val_recall: 0.8658 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 98ms/step - accuracy: 0.7930 - auc: 0.8733 - f1_score: 0.8313 - loss: 0.4333 - precision: 0.8178 - recall: 0.8485 - val_accuracy: 0.8638 - val_auc: 0.9342 - val_f1_score: 0.8869 - val_loss: 0.3427 - val_precision: 0.8928 - val_recall: 0.8864 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.8117 - auc: 0.8836 - f1_score: 0.8449 - loss: 0.4184 - precision: 0.8421 - recall: 0.8521 - val_accuracy: 0.8761 - val_auc: 0.9464 - val_f1_score: 0.8948 - val_loss: 0.3242 - val_precision: 0.8921 - val_recall: 0.9037 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 89ms/step - accuracy: 0.8173 - auc: 0.8926 - f1_score: 0.8510 - loss: 0.4029 - precision: 0.8427 - recall: 0.8629 - val_accuracy: 0.8717 - val_auc: 0.9414 - val_f1_score: 0.8870 - val_loss: 0.3322 - val_precision: 0.9120 - val_recall: 0.8736 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 88ms/step - accuracy: 0.8055 - auc: 0.8821 - f1_score: 0.8425 - loss: 0.4182 - precision: 0.8347 - recall: 0.8534 - val_accuracy: 0.8728 - val_auc: 0.9451 - val_f1_score: 0.8969 - val_loss: 0.3185 - val_precision: 0.8866 - val_recall: 0.9092 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 88ms/step - accuracy: 0.8200 - auc: 0.8905 - f1_score: 0.8518 - loss: 0.4069 - precision: 0.8513 - recall: 0.8533 - val_accuracy: 0.8666 - val_auc: 0.9471 - val_f1_score: 0.8874 - val_loss: 0.3235 - val_precision: 0.9231 - val_recall: 0.8556 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 87ms/step - accuracy: 0.8109 - auc: 0.8908 - f1_score: 0.8445 - loss: 0.4027 - precision: 0.8415 - recall: 0.8510 - val_accuracy: 0.8650 - val_auc: 0.9368 - val_f1_score: 0.8853 - val_loss: 0.3259 - val_precision: 0.8926 - val_recall: 0.8827 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 90ms/step - accuracy: 0.8170 - auc: 0.8970 - f1_score: 0.8513 - loss: 0.3946 - precision: 0.8480 - recall: 0.8576 - val_accuracy: 0.8744 - val_auc: 0.9495 - val_f1_score: 0.8889 - val_loss: 0.3163 - val_precision: 0.9328 - val_recall: 0.8548 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 86ms/step - accuracy: 0.8140 - auc: 0.8966 - f1_score: 0.8496 - loss: 0.3918 - precision: 0.8483 - recall: 0.8538 - val_accuracy: 0.8811 - val_auc: 0.9556 - val_f1_score: 0.8981 - val_loss: 0.2997 - val_precision: 0.9180 - val_recall: 0.8855 - learning_rate: 0.0010\n",
      "Epoch 23/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 86ms/step - accuracy: 0.8179 - auc: 0.8923 - f1_score: 0.8513 - loss: 0.4011 - precision: 0.8446 - recall: 0.8608 - val_accuracy: 0.8856 - val_auc: 0.9545 - val_f1_score: 0.9007 - val_loss: 0.3014 - val_precision: 0.9250 - val_recall: 0.8856 - learning_rate: 0.0010\n",
      "Epoch 24/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 83ms/step - accuracy: 0.8126 - auc: 0.8915 - f1_score: 0.8466 - loss: 0.4021 - precision: 0.8453 - recall: 0.8505 - val_accuracy: 0.8901 - val_auc: 0.9542 - val_f1_score: 0.9084 - val_loss: 0.2997 - val_precision: 0.9066 - val_recall: 0.9141 - learning_rate: 0.0010\n",
      "Epoch 25/80\n",
      "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 88ms/step - accuracy: 0.8202 - auc: 0.8973 - f1_score: 0.8531 - loss: 0.3925 - precision: 0.8461 - recall: 0.8643 - val_accuracy: 0.8862 - val_auc: 0.9550 - val_f1_score: 0.9030 - val_loss: 0.3035 - val_precision: 0.9088 - val_recall: 0.9038 - learning_rate: 0.0010\n",
      "Epoch 26/80\n",
      "\u001b[1m 70/243\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.8161 - auc: 0.9020 - f1_score: 0.8525 - loss: 0.3813 - precision: 0.8537 - recall: 0.8535"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Initial training of the model\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Record the end time\u001b[39;00m\n\u001b[0;32m     26\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32md:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_results = {}\n",
    "results_file = os.path.join(run_dir, 'training_results.json')\n",
    "\n",
    "for base_model, custom_bool in zip(all_models, is_custom_model):\n",
    "    model = generate_model(base_model, custom=custom_bool) # To display the model summary\n",
    "    model.summary()\n",
    "    training_results[model.name] = {}\n",
    "    plot_model(model, show_shapes=True, show_layer_names=True, to_file=os.path.join(\"architectures\", f\"{model.name}_architecture.png\"))\n",
    "    for dataset_id, train_dataset, val_dataset, steps_per_epoch, validation_steps in zip(combined_dataset_names, combined_training_datasets, combined_val_datasets, steps_per_epoch_list, validation_steps_list):\n",
    "        model.load_weights(os.path.join(checkpoint_path, f\"{model.name}_initial.weights.h5\"))\n",
    "        print(f\"Training model: {model.name} on dataset: {dataset_id}\")\n",
    "        \n",
    "        # Record the start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Initial training of the model\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=val_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks_list\n",
    "        )\n",
    "\n",
    "        # Record the end time\n",
    "        end_time = time.time()\n",
    "        # Calculate the training time\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        model_ds_dir = os.path.join(run_dir, model.name, dataset_id)\n",
    "        os.makedirs(model_ds_dir, exist_ok=True)\n",
    "        # Save the model\n",
    "        model.save(os.path.join(model_ds_dir, f\"{model.name}_{dataset_id}.keras\"))\n",
    "\n",
    "        ### Evaluation stage ###\n",
    "        optimal_threshold = full_eval(model_ds_dir, history, model, dataset_id, test_dataset, true_labels, test_steps)\n",
    "        \n",
    "        training_results[model.name][dataset_id] = {\n",
    "            'history': history.history,\n",
    "            'training_time': training_time,\n",
    "            'optimal_threshold': float(optimal_threshold),\n",
    "            'train_dataset_size': steps_per_epoch * batch_size,\n",
    "            'val_dataset_size': validation_steps * batch_size,\n",
    "            \"evaluation\": model.evaluate(test_dataset, return_dict=True, steps=test_steps)\n",
    "        }\n",
    "\n",
    "        # Save the training results to a file after each iteration\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(training_results, f, indent=4)\n",
    "        \n",
    "        model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list) # Reset the model for the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute force loop completed!\n",
      "All models and evaluations are available at: runs\\run_6\n"
     ]
    }
   ],
   "source": [
    "print(\"Brute force loop completed!\")\n",
    "print(f\"All models and evaluations are available at: {run_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1351460,
     "sourceId": 2247205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
