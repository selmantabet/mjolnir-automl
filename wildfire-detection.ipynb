{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brute Force Pipeline for Wildfire Detection - by Selman Tabet @ https://selman.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Dissertation\\Kaggle Data\\wildfire-detection\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chaos\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "print(socket.gethostname())\n",
    "import os\n",
    "try: # for CUDA enviroment\n",
    "    os.system(\"nvidia-smi\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Data processing libraries\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "# ML libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Chart generating libraries\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from IPython import get_ipython\n",
    "from pprint import pprint\n",
    "\n",
    "# Custom helper libraries\n",
    "from default_params import *\n",
    "from wildfirenet import *\n",
    "from utils.img_processing import resize_and_compress_images\n",
    "from utils.dataset_processors import *\n",
    "from utils.plot_functions import *\n",
    "from utils.evaluator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES: None\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "cuda_visible_devices = os.environ.get('CUDA_VISIBLE_DEVICES')\n",
    "print(f\"CUDA_VISIBLE_DEVICES: {cuda_visible_devices}\")\n",
    "print(tf.config.get_visible_devices())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse arguments from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Config Path: None\n",
      "No Python config file specified, using default config\n"
     ]
    }
   ],
   "source": [
    "# Detect if running in a Jupyter notebook\n",
    "def in_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        else:\n",
    "            return False  # Other type (terminal, etc.)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "    \n",
    "from_py = False\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Parse command line arguments\")\n",
    "parser.add_argument('--from-py-cfg', type=str,\n",
    "                    help='Path to the config Python file')\n",
    "if in_notebook():\n",
    "    args = parser.parse_args([])  # Ignore sys.argv\n",
    "else:\n",
    "    args = parser.parse_args()\n",
    "config_file_path = args.from_py_cfg\n",
    "print(f\"Python Config Path: {config_file_path}\")\n",
    "\n",
    "if config_file_path:\n",
    "    import importlib.util\n",
    "    spec = importlib.util.spec_from_file_location(\"config_module\", config_file_path)\n",
    "    config_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(config_module)\n",
    "    config = config_module.cfg\n",
    "    print(\"Loaded config from Python file:\")\n",
    "    pprint(config)\n",
    "    # Datasets, models, and hyperparameters are mandatory and must be processed now.\n",
    "    training_datasets = config.get('train', {})\n",
    "    if training_datasets is None or len(training_datasets) == 0:\n",
    "        raise ValueError(\"No train datasets defined in config\")\n",
    "    full_test_dir = config.get('test')\n",
    "    base_models = config.get('keras_models', [])\n",
    "    custom_models = config.get('custom_models', [])\n",
    "    if base_models is None or len(base_models) == 0:\n",
    "        if custom_models is None or len(custom_models) == 0:\n",
    "            raise ValueError(\"No models defined in config\")\n",
    "    \n",
    "    hyperparameters = config.get('hyperparameters')\n",
    "    default_hyperparameters = default_cfg.get('hyperparameters', {})\n",
    "    if hyperparameters is None or len(hyperparameters) == 0:\n",
    "        print(\"No training hyperparameters defined in config, using defaults\")\n",
    "        hyperparameters = default_hyperparameters\n",
    "    else:\n",
    "        for key, value in default_hyperparameters.items():\n",
    "            if key not in hyperparameters:\n",
    "                print(f\"Missing parameter - falling back to default hyperparameter {key}:{default_hyperparameters[key]}\")\n",
    "                hyperparameters[key] = default_hyperparameters[key]\n",
    "    from_py = True # Successfully completed the import\n",
    "else:\n",
    "    print(\"No Python config file specified, using default config\")\n",
    "    config = default_cfg\n",
    "    training_datasets = config.get('train', {})\n",
    "    base_models = config.get('keras_models', [])\n",
    "    custom_models = config.get('custom_models', [])\n",
    "    hyperparameters = config.get('hyperparameters')\n",
    "    full_test_dir = config.get('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All models: [<function MobileNetV3Small at 0x00000290B3857BA0>, <Sequential name=WildfireNet, built=True>]\n",
      "Is custom model: [False, True]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dirs = [training_datasets[ds].get('train') for ds in training_datasets]\n",
    "test_dirs = [training_datasets[ds].get('test') for ds in training_datasets]\n",
    "val_dirs = [training_datasets[ds].get('val') for ds in training_datasets]\n",
    "\n",
    "# Combine base_models and custom_models\n",
    "all_models = base_models + custom_models\n",
    "# Create a list to keep track of which models are custom\n",
    "is_custom_model = [False] * len(base_models) + [True] * len(custom_models)\n",
    "\n",
    "print(\"All models:\", all_models)\n",
    "print(\"Is custom model:\", is_custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if from_py:\n",
    "    epochs = hyperparameters.get('epochs')\n",
    "    batch_size = hyperparameters.get('batch_size')\n",
    "    img_height = config.get('image_height', default_cfg.get('image_height'))\n",
    "    img_width = config.get('image_width', default_cfg.get('image_width'))\n",
    "    optimizer_fn = config.get('optimizer', default_cfg.get('optimizer'))\n",
    "    loss_fn = config.get('loss', default_cfg.get('loss'))\n",
    "    callbacks_list = config.get('callbacks', default_cfg.get('callbacks'))\n",
    "    metrics_list = config.get('metrics', default_cfg.get('metrics'))\n",
    "    enforce_image_size = config.get('enforce_resolution', default_cfg.get('enforce_resolution'))\n",
    "else:\n",
    "    epochs = hyperparameters.get('epochs')\n",
    "    batch_size = hyperparameters.get('batch_size')\n",
    "    img_height = default_cfg.get('image_height')\n",
    "    img_width = default_cfg.get('image_width')\n",
    "    optimizer_fn = default_cfg.get('optimizer')\n",
    "    loss_fn = default_cfg.get('loss')\n",
    "    callbacks_list = default_cfg.get('callbacks')\n",
    "    metrics_list = default_cfg.get('metrics')\n",
    "    enforce_image_size = default_cfg.get('enforce_resolution')\n",
    "\n",
    "checkpoint_path = os.path.join(\"checkpoint\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforce defined resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if enforce_image_size:\n",
    "    all_dirs = train_dirs + test_dirs + val_dirs + [full_test_dir]\n",
    "    all_dirs = [d for d in all_dirs if d is not None]\n",
    "    for directory in all_dirs:\n",
    "        print(f\"Adjusting resolutions of images in {directory}\")\n",
    "        resize_and_compress_images(directory, target_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: The Wildfire Dataset\n",
      "Augmenting The Wildfire Dataset\n",
      "Creating generators for training\n",
      "Found 1887 images belonging to 2 classes.\n",
      "Found 1887 images belonging to 2 classes.\n",
      "Creating generators for validation\n",
      "Found 402 images belonging to 2 classes.\n",
      "Found 402 images belonging to 2 classes.\n",
      "Number of samples in generator: 1887\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 730\n",
      "nofire: 1157\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 730\n",
      "nofire: 1157\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 1460\n",
      "nofire: 2314\n",
      "--------------------\n",
      "Processing: DeepFire\n",
      "Augmenting DeepFire\n",
      "Creating generators for training\n",
      "Found 1520 images belonging to 2 classes.\n",
      "Found 1520 images belonging to 2 classes.\n",
      "No validation set, splitting training set.\n",
      "Splitted dataset:\n",
      "Training dataset size: 2432 samples\n",
      "Validation dataset size: 608 samples\n",
      "Number of samples in generator: 1520\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 760\n",
      "nofire: 760\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 760\n",
      "nofire: 760\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 1520\n",
      "nofire: 1520\n",
      "--------------------\n",
      "Processing: FIRE\n",
      "Augmenting FIRE\n",
      "Creating generators for training\n",
      "Found 999 images belonging to 2 classes.\n",
      "Found 999 images belonging to 2 classes.\n",
      "No validation set, splitting training set.\n",
      "Splitted dataset:\n",
      "Training dataset size: 1599 samples\n",
      "Validation dataset size: 399 samples\n",
      "Number of samples in generator: 999\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 755\n",
      "nofire: 244\n",
      "\n",
      "Augmented Dataset Class Counts:\n",
      "fire: 755\n",
      "nofire: 244\n",
      "\n",
      "\n",
      "Combined Dataset Class Counts:\n",
      "fire: 1510\n",
      "nofire: 488\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_names = []\n",
    "train_datasets = [] # [ (dataset_1_train, dataset_2_train), ... ]\n",
    "train_sizes = [] # [ (dataset_1_train_size, dataset_2_train_size), ... ]\n",
    "val_datasets = [] # [ (dataset_1_val, dataset_2_val), ... ]\n",
    "val_sizes = [] # [ (dataset_1_val_size, dataset_2_val_size), ... ]\n",
    "\n",
    "\n",
    "for d in training_datasets:\n",
    "    print(f\"Processing: {d}\")\n",
    "    train_dir = training_datasets[d].get('train')\n",
    "    augment = training_datasets[d].get('augment', True)\n",
    "    print(\"Augmenting\" if augment else \"Not augmenting\", d)\n",
    "    # Apply original and augmented data generators for training\n",
    "    print(\"Creating generators for training\")\n",
    "    train_generator, augmented_train_generator = create_generators(train_dir, augment=augment, img_width=img_width, img_height=img_height)\n",
    "    train_samples = samples_from_generators([train_generator, augmented_train_generator])  \n",
    "    train_dataset = generators_to_dataset([train_generator, augmented_train_generator], batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "    \n",
    "    # Apply original and augmented data generators for validation\n",
    "    if \"val\" in training_datasets[d]:\n",
    "        val_dir = training_datasets[d]['val']\n",
    "        print(\"Creating generators for validation\")\n",
    "        val_generator, augmented_val_generator = create_generators(val_dir, augment=augment, shuffle=False, img_width=img_width, img_height=img_height)\n",
    "        val_samples = samples_from_generators([val_generator, augmented_val_generator])\n",
    "        val_dataset = generators_to_dataset([train_generator, augmented_train_generator], batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "    else:\n",
    "        print(\"No validation set, splitting training set.\")\n",
    "        train_dataset, val_dataset, train_samples, val_samples = val_split(train_dataset, train_samples)\n",
    "        val_generator, augmented_val_generator = None, None\n",
    "    \n",
    "    # Calculate the number of samples for training and validation\n",
    "    train_sizes.append(train_samples)\n",
    "    val_sizes.append(val_samples)\n",
    "\n",
    "    show_counts_from_generators(train_generator, augmented_train_generator)\n",
    "\n",
    "    train_datasets.append(train_dataset)\n",
    "    val_datasets.append(val_dataset)\n",
    "    dataset_names.append(d)\n",
    "    \n",
    "# Ensure that the lengths are consistent across the board before continuing\n",
    "assert(len(train_sizes) == len(train_datasets) and len(train_sizes) == len(val_sizes) and len(val_sizes) == len(val_datasets))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute Force Combinatorial Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_combos = [] # [(0,), (1,), (0, 1), ...] where 0, 1 are the indices of the datasets within their respective lists\n",
    "for r in range(1, len(dataset_names) + 1):\n",
    "    dataset_combos.extend(combinations(range(len(dataset_names)), r))\n",
    "combined_training_datasets = []\n",
    "combined_val_datasets = []\n",
    "combined_dataset_names = []\n",
    "steps_per_epoch_list = []\n",
    "validation_steps_list = []\n",
    "\n",
    "for combo in dataset_combos:\n",
    "    training_dataset = None\n",
    "    val_dataset = None\n",
    "    train_size = None\n",
    "    val_size = None\n",
    "    for idx in combo:\n",
    "        if training_dataset is None:\n",
    "            training_dataset = train_datasets[idx]\n",
    "            val_dataset = val_datasets[idx]\n",
    "            train_size = train_sizes[idx]\n",
    "            val_size = val_sizes[idx]\n",
    "        else:\n",
    "            training_dataset = training_dataset.concatenate(train_datasets[idx])\n",
    "            val_dataset = val_dataset.concatenate(val_datasets[idx])\n",
    "            train_size += train_sizes[idx]\n",
    "            val_size += val_sizes[idx]\n",
    "    combined_dataset_names.append(\"_\".join([dataset_names[idx] for idx in combo]))\n",
    "    combined_training_datasets.append(training_dataset)\n",
    "    combined_val_datasets.append(val_dataset)\n",
    "    steps_per_epoch_list.append(train_size // batch_size)\n",
    "    validation_steps_list.append(val_size // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute Force Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidation Combos [(0,), (1,), (2,), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (0, 1, 2), (0, 1, 3), (0, 1, 4), (0, 1, 5), (0, 2, 3), (0, 2, 4), (0, 2, 5), (0, 3, 4), (0, 3, 5), (0, 4, 5), (1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5), (2, 3, 4), (2, 3, 5), (2, 4, 5), (0, 1, 2, 3), (0, 1, 2, 4), (0, 1, 2, 5), (0, 1, 3, 4), (0, 1, 3, 5), (0, 1, 4, 5), (0, 2, 3, 4), (0, 2, 3, 5), (0, 2, 4, 5), (0, 3, 4, 5), (1, 2, 3, 4), (1, 2, 3, 5), (1, 2, 4, 5), (1, 3, 4, 5), (2, 3, 4, 5), (0, 1, 2, 3, 4), (0, 1, 2, 3, 5), (0, 1, 2, 4, 5), (0, 1, 3, 4, 5), (0, 2, 3, 4, 5), (1, 2, 3, 4, 5), (0, 1, 2, 3, 4, 5)]\n"
     ]
    }
   ],
   "source": [
    "consolidation_combos = []\n",
    "consolidated_datasets = train_datasets + val_datasets\n",
    "consolidated_sizes = train_sizes + val_sizes\n",
    "# Generate combinations ensuring at least one training dataset\n",
    "for n in range(1, len(consolidated_datasets) + 1):\n",
    "    for combo in combinations(range(len(consolidated_datasets)), n):\n",
    "        if any(idx < len(train_datasets) for idx in combo): # Ensure at least one element from train_datasets\n",
    "            consolidation_combos.append(combo)\n",
    "\n",
    "print(\"Consolidation Combos\", consolidation_combos)\n",
    "\n",
    "# Generate consolidated datasets\n",
    "consolidated_training_datasets = []\n",
    "consolidated_steps_per_epoch_list = []\n",
    "consolidated_ids = []\n",
    "mapping_dict = {}\n",
    "\n",
    "for id, combo in enumerate(consolidation_combos):\n",
    "    train_dataset_names = []\n",
    "    val_dataset_names = []\n",
    "    consolidated_training_datasets.append(consolidate_to_train([consolidated_datasets[idx] for idx in combo]))\n",
    "    consolidated_steps_per_epoch_list.append(sum([consolidated_sizes[idx] for idx in combo]) // batch_size)\n",
    "    if len(combo) == len(consolidated_datasets):\n",
    "        mapping_dict[\"all\"] = {\"train\": \"all\", \"val\": \"all\"}\n",
    "    else:\n",
    "        for idx in combo:\n",
    "            normalized_idx = idx % len(dataset_names) # Normalize the index to the dataset_names list to avoid out of bound access\n",
    "            if idx < len(dataset_names):\n",
    "                train_dataset_names.append(dataset_names[normalized_idx])\n",
    "            else:\n",
    "                val_dataset_names.append(dataset_names[normalized_idx])\n",
    "        mapping_dict[id] = {\"train\": train_dataset_names, \"val\": val_dataset_names}\n",
    "    consolidated_ids.append(id) # Keeping this to guarantee the order for training loops\n",
    "\n",
    "# Ensure that the lengths are consistent across the board\n",
    "assert(len(consolidated_training_datasets) == len(consolidated_steps_per_epoch_list) and len(consolidated_steps_per_epoch_list) == len(consolidated_ids) and len(mapping_dict.keys()) == len(consolidated_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 858 images belonging to 2 classes.\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "\n",
      "\n",
      "Test Dataset Class Counts:\n",
      "fire: 371\n",
      "nofire: 487\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if full_test_dir is None:\n",
    "    test_generators = []\n",
    "    print(\"No target test directory provided, merging all tests from provided datasets if available\")\n",
    "    for d in test_dirs:\n",
    "        if d is not None:\n",
    "            test_generators.append(create_generators(d, augment=False, shuffle=False, img_height=img_height, img_width=img_width, batch_size=batch_size)[0]) # No augmentation/shuffle for testing\n",
    "    if len(test_generators) == 0:\n",
    "        raise ValueError(\"No tests found in the provided datasets\")\n",
    "    true_labels = np.concatenate([gen.classes for gen in test_generators])\n",
    "    test_dataset = generators_to_dataset(test_generators, batch_size=batch_size)\n",
    "    test_steps = sum([gen.samples for gen in test_generators]) // batch_size\n",
    "    print(\"Test Dataset Class Counts:\")\n",
    "    for gen in test_generators:\n",
    "        print(\"Class indices:\", gen.class_indices)\n",
    "        for class_name, class_index in gen.class_indices.items():\n",
    "            print(f\"{class_name}: {sum(gen.classes == class_index)}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "else:\n",
    "    test_generator, augmented_test_generator = create_generators(full_test_dir, augment=False, shuffle=False, img_height=img_height, img_width=img_width, batch_size=batch_size) # No augmentation/shuffle for testing\n",
    "    test_dataset = create_dataset(test_generator, batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "    test_steps = test_generator.samples // batch_size\n",
    "    true_labels = test_generator.classes\n",
    "    print(\"Class indices:\", test_generator.class_indices)\n",
    "    print(\"\\n\")\n",
    "    print(\"Test Dataset Class Counts:\")\n",
    "    for class_name, class_index in test_generator.class_indices.items():\n",
    "        print(f\"{class_name}: {sum(test_generator.classes == class_index)}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "true_labels = true_labels[: (len(true_labels) // batch_size) * batch_size] # Ensure that the true labels are divisible by the batch size to avoid size mismatch with predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_model(bm, custom=False):\n",
    "    if custom:\n",
    "        model = bm\n",
    "        model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list)\n",
    "        model.save_weights(os.path.join(checkpoint_path, f\"{model.name}_initial.weights.h5\"))    \n",
    "        return model\n",
    "    \n",
    "    base_model = bm(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_shape=(img_height, img_width, 3)\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create the model\n",
    "    inputs = Input(shape=(img_height, img_width, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs, outputs, name=bm.__name__)\n",
    "    model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list)\n",
    "    model.save_weights(os.path.join(checkpoint_path, f\"{model.name}_initial.weights.h5\"))    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the models and combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_results = {}\n",
    "run_number = len([d for d in os.listdir(\"runs\") if os.path.isdir(os.path.join(\"runs\", d)) and d.startswith('run_')]) + 1\n",
    "run_dir = os.path.join(\"runs\", f\"run_{run_number}\")\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(run_dir, 'brute_force_mapping_dict.json'), 'w') as f:\n",
    "    json.dump(mapping_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MobileNetV3Small\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MobileNetV3Small\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MobileNetV3Small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MobileNetV3Small (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m)      │       \u001b[38;5;34m939,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m147,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,090,417</span> (4.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,090,417\u001b[0m (4.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">149,633</span> (584.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m149,633\u001b[0m (584.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">940,784</span> (3.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m940,784\u001b[0m (3.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: MobileNetV3Small on dataset: The Wildfire Dataset\n",
      "Epoch 1/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 170ms/step - accuracy: 0.6149 - auc: 0.6826 - f1_score: 0.6429 - loss: 0.7686 - precision: 0.7215 - recall: 0.5944 - val_accuracy: 0.5987 - val_auc: 0.6427 - val_f1_score: 0.7453 - val_loss: 0.6687 - val_precision: 0.5987 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7151 - auc: 0.7761 - f1_score: 0.7654 - loss: 0.6004 - precision: 0.7753 - recall: 0.7611 - val_accuracy: 0.6037 - val_auc: 0.8335 - val_f1_score: 0.7501 - val_loss: 0.6549 - val_precision: 0.6037 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - accuracy: 0.7435 - auc: 0.8065 - f1_score: 0.7914 - loss: 0.5388 - precision: 0.7836 - recall: 0.8048 - val_accuracy: 0.5962 - val_auc: 0.8784 - val_f1_score: 0.7389 - val_loss: 0.6090 - val_precision: 0.5917 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.7416 - auc: 0.8143 - f1_score: 0.7910 - loss: 0.5220 - precision: 0.7881 - recall: 0.7983 - val_accuracy: 0.7387 - val_auc: 0.8688 - val_f1_score: 0.8060 - val_loss: 0.5499 - val_precision: 0.7075 - val_recall: 0.9514 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7557 - auc: 0.8265 - f1_score: 0.8046 - loss: 0.5009 - precision: 0.7924 - recall: 0.8199 - val_accuracy: 0.7812 - val_auc: 0.8789 - val_f1_score: 0.8386 - val_loss: 0.4932 - val_precision: 0.7607 - val_recall: 0.9389 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7480 - auc: 0.8326 - f1_score: 0.7963 - loss: 0.4920 - precision: 0.7771 - recall: 0.8215 - val_accuracy: 0.8225 - val_auc: 0.8953 - val_f1_score: 0.8511 - val_loss: 0.4389 - val_precision: 0.8528 - val_recall: 0.8598 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.7640 - auc: 0.8415 - f1_score: 0.8074 - loss: 0.4792 - precision: 0.8005 - recall: 0.8194 - val_accuracy: 0.8150 - val_auc: 0.8877 - val_f1_score: 0.8488 - val_loss: 0.4252 - val_precision: 0.8509 - val_recall: 0.8543 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - accuracy: 0.7594 - auc: 0.8387 - f1_score: 0.8049 - loss: 0.4828 - precision: 0.8002 - recall: 0.8126 - val_accuracy: 0.7987 - val_auc: 0.8787 - val_f1_score: 0.8318 - val_loss: 0.4363 - val_precision: 0.8544 - val_recall: 0.8149 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 81ms/step - accuracy: 0.7723 - auc: 0.8427 - f1_score: 0.8118 - loss: 0.4809 - precision: 0.7979 - recall: 0.8311 - val_accuracy: 0.8150 - val_auc: 0.8914 - val_f1_score: 0.8353 - val_loss: 0.4258 - val_precision: 0.8520 - val_recall: 0.8378 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.7829 - auc: 0.8586 - f1_score: 0.8265 - loss: 0.4522 - precision: 0.8363 - recall: 0.8208 - val_accuracy: 0.8200 - val_auc: 0.8942 - val_f1_score: 0.8540 - val_loss: 0.4164 - val_precision: 0.8676 - val_recall: 0.8436 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - accuracy: 0.7776 - auc: 0.8437 - f1_score: 0.8224 - loss: 0.4750 - precision: 0.8036 - recall: 0.8476 - val_accuracy: 0.8425 - val_auc: 0.9136 - val_f1_score: 0.8622 - val_loss: 0.3894 - val_precision: 0.8758 - val_recall: 0.8535 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 80ms/step - accuracy: 0.7774 - auc: 0.8478 - f1_score: 0.8179 - loss: 0.4695 - precision: 0.8124 - recall: 0.8268 - val_accuracy: 0.8325 - val_auc: 0.9171 - val_f1_score: 0.8595 - val_loss: 0.3784 - val_precision: 0.8787 - val_recall: 0.8468 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - accuracy: 0.7827 - auc: 0.8525 - f1_score: 0.8212 - loss: 0.4716 - precision: 0.8024 - recall: 0.8445 - val_accuracy: 0.8225 - val_auc: 0.9012 - val_f1_score: 0.8495 - val_loss: 0.4023 - val_precision: 0.8849 - val_recall: 0.8250 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - accuracy: 0.7773 - auc: 0.8469 - f1_score: 0.8190 - loss: 0.4743 - precision: 0.8148 - recall: 0.8258 - val_accuracy: 0.8225 - val_auc: 0.9074 - val_f1_score: 0.8552 - val_loss: 0.3915 - val_precision: 0.8373 - val_recall: 0.8786 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - accuracy: 0.7943 - auc: 0.8632 - f1_score: 0.8346 - loss: 0.4519 - precision: 0.8133 - recall: 0.8596 - val_accuracy: 0.8475 - val_auc: 0.9210 - val_f1_score: 0.8676 - val_loss: 0.3755 - val_precision: 0.8951 - val_recall: 0.8513 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 83ms/step - accuracy: 0.7790 - auc: 0.8526 - f1_score: 0.8222 - loss: 0.4622 - precision: 0.8129 - recall: 0.8338 - val_accuracy: 0.8213 - val_auc: 0.9057 - val_f1_score: 0.8449 - val_loss: 0.3959 - val_precision: 0.8505 - val_recall: 0.8487 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 159ms/step - accuracy: 0.7839 - auc: 0.8625 - f1_score: 0.8250 - loss: 0.4445 - precision: 0.8279 - recall: 0.8249 - val_accuracy: 0.8500 - val_auc: 0.9298 - val_f1_score: 0.8764 - val_loss: 0.3537 - val_precision: 0.8778 - val_recall: 0.8813 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 160ms/step - accuracy: 0.7871 - auc: 0.8653 - f1_score: 0.8269 - loss: 0.4440 - precision: 0.8279 - recall: 0.8288 - val_accuracy: 0.8425 - val_auc: 0.9152 - val_f1_score: 0.8672 - val_loss: 0.3834 - val_precision: 0.9013 - val_recall: 0.8400 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 167ms/step - accuracy: 0.7884 - auc: 0.8711 - f1_score: 0.8257 - loss: 0.4342 - precision: 0.8268 - recall: 0.8260 - val_accuracy: 0.8537 - val_auc: 0.9273 - val_f1_score: 0.8819 - val_loss: 0.3576 - val_precision: 0.8902 - val_recall: 0.8780 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 161ms/step - accuracy: 0.7969 - auc: 0.8695 - f1_score: 0.8346 - loss: 0.4383 - precision: 0.8246 - recall: 0.8492 - val_accuracy: 0.8512 - val_auc: 0.9341 - val_f1_score: 0.8771 - val_loss: 0.3564 - val_precision: 0.8926 - val_recall: 0.8618 - learning_rate: 0.0010\n",
      "Epoch 21/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 154ms/step - accuracy: 0.7887 - auc: 0.8648 - f1_score: 0.8277 - loss: 0.4476 - precision: 0.8188 - recall: 0.8404 - val_accuracy: 0.8438 - val_auc: 0.9204 - val_f1_score: 0.8639 - val_loss: 0.3642 - val_precision: 0.8982 - val_recall: 0.8371 - learning_rate: 0.0010\n",
      "Epoch 22/80\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8053 - auc: 0.8790 - f1_score: 0.8445 - loss: 0.4217 - precision: 0.8328 - recall: 0.8590\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 157ms/step - accuracy: 0.8053 - auc: 0.8791 - f1_score: 0.8445 - loss: 0.4217 - precision: 0.8328 - recall: 0.8590 - val_accuracy: 0.8413 - val_auc: 0.9141 - val_f1_score: 0.8675 - val_loss: 0.3761 - val_precision: 0.8721 - val_recall: 0.8631 - learning_rate: 0.0010\n",
      "Training time: 326.69 seconds\n",
      "Evaluating MobileNetV3Small on The Wildfire Dataset...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 942ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "True labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "True labels shape: (832,)\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step\n",
      "Predicted probabilities: [[0.37133127]\n",
      " [0.08147313]\n",
      " [0.49239337]\n",
      " [0.03901114]\n",
      " [0.3958896 ]\n",
      " [0.34476426]\n",
      " [0.14599554]\n",
      " [0.17370406]\n",
      " [0.16791557]\n",
      " [0.717523  ]\n",
      " [0.15882306]\n",
      " [0.16715723]\n",
      " [0.3412481 ]\n",
      " [0.31070116]\n",
      " [0.629024  ]\n",
      " [0.21325667]\n",
      " [0.39499864]\n",
      " [0.15607245]\n",
      " [0.28113517]\n",
      " [0.19815743]\n",
      " [0.144448  ]\n",
      " [0.28566143]\n",
      " [0.34877154]\n",
      " [0.32163405]\n",
      " [0.42024308]\n",
      " [0.16475132]\n",
      " [0.30145937]\n",
      " [0.3432974 ]\n",
      " [0.3547372 ]\n",
      " [0.4838977 ]\n",
      " [0.30383912]\n",
      " [0.24104662]\n",
      " [0.4473728 ]\n",
      " [0.17522007]\n",
      " [0.1232325 ]\n",
      " [0.33396927]\n",
      " [0.7169516 ]\n",
      " [0.5985515 ]\n",
      " [0.41428748]\n",
      " [0.27565828]\n",
      " [0.10175936]\n",
      " [0.4951103 ]\n",
      " [0.26732075]\n",
      " [0.5594921 ]\n",
      " [0.06256128]\n",
      " [0.4766828 ]\n",
      " [0.4393683 ]\n",
      " [0.21574023]\n",
      " [0.49971142]\n",
      " [0.5291053 ]\n",
      " [0.42244238]\n",
      " [0.25219867]\n",
      " [0.3682936 ]\n",
      " [0.569057  ]\n",
      " [0.13168034]\n",
      " [0.18411352]\n",
      " [0.37967   ]\n",
      " [0.5515802 ]\n",
      " [0.17827515]\n",
      " [0.0442994 ]\n",
      " [0.51330745]\n",
      " [0.18271099]\n",
      " [0.28728935]\n",
      " [0.0455754 ]\n",
      " [0.5097992 ]\n",
      " [0.18848357]\n",
      " [0.1994557 ]\n",
      " [0.09607655]\n",
      " [0.29684216]\n",
      " [0.32672936]\n",
      " [0.2645623 ]\n",
      " [0.11170469]\n",
      " [0.33835736]\n",
      " [0.88505465]\n",
      " [0.24982975]\n",
      " [0.47527158]\n",
      " [0.7307993 ]\n",
      " [0.13392007]\n",
      " [0.49130684]\n",
      " [0.7635033 ]\n",
      " [0.6326367 ]\n",
      " [0.74381673]\n",
      " [0.5263861 ]\n",
      " [0.15736328]\n",
      " [0.45977166]\n",
      " [0.18076636]\n",
      " [0.11188542]\n",
      " [0.5639475 ]\n",
      " [0.41646022]\n",
      " [0.08049357]\n",
      " [0.32082528]\n",
      " [0.28151852]\n",
      " [0.11742733]\n",
      " [0.35062304]\n",
      " [0.11329591]\n",
      " [0.27407956]\n",
      " [0.5113921 ]\n",
      " [0.65449166]\n",
      " [0.18738012]\n",
      " [0.47359905]\n",
      " [0.06270929]\n",
      " [0.816802  ]\n",
      " [0.16452652]\n",
      " [0.41610867]\n",
      " [0.17372702]\n",
      " [0.14790098]\n",
      " [0.2595411 ]\n",
      " [0.18928614]\n",
      " [0.79836243]\n",
      " [0.7474528 ]\n",
      " [0.2655858 ]\n",
      " [0.23568322]\n",
      " [0.0760878 ]\n",
      " [0.8568404 ]\n",
      " [0.16371307]\n",
      " [0.31112868]\n",
      " [0.67389613]\n",
      " [0.06310786]\n",
      " [0.44966042]\n",
      " [0.1507729 ]\n",
      " [0.9787356 ]\n",
      " [0.16950071]\n",
      " [0.6027163 ]\n",
      " [0.26758704]\n",
      " [0.1987538 ]\n",
      " [0.2664455 ]\n",
      " [0.3414959 ]\n",
      " [0.52275324]\n",
      " [0.167769  ]\n",
      " [0.170864  ]\n",
      " [0.28672582]\n",
      " [0.27728823]\n",
      " [0.21715587]\n",
      " [0.2512024 ]\n",
      " [0.8177931 ]\n",
      " [0.11566085]\n",
      " [0.5062809 ]\n",
      " [0.34159255]\n",
      " [0.21612369]\n",
      " [0.26119885]\n",
      " [0.9975343 ]\n",
      " [0.56786025]\n",
      " [0.47683704]\n",
      " [0.35677832]\n",
      " [0.09872777]\n",
      " [0.19198333]\n",
      " [0.5476823 ]\n",
      " [0.5054103 ]\n",
      " [0.42328057]\n",
      " [0.75647753]\n",
      " [0.334529  ]\n",
      " [0.10287725]\n",
      " [0.38285038]\n",
      " [0.29974353]\n",
      " [0.24530658]\n",
      " [0.3129036 ]\n",
      " [0.2571694 ]\n",
      " [0.6274106 ]\n",
      " [0.49750307]\n",
      " [0.52514946]\n",
      " [0.4963687 ]\n",
      " [0.5420116 ]\n",
      " [0.1250223 ]\n",
      " [0.7839452 ]\n",
      " [0.2655015 ]\n",
      " [0.18780506]\n",
      " [0.363202  ]\n",
      " [0.12715001]\n",
      " [0.47681957]\n",
      " [0.15983178]\n",
      " [0.5521555 ]\n",
      " [0.21016742]\n",
      " [0.8760797 ]\n",
      " [0.13519458]\n",
      " [0.49117368]\n",
      " [0.27530682]\n",
      " [0.36459368]\n",
      " [0.31803814]\n",
      " [0.45497227]\n",
      " [0.34122658]\n",
      " [0.3114442 ]\n",
      " [0.25483826]\n",
      " [0.44688186]\n",
      " [0.61408806]\n",
      " [0.34199807]\n",
      " [0.45089057]\n",
      " [0.23272768]\n",
      " [0.15173186]\n",
      " [0.6683078 ]\n",
      " [0.6502951 ]\n",
      " [0.25869116]\n",
      " [0.08788716]\n",
      " [0.40274048]\n",
      " [0.92774886]\n",
      " [0.37622288]\n",
      " [0.9536881 ]\n",
      " [0.94687223]\n",
      " [0.67481315]\n",
      " [0.6208175 ]\n",
      " [0.5593283 ]\n",
      " [0.97675616]\n",
      " [0.27869135]\n",
      " [0.39639953]\n",
      " [0.9269338 ]\n",
      " [0.329731  ]\n",
      " [0.43579647]\n",
      " [0.08494519]\n",
      " [0.40533012]\n",
      " [0.46732166]\n",
      " [0.36170554]\n",
      " [0.46087748]\n",
      " [0.4399985 ]\n",
      " [0.19441192]\n",
      " [0.5987451 ]\n",
      " [0.24699748]\n",
      " [0.792862  ]\n",
      " [0.27408963]\n",
      " [0.40499273]\n",
      " [0.11364098]\n",
      " [0.3612736 ]\n",
      " [0.21431388]\n",
      " [0.876     ]\n",
      " [0.23415317]\n",
      " [0.58301616]\n",
      " [0.0918361 ]\n",
      " [0.19816406]\n",
      " [0.29210478]\n",
      " [0.9114958 ]\n",
      " [0.14160588]\n",
      " [0.94864297]\n",
      " [0.18913977]\n",
      " [0.25890195]\n",
      " [0.33481878]\n",
      " [0.2944681 ]\n",
      " [0.62998474]\n",
      " [0.73466754]\n",
      " [0.568308  ]\n",
      " [0.5190259 ]\n",
      " [0.723222  ]\n",
      " [0.19231439]\n",
      " [0.3913272 ]\n",
      " [0.48724133]\n",
      " [0.5770391 ]\n",
      " [0.24873322]\n",
      " [0.34597346]\n",
      " [0.32086906]\n",
      " [0.76115066]\n",
      " [0.24038576]\n",
      " [0.24609369]\n",
      " [0.81760126]\n",
      " [0.78329605]\n",
      " [0.3663012 ]\n",
      " [0.7470156 ]\n",
      " [0.5821644 ]\n",
      " [0.7421942 ]\n",
      " [0.27037266]\n",
      " [0.29166174]\n",
      " [0.56779814]\n",
      " [0.11588905]\n",
      " [0.721708  ]\n",
      " [0.1890174 ]\n",
      " [0.15067962]\n",
      " [0.12551685]\n",
      " [0.26085576]\n",
      " [0.8042365 ]\n",
      " [0.1852707 ]\n",
      " [0.94347644]\n",
      " [0.80959994]\n",
      " [0.26035938]\n",
      " [0.06957106]\n",
      " [0.21636623]\n",
      " [0.9406143 ]\n",
      " [0.69761413]\n",
      " [0.456767  ]\n",
      " [0.70113325]\n",
      " [0.99842787]\n",
      " [0.26196742]\n",
      " [0.2472879 ]\n",
      " [0.52062243]\n",
      " [0.50455177]\n",
      " [0.73431504]\n",
      " [0.6029917 ]\n",
      " [0.9109469 ]\n",
      " [0.19483718]\n",
      " [0.17932154]\n",
      " [0.5129627 ]\n",
      " [0.14142554]\n",
      " [0.39292827]\n",
      " [0.10461182]\n",
      " [0.23840356]\n",
      " [0.27594212]\n",
      " [0.45258683]\n",
      " [0.5107776 ]\n",
      " [0.2328799 ]\n",
      " [0.25083905]\n",
      " [0.07521096]\n",
      " [0.45684838]\n",
      " [0.6886492 ]\n",
      " [0.45557448]\n",
      " [0.65532714]\n",
      " [0.8318383 ]\n",
      " [0.10537905]\n",
      " [0.5505593 ]\n",
      " [0.6042974 ]\n",
      " [0.4328428 ]\n",
      " [0.35867545]\n",
      " [0.38350672]\n",
      " [0.30237213]\n",
      " [0.2577913 ]\n",
      " [0.8386292 ]\n",
      " [0.9143437 ]\n",
      " [0.02993629]\n",
      " [0.57506216]\n",
      " [0.09925192]\n",
      " [0.24250461]\n",
      " [0.18349917]\n",
      " [0.5303083 ]\n",
      " [0.62420046]\n",
      " [0.20345186]\n",
      " [0.6171597 ]\n",
      " [0.23234953]\n",
      " [0.8346712 ]\n",
      " [0.50832236]\n",
      " [0.22824635]\n",
      " [0.60290587]\n",
      " [0.4594241 ]\n",
      " [0.1637229 ]\n",
      " [0.18944187]\n",
      " [0.33320737]\n",
      " [0.36573434]\n",
      " [0.22583272]\n",
      " [0.11535714]\n",
      " [0.15148717]\n",
      " [0.37750727]\n",
      " [0.5249275 ]\n",
      " [0.52031004]\n",
      " [0.2638801 ]\n",
      " [0.3110066 ]\n",
      " [0.22472818]\n",
      " [0.7965624 ]\n",
      " [0.13897371]\n",
      " [0.23957239]\n",
      " [0.50019217]\n",
      " [0.3188689 ]\n",
      " [0.63313293]\n",
      " [0.66516364]\n",
      " [0.62792325]\n",
      " [0.79872817]\n",
      " [0.5277048 ]\n",
      " [0.14343493]\n",
      " [0.9109362 ]\n",
      " [0.14095467]\n",
      " [0.9050109 ]\n",
      " [0.72987515]\n",
      " [0.43281445]\n",
      " [0.7875587 ]\n",
      " [0.8536885 ]\n",
      " [0.23026372]\n",
      " [0.9436746 ]\n",
      " [0.41936094]\n",
      " [0.62174356]\n",
      " [0.8670291 ]\n",
      " [0.5864543 ]\n",
      " [0.54566014]\n",
      " [0.81239235]\n",
      " [0.84778744]\n",
      " [0.9846255 ]\n",
      " [0.7088645 ]\n",
      " [0.8284263 ]\n",
      " [0.24592686]\n",
      " [0.91433936]\n",
      " [0.79957414]\n",
      " [0.70736074]\n",
      " [0.9670913 ]\n",
      " [0.7779979 ]\n",
      " [0.6803432 ]\n",
      " [0.7075047 ]\n",
      " [0.20055188]\n",
      " [0.67798233]\n",
      " [0.59566   ]\n",
      " [0.61788666]\n",
      " [0.41903633]\n",
      " [0.37827525]\n",
      " [0.90295196]\n",
      " [0.9588689 ]\n",
      " [0.15813035]\n",
      " [0.9728753 ]\n",
      " [0.6263224 ]\n",
      " [0.8633558 ]\n",
      " [0.98530596]\n",
      " [0.23828799]\n",
      " [0.5777656 ]\n",
      " [0.7512909 ]\n",
      " [0.5638845 ]\n",
      " [0.93118536]\n",
      " [0.70983255]\n",
      " [0.7050375 ]\n",
      " [0.4293752 ]\n",
      " [0.5473318 ]\n",
      " [0.3751992 ]\n",
      " [0.9117404 ]\n",
      " [0.8622406 ]\n",
      " [0.6362928 ]\n",
      " [0.9329613 ]\n",
      " [0.5772015 ]\n",
      " [0.60192996]\n",
      " [0.95903707]\n",
      " [0.8686807 ]\n",
      " [0.77475303]\n",
      " [0.6971638 ]\n",
      " [0.9710351 ]\n",
      " [0.67496276]\n",
      " [0.5539679 ]\n",
      " [0.8589814 ]\n",
      " [0.94640905]\n",
      " [0.9506726 ]\n",
      " [0.83879066]\n",
      " [0.9963282 ]\n",
      " [0.9813172 ]\n",
      " [0.9953793 ]\n",
      " [0.99274135]\n",
      " [0.6534359 ]\n",
      " [0.8584849 ]\n",
      " [0.3613609 ]\n",
      " [0.8326448 ]\n",
      " [0.4961865 ]\n",
      " [0.99478513]\n",
      " [0.56751597]\n",
      " [0.9031314 ]\n",
      " [0.9934519 ]\n",
      " [0.9960947 ]\n",
      " [0.767895  ]\n",
      " [0.57111615]\n",
      " [0.9081333 ]\n",
      " [0.83440167]\n",
      " [0.98967814]\n",
      " [0.9981784 ]\n",
      " [0.6831313 ]\n",
      " [0.7338557 ]\n",
      " [0.6724801 ]\n",
      " [0.9605514 ]\n",
      " [0.8220763 ]\n",
      " [0.86094487]\n",
      " [0.97387767]\n",
      " [0.8248624 ]\n",
      " [0.8316995 ]\n",
      " [0.27187923]\n",
      " [0.99060947]\n",
      " [0.37108627]\n",
      " [0.91489154]\n",
      " [0.8763078 ]\n",
      " [0.8889332 ]\n",
      " [0.13554397]\n",
      " [0.7507998 ]\n",
      " [0.4223856 ]\n",
      " [0.54893196]\n",
      " [0.9874485 ]\n",
      " [0.41917405]\n",
      " [0.971776  ]\n",
      " [0.82027996]\n",
      " [0.5516599 ]\n",
      " [0.6444473 ]\n",
      " [0.71618044]\n",
      " [0.9752824 ]\n",
      " [0.9770622 ]\n",
      " [0.23441346]\n",
      " [0.8863647 ]\n",
      " [0.93401754]\n",
      " [0.55408144]\n",
      " [0.8658985 ]\n",
      " [0.75578153]\n",
      " [0.91590506]\n",
      " [0.73130345]\n",
      " [0.9989894 ]\n",
      " [0.68638635]\n",
      " [0.62279296]\n",
      " [0.7109164 ]\n",
      " [0.9811301 ]\n",
      " [0.73627275]\n",
      " [0.98909444]\n",
      " [0.6403612 ]\n",
      " [0.37196723]\n",
      " [0.9231947 ]\n",
      " [0.911459  ]\n",
      " [0.86757606]\n",
      " [0.7734805 ]\n",
      " [0.9305682 ]\n",
      " [0.7652584 ]\n",
      " [0.61476827]\n",
      " [0.85080755]\n",
      " [0.56914115]\n",
      " [0.6868935 ]\n",
      " [0.9609339 ]\n",
      " [0.809554  ]\n",
      " [0.96511143]\n",
      " [0.9299906 ]\n",
      " [0.9777382 ]\n",
      " [0.57793033]\n",
      " [0.199634  ]\n",
      " [0.9612959 ]\n",
      " [0.47802585]\n",
      " [0.9024252 ]\n",
      " [0.9840036 ]\n",
      " [0.63066316]\n",
      " [0.6555544 ]\n",
      " [0.58900505]\n",
      " [0.9226748 ]\n",
      " [0.5208102 ]\n",
      " [0.8879838 ]\n",
      " [0.6209816 ]\n",
      " [0.83867425]\n",
      " [0.93693864]\n",
      " [0.83236885]\n",
      " [0.9107249 ]\n",
      " [0.9962475 ]\n",
      " [0.9901924 ]\n",
      " [0.9935629 ]\n",
      " [0.98729813]\n",
      " [0.5842619 ]\n",
      " [0.85166645]\n",
      " [0.9982944 ]\n",
      " [0.5211479 ]\n",
      " [0.326714  ]\n",
      " [0.58624375]\n",
      " [0.9700001 ]\n",
      " [0.36284602]\n",
      " [0.37223944]\n",
      " [0.932316  ]\n",
      " [0.92580235]\n",
      " [0.75989723]\n",
      " [0.9200017 ]\n",
      " [0.82451475]\n",
      " [0.5944903 ]\n",
      " [0.9546997 ]\n",
      " [0.78705674]\n",
      " [0.634406  ]\n",
      " [0.8532263 ]\n",
      " [0.59751403]\n",
      " [0.93987143]\n",
      " [0.9754579 ]\n",
      " [0.80962884]\n",
      " [0.6700494 ]\n",
      " [0.865617  ]\n",
      " [0.50640845]\n",
      " [0.82138157]\n",
      " [0.79458475]\n",
      " [0.5745981 ]\n",
      " [0.92631793]\n",
      " [0.74221957]\n",
      " [0.23026516]\n",
      " [0.9963107 ]\n",
      " [0.42552087]\n",
      " [0.9960817 ]\n",
      " [0.5705385 ]\n",
      " [0.51412225]\n",
      " [0.99368083]\n",
      " [0.4005286 ]\n",
      " [0.9884233 ]\n",
      " [0.8394106 ]\n",
      " [0.6657406 ]\n",
      " [0.82834226]\n",
      " [0.92680883]\n",
      " [0.9667872 ]\n",
      " [0.8710656 ]\n",
      " [0.98822224]\n",
      " [0.89323753]\n",
      " [0.9797515 ]\n",
      " [0.98805714]\n",
      " [0.9765586 ]\n",
      " [0.18528564]\n",
      " [0.3151058 ]\n",
      " [0.58658755]\n",
      " [0.9503848 ]\n",
      " [0.46928918]\n",
      " [0.1417376 ]\n",
      " [0.9285445 ]\n",
      " [0.95600057]\n",
      " [0.98038816]\n",
      " [0.44638556]\n",
      " [0.9394347 ]\n",
      " [0.2302638 ]\n",
      " [0.8713459 ]\n",
      " [0.92002034]\n",
      " [0.21152106]\n",
      " [0.77885836]\n",
      " [0.54363096]\n",
      " [0.95580614]\n",
      " [0.9495429 ]\n",
      " [0.8975839 ]\n",
      " [0.929645  ]\n",
      " [0.9235226 ]\n",
      " [0.8887849 ]\n",
      " [0.96894366]\n",
      " [0.9853311 ]\n",
      " [0.98830914]\n",
      " [0.9996954 ]\n",
      " [0.6841064 ]\n",
      " [0.96850795]\n",
      " [0.99687827]\n",
      " [0.7631023 ]\n",
      " [0.7777683 ]\n",
      " [0.99637794]\n",
      " [0.6882991 ]\n",
      " [0.9996349 ]\n",
      " [0.96014786]\n",
      " [0.9697614 ]\n",
      " [0.6053957 ]\n",
      " [0.989875  ]\n",
      " [0.9953453 ]\n",
      " [0.98942596]\n",
      " [0.9907309 ]\n",
      " [0.9397297 ]\n",
      " [0.9694096 ]\n",
      " [0.9829815 ]\n",
      " [0.99753237]\n",
      " [0.94498694]\n",
      " [0.78025615]\n",
      " [0.98561656]\n",
      " [0.9595692 ]\n",
      " [0.9269457 ]\n",
      " [0.80578905]\n",
      " [0.8029491 ]\n",
      " [0.9819133 ]\n",
      " [0.99636775]\n",
      " [0.9734428 ]\n",
      " [0.97474533]\n",
      " [0.9109529 ]\n",
      " [0.71818495]\n",
      " [0.9949181 ]\n",
      " [0.8878763 ]\n",
      " [0.57007873]\n",
      " [0.58627236]\n",
      " [0.88960636]\n",
      " [0.72987616]\n",
      " [0.8738614 ]\n",
      " [0.93280154]\n",
      " [0.4748368 ]\n",
      " [0.7981659 ]\n",
      " [0.82103735]\n",
      " [0.54323936]\n",
      " [0.23651527]\n",
      " [0.7916435 ]\n",
      " [0.7359916 ]\n",
      " [0.6410895 ]\n",
      " [0.841184  ]\n",
      " [0.81160367]\n",
      " [0.78073764]\n",
      " [0.87069964]\n",
      " [0.656868  ]\n",
      " [0.3163141 ]\n",
      " [0.9046155 ]\n",
      " [0.69209486]\n",
      " [0.9569417 ]\n",
      " [0.62688255]\n",
      " [0.2287077 ]\n",
      " [0.88580364]\n",
      " [0.44278538]\n",
      " [0.62555295]\n",
      " [0.5955645 ]\n",
      " [0.9653506 ]\n",
      " [0.9590193 ]\n",
      " [0.4946541 ]\n",
      " [0.9308674 ]\n",
      " [0.27179474]\n",
      " [0.7888298 ]\n",
      " [0.7257164 ]\n",
      " [0.85320306]\n",
      " [0.82420856]\n",
      " [0.70569414]\n",
      " [0.60853297]\n",
      " [0.04512684]\n",
      " [0.6875832 ]\n",
      " [0.6590787 ]\n",
      " [0.88742036]\n",
      " [0.9088348 ]\n",
      " [0.2669834 ]\n",
      " [0.5518998 ]\n",
      " [0.9308112 ]\n",
      " [0.6986018 ]\n",
      " [0.91343766]\n",
      " [0.63595265]\n",
      " [0.4710131 ]\n",
      " [0.9873669 ]\n",
      " [0.80842626]\n",
      " [0.32828125]\n",
      " [0.8696773 ]\n",
      " [0.74054635]\n",
      " [0.5075151 ]\n",
      " [0.6314443 ]\n",
      " [0.8507535 ]\n",
      " [0.22938974]\n",
      " [0.7477278 ]\n",
      " [0.9798676 ]\n",
      " [0.68700945]\n",
      " [0.9334255 ]\n",
      " [0.26419643]\n",
      " [0.86837244]\n",
      " [0.9784491 ]\n",
      " [0.8907173 ]\n",
      " [0.56681   ]\n",
      " [0.6098461 ]\n",
      " [0.8347765 ]\n",
      " [0.8780399 ]\n",
      " [0.69539225]\n",
      " [0.70535743]\n",
      " [0.43889025]\n",
      " [0.38588694]\n",
      " [0.98460364]\n",
      " [0.819403  ]\n",
      " [0.52110624]\n",
      " [0.6105627 ]\n",
      " [0.39191288]\n",
      " [0.42329827]\n",
      " [0.37705046]\n",
      " [0.8721029 ]\n",
      " [0.760341  ]\n",
      " [0.90323114]\n",
      " [0.5326524 ]\n",
      " [0.40187725]\n",
      " [0.89870447]\n",
      " [0.98279536]\n",
      " [0.99060476]\n",
      " [0.9791983 ]\n",
      " [0.42314756]\n",
      " [0.5672325 ]\n",
      " [0.93465686]\n",
      " [0.98821914]\n",
      " [0.43452892]\n",
      " [0.26767287]\n",
      " [0.90528893]\n",
      " [0.99161553]\n",
      " [0.9482148 ]\n",
      " [0.9959637 ]\n",
      " [0.9607168 ]\n",
      " [0.7907086 ]\n",
      " [0.9988144 ]\n",
      " [0.9140284 ]\n",
      " [0.97911036]\n",
      " [0.5123595 ]\n",
      " [0.90630734]\n",
      " [0.9440437 ]\n",
      " [0.81551796]\n",
      " [0.7138562 ]\n",
      " [0.826561  ]\n",
      " [0.7165689 ]\n",
      " [0.29709437]\n",
      " [0.54172826]\n",
      " [0.7728044 ]\n",
      " [0.6956384 ]\n",
      " [0.80674154]\n",
      " [0.22354424]\n",
      " [0.7680357 ]\n",
      " [0.9909539 ]\n",
      " [0.22547987]\n",
      " [0.32528424]\n",
      " [0.30675605]\n",
      " [0.6882393 ]\n",
      " [0.9546965 ]\n",
      " [0.6649793 ]\n",
      " [0.7731263 ]\n",
      " [0.3420325 ]\n",
      " [0.88046336]\n",
      " [0.9820428 ]\n",
      " [0.60379446]\n",
      " [0.6265582 ]\n",
      " [0.66324824]\n",
      " [0.97600895]\n",
      " [0.85758746]\n",
      " [0.937386  ]\n",
      " [0.9589882 ]\n",
      " [0.9988137 ]\n",
      " [0.9946059 ]\n",
      " [0.9723686 ]\n",
      " [0.98828596]\n",
      " [0.9791682 ]\n",
      " [0.92417884]\n",
      " [0.93009466]\n",
      " [0.9967992 ]\n",
      " [0.690225  ]\n",
      " [0.9592578 ]\n",
      " [0.9910502 ]\n",
      " [0.9005221 ]\n",
      " [0.9522238 ]\n",
      " [0.99080414]\n",
      " [0.9859844 ]\n",
      " [0.99034196]\n",
      " [0.4806935 ]\n",
      " [0.9510456 ]\n",
      " [0.98033756]\n",
      " [0.7799269 ]\n",
      " [0.837293  ]\n",
      " [0.58664   ]\n",
      " [0.67847157]\n",
      " [0.9776611 ]\n",
      " [0.9694921 ]\n",
      " [0.5266099 ]\n",
      " [0.8870091 ]\n",
      " [0.8742197 ]\n",
      " [0.9896847 ]\n",
      " [0.9577651 ]\n",
      " [0.96086127]\n",
      " [0.9754471 ]\n",
      " [0.37844044]\n",
      " [0.57928646]\n",
      " [0.6210152 ]\n",
      " [0.773803  ]\n",
      " [0.88380563]\n",
      " [0.73480594]\n",
      " [0.81624234]\n",
      " [0.8385529 ]\n",
      " [0.89188707]\n",
      " [0.81268233]\n",
      " [0.67259896]\n",
      " [0.99351346]\n",
      " [0.67072284]\n",
      " [0.9118961 ]\n",
      " [0.98010075]\n",
      " [0.88300145]\n",
      " [0.8969368 ]\n",
      " [0.45455652]\n",
      " [0.88095444]\n",
      " [0.9930525 ]\n",
      " [0.45754683]\n",
      " [0.2811244 ]\n",
      " [0.97924083]\n",
      " [0.5475157 ]\n",
      " [0.52502966]\n",
      " [0.19680865]\n",
      " [0.34981522]\n",
      " [0.19376732]\n",
      " [0.50833243]\n",
      " [0.3499256 ]]\n",
      "Predicted probabilities shape: (832, 1)\n",
      "Predicted labels: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0\n",
      " 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1\n",
      " 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 1 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 0\n",
      " 1 0 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 1 1 1 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 1 1 0 1 1 0 0 0 0 0 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 0 1 1\n",
      " 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0]\n",
      "Predicted labels shape: (832,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.8494 - auc: 0.4623 - f1_score: 0.7915 - loss: 0.3714 - precision: 0.9387 - recall: 0.8672\n",
      "Training model: MobileNetV3Small on dataset: DeepFire\n",
      "Epoch 1/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 118ms/step - accuracy: 0.6969 - auc: 0.8111 - f1_score: 0.6911 - loss: 0.6974 - precision: 0.7615 - recall: 0.7745 - val_accuracy: 0.4967 - val_auc: 0.8989 - val_f1_score: 0.6585 - val_loss: 0.7787 - val_precision: 0.4967 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - accuracy: 0.8105 - auc: 0.8931 - f1_score: 0.8051 - loss: 0.4449 - precision: 0.8337 - recall: 0.7849 - val_accuracy: 0.5115 - val_auc: 0.9189 - val_f1_score: 0.6697 - val_loss: 0.6879 - val_precision: 0.5107 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - accuracy: 0.8431 - auc: 0.9207 - f1_score: 0.8381 - loss: 0.3679 - precision: 0.8371 - recall: 0.8413 - val_accuracy: 0.4819 - val_auc: 0.9164 - val_f1_score: 0.6466 - val_loss: 0.7174 - val_precision: 0.4811 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 86ms/step - accuracy: 0.8290 - auc: 0.9117 - f1_score: 0.8274 - loss: 0.3982 - precision: 0.8201 - recall: 0.8451 - val_accuracy: 0.5033 - val_auc: 0.9276 - val_f1_score: 0.6545 - val_loss: 0.6614 - val_precision: 0.4907 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8384 - auc: 0.9206 - f1_score: 0.8407 - loss: 0.3671 - precision: 0.8517 - recall: 0.8339 - val_accuracy: 0.6299 - val_auc: 0.9068 - val_f1_score: 0.7305 - val_loss: 0.5863 - val_precision: 0.5836 - val_recall: 0.9968 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8566 - auc: 0.9347 - f1_score: 0.8534 - loss: 0.3321 - precision: 0.8432 - recall: 0.8698 - val_accuracy: 0.7336 - val_auc: 0.9177 - val_f1_score: 0.7792 - val_loss: 0.5102 - val_precision: 0.6659 - val_recall: 0.9479 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.8572 - auc: 0.9279 - f1_score: 0.8560 - loss: 0.3521 - precision: 0.8782 - recall: 0.8365 - val_accuracy: 0.8224 - val_auc: 0.9454 - val_f1_score: 0.8276 - val_loss: 0.4231 - val_precision: 0.7493 - val_recall: 0.9373 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.8502 - auc: 0.9271 - f1_score: 0.8433 - loss: 0.3598 - precision: 0.8312 - recall: 0.8649 - val_accuracy: 0.9095 - val_auc: 0.9698 - val_f1_score: 0.9039 - val_loss: 0.3126 - val_precision: 0.8882 - val_recall: 0.9278 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.8734 - auc: 0.9437 - f1_score: 0.8755 - loss: 0.3088 - precision: 0.8757 - recall: 0.8772 - val_accuracy: 0.8964 - val_auc: 0.9689 - val_f1_score: 0.8934 - val_loss: 0.2748 - val_precision: 0.8594 - val_recall: 0.9386 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.8823 - auc: 0.9489 - f1_score: 0.8813 - loss: 0.2909 - precision: 0.8605 - recall: 0.9089 - val_accuracy: 0.9046 - val_auc: 0.9691 - val_f1_score: 0.8991 - val_loss: 0.2432 - val_precision: 0.9155 - val_recall: 0.8914 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.8753 - auc: 0.9422 - f1_score: 0.8762 - loss: 0.3087 - precision: 0.8815 - recall: 0.8765 - val_accuracy: 0.9095 - val_auc: 0.9719 - val_f1_score: 0.9041 - val_loss: 0.2295 - val_precision: 0.9107 - val_recall: 0.9014 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 87ms/step - accuracy: 0.8707 - auc: 0.9394 - f1_score: 0.8708 - loss: 0.3193 - precision: 0.8602 - recall: 0.8844 - val_accuracy: 0.9128 - val_auc: 0.9773 - val_f1_score: 0.9085 - val_loss: 0.2265 - val_precision: 0.8933 - val_recall: 0.9273 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.8695 - auc: 0.9440 - f1_score: 0.8666 - loss: 0.3099 - precision: 0.8820 - recall: 0.8649 - val_accuracy: 0.9079 - val_auc: 0.9679 - val_f1_score: 0.8991 - val_loss: 0.2346 - val_precision: 0.9041 - val_recall: 0.9041 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.8627 - auc: 0.9389 - f1_score: 0.8622 - loss: 0.3176 - precision: 0.8441 - recall: 0.8877 - val_accuracy: 0.8980 - val_auc: 0.9656 - val_f1_score: 0.8917 - val_loss: 0.2396 - val_precision: 0.8926 - val_recall: 0.8986 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.8876 - auc: 0.9566 - f1_score: 0.8893 - loss: 0.2708 - precision: 0.8759 - recall: 0.9039 - val_accuracy: 0.9260 - val_auc: 0.9807 - val_f1_score: 0.9236 - val_loss: 0.1944 - val_precision: 0.9306 - val_recall: 0.9147 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.8727 - auc: 0.9425 - f1_score: 0.8703 - loss: 0.3095 - precision: 0.8794 - recall: 0.8650"
     ]
    }
   ],
   "source": [
    "\n",
    "results_file = os.path.join(run_dir, 'training_results.json')\n",
    "\n",
    "for base_model, custom_bool in zip(all_models, is_custom_model):\n",
    "    model = generate_model(base_model, custom=custom_bool) # To display the model summary\n",
    "    model.summary()\n",
    "    training_results[model.name] = {}\n",
    "    plot_model(model, show_shapes=True, show_layer_names=True, to_file=os.path.join(\"architectures\", f\"{model.name}_architecture.png\"))\n",
    "    for dataset_id, train_dataset, val_dataset, steps_per_epoch, validation_steps in zip(combined_dataset_names, combined_training_datasets, combined_val_datasets, steps_per_epoch_list, validation_steps_list):\n",
    "        model.load_weights(os.path.join(checkpoint_path, f\"{model.name}_initial.weights.h5\"))\n",
    "        print(f\"Training model: {model.name} on dataset: {dataset_id}\")\n",
    "        \n",
    "        # Record the start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Initial training of the model\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=val_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks_list\n",
    "        )\n",
    "\n",
    "        # Record the end time\n",
    "        end_time = time.time()\n",
    "        # Calculate the training time\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        model_ds_dir = os.path.join(run_dir, model.name, dataset_id)\n",
    "        os.makedirs(model_ds_dir, exist_ok=True)\n",
    "        # Save the model\n",
    "        model.save(os.path.join(model_ds_dir, f\"{model.name}_{dataset_id}.keras\"))\n",
    "\n",
    "        ### Evaluation stage ###\n",
    "        optimal_threshold = full_eval(model_ds_dir, history, model, dataset_id, test_dataset, true_labels, test_steps)\n",
    "        \n",
    "        training_results[model.name][dataset_id] = {\n",
    "            'history': history.history,\n",
    "            'training_time': training_time,\n",
    "            'optimal_threshold': float(optimal_threshold),\n",
    "            'train_dataset_size': steps_per_epoch * batch_size,\n",
    "            'val_dataset_size': validation_steps * batch_size,\n",
    "            \"evaluation\": model.evaluate(test_dataset, return_dict=True, steps=test_steps)\n",
    "        }\n",
    "\n",
    "        # Save the training results to a file after each iteration\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(training_results, f, indent=4)\n",
    "        \n",
    "        model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list) # Reset the model for the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute force loop completed!\n",
      "All models and evaluations are available at: runs\\run_6\n"
     ]
    }
   ],
   "source": [
    "print(\"Brute force loop completed!\")\n",
    "print(f\"All models and evaluations are available at: {run_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1351460,
     "sourceId": 2247205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
