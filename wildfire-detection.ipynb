{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Brute-Force Training and Evaluation Pipeline for Datasets and Models - by Selman Tabet @ https://selman.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname:  Chaos\n",
      "CUDA_VISIBLE_DEVICES: None\n",
      "TF All Devices:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "TF GPUs: []\n"
     ]
    }
   ],
   "source": [
    "# Data processing libraries\n",
    "import numpy as np\n",
    "from itertools import combinations # For brute force combinatoric search\n",
    "import json # For saving and loading training results\n",
    "import argparse # For command line arguments\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Tensorflow-Keras ML libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model # To plot model architecture\n",
    "\n",
    "from IPython import get_ipython # To check if code is running in Jupyter notebook\n",
    "import importlib.util # To import config module from str\n",
    "from pprint import pprint # To show config\n",
    "\n",
    "# Custom helper libraries\n",
    "from utils.img_processing import enforce_image_params\n",
    "from utils.dataset_processors import * # Dataset and generator processing functions\n",
    "from utils.plot_functions import * # Plotting functions\n",
    "from utils.evaluator import * # Complete evaluation program\n",
    "from utils.initializer import * # Set temp path and other initializations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify pipeline parameters here\n",
    "The configuration object is the most important part of the pipeline. It contains all the parameters that the pipeline will use to train and evaluate the models. The configuration object is a dictionary that MUST be named ***'default_cfg'***. The configuration object must contain the following:\n",
    "```python\n",
    "{\n",
    "    'datasets': {\n",
    "        \"dataset_name1\": {\n",
    "            'train': path str to the training dataset ***(required)***,\n",
    "            'val': path str to the validation dataset (optional),\n",
    "            'test': path str to the test dataset (optional),\n",
    "        },\n",
    "        \"dataset_name2\": {}, # Keep adding datasets as needed\n",
    "        \"dataset_name3\": {},\n",
    "        ...\n",
    "    },\n",
    "    'test': path str to the test dataset (optional, recommended),\n",
    "    'val_size': float of the validation dataset to split (optional, default=0.2),\n",
    "    'keras_models': [list of instances of the keras.applications base models]\n",
    "    'custom_models': [list of instances of custom models, to be compiled without modification],\n",
    "    'hyperparameters': {\n",
    "        'batch_size': int ***(required)***,\n",
    "        'epochs': int ***(required)***,\n",
    "    },\n",
    "    'optimizer': instance of keras.optimizers.Optimizer or str ***(required)***,\n",
    "    'loss': instance of keras.losses.Loss or str ***(required)***,\n",
    "    'image_width': int ***(required)***,\n",
    "    'image_height': int ***(required)***,\n",
    "    'metrics': [list of metric functions] ***(required)***,\n",
    "    'callbacks': [list of instances of keras.callbacks.Callback] (optional),\n",
    "    'enforce_image_params': bool to force RGB color mode and image sizes according to above specs (optional)\n",
    "    'metric_weights': { 'metric1': 1,\n",
    "                        'metric2': 1.5,\n",
    "                        ...\n",
    "                        # All metrics must be present in the list of metrics\n",
    "                    } (optional)\n",
    "}\n",
    "\n",
    "```\n",
    "The \"test\" configuration key is optional and is used to specify a test dataset that will be used to evaluate all models after training. If the \"test\" key is not provided, the pipeline will take the \"test\" paths provided under each dataset, then combine them to form a consolidated test set to evaluate all models with.\n",
    "\n",
    "**Note: Ensure that the dataset classes are in separate folders and that the folder names are the class names. The pipeline will automatically detect the classes from the dataset paths.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dissertation\\Kaggle Data\\wildfire-detection\\venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.applications import MobileNetV3Small, MobileNetV2, VGG19, ResNet50V2, Xception, DenseNet121\n",
    "from custom_metrics import f1_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# WildfireNet model, for comparison to other SOTA models in dissertation.\n",
    "from wildfirenet import create_wildfire_model\n",
    "\n",
    "DATASETS = {\n",
    "    \"The Wildfire Dataset\": {\n",
    "        \"train\": os.path.join(\"datasets\", \"dataset_1\", \"train\"),\n",
    "        \"test\": os.path.join(\"datasets\", \"dataset_1\", \"test\"),\n",
    "        \"val\": os.path.join(\"datasets\", \"dataset_1\", \"val\"),\n",
    "    },\n",
    "    \"DeepFire\": {\n",
    "        \"train\": os.path.join(\"datasets\", \"dataset_2\", \"Training\"),\n",
    "        \"test\": os.path.join(\"datasets\", \"dataset_2\", \"Testing\"),\n",
    "    },\n",
    "    \"FIRE\": {\n",
    "        \"train\": os.path.join(\"datasets\", \"dataset_3\"),\n",
    "    },\n",
    "}\n",
    "\n",
    "default_cfg = {\n",
    "    \"datasets\": DATASETS,  # The datasets to use\n",
    "    # This overrides the test datasets stored under \"datasets\"\n",
    "    \"test\": os.path.join(\"datasets\", \"d4_test\"),\n",
    "    \"val_size\": 0.2,  # The size of the validation dataset if splitting is needed\n",
    "    \"keras_models\": [MobileNetV3Small, MobileNetV2, VGG19, ResNet50V2, Xception, DenseNet121],\n",
    "    \"custom_models\": [create_wildfire_model(224, 224)],  # Custom models to use\n",
    "    \"hyperparameters\": {\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 80,\n",
    "    },\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss\": \"binary_crossentropy\",\n",
    "    \"image_width\": 224,\n",
    "    \"image_height\": 224,\n",
    "    \"metrics\": ['accuracy',  # Metrics functions, directly handed to model.compile\n",
    "                Precision(name=\"precision\"),\n",
    "                Recall(name=\"recall\"),\n",
    "                AUC(name=\"auc\"),\n",
    "                f1_score\n",
    "                ],\n",
    "    \"callbacks\": [  # Callback functions, directly handed to model.fit\n",
    "        EarlyStopping(monitor='val_loss', patience=5,\n",
    "                      restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath=os.path.join(\"tmp\", 'temp_model.keras'),\n",
    "                        monitor='val_loss', save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
    "                          patience=3, verbose=1)\n",
    "    ],\n",
    "    # If True, the image sizes and RGB colour mode will be enforced on all images\n",
    "    \"enforce_image_settings\": True,\n",
    "    \"metric_weights\": { # Weights for each metric in for Weighted Sum of Metrics Calculation\n",
    "        \"accuracy\": 1,\n",
    "        \"precision\": 1,\n",
    "        \"recall\": 1.3,\n",
    "        \"auc\": 1.2,\n",
    "        \"f1_score\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse arguments from command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Python config file specified, using default (notebook) config.\n"
     ]
    }
   ],
   "source": [
    "# Detect if script is running in a Jupyter notebook\n",
    "# Generated using GPT-4o. Prompt: \"Detect if running in a Jupyter notebook\"\n",
    "def in_notebook():\n",
    "    try:\n",
    "        shell = get_ipython().__class__.__name__\n",
    "        if shell == 'ZMQInteractiveShell':\n",
    "            return True   # Jupyter notebook or qtconsole\n",
    "        else:\n",
    "            return False  # Other type (terminal, etc.)\n",
    "    except NameError:\n",
    "        return False      # Probably standard Python interpreter\n",
    "    \n",
    "from_py = False # Flag to check if config was loaded from provided Python file\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Parse command line arguments\")\n",
    "parser.add_argument('--from-py-cfg', type=str,\n",
    "                    help='Path to the config Python file')\n",
    "if not in_notebook():\n",
    "    args = parser.parse_args()\n",
    "    config_file_path = args.from_py_cfg\n",
    "    print(f\"Python Config Path: {config_file_path}\")\n",
    "else:\n",
    "    config_file_path = False\n",
    "\n",
    "if config_file_path: # Load config from Python file\n",
    "    spec = importlib.util.spec_from_file_location(\"config_module\", config_file_path)\n",
    "    config_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(config_module)\n",
    "    config = config_module.cfg\n",
    "    print(\"Loaded config from Python file:\")\n",
    "    pprint(config)\n",
    "    # Datasets, models, and hyperparameters are mandatory and must be processed now.\n",
    "    training_datasets = config.get('datasets', {})\n",
    "    full_test_dir = config.get('test')\n",
    "    base_models = config.get('keras_models', [])\n",
    "    custom_models = config.get('custom_models', [])\n",
    "    hyperparameters = config.get('hyperparameters')\n",
    "    default_hyperparameters = default_cfg.get('hyperparameters', {})\n",
    "    metric_weights = config.get('metric_weights', {})\n",
    "    if hyperparameters is None or len(hyperparameters) == 0:\n",
    "        print(\"No training hyperparameters defined in config, using defaults defined above.\")\n",
    "        hyperparameters = default_hyperparameters # Use default hyperparameters\n",
    "    else: # Check for missing hyperparameters and fall back to defaults\n",
    "        for key, value in default_hyperparameters.items():\n",
    "            if key not in hyperparameters:\n",
    "                print(f\"Missing hyperparameter - falling back to default {key}:{default_hyperparameters[key]}\")\n",
    "                hyperparameters[key] = default_hyperparameters.get(key)\n",
    "    from_py = True # Successfully completed the config import\n",
    "else:\n",
    "    print(\"No Python config file specified, using default (notebook) config.\")\n",
    "    config = default_cfg\n",
    "    training_datasets = config.get('datasets', {})\n",
    "    base_models = config.get('keras_models', [])\n",
    "    custom_models = config.get('custom_models', [])\n",
    "    hyperparameters = config.get('hyperparameters', {\"epochs\": 50, \"batch_size\": 32})\n",
    "    full_test_dir = config.get('test')\n",
    "    metric_weights = config.get('metric_weights', {})\n",
    "# Check if training datasets are defined\n",
    "if training_datasets is None or len(training_datasets) == 0:\n",
    "    raise ValueError(\"No train datasets defined in config.\")\n",
    "# Check if either base_models or custom_models are defined\n",
    "if base_models is None or len(base_models) == 0:\n",
    "    if custom_models is None or len(custom_models) == 0:\n",
    "        raise ValueError(\"No models defined in config.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dirs = [training_datasets[ds].get('train') for ds in training_datasets]\n",
    "test_dirs = [training_datasets[ds].get('test') for ds in training_datasets]\n",
    "val_dirs = [training_datasets[ds].get('val') for ds in training_datasets]\n",
    "\n",
    "# Combine all directories for image params enforcement\n",
    "all_dirs = train_dirs + test_dirs + val_dirs + [full_test_dir]\n",
    "all_dirs = [d for d in all_dirs if d is not None] # Remove None values\n",
    "\n",
    "# Combine base_models and custom_models to be looped over in training\n",
    "all_models = base_models + custom_models\n",
    "# Create a list to keep track of which models are custom\n",
    "is_custom_model = [False] * len(base_models) + [True] * len(custom_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if from_py:\n",
    "    # Load parameters from custom config script\n",
    "    epochs = hyperparameters.get('epochs') # Guaranteed to be present\n",
    "    batch_size = hyperparameters.get('batch_size') # Guaranteed to be present\n",
    "    img_height = config.get('image_height', default_cfg.get('image_height'))\n",
    "    img_width = config.get('image_width', default_cfg.get('image_width'))\n",
    "    optimizer_fn = config.get('optimizer', default_cfg.get('optimizer'))\n",
    "    loss_fn = config.get('loss', default_cfg.get('loss'))\n",
    "    callbacks_list = config.get('callbacks', default_cfg.get('callbacks'))\n",
    "    metrics_list = config.get('metrics', default_cfg.get('metrics'))\n",
    "    enforce_image_size = config.get('enforce_image_settings', default_cfg.get('enforce_image_settings'))\n",
    "    val_size = config.get('val_size', default_cfg.get('val_size'))\n",
    "else:\n",
    "    # Load parameters from default config object\n",
    "    epochs = hyperparameters.get('epochs', 50)\n",
    "    batch_size = hyperparameters.get('batch_size', 32)\n",
    "    img_height = default_cfg.get('image_height', 224)\n",
    "    img_width = default_cfg.get('image_width', 224)\n",
    "    optimizer_fn = default_cfg.get('optimizer', 'adam')\n",
    "    loss_fn = default_cfg.get('loss', 'binary_crossentropy')\n",
    "    callbacks_list = default_cfg.get('callbacks', [])\n",
    "    metrics_list = default_cfg.get('metrics', ['accuracy'])\n",
    "    enforce_image_size = default_cfg.get('enforce_image_settings', False)\n",
    "    val_size = default_cfg.get('val_size', 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforce defined resolution and colour mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting image properties in datasets\\dataset_1\\train\n",
      "Adjusting image properties in datasets\\dataset_2\\Training\n",
      "Adjusting image properties in datasets\\dataset_1\\test\n",
      "Adjusting image properties in datasets\\dataset_2\\Testing\n",
      "Adjusting image properties in datasets\\dataset_1\\val\n",
      "Adjusting image properties in datasets\\d4_test\n"
     ]
    }
   ],
   "source": [
    "if enforce_image_size: # Enforce image size and RGB colour mode for all images\n",
    "    for directory in all_dirs:\n",
    "        print(f\"Adjusting image properties in {directory}\")\n",
    "        enforce_image_params(directory, target_size=(img_width, img_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create training and validation generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: The Wildfire Dataset\n",
      "Augmenting The Wildfire Dataset\n",
      "Creating generators for training\n",
      "Found 1887 images belonging to 2 classes.\n",
      "Found 402 images belonging to 2 classes.\n",
      "--------------------\n",
      "Number of samples in generator: 1887\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 730\n",
      "nofire: 1157\n",
      "--------------------\n",
      "--------------------\n",
      "Number of samples in generator: 402\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 156\n",
      "nofire: 246\n",
      "--------------------\n",
      "Processing: DeepFire\n",
      "Augmenting DeepFire\n",
      "Creating generators for training\n",
      "Found 1216 images belonging to 2 classes.\n",
      "Found 304 images belonging to 2 classes.\n",
      "--------------------\n",
      "Number of samples in generator: 1216\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 608\n",
      "nofire: 608\n",
      "--------------------\n",
      "--------------------\n",
      "Number of samples in generator: 304\n",
      "Number of classes: 2\n",
      "--------------------\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "Class names: ['fire', 'nofire']\n",
      "Dataset Class Counts:\n",
      "fire: 152\n",
      "nofire: 152\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_names = [] # [ \"dataset_1\", \"dataset_2\", ... ]\n",
    "train_generators = [] # [ (dataset_1_train, dataset_2_train), ... ]\n",
    "train_sizes = [] # [ (dataset_1_train_size, dataset_2_train_size), ... ]\n",
    "val_generators = [] # [ (dataset_1_val, dataset_2_val), ... ]\n",
    "val_sizes = [] # [ (dataset_1_val_size, dataset_2_val_size), ... ]\n",
    "train_counts = [] # [ (dataset_1_train_counts, dataset_2_train_counts), ... ]\n",
    "val_counts = [] # [ (dataset_1_val_counts, dataset_2_val_counts), ... ]\n",
    "\n",
    "for d in training_datasets:\n",
    "    print(f\"Processing: {d}\")\n",
    "    train_dir = training_datasets[d].get('train')\n",
    "    augment = training_datasets[d].get('augment', True)\n",
    "    print(\"Augmenting\" if augment else \"Not augmenting\", d)\n",
    "    # Apply original and augmented data generators for training\n",
    "    print(\"Creating generators for training\")\n",
    "    if \"val\" in training_datasets[d]: # Use separate validation dataset\n",
    "        train_generator = create_generator(train_dir, batch_size=batch_size, augment=augment, img_width=img_width, img_height=img_height)\n",
    "        val_generator = create_generator(training_datasets[d]['val'], batch_size=batch_size, augment=False, shuffle=False, img_width=img_width, img_height=img_height)\n",
    "    else: # Split the training dataset into training and validation\n",
    "        train_generator, val_generator = create_split_generators(train_dir, val_size=val_size, batch_size=batch_size, augment=augment, img_width=img_width, img_height=img_height)\n",
    "\n",
    "    train_samples = train_generator.samples\n",
    "    class_indices = train_generator.class_indices # Class indices must be consistent across training and validation, assertion will be made later\n",
    "    train_count_dict = class_counts_from_generator(train_generator)\n",
    "    \n",
    "    val_samples = val_generator.samples\n",
    "    val_count_dict = class_counts_from_generator(val_generator)\n",
    "    \n",
    "    # Calculate the number of samples for training and validation\n",
    "    train_sizes.append(train_samples)\n",
    "    val_sizes.append(val_samples)\n",
    "    \n",
    "    train_counts.append(train_count_dict)\n",
    "    val_counts.append(val_count_dict)\n",
    "    train_generators.append(train_generator)\n",
    "    val_generators.append(val_generator)\n",
    "    dataset_names.append(d)\n",
    "    \n",
    "# Ensure that the lengths are consistent across the board before continuing\n",
    "assert len(train_sizes) == len(train_generators) == len(val_sizes) == len(val_generators) == len(val_counts) == len(train_counts) == len(dataset_names), \"Dataset lengths are inconsistent.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute Force Combinatorial Search Space Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_combos = [] # [(0,), (1,), (0, 1), ...] where 0, 1 are the indices of the datasets within their respective lists\n",
    "for r in range(1, len(dataset_names) + 1): # For all combination sizes\n",
    "    # Generate all possible combinations of datasets for each size\n",
    "    dataset_combos.extend(combinations(range(len(dataset_names)), r))\n",
    "    \n",
    "combined_training_datasets = []\n",
    "combined_val_datasets = []\n",
    "combined_dataset_names = []\n",
    "steps_per_epoch_list = []\n",
    "validation_steps_list = []\n",
    "train_counts_list = []\n",
    "val_counts_list = []\n",
    "\n",
    "for combo in dataset_combos:\n",
    "    # Initialize variables for each combination\n",
    "    train_generators_list = None\n",
    "    val_generators_list = None\n",
    "    train_size = None\n",
    "    val_size = None\n",
    "    train_count = None\n",
    "    val_count = None\n",
    "    for idx in combo:\n",
    "        if train_generators_list is None:\n",
    "            # Initialize the lists with the first dataset\n",
    "            train_generators_list = [train_generators[idx]]\n",
    "            val_generators_list = [val_generators[idx]]\n",
    "            train_size = train_sizes[idx]\n",
    "            val_size = val_sizes[idx]\n",
    "            train_count = train_counts[idx]\n",
    "            val_count = val_counts[idx]\n",
    "        else:\n",
    "            # Combine the rest of the datasets\n",
    "            train_generators_list.append(train_generators[idx])\n",
    "            val_generators_list.append(val_generators[idx])\n",
    "            train_size += train_sizes[idx]\n",
    "            val_size += val_sizes[idx]\n",
    "            train_count = {k: train_count.get(k, 0) + train_counts[idx].get(k, 0) for k in set(train_count) | set(train_counts[idx])}\n",
    "            val_count = {k: val_count.get(k, 0) + val_counts[idx].get(k, 0) for k in set(val_count) | set(val_counts[idx])}\n",
    "        train_count = {k: int(v) for k, v in train_count.items()} # NumPy int64 to int cast\n",
    "        val_count = {k: int(v) for k, v in val_count.items()}\n",
    "\n",
    "    # Combine all accumulated generators for this combination into a single dataset\n",
    "    training_dataset = generators_to_dataset(train_generators_list, batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "    val_dataset = generators_to_dataset(val_generators_list, batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "    # Append the combined datasets and other relevant parameters to their respective lists\n",
    "    combined_dataset_names.append(\"_\".join([dataset_names[idx] for idx in combo]))\n",
    "    combined_training_datasets.append(training_dataset)\n",
    "    combined_val_datasets.append(val_dataset)\n",
    "    steps_per_epoch_list.append(train_size // batch_size)\n",
    "    validation_steps_list.append(val_size // batch_size)\n",
    "    train_counts_list.append(train_count)\n",
    "    val_counts_list.append(val_count)\n",
    "    # Zip all the lists together for easier unpacking in the training loop\n",
    "    training_params = list(zip(combined_dataset_names, combined_training_datasets, combined_val_datasets, steps_per_epoch_list, validation_steps_list, train_counts_list, val_counts_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      "Test Dataset Class Counts:\n",
      "Class indices: {'fire': 0, 'nofire': 1}\n",
      "fire: 200\n",
      "nofire: 200\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if full_test_dir is None:\n",
    "    test_generators = []\n",
    "    print(\"No target test directory provided, merging all tests from provided datasets if available.\")\n",
    "    for d in test_dirs:\n",
    "        if d is not None:\n",
    "            test_generators.append(create_generator(d, batch_size=batch_size, augment=False, shuffle=False, img_height=img_height, img_width=img_width)) # No augmentation/shuffle for testing\n",
    "    if len(test_generators) == 0:\n",
    "        raise ValueError(\"No tests found in the provided datasets.\")\n",
    "\n",
    "    test_steps = sum([gen.samples for gen in test_generators]) // batch_size\n",
    "    test_dataset = generators_to_dataset(test_generators, batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "else:\n",
    "    test_generators = [create_generator(full_test_dir, batch_size=batch_size, augment=False, shuffle=False, img_height=img_height, img_width=img_width)] # No augmentation/shuffle for testing\n",
    "    test_steps = test_generators[0].samples // batch_size\n",
    "    test_dataset = create_dataset(test_generators[0], batch_size=batch_size, img_height=img_height, img_width=img_width)\n",
    "if len(test_generators) > 0:\n",
    "    assert test_generators[0].class_indices == train_generators[0].class_indices, \"Test and training class indices do not match, check the provided directories and their class names.\"\n",
    "else:\n",
    "    raise ValueError(\"No test generators were created.\")\n",
    "\n",
    "print(\"Test Dataset Class Counts:\")\n",
    "for gen in test_generators:\n",
    "    print(\"Class indices:\", gen.class_indices)\n",
    "    for class_name, class_index in gen.class_indices.items():\n",
    "        print(f\"{class_name}: {sum(gen.classes == class_index)}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_model(bm, custom=False, to_dir=TEMP_DIR):\n",
    "    if custom: # Custom models are compiled and saved as is\n",
    "        model = bm\n",
    "        model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list)\n",
    "        os.makedirs(os.path.join(to_dir, model.name), exist_ok=True)\n",
    "        model.save_weights(os.path.join(to_dir, model.name, f\"{model.name}_initial.weights.h5\"))\n",
    "        return model\n",
    "    \n",
    "    base_model = bm(\n",
    "        include_top=False, \n",
    "        weights='imagenet', # Use pre-trained weights for transfer learning\n",
    "        input_shape=(img_height, img_width, 3)\n",
    "    )\n",
    "    base_model.trainable = False # Freeze the base model weights for transfer learning\n",
    "\n",
    "    # Create the model\n",
    "    inputs = Input(shape=(img_height, img_width, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x) # Pooling layer for dimensionality reduction\n",
    "    x = BatchNormalization()(x) # Batch normalization layer for stability\n",
    "    x = Dropout(0.5)(x) # Regularization layer\n",
    "    x = Dense(256, activation='relu')(x) # Trainable layer for this application\n",
    "    x = BatchNormalization()(x) # Batch normalization layer\n",
    "    x = Dropout(0.5)(x) # Regularization layer\n",
    "    outputs = Dense(1, activation='sigmoid')(x) # Binary classification output\n",
    "\n",
    "    model = Model(inputs, outputs, name=bm.__name__)\n",
    "    model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list)\n",
    "    os.makedirs(os.path.join(to_dir, model.name), exist_ok=True)\n",
    "    model.save_weights(os.path.join(to_dir, model.name, f\"{model.name}_initial.weights.h5\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluating the models and combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "run_number = len([d for d in os.listdir(\"runs\") if os.path.isdir(os.path.join(\"runs\", d)) and d.startswith('run_')]) + 1\n",
    "run_dir = os.path.join(\"runs\", f\"run_{run_number}\")\n",
    "os.makedirs(run_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = { # Save basic run info for reference\n",
    "    \"datasets\": training_datasets,\n",
    "    \"val_size\": val_size,\n",
    "    \"hyperparameters\": hyperparameters,\n",
    "    \"test_dirs\": test_dirs,\n",
    "    \"full_test\": full_test_dir,\n",
    "    \"number_of_models\": len(all_models),\n",
    "    \"metric_weights\": metric_weights,\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_dir, \"run_config.json\"), \"w\") as f:\n",
    "    json.dump(run_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MobileNetV3Small\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MobileNetV3Small\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MobileNetV3Small (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">939,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ MobileNetV3Small (\u001b[38;5;33mFunctional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m576\u001b[0m)      │       \u001b[38;5;34m939,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m576\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m147,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,090,417</span> (4.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,090,417\u001b[0m (4.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">149,633</span> (584.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m149,633\u001b[0m (584.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">940,784</span> (3.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m940,784\u001b[0m (3.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: MobileNetV3Small on dataset: The Wildfire Dataset\n",
      "Class weights: {0: 1.2924657534246575, 1: 0.8154710458081245}\n",
      "Epoch 1/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 252ms/step - accuracy: 0.5720 - auc: 0.6182 - f1_score: 0.6029 - loss: 0.8494 - precision: 0.6900 - recall: 0.5470 - val_accuracy: 0.5938 - val_auc: 0.7574 - val_f1_score: 0.6019 - val_loss: 0.6704 - val_precision: 0.5938 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 205ms/step - accuracy: 0.6447 - auc: 0.6877 - f1_score: 0.6860 - loss: 0.7320 - precision: 0.7557 - recall: 0.6368 - val_accuracy: 0.6406 - val_auc: 0.7268 - val_f1_score: 0.6619 - val_loss: 0.6425 - val_precision: 0.6406 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 210ms/step - accuracy: 0.6502 - auc: 0.7220 - f1_score: 0.6892 - loss: 0.6747 - precision: 0.7618 - recall: 0.6319 - val_accuracy: 0.6406 - val_auc: 0.7754 - val_f1_score: 0.6619 - val_loss: 0.6446 - val_precision: 0.6406 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 211ms/step - accuracy: 0.6450 - auc: 0.7199 - f1_score: 0.6825 - loss: 0.6491 - precision: 0.7524 - recall: 0.6350 - val_accuracy: 0.5990 - val_auc: 0.8033 - val_f1_score: 0.6200 - val_loss: 0.6540 - val_precision: 0.5969 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - accuracy: 0.6572 - auc: 0.7055 - f1_score: 0.7050 - loss: 0.6796 - precision: 0.7521 - recall: 0.6651 - val_accuracy: 0.6849 - val_auc: 0.7774 - val_f1_score: 0.5038 - val_loss: 0.6420 - val_precision: 0.7861 - val_recall: 0.6447 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 217ms/step - accuracy: 0.6681 - auc: 0.7450 - f1_score: 0.7012 - loss: 0.6340 - precision: 0.7978 - recall: 0.6301 - val_accuracy: 0.6901 - val_auc: 0.7897 - val_f1_score: 0.5749 - val_loss: 0.6390 - val_precision: 0.6912 - val_recall: 0.8640 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 215ms/step - accuracy: 0.6753 - auc: 0.7412 - f1_score: 0.7043 - loss: 0.6364 - precision: 0.7522 - recall: 0.6676 - val_accuracy: 0.7057 - val_auc: 0.7842 - val_f1_score: 0.5619 - val_loss: 0.6279 - val_precision: 0.7220 - val_recall: 0.8202 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.6850 - auc: 0.7478 - f1_score: 0.7306 - loss: 0.6033 - precision: 0.7977 - recall: 0.6765 - val_accuracy: 0.7135 - val_auc: 0.7996 - val_f1_score: 0.4839 - val_loss: 0.6028 - val_precision: 0.8207 - val_recall: 0.6623 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 213ms/step - accuracy: 0.6738 - auc: 0.7474 - f1_score: 0.7052 - loss: 0.6051 - precision: 0.7862 - recall: 0.6435 - val_accuracy: 0.7188 - val_auc: 0.8175 - val_f1_score: 0.5313 - val_loss: 0.5912 - val_precision: 0.8750 - val_recall: 0.6545 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 217ms/step - accuracy: 0.6718 - auc: 0.7502 - f1_score: 0.7049 - loss: 0.5946 - precision: 0.7744 - recall: 0.6501 - val_accuracy: 0.7031 - val_auc: 0.8241 - val_f1_score: 0.5193 - val_loss: 0.5541 - val_precision: 0.8708 - val_recall: 0.6301 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - accuracy: 0.6768 - auc: 0.7540 - f1_score: 0.7180 - loss: 0.5924 - precision: 0.7915 - recall: 0.6599 - val_accuracy: 0.7422 - val_auc: 0.8243 - val_f1_score: 0.5193 - val_loss: 0.5484 - val_precision: 0.8564 - val_recall: 0.6798 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 216ms/step - accuracy: 0.7033 - auc: 0.7680 - f1_score: 0.7316 - loss: 0.5895 - precision: 0.7986 - recall: 0.6793 - val_accuracy: 0.7318 - val_auc: 0.8241 - val_f1_score: 0.5081 - val_loss: 0.5445 - val_precision: 0.8571 - val_recall: 0.6579 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - accuracy: 0.6888 - auc: 0.7656 - f1_score: 0.7125 - loss: 0.5889 - precision: 0.7811 - recall: 0.6593 - val_accuracy: 0.7422 - val_auc: 0.8271 - val_f1_score: 0.5190 - val_loss: 0.5356 - val_precision: 0.8644 - val_recall: 0.6711 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 218ms/step - accuracy: 0.6999 - auc: 0.7552 - f1_score: 0.7287 - loss: 0.6053 - precision: 0.7927 - recall: 0.6806 - val_accuracy: 0.7656 - val_auc: 0.8368 - val_f1_score: 0.5570 - val_loss: 0.5217 - val_precision: 0.8165 - val_recall: 0.7807 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.7102 - auc: 0.7767 - f1_score: 0.7422 - loss: 0.5728 - precision: 0.8123 - recall: 0.6847 - val_accuracy: 0.7500 - val_auc: 0.8382 - val_f1_score: 0.4942 - val_loss: 0.5243 - val_precision: 0.8511 - val_recall: 0.7018 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - accuracy: 0.7172 - auc: 0.8071 - f1_score: 0.7500 - loss: 0.5393 - precision: 0.8340 - recall: 0.6877 - val_accuracy: 0.7682 - val_auc: 0.8241 - val_f1_score: 0.5938 - val_loss: 0.5168 - val_precision: 0.8428 - val_recall: 0.7846 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 214ms/step - accuracy: 0.6991 - auc: 0.7651 - f1_score: 0.7302 - loss: 0.5865 - precision: 0.7771 - recall: 0.6873 - val_accuracy: 0.7474 - val_auc: 0.8211 - val_f1_score: 0.5609 - val_loss: 0.5430 - val_precision: 0.8901 - val_recall: 0.6911 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 230ms/step - accuracy: 0.7069 - auc: 0.7852 - f1_score: 0.7324 - loss: 0.5646 - precision: 0.8375 - recall: 0.6549 - val_accuracy: 0.7370 - val_auc: 0.8414 - val_f1_score: 0.5261 - val_loss: 0.5190 - val_precision: 0.8770 - val_recall: 0.6777 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.6862 - auc: 0.7643 - f1_score: 0.7132 - loss: 0.5909 - precision: 0.7766 - recall: 0.6638\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 219ms/step - accuracy: 0.6863 - auc: 0.7644 - f1_score: 0.7134 - loss: 0.5908 - precision: 0.7768 - recall: 0.6640 - val_accuracy: 0.7578 - val_auc: 0.8288 - val_f1_score: 0.5381 - val_loss: 0.5241 - val_precision: 0.8534 - val_recall: 0.7149 - learning_rate: 0.0010\n",
      "Epoch 20/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 232ms/step - accuracy: 0.6999 - auc: 0.7769 - f1_score: 0.7306 - loss: 0.5689 - precision: 0.8003 - recall: 0.6750 - val_accuracy: 0.7786 - val_auc: 0.8482 - val_f1_score: 0.5511 - val_loss: 0.4974 - val_precision: 0.8667 - val_recall: 0.7412 - learning_rate: 5.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 223ms/step - accuracy: 0.6777 - auc: 0.7786 - f1_score: 0.7084 - loss: 0.5581 - precision: 0.7929 - recall: 0.6447 - val_accuracy: 0.7682 - val_auc: 0.8323 - val_f1_score: 0.5491 - val_loss: 0.5162 - val_precision: 0.8458 - val_recall: 0.7456 - learning_rate: 5.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 217ms/step - accuracy: 0.7237 - auc: 0.8012 - f1_score: 0.7547 - loss: 0.5462 - precision: 0.8065 - recall: 0.7134 - val_accuracy: 0.7474 - val_auc: 0.8338 - val_f1_score: 0.4999 - val_loss: 0.5181 - val_precision: 0.8466 - val_recall: 0.7018 - learning_rate: 5.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.6989 - auc: 0.7728 - f1_score: 0.7302 - loss: 0.5794 - precision: 0.7962 - recall: 0.6792\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 221ms/step - accuracy: 0.6989 - auc: 0.7729 - f1_score: 0.7302 - loss: 0.5791 - precision: 0.7961 - recall: 0.6793 - val_accuracy: 0.7682 - val_auc: 0.8330 - val_f1_score: 0.5812 - val_loss: 0.5127 - val_precision: 0.8720 - val_recall: 0.7480 - learning_rate: 5.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 219ms/step - accuracy: 0.6919 - auc: 0.7732 - f1_score: 0.7300 - loss: 0.5687 - precision: 0.8106 - recall: 0.6644 - val_accuracy: 0.7604 - val_auc: 0.8367 - val_f1_score: 0.5738 - val_loss: 0.5130 - val_precision: 0.8738 - val_recall: 0.7317 - learning_rate: 2.5000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 226ms/step - accuracy: 0.7160 - auc: 0.7981 - f1_score: 0.7433 - loss: 0.5468 - precision: 0.8229 - recall: 0.6838 - val_accuracy: 0.7656 - val_auc: 0.8505 - val_f1_score: 0.5545 - val_loss: 0.4961 - val_precision: 0.8725 - val_recall: 0.7355 - learning_rate: 2.5000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 220ms/step - accuracy: 0.7143 - auc: 0.7796 - f1_score: 0.7515 - loss: 0.5655 - precision: 0.8277 - recall: 0.6932 - val_accuracy: 0.7760 - val_auc: 0.8444 - val_f1_score: 0.5447 - val_loss: 0.5045 - val_precision: 0.8660 - val_recall: 0.7368 - learning_rate: 2.5000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 249ms/step - accuracy: 0.7104 - auc: 0.7916 - f1_score: 0.7327 - loss: 0.5523 - precision: 0.7995 - recall: 0.6852 - val_accuracy: 0.8047 - val_auc: 0.8553 - val_f1_score: 0.5665 - val_loss: 0.4824 - val_precision: 0.8660 - val_recall: 0.7939 - learning_rate: 2.5000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 258ms/step - accuracy: 0.7265 - auc: 0.8064 - f1_score: 0.7600 - loss: 0.5350 - precision: 0.8319 - recall: 0.7043 - val_accuracy: 0.7708 - val_auc: 0.8399 - val_f1_score: 0.5438 - val_loss: 0.5073 - val_precision: 0.8535 - val_recall: 0.7412 - learning_rate: 2.5000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 256ms/step - accuracy: 0.7159 - auc: 0.7949 - f1_score: 0.7415 - loss: 0.5591 - precision: 0.8255 - recall: 0.6797 - val_accuracy: 0.7552 - val_auc: 0.8363 - val_f1_score: 0.5053 - val_loss: 0.5123 - val_precision: 0.8490 - val_recall: 0.7149 - learning_rate: 2.5000e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step - accuracy: 0.7086 - auc: 0.7757 - f1_score: 0.7374 - loss: 0.5699 - precision: 0.8214 - recall: 0.6727\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 235ms/step - accuracy: 0.7084 - auc: 0.7758 - f1_score: 0.7374 - loss: 0.5699 - precision: 0.8213 - recall: 0.6727 - val_accuracy: 0.7656 - val_auc: 0.8405 - val_f1_score: 0.5757 - val_loss: 0.5105 - val_precision: 0.8750 - val_recall: 0.7398 - learning_rate: 2.5000e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 238ms/step - accuracy: 0.7179 - auc: 0.8071 - f1_score: 0.7408 - loss: 0.5371 - precision: 0.8119 - recall: 0.6863 - val_accuracy: 0.7682 - val_auc: 0.8496 - val_f1_score: 0.5738 - val_loss: 0.5006 - val_precision: 0.8867 - val_recall: 0.7317 - learning_rate: 1.2500e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 292ms/step - accuracy: 0.7172 - auc: 0.8019 - f1_score: 0.7481 - loss: 0.5445 - precision: 0.8242 - recall: 0.6860 - val_accuracy: 0.7839 - val_auc: 0.8448 - val_f1_score: 0.5510 - val_loss: 0.5014 - val_precision: 0.8643 - val_recall: 0.7544 - learning_rate: 1.2500e-04\n",
      "Training time: 419.25 seconds\n",
      "Evaluating MobileNetV3Small on The Wildfire Dataset...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dissertation\\Kaggle Data\\wildfire-detection\\utils\\plot_functions.py:65: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_scores = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 128ms/step - accuracy: 0.7078 - auc: 0.4803 - f1_score: 0.2399 - loss: 0.7102 - precision: 0.3768 - recall: 0.5198  \n",
      "Training results for MobileNetV3Small on The Wildfire Dataset:\n",
      "{'class_weights': {0: 1.2924657534246575, 1: 0.8154710458081245},\n",
      " 'evaluation': {'accuracy': 0.7421875,\n",
      "                'auc': 0.757472813129425,\n",
      "                'f1_score': 0.4932771921157837,\n",
      "                'loss': 0.617217481136322,\n",
      "                'precision': 0.7285068035125732,\n",
      "                'recall': 0.8050000071525574},\n",
      " 'history': {'accuracy': [0.602909505367279,\n",
      "                          0.654633641242981,\n",
      "                          0.6449353694915771,\n",
      "                          0.6621767282485962,\n",
      "                          0.6600215435028076,\n",
      "                          0.6681034564971924,\n",
      "                          0.6686422228813171,\n",
      "                          0.685883641242981,\n",
      "                          0.6907327771186829,\n",
      "                          0.6794180870056152,\n",
      "                          0.6923491358757019,\n",
      "                          0.6934267282485962,\n",
      "                          0.7036637663841248,\n",
      "                          0.6901939511299133,\n",
      "                          0.7009698152542114,\n",
      "                          0.7128232717514038,\n",
      "                          0.6961206793785095,\n",
      "                          0.6993534564971924,\n",
      "                          0.6945043206214905,\n",
      "                          0.7068965435028076,\n",
      "                          0.6815732717514038,\n",
      "                          0.7133620977401733,\n",
      "                          0.6993534564971924,\n",
      "                          0.7085129022598267,\n",
      "                          0.7144396305084229,\n",
      "                          0.7079741358757019,\n",
      "                          0.712284505367279,\n",
      "                          0.7165948152542114,\n",
      "                          0.7112069129943848,\n",
      "                          0.7025862336158752,\n",
      "                          0.7117456793785095,\n",
      "                          0.7112069129943848],\n",
      "             'auc': [0.6569181084632874,\n",
      "                     0.7089558243751526,\n",
      "                     0.7060718536376953,\n",
      "                     0.7277626991271973,\n",
      "                     0.7184997797012329,\n",
      "                     0.7422866225242615,\n",
      "                     0.7363938689231873,\n",
      "                     0.7511799931526184,\n",
      "                     0.7563115954399109,\n",
      "                     0.7566840052604675,\n",
      "                     0.7685041427612305,\n",
      "                     0.7599498629570007,\n",
      "                     0.7707564234733582,\n",
      "                     0.7569158673286438,\n",
      "                     0.767295777797699,\n",
      "                     0.8047598004341125,\n",
      "                     0.7732582688331604,\n",
      "                     0.7778385877609253,\n",
      "                     0.7668777704238892,\n",
      "                     0.7882829904556274,\n",
      "                     0.7735568284988403,\n",
      "                     0.7968730926513672,\n",
      "                     0.7806863784790039,\n",
      "                     0.7832210063934326,\n",
      "                     0.8054882884025574,\n",
      "                     0.7883148193359375,\n",
      "                     0.7898389101028442,\n",
      "                     0.7988063097000122,\n",
      "                     0.7913610339164734,\n",
      "                     0.7779415845870972,\n",
      "                     0.8038292527198792,\n",
      "                     0.7901532053947449],\n",
      "             'f1_score': [0.6325175166130066,\n",
      "                          0.6942741274833679,\n",
      "                          0.6822553873062134,\n",
      "                          0.6982417702674866,\n",
      "                          0.7028444409370422,\n",
      "                          0.7019464373588562,\n",
      "                          0.701403796672821,\n",
      "                          0.7241041660308838,\n",
      "                          0.7221329212188721,\n",
      "                          0.7131748199462891,\n",
      "                          0.7275658249855042,\n",
      "                          0.7260273694992065,\n",
      "                          0.7343898415565491,\n",
      "                          0.721282958984375,\n",
      "                          0.7349581122398376,\n",
      "                          0.7467734217643738,\n",
      "                          0.7278730273246765,\n",
      "                          0.7319793701171875,\n",
      "                          0.7257111072540283,\n",
      "                          0.7376294732093811,\n",
      "                          0.712723970413208,\n",
      "                          0.746458888053894,\n",
      "                          0.7309852838516235,\n",
      "                          0.7407214641571045,\n",
      "                          0.7392539381980896,\n",
      "                          0.7443175911903381,\n",
      "                          0.7358161807060242,\n",
      "                          0.7484726309776306,\n",
      "                          0.7387542724609375,\n",
      "                          0.7346675395965576,\n",
      "                          0.7370665073394775,\n",
      "                          0.7411535382270813],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0001250000059371814,\n",
      "                               0.0001250000059371814],\n",
      "             'loss': [0.7915048003196716,\n",
      "                      0.7087830901145935,\n",
      "                      0.694262683391571,\n",
      "                      0.6543780565261841,\n",
      "                      0.6675597429275513,\n",
      "                      0.6295767426490784,\n",
      "                      0.637611448764801,\n",
      "                      0.6018611788749695,\n",
      "                      0.6020861864089966,\n",
      "                      0.5900462865829468,\n",
      "                      0.5804673433303833,\n",
      "                      0.5903318524360657,\n",
      "                      0.5781290531158447,\n",
      "                      0.598522424697876,\n",
      "                      0.5836068987846375,\n",
      "                      0.5395870804786682,\n",
      "                      0.5754384398460388,\n",
      "                      0.5668889284133911,\n",
      "                      0.5831526517868042,\n",
      "                      0.5560308694839478,\n",
      "                      0.5667998194694519,\n",
      "                      0.5436225533485413,\n",
      "                      0.5666946768760681,\n",
      "                      0.5601626038551331,\n",
      "                      0.5386927723884583,\n",
      "                      0.5518161058425903,\n",
      "                      0.5541816353797913,\n",
      "                      0.5432828068733215,\n",
      "                      0.555694580078125,\n",
      "                      0.5663208961486816,\n",
      "                      0.5384223461151123,\n",
      "                      0.5549810528755188],\n",
      "             'precision': [0.7214206457138062,\n",
      "                           0.7502517700195312,\n",
      "                           0.7515657544136047,\n",
      "                           0.7641606330871582,\n",
      "                           0.7477567195892334,\n",
      "                           0.7937365174293518,\n",
      "                           0.759048581123352,\n",
      "                           0.7901740074157715,\n",
      "                           0.7960042357444763,\n",
      "                           0.7832980751991272,\n",
      "                           0.8025078177452087,\n",
      "                           0.8002102971076965,\n",
      "                           0.8048268556594849,\n",
      "                           0.7928496599197388,\n",
      "                           0.8024818897247314,\n",
      "                           0.8211716413497925,\n",
      "                           0.7864583134651184,\n",
      "                           0.8180851340293884,\n",
      "                           0.7910135984420776,\n",
      "                           0.8147368431091309,\n",
      "                           0.7898089289665222,\n",
      "                           0.8148913979530334,\n",
      "                           0.7909371852874756,\n",
      "                           0.8175105452537537,\n",
      "                           0.820622980594635,\n",
      "                           0.8221994042396545,\n",
      "                           0.8070362210273743,\n",
      "                           0.831756055355072,\n",
      "                           0.8185698986053467,\n",
      "                           0.8136842250823975,\n",
      "                           0.8149732351303101,\n",
      "                           0.8168420791625977],\n",
      "             'recall': [0.5721830725669861,\n",
      "                        0.6546573042869568,\n",
      "                        0.6310254335403442,\n",
      "                        0.6508771777153015,\n",
      "                        0.664893627166748,\n",
      "                        0.6336206793785095,\n",
      "                        0.657706081867218,\n",
      "                        0.6713043451309204,\n",
      "                        0.6657871603965759,\n",
      "                        0.6551724076271057,\n",
      "                        0.6678261160850525,\n",
      "                        0.667543888092041,\n",
      "                        0.6781609058380127,\n",
      "                        0.666077733039856,\n",
      "                        0.680701732635498,\n",
      "                        0.6899827122688293,\n",
      "                        0.6777378916740417,\n",
      "                        0.6652249097824097,\n",
      "                        0.6734875440597534,\n",
      "                        0.6777583360671997,\n",
      "                        0.6543535590171814,\n",
      "                        0.6906222701072693,\n",
      "                        0.683882474899292,\n",
      "                        0.6780402660369873,\n",
      "                        0.6779059171676636,\n",
      "                        0.6843456029891968,\n",
      "                        0.6819819808006287,\n",
      "                        0.6836646795272827,\n",
      "                        0.6769638061523438,\n",
      "                        0.6733449697494507,\n",
      "                        0.6779359579086304,\n",
      "                        0.6818980574607849],\n",
      "             'val_accuracy': [0.59375,\n",
      "                              0.640625,\n",
      "                              0.640625,\n",
      "                              0.5989583134651184,\n",
      "                              0.6848958134651184,\n",
      "                              0.6901041865348816,\n",
      "                              0.7057291865348816,\n",
      "                              0.7135416865348816,\n",
      "                              0.71875,\n",
      "                              0.703125,\n",
      "                              0.7421875,\n",
      "                              0.7317708134651184,\n",
      "                              0.7421875,\n",
      "                              0.765625,\n",
      "                              0.75,\n",
      "                              0.7682291865348816,\n",
      "                              0.7473958134651184,\n",
      "                              0.7369791865348816,\n",
      "                              0.7578125,\n",
      "                              0.7786458134651184,\n",
      "                              0.7682291865348816,\n",
      "                              0.7473958134651184,\n",
      "                              0.7682291865348816,\n",
      "                              0.7604166865348816,\n",
      "                              0.765625,\n",
      "                              0.7760416865348816,\n",
      "                              0.8046875,\n",
      "                              0.7708333134651184,\n",
      "                              0.7552083134651184,\n",
      "                              0.765625,\n",
      "                              0.7682291865348816,\n",
      "                              0.7838541865348816],\n",
      "             'val_auc': [0.7573942542076111,\n",
      "                         0.7268174886703491,\n",
      "                         0.7753623723983765,\n",
      "                         0.8032782077789307,\n",
      "                         0.7773982286453247,\n",
      "                         0.789726734161377,\n",
      "                         0.7842302322387695,\n",
      "                         0.7995530366897583,\n",
      "                         0.8174707889556885,\n",
      "                         0.8240839242935181,\n",
      "                         0.8242802619934082,\n",
      "                         0.8240835070610046,\n",
      "                         0.8270776271820068,\n",
      "                         0.8367634415626526,\n",
      "                         0.8381550908088684,\n",
      "                         0.8240838646888733,\n",
      "                         0.8211087584495544,\n",
      "                         0.8413746953010559,\n",
      "                         0.8287505507469177,\n",
      "                         0.8481781482696533,\n",
      "                         0.8323493003845215,\n",
      "                         0.8337691426277161,\n",
      "                         0.8330240249633789,\n",
      "                         0.8366619348526001,\n",
      "                         0.8504539728164673,\n",
      "                         0.8443825840950012,\n",
      "                         0.8552912473678589,\n",
      "                         0.8398841619491577,\n",
      "                         0.8362573385238647,\n",
      "                         0.8404766321182251,\n",
      "                         0.8495787382125854,\n",
      "                         0.8447761535644531],\n",
      "             'val_f1_score': [0.6018518805503845,\n",
      "                              0.6618518233299255,\n",
      "                              0.6618518233299255,\n",
      "                              0.6199999451637268,\n",
      "                              0.5038369297981262,\n",
      "                              0.5749484896659851,\n",
      "                              0.5619420409202576,\n",
      "                              0.48387980461120605,\n",
      "                              0.5312592387199402,\n",
      "                              0.5192891955375671,\n",
      "                              0.5192824006080627,\n",
      "                              0.5081470608711243,\n",
      "                              0.5189672708511353,\n",
      "                              0.5570220351219177,\n",
      "                              0.49417829513549805,\n",
      "                              0.5937835574150085,\n",
      "                              0.5608542561531067,\n",
      "                              0.5261327624320984,\n",
      "                              0.538057267665863,\n",
      "                              0.5511323809623718,\n",
      "                              0.5491166710853577,\n",
      "                              0.4999113082885742,\n",
      "                              0.5811967849731445,\n",
      "                              0.5737925171852112,\n",
      "                              0.5545021891593933,\n",
      "                              0.5447399020195007,\n",
      "                              0.5664647817611694,\n",
      "                              0.5438386797904968,\n",
      "                              0.5052987337112427,\n",
      "                              0.5756645202636719,\n",
      "                              0.5737635493278503,\n",
      "                              0.5510287880897522],\n",
      "             'val_loss': [0.6704198718070984,\n",
      "                          0.6425445675849915,\n",
      "                          0.6446210145950317,\n",
      "                          0.6540403962135315,\n",
      "                          0.6419785022735596,\n",
      "                          0.6390488147735596,\n",
      "                          0.6279463171958923,\n",
      "                          0.60284024477005,\n",
      "                          0.5911952257156372,\n",
      "                          0.5541452765464783,\n",
      "                          0.5483588576316833,\n",
      "                          0.5445007681846619,\n",
      "                          0.5356290936470032,\n",
      "                          0.5216982960700989,\n",
      "                          0.5243076682090759,\n",
      "                          0.5168123245239258,\n",
      "                          0.543034017086029,\n",
      "                          0.5190365314483643,\n",
      "                          0.5241351127624512,\n",
      "                          0.49739357829093933,\n",
      "                          0.5162342190742493,\n",
      "                          0.5180569291114807,\n",
      "                          0.5126628279685974,\n",
      "                          0.5129559636116028,\n",
      "                          0.4960716962814331,\n",
      "                          0.5045219659805298,\n",
      "                          0.48240411281585693,\n",
      "                          0.5072751641273499,\n",
      "                          0.5122935175895691,\n",
      "                          0.5104805827140808,\n",
      "                          0.5005573630332947,\n",
      "                          0.5014219880104065],\n",
      "             'val_precision': [0.59375,\n",
      "                               0.640625,\n",
      "                               0.640625,\n",
      "                               0.5968586206436157,\n",
      "                               0.7860962748527527,\n",
      "                               0.6912280917167664,\n",
      "                               0.7220077514648438,\n",
      "                               0.820652186870575,\n",
      "                               0.875,\n",
      "                               0.8707864880561829,\n",
      "                               0.8563535809516907,\n",
      "                               0.8571428656578064,\n",
      "                               0.8644067645072937,\n",
      "                               0.8165137767791748,\n",
      "                               0.8510638475418091,\n",
      "                               0.8427947759628296,\n",
      "                               0.8900523781776428,\n",
      "                               0.8770053386688232,\n",
      "                               0.8534031510353088,\n",
      "                               0.8666666746139526,\n",
      "                               0.8457711338996887,\n",
      "                               0.8465608358383179,\n",
      "                               0.8720378875732422,\n",
      "                               0.8737863898277283,\n",
      "                               0.8725489974021912,\n",
      "                               0.8659793734550476,\n",
      "                               0.8660287261009216,\n",
      "                               0.8535353541374207,\n",
      "                               0.8489583134651184,\n",
      "                               0.875,\n",
      "                               0.8866994976997375,\n",
      "                               0.8643215894699097],\n",
      "             'val_recall': [1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            0.6447368264198303,\n",
      "                            0.8640350699424744,\n",
      "                            0.8201754093170166,\n",
      "                            0.6622806787490845,\n",
      "                            0.6544715166091919,\n",
      "                            0.630081295967102,\n",
      "                            0.6798245906829834,\n",
      "                            0.6578947305679321,\n",
      "                            0.6710526347160339,\n",
      "                            0.780701756477356,\n",
      "                            0.7017543911933899,\n",
      "                            0.7845528721809387,\n",
      "                            0.6910569071769714,\n",
      "                            0.6776859760284424,\n",
      "                            0.7149122953414917,\n",
      "                            0.7412280440330505,\n",
      "                            0.7456140518188477,\n",
      "                            0.7017543911933899,\n",
      "                            0.7479674816131592,\n",
      "                            0.7317073345184326,\n",
      "                            0.7355371713638306,\n",
      "                            0.7368420958518982,\n",
      "                            0.7938596606254578,\n",
      "                            0.7412280440330505,\n",
      "                            0.7149122953414917,\n",
      "                            0.7398374080657959,\n",
      "                            0.7317073345184326,\n",
      "                            0.7543859481811523]},\n",
      " 'optimal_threshold': 0.9962440133094788,\n",
      " 'train_counts': {'fire': 730, 'nofire': 1157},\n",
      " 'train_counts_total': 1887,\n",
      " 'train_dataset_size': 1856,\n",
      " 'training_time': 419.2459716796875,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_counts_total': 402,\n",
      " 'val_dataset_size': 384}\n",
      "Training model: MobileNetV3Small on dataset: DeepFire\n",
      "Class weights: {0: 1.0, 1: 1.0}\n",
      "Epoch 1/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 478ms/step - accuracy: 0.5944 - auc: 0.7054 - f1_score: 0.5616 - loss: 0.8601 - precision: 0.6718 - recall: 0.6874 - val_accuracy: 0.4722 - val_auc: 0.8377 - val_f1_score: 0.4889 - val_loss: 0.7066 - val_precision: 0.4722 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 372ms/step - accuracy: 0.7508 - auc: 0.8213 - f1_score: 0.7395 - loss: 0.5671 - precision: 0.7580 - recall: 0.7230 - val_accuracy: 0.5278 - val_auc: 0.8999 - val_f1_score: 0.5630 - val_loss: 0.6757 - val_precision: 0.5278 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 417ms/step - accuracy: 0.7694 - auc: 0.8426 - f1_score: 0.7656 - loss: 0.5285 - precision: 0.7600 - recall: 0.7798 - val_accuracy: 0.5278 - val_auc: 0.9156 - val_f1_score: 0.5630 - val_loss: 0.6725 - val_precision: 0.5278 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 395ms/step - accuracy: 0.7684 - auc: 0.8469 - f1_score: 0.7738 - loss: 0.5110 - precision: 0.7701 - recall: 0.7829 - val_accuracy: 0.4722 - val_auc: 0.9207 - val_f1_score: 0.5026 - val_loss: 0.6935 - val_precision: 0.4722 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 390ms/step - accuracy: 0.7660 - auc: 0.8397 - f1_score: 0.7630 - loss: 0.5333 - precision: 0.7651 - recall: 0.7646 - val_accuracy: 0.4722 - val_auc: 0.8094 - val_f1_score: 0.5026 - val_loss: 0.7303 - val_precision: 0.4722 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.7776 - auc: 0.8583 - f1_score: 0.7790 - loss: 0.4863 - precision: 0.7681 - recall: 0.8013\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 553ms/step - accuracy: 0.7774 - auc: 0.8581 - f1_score: 0.7788 - loss: 0.4868 - precision: 0.7679 - recall: 0.8011 - val_accuracy: 0.4722 - val_auc: 0.9157 - val_f1_score: 0.4889 - val_loss: 0.7166 - val_precision: 0.4722 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 258ms/step - accuracy: 0.7736 - auc: 0.8519 - f1_score: 0.7721 - loss: 0.4979 - precision: 0.7655 - recall: 0.7838 - val_accuracy: 0.5278 - val_auc: 0.9335 - val_f1_score: 0.5630 - val_loss: 0.6484 - val_precision: 0.5278 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 8/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 404ms/step - accuracy: 0.7730 - auc: 0.8513 - f1_score: 0.7752 - loss: 0.5058 - precision: 0.7693 - recall: 0.7881 - val_accuracy: 0.5486 - val_auc: 0.9353 - val_f1_score: 0.5641 - val_loss: 0.6116 - val_precision: 0.5390 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 9/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 406ms/step - accuracy: 0.7879 - auc: 0.8653 - f1_score: 0.7795 - loss: 0.4761 - precision: 0.7696 - recall: 0.7984 - val_accuracy: 0.4965 - val_auc: 0.9436 - val_f1_score: 0.5044 - val_loss: 0.6350 - val_precision: 0.4840 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 496ms/step - accuracy: 0.7756 - auc: 0.8556 - f1_score: 0.7560 - loss: 0.5064 - precision: 0.7343 - recall: 0.7890 - val_accuracy: 0.5451 - val_auc: 0.9336 - val_f1_score: 0.5060 - val_loss: 0.5968 - val_precision: 0.5094 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 11/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 450ms/step - accuracy: 0.7807 - auc: 0.8594 - f1_score: 0.7831 - loss: 0.4925 - precision: 0.7896 - recall: 0.7819 - val_accuracy: 0.5938 - val_auc: 0.9408 - val_f1_score: 0.5018 - val_loss: 0.5801 - val_precision: 0.5375 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 12/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 457ms/step - accuracy: 0.7982 - auc: 0.8822 - f1_score: 0.7984 - loss: 0.4362 - precision: 0.8191 - recall: 0.7839 - val_accuracy: 0.7535 - val_auc: 0.9329 - val_f1_score: 0.6064 - val_loss: 0.5098 - val_precision: 0.6816 - val_recall: 1.0000 - learning_rate: 5.0000e-04\n",
      "Epoch 13/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 456ms/step - accuracy: 0.7665 - auc: 0.8482 - f1_score: 0.7694 - loss: 0.5065 - precision: 0.7792 - recall: 0.7687 - val_accuracy: 0.7639 - val_auc: 0.9334 - val_f1_score: 0.6019 - val_loss: 0.4819 - val_precision: 0.6927 - val_recall: 0.9934 - learning_rate: 5.0000e-04\n",
      "Epoch 14/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 402ms/step - accuracy: 0.7877 - auc: 0.8853 - f1_score: 0.7895 - loss: 0.4279 - precision: 0.7975 - recall: 0.7817 - val_accuracy: 0.7778 - val_auc: 0.9432 - val_f1_score: 0.5226 - val_loss: 0.4871 - val_precision: 0.6837 - val_recall: 0.9853 - learning_rate: 5.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 466ms/step - accuracy: 0.8151 - auc: 0.8859 - f1_score: 0.8069 - loss: 0.4274 - precision: 0.7994 - recall: 0.8336 - val_accuracy: 0.8056 - val_auc: 0.9443 - val_f1_score: 0.5235 - val_loss: 0.4481 - val_precision: 0.7151 - val_recall: 0.9779 - learning_rate: 5.0000e-04\n",
      "Epoch 16/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 444ms/step - accuracy: 0.7978 - auc: 0.8813 - f1_score: 0.7956 - loss: 0.4452 - precision: 0.7723 - recall: 0.8273 - val_accuracy: 0.8611 - val_auc: 0.9456 - val_f1_score: 0.5210 - val_loss: 0.3955 - val_precision: 0.7857 - val_recall: 0.9706 - learning_rate: 5.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 431ms/step - accuracy: 0.7951 - auc: 0.8783 - f1_score: 0.7965 - loss: 0.4504 - precision: 0.8085 - recall: 0.7949 - val_accuracy: 0.8646 - val_auc: 0.9418 - val_f1_score: 0.6022 - val_loss: 0.3633 - val_precision: 0.8229 - val_recall: 0.9474 - learning_rate: 5.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 425ms/step - accuracy: 0.8220 - auc: 0.8846 - f1_score: 0.8195 - loss: 0.4348 - precision: 0.8188 - recall: 0.8213 - val_accuracy: 0.8472 - val_auc: 0.9377 - val_f1_score: 0.6015 - val_loss: 0.3520 - val_precision: 0.7967 - val_recall: 0.9539 - learning_rate: 5.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 454ms/step - accuracy: 0.8024 - auc: 0.8854 - f1_score: 0.7967 - loss: 0.4453 - precision: 0.7677 - recall: 0.8351 - val_accuracy: 0.8472 - val_auc: 0.9411 - val_f1_score: 0.5244 - val_loss: 0.3589 - val_precision: 0.7738 - val_recall: 0.9559 - learning_rate: 5.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 412ms/step - accuracy: 0.8055 - auc: 0.8805 - f1_score: 0.8057 - loss: 0.4537 - precision: 0.8004 - recall: 0.8104 - val_accuracy: 0.8646 - val_auc: 0.9439 - val_f1_score: 0.5155 - val_loss: 0.3315 - val_precision: 0.8089 - val_recall: 0.9338 - learning_rate: 5.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 411ms/step - accuracy: 0.7891 - auc: 0.8629 - f1_score: 0.7907 - loss: 0.4684 - precision: 0.8020 - recall: 0.7827 - val_accuracy: 0.8368 - val_auc: 0.9394 - val_f1_score: 0.5014 - val_loss: 0.3423 - val_precision: 0.7730 - val_recall: 0.9265 - learning_rate: 5.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 447ms/step - accuracy: 0.8207 - auc: 0.8945 - f1_score: 0.8203 - loss: 0.4100 - precision: 0.8008 - recall: 0.8454 - val_accuracy: 0.8646 - val_auc: 0.9423 - val_f1_score: 0.6004 - val_loss: 0.3221 - val_precision: 0.8266 - val_recall: 0.9408 - learning_rate: 5.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 427ms/step - accuracy: 0.8036 - auc: 0.8776 - f1_score: 0.8005 - loss: 0.4504 - precision: 0.7916 - recall: 0.8132 - val_accuracy: 0.8646 - val_auc: 0.9449 - val_f1_score: 0.6023 - val_loss: 0.3148 - val_precision: 0.8266 - val_recall: 0.9408 - learning_rate: 5.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 410ms/step - accuracy: 0.8367 - auc: 0.9036 - f1_score: 0.8365 - loss: 0.4012 - precision: 0.8177 - recall: 0.8558 - val_accuracy: 0.8576 - val_auc: 0.9460 - val_f1_score: 0.5173 - val_loss: 0.3148 - val_precision: 0.7987 - val_recall: 0.9338 - learning_rate: 5.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 424ms/step - accuracy: 0.7883 - auc: 0.8773 - f1_score: 0.7903 - loss: 0.4448 - precision: 0.7913 - recall: 0.7903 - val_accuracy: 0.8438 - val_auc: 0.9430 - val_f1_score: 0.5150 - val_loss: 0.3418 - val_precision: 0.7791 - val_recall: 0.9338 - learning_rate: 5.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8200 - auc: 0.9035 - f1_score: 0.8200 - loss: 0.3891 - precision: 0.8209 - recall: 0.8241\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 411ms/step - accuracy: 0.8196 - auc: 0.9031 - f1_score: 0.8196 - loss: 0.3898 - precision: 0.8203 - recall: 0.8238 - val_accuracy: 0.8542 - val_auc: 0.9434 - val_f1_score: 0.5140 - val_loss: 0.3359 - val_precision: 0.7866 - val_recall: 0.9485 - learning_rate: 5.0000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 405ms/step - accuracy: 0.8256 - auc: 0.9049 - f1_score: 0.8189 - loss: 0.3970 - precision: 0.7953 - recall: 0.8513 - val_accuracy: 0.8438 - val_auc: 0.9380 - val_f1_score: 0.6023 - val_loss: 0.3408 - val_precision: 0.7989 - val_recall: 0.9408 - learning_rate: 2.5000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 405ms/step - accuracy: 0.7906 - auc: 0.8705 - f1_score: 0.7967 - loss: 0.4539 - precision: 0.7775 - recall: 0.8208 - val_accuracy: 0.8576 - val_auc: 0.9392 - val_f1_score: 0.6023 - val_loss: 0.3306 - val_precision: 0.8171 - val_recall: 0.9408 - learning_rate: 2.5000e-04\n",
      "Training time: 450.42 seconds\n",
      "Evaluating MobileNetV3Small on DeepFire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 127ms/step - accuracy: 0.8478 - auc: 0.5879 - f1_score: 0.2497 - loss: 0.3132 - precision: 0.4713 - recall: 0.5503  \n",
      "Training results for MobileNetV3Small on DeepFire:\n",
      "{'class_weights': {0: 1.0, 1: 1.0},\n",
      " 'evaluation': {'accuracy': 0.8515625,\n",
      "                'auc': 0.939755380153656,\n",
      "                'f1_score': 0.5244348645210266,\n",
      "                'loss': 0.31233659386634827,\n",
      "                'precision': 0.8522167205810547,\n",
      "                'recall': 0.8650000095367432},\n",
      " 'history': {'accuracy': [0.6694079041481018,\n",
      "                          0.7417762875556946,\n",
      "                          0.7516447305679321,\n",
      "                          0.7779605388641357,\n",
      "                          0.7680920958518982,\n",
      "                          0.7697368264198303,\n",
      "                          0.7763158082962036,\n",
      "                          0.7911184430122375,\n",
      "                          0.7845394611358643,\n",
      "                          0.78125,\n",
      "                          0.7787829041481018,\n",
      "                          0.7886512875556946,\n",
      "                          0.7722039222717285,\n",
      "                          0.7902960777282715,\n",
      "                          0.8174341917037964,\n",
      "                          0.7976973652839661,\n",
      "                          0.8067434430122375,\n",
      "                          0.8100329041481018,\n",
      "                          0.8059210777282715,\n",
      "                          0.7944079041481018,\n",
      "                          0.7927631735801697,\n",
      "                          0.8034539222717285,\n",
      "                          0.8034539222717285,\n",
      "                          0.8223684430122375,\n",
      "                          0.7993420958518982,\n",
      "                          0.8042762875556946,\n",
      "                          0.8157894611358643,\n",
      "                          0.8026315569877625],\n",
      "             'auc': [0.7357845306396484,\n",
      "                     0.8105117082595825,\n",
      "                     0.8248246908187866,\n",
      "                     0.8482784628868103,\n",
      "                     0.8448929190635681,\n",
      "                     0.8499677777290344,\n",
      "                     0.8555675148963928,\n",
      "                     0.8708422183990479,\n",
      "                     0.8658565878868103,\n",
      "                     0.8637384176254272,\n",
      "                     0.8514475226402283,\n",
      "                     0.8707299828529358,\n",
      "                     0.8534520268440247,\n",
      "                     0.8790820837020874,\n",
      "                     0.8904193639755249,\n",
      "                     0.8796447515487671,\n",
      "                     0.8768449425697327,\n",
      "                     0.884975254535675,\n",
      "                     0.8805199265480042,\n",
      "                     0.8753286600112915,\n",
      "                     0.8663746118545532,\n",
      "                     0.8786222338676453,\n",
      "                     0.8819577097892761,\n",
      "                     0.8902286887168884,\n",
      "                     0.8817669749259949,\n",
      "                     0.8906682729721069,\n",
      "                     0.8947354555130005,\n",
      "                     0.8788724541664124],\n",
      "             'f1_score': [0.6522228717803955,\n",
      "                          0.7371630668640137,\n",
      "                          0.7544147968292236,\n",
      "                          0.7773886322975159,\n",
      "                          0.7651717066764832,\n",
      "                          0.7704813480377197,\n",
      "                          0.7759661674499512,\n",
      "                          0.7920727729797363,\n",
      "                          0.7828018665313721,\n",
      "                          0.7793510556221008,\n",
      "                          0.7763931751251221,\n",
      "                          0.7861234545707703,\n",
      "                          0.7710164189338684,\n",
      "                          0.7901511192321777,\n",
      "                          0.8149650692939758,\n",
      "                          0.7961572408676147,\n",
      "                          0.8037241101264954,\n",
      "                          0.8086458444595337,\n",
      "                          0.8042752742767334,\n",
      "                          0.7931633591651917,\n",
      "                          0.7907364964485168,\n",
      "                          0.8069645166397095,\n",
      "                          0.8022158145904541,\n",
      "                          0.8234307169914246,\n",
      "                          0.7989065647125244,\n",
      "                          0.8032376170158386,\n",
      "                          0.8161044716835022,\n",
      "                          0.8043840527534485],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628],\n",
      "             'loss': [0.7338815927505493,\n",
      "                      0.578627347946167,\n",
      "                      0.5602507591247559,\n",
      "                      0.5199238657951355,\n",
      "                      0.5286567807197571,\n",
      "                      0.507048487663269,\n",
      "                      0.48877495527267456,\n",
      "                      0.4603365361690521,\n",
      "                      0.4716568887233734,\n",
      "                      0.4844421446323395,\n",
      "                      0.5046274662017822,\n",
      "                      0.4648539423942566,\n",
      "                      0.493843138217926,\n",
      "                      0.44410333037376404,\n",
      "                      0.4214421212673187,\n",
      "                      0.44466185569763184,\n",
      "                      0.4549248218536377,\n",
      "                      0.4342125952243805,\n",
      "                      0.4506184458732605,\n",
      "                      0.45944494009017944,\n",
      "                      0.464774489402771,\n",
      "                      0.4439030587673187,\n",
      "                      0.43882516026496887,\n",
      "                      0.42425280809402466,\n",
      "                      0.4385523498058319,\n",
      "                      0.4175195097923279,\n",
      "                      0.41315436363220215,\n",
      "                      0.43934014439582825],\n",
      "             'precision': [0.6911581754684448,\n",
      "                           0.7483108043670654,\n",
      "                           0.7413249015808105,\n",
      "                           0.7734627723693848,\n",
      "                           0.7680920958518982,\n",
      "                           0.7570533156394958,\n",
      "                           0.7709677219390869,\n",
      "                           0.7791798114776611,\n",
      "                           0.7826797366142273,\n",
      "                           0.779411792755127,\n",
      "                           0.777414083480835,\n",
      "                           0.7891268730163574,\n",
      "                           0.7682333588600159,\n",
      "                           0.7888706922531128,\n",
      "                           0.8053797483444214,\n",
      "                           0.7938311696052551,\n",
      "                           0.8003220558166504,\n",
      "                           0.8115702271461487,\n",
      "                           0.8059210777282715,\n",
      "                           0.7953795194625854,\n",
      "                           0.7918033003807068,\n",
      "                           0.7896389365196228,\n",
      "                           0.7971014380455017,\n",
      "                           0.8161290287971497,\n",
      "                           0.7983606457710266,\n",
      "                           0.7983871102333069,\n",
      "                           0.807692289352417,\n",
      "                           0.7929936051368713],\n",
      "             'recall': [0.6868811845779419,\n",
      "                        0.7286184430122375,\n",
      "                        0.7730262875556946,\n",
      "                        0.7861841917037964,\n",
      "                        0.7680920958518982,\n",
      "                        0.7944079041481018,\n",
      "                        0.7861841917037964,\n",
      "                        0.8125,\n",
      "                        0.7878289222717285,\n",
      "                        0.7845394611358643,\n",
      "                        0.78125,\n",
      "                        0.7878289222717285,\n",
      "                        0.7796052694320679,\n",
      "                        0.7927631735801697,\n",
      "                        0.8371710777282715,\n",
      "                        0.8042762875556946,\n",
      "                        0.8174341917037964,\n",
      "                        0.8075658082962036,\n",
      "                        0.8059210777282715,\n",
      "                        0.7927631735801697,\n",
      "                        0.7944079041481018,\n",
      "                        0.8273026347160339,\n",
      "                        0.8141447305679321,\n",
      "                        0.8322368264198303,\n",
      "                        0.8009868264198303,\n",
      "                        0.8141447305679321,\n",
      "                        0.8289473652839661,\n",
      "                        0.8190789222717285],\n",
      "             'val_accuracy': [0.4722222089767456,\n",
      "                              0.5277777910232544,\n",
      "                              0.5277777910232544,\n",
      "                              0.4722222089767456,\n",
      "                              0.4722222089767456,\n",
      "                              0.4722222089767456,\n",
      "                              0.5277777910232544,\n",
      "                              0.5486111044883728,\n",
      "                              0.4965277910232544,\n",
      "                              0.5451388955116272,\n",
      "                              0.59375,\n",
      "                              0.7534722089767456,\n",
      "                              0.7638888955116272,\n",
      "                              0.7777777910232544,\n",
      "                              0.8055555820465088,\n",
      "                              0.8611111044883728,\n",
      "                              0.8645833134651184,\n",
      "                              0.8472222089767456,\n",
      "                              0.8472222089767456,\n",
      "                              0.8645833134651184,\n",
      "                              0.8368055820465088,\n",
      "                              0.8645833134651184,\n",
      "                              0.8645833134651184,\n",
      "                              0.8576388955116272,\n",
      "                              0.84375,\n",
      "                              0.8541666865348816,\n",
      "                              0.84375,\n",
      "                              0.8576388955116272],\n",
      "             'val_auc': [0.8377273678779602,\n",
      "                         0.899888813495636,\n",
      "                         0.9156347513198853,\n",
      "                         0.9207382202148438,\n",
      "                         0.8094040155410767,\n",
      "                         0.9156830310821533,\n",
      "                         0.933509111404419,\n",
      "                         0.935347318649292,\n",
      "                         0.9435951709747314,\n",
      "                         0.9336299896240234,\n",
      "                         0.9408378601074219,\n",
      "                         0.9329286217689514,\n",
      "                         0.9334123134613037,\n",
      "                         0.9432082176208496,\n",
      "                         0.944296658039093,\n",
      "                         0.945626974105835,\n",
      "                         0.941781222820282,\n",
      "                         0.9377176761627197,\n",
      "                         0.9411280751228333,\n",
      "                         0.9438612461090088,\n",
      "                         0.9394108057022095,\n",
      "                         0.9423132538795471,\n",
      "                         0.9448770880699158,\n",
      "                         0.9459655284881592,\n",
      "                         0.9429905414581299,\n",
      "                         0.9434016942977905,\n",
      "                         0.9379836916923523,\n",
      "                         0.9392415285110474],\n",
      "             'val_f1_score': [0.4888888895511627,\n",
      "                              0.5629629492759705,\n",
      "                              0.5629629492759705,\n",
      "                              0.5026454925537109,\n",
      "                              0.5026454925537109,\n",
      "                              0.4888888895511627,\n",
      "                              0.5629629492759705,\n",
      "                              0.5641025304794312,\n",
      "                              0.5043771266937256,\n",
      "                              0.5059531331062317,\n",
      "                              0.5017921328544617,\n",
      "                              0.6063951849937439,\n",
      "                              0.6018723249435425,\n",
      "                              0.522598922252655,\n",
      "                              0.5235211849212646,\n",
      "                              0.5209678411483765,\n",
      "                              0.602183997631073,\n",
      "                              0.6014969944953918,\n",
      "                              0.5243833065032959,\n",
      "                              0.5154721736907959,\n",
      "                              0.5013725161552429,\n",
      "                              0.6004202961921692,\n",
      "                              0.6022700667381287,\n",
      "                              0.5173218846321106,\n",
      "                              0.5149511098861694,\n",
      "                              0.5140005946159363,\n",
      "                              0.6022700667381287,\n",
      "                              0.6022700667381287],\n",
      "             'val_loss': [0.7065853476524353,\n",
      "                          0.6756850481033325,\n",
      "                          0.6724814176559448,\n",
      "                          0.6934831738471985,\n",
      "                          0.7302843332290649,\n",
      "                          0.7166095972061157,\n",
      "                          0.6483748555183411,\n",
      "                          0.6115567684173584,\n",
      "                          0.635001540184021,\n",
      "                          0.5967836976051331,\n",
      "                          0.580085039138794,\n",
      "                          0.5098005533218384,\n",
      "                          0.48194074630737305,\n",
      "                          0.4870712459087372,\n",
      "                          0.44813692569732666,\n",
      "                          0.3954608142375946,\n",
      "                          0.3632920980453491,\n",
      "                          0.35203462839126587,\n",
      "                          0.35891783237457275,\n",
      "                          0.3314912021160126,\n",
      "                          0.3423449695110321,\n",
      "                          0.32205310463905334,\n",
      "                          0.3147953748703003,\n",
      "                          0.3148442804813385,\n",
      "                          0.3418170213699341,\n",
      "                          0.33594033122062683,\n",
      "                          0.34078505635261536,\n",
      "                          0.3306015431880951],\n",
      "             'val_precision': [0.4722222089767456,\n",
      "                               0.5277777910232544,\n",
      "                               0.5277777910232544,\n",
      "                               0.4722222089767456,\n",
      "                               0.4722222089767456,\n",
      "                               0.4722222089767456,\n",
      "                               0.5277777910232544,\n",
      "                               0.5390070676803589,\n",
      "                               0.4839857518672943,\n",
      "                               0.5093632936477661,\n",
      "                               0.5375494360923767,\n",
      "                               0.681614339351654,\n",
      "                               0.6926605701446533,\n",
      "                               0.6836734414100647,\n",
      "                               0.7150537371635437,\n",
      "                               0.7857142686843872,\n",
      "                               0.822857141494751,\n",
      "                               0.7967032790184021,\n",
      "                               0.773809552192688,\n",
      "                               0.808917224407196,\n",
      "                               0.7730061411857605,\n",
      "                               0.8265895843505859,\n",
      "                               0.8265895843505859,\n",
      "                               0.7987421154975891,\n",
      "                               0.7791411280632019,\n",
      "                               0.7865853905677795,\n",
      "                               0.7988826632499695,\n",
      "                               0.8171428442001343],\n",
      "             'val_recall': [1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            0.9934210777282715,\n",
      "                            0.9852941036224365,\n",
      "                            0.9779411554336548,\n",
      "                            0.970588207244873,\n",
      "                            0.9473684430122375,\n",
      "                            0.9539473652839661,\n",
      "                            0.9558823704719543,\n",
      "                            0.9338235259056091,\n",
      "                            0.9264705777168274,\n",
      "                            0.9407894611358643,\n",
      "                            0.9407894611358643,\n",
      "                            0.9338235259056091,\n",
      "                            0.9338235259056091,\n",
      "                            0.9485294222831726,\n",
      "                            0.9407894611358643,\n",
      "                            0.9407894611358643]},\n",
      " 'optimal_threshold': 0.36477354168891907,\n",
      " 'train_counts': {'fire': 608, 'nofire': 608},\n",
      " 'train_counts_total': 1216,\n",
      " 'train_dataset_size': 1216,\n",
      " 'training_time': 450.417649269104,\n",
      " 'val_counts': {'fire': 152, 'nofire': 152},\n",
      " 'val_counts_total': 304,\n",
      " 'val_dataset_size': 288}\n",
      "Training model: MobileNetV3Small on dataset: The Wildfire Dataset_DeepFire\n",
      "Class weights: {0: 1.1595665171898355, 1: 0.8790368271954674}\n",
      "Epoch 1/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 456ms/step - accuracy: 0.5878 - auc: 0.7307 - f1_score: 0.6196 - loss: 0.8598 - precision: 0.7460 - recall: 0.6507 - val_accuracy: 0.6023 - val_auc: 0.7484 - val_f1_score: 0.6210 - val_loss: 0.6729 - val_precision: 0.6023 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 398ms/step - accuracy: 0.6297 - auc: 0.6811 - f1_score: 0.6809 - loss: 0.7199 - precision: 0.7270 - recall: 0.6499 - val_accuracy: 0.5568 - val_auc: 0.7662 - val_f1_score: 0.5756 - val_loss: 0.7098 - val_precision: 0.5568 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 412ms/step - accuracy: 0.6756 - auc: 0.7352 - f1_score: 0.7217 - loss: 0.6401 - precision: 0.7401 - recall: 0.7088 - val_accuracy: 0.5568 - val_auc: 0.7771 - val_f1_score: 0.5756 - val_loss: 0.6658 - val_precision: 0.5568 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 279ms/step - accuracy: 0.6796 - auc: 0.7427 - f1_score: 0.7249 - loss: 0.6219 - precision: 0.7561 - recall: 0.7045 - val_accuracy: 0.5909 - val_auc: 0.8020 - val_f1_score: 0.5694 - val_loss: 0.6215 - val_precision: 0.5788 - val_recall: 0.9745 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.6736 - auc: 0.7385 - f1_score: 0.7245 - loss: 0.6036 - precision: 0.7516 - recall: 0.7069 - val_accuracy: 0.7429 - val_auc: 0.8088 - val_f1_score: 0.4847 - val_loss: 0.5940 - val_precision: 0.8149 - val_recall: 0.6964 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - accuracy: 0.6751 - auc: 0.7530 - f1_score: 0.7190 - loss: 0.5865 - precision: 0.7775 - recall: 0.6735 - val_accuracy: 0.7557 - val_auc: 0.8239 - val_f1_score: 0.5349 - val_loss: 0.5633 - val_precision: 0.7546 - val_recall: 0.8316 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 217ms/step - accuracy: 0.7069 - auc: 0.7600 - f1_score: 0.7529 - loss: 0.5785 - precision: 0.7734 - recall: 0.7368 - val_accuracy: 0.7443 - val_auc: 0.8100 - val_f1_score: 0.6126 - val_loss: 0.5468 - val_precision: 0.8720 - val_recall: 0.7398 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 220ms/step - accuracy: 0.6970 - auc: 0.7645 - f1_score: 0.7458 - loss: 0.5702 - precision: 0.7677 - recall: 0.7313 - val_accuracy: 0.7571 - val_auc: 0.8167 - val_f1_score: 0.6231 - val_loss: 0.5287 - val_precision: 0.8729 - val_recall: 0.7602 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 211ms/step - accuracy: 0.6959 - auc: 0.7706 - f1_score: 0.7384 - loss: 0.5697 - precision: 0.7703 - recall: 0.7144 - val_accuracy: 0.7301 - val_auc: 0.7856 - val_f1_score: 0.6438 - val_loss: 0.5513 - val_precision: 0.8356 - val_recall: 0.7642 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 219ms/step - accuracy: 0.7003 - auc: 0.7717 - f1_score: 0.7393 - loss: 0.5662 - precision: 0.7718 - recall: 0.7139 - val_accuracy: 0.7628 - val_auc: 0.8147 - val_f1_score: 0.6474 - val_loss: 0.5220 - val_precision: 0.8770 - val_recall: 0.7683 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.7299 - auc: 0.7918 - f1_score: 0.7711 - loss: 0.5466 - precision: 0.8046 - recall: 0.7437 - val_accuracy: 0.7827 - val_auc: 0.8427 - val_f1_score: 0.6549 - val_loss: 0.4767 - val_precision: 0.8587 - val_recall: 0.8217 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 213ms/step - accuracy: 0.7064 - auc: 0.7724 - f1_score: 0.7559 - loss: 0.5575 - precision: 0.7842 - recall: 0.7326 - val_accuracy: 0.7926 - val_auc: 0.8378 - val_f1_score: 0.6628 - val_loss: 0.4896 - val_precision: 0.8701 - val_recall: 0.8238 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7308 - auc: 0.7901 - f1_score: 0.7672 - loss: 0.5463 - precision: 0.7902 - recall: 0.7511 - val_accuracy: 0.7955 - val_auc: 0.8525 - val_f1_score: 0.6600 - val_loss: 0.4756 - val_precision: 0.8839 - val_recall: 0.8115 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 206ms/step - accuracy: 0.7206 - auc: 0.8004 - f1_score: 0.7618 - loss: 0.5293 - precision: 0.7948 - recall: 0.7352 - val_accuracy: 0.7812 - val_auc: 0.8413 - val_f1_score: 0.6435 - val_loss: 0.4980 - val_precision: 0.8995 - val_recall: 0.7705 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - accuracy: 0.7228 - auc: 0.7958 - f1_score: 0.7628 - loss: 0.5370 - precision: 0.8113 - recall: 0.7240 - val_accuracy: 0.7528 - val_auc: 0.8284 - val_f1_score: 0.6197 - val_loss: 0.5193 - val_precision: 0.8905 - val_recall: 0.7336 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.7180 - auc: 0.7867 - f1_score: 0.7590 - loss: 0.5483 - precision: 0.7843 - recall: 0.7403\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 212ms/step - accuracy: 0.7180 - auc: 0.7867 - f1_score: 0.7590 - loss: 0.5483 - precision: 0.7843 - recall: 0.7403 - val_accuracy: 0.7571 - val_auc: 0.8403 - val_f1_score: 0.6263 - val_loss: 0.5163 - val_precision: 0.9054 - val_recall: 0.7254 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 214ms/step - accuracy: 0.7190 - auc: 0.7900 - f1_score: 0.7610 - loss: 0.5408 - precision: 0.8068 - recall: 0.7214 - val_accuracy: 0.7855 - val_auc: 0.8510 - val_f1_score: 0.6031 - val_loss: 0.4913 - val_precision: 0.8861 - val_recall: 0.7675 - learning_rate: 5.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 235ms/step - accuracy: 0.7208 - auc: 0.8058 - f1_score: 0.7576 - loss: 0.5225 - precision: 0.8191 - recall: 0.7098 - val_accuracy: 0.7983 - val_auc: 0.8555 - val_f1_score: 0.6119 - val_loss: 0.4782 - val_precision: 0.8774 - val_recall: 0.8004 - learning_rate: 5.0000e-04\n",
      "Training time: 441.19 seconds\n",
      "Evaluating MobileNetV3Small on The Wildfire Dataset_DeepFire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.6482 - auc: 0.4857 - f1_score: 0.2447 - loss: 0.8003 - precision: 0.3478 - recall: 0.5411         \n",
      "Training results for MobileNetV3Small on The Wildfire Dataset_DeepFire:\n",
      "{'class_weights': {0: 1.1595665171898355, 1: 0.8790368271954674},\n",
      " 'evaluation': {'accuracy': 0.7213541865348816,\n",
      "                'auc': 0.7683016657829285,\n",
      "                'f1_score': 0.509790301322937,\n",
      "                'loss': 0.6348443627357483,\n",
      "                'precision': 0.6882591247558594,\n",
      "                'recall': 0.8500000238418579},\n",
      " 'history': {'accuracy': [0.6263020634651184,\n",
      "                          0.6481119990348816,\n",
      "                          0.6627604365348816,\n",
      "                          0.6783854365348816,\n",
      "                          0.6780598759651184,\n",
      "                          0.6875,\n",
      "                          0.7041015625,\n",
      "                          0.7060546875,\n",
      "                          0.6956380009651184,\n",
      "                          0.7005208134651184,\n",
      "                          0.7281901240348816,\n",
      "                          0.6985676884651184,\n",
      "                          0.720703125,\n",
      "                          0.7229817509651184,\n",
      "                          0.716796875,\n",
      "                          0.720703125,\n",
      "                          0.7298176884651184,\n",
      "                          0.7164713740348816],\n",
      "             'auc': [0.7046999335289001,\n",
      "                     0.69947749376297,\n",
      "                     0.7186853885650635,\n",
      "                     0.7419186234474182,\n",
      "                     0.7409394979476929,\n",
      "                     0.758712112903595,\n",
      "                     0.7652629017829895,\n",
      "                     0.7714309692382812,\n",
      "                     0.7647599577903748,\n",
      "                     0.7740445733070374,\n",
      "                     0.7882443070411682,\n",
      "                     0.7645841240882874,\n",
      "                     0.78815758228302,\n",
      "                     0.7965391874313354,\n",
      "                     0.7853357791900635,\n",
      "                     0.7883950471878052,\n",
      "                     0.7956132888793945,\n",
      "                     0.7977273464202881],\n",
      "             'f1_score': [0.665411651134491,\n",
      "                          0.6976735591888428,\n",
      "                          0.7106389403343201,\n",
      "                          0.7239810824394226,\n",
      "                          0.7238100171089172,\n",
      "                          0.7301390767097473,\n",
      "                          0.749652624130249,\n",
      "                          0.7521042823791504,\n",
      "                          0.7402291893959045,\n",
      "                          0.7405857443809509,\n",
      "                          0.7684661746025085,\n",
      "                          0.7434733510017395,\n",
      "                          0.7617961764335632,\n",
      "                          0.7638646960258484,\n",
      "                          0.7580678462982178,\n",
      "                          0.7616173624992371,\n",
      "                          0.7663657665252686,\n",
      "                          0.7555744647979736],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257],\n",
      "             'loss': [0.7818257808685303,\n",
      "                      0.6864877343177795,\n",
      "                      0.6495999097824097,\n",
      "                      0.6123982071876526,\n",
      "                      0.6108470559120178,\n",
      "                      0.5788286328315735,\n",
      "                      0.5724011063575745,\n",
      "                      0.5649833083152771,\n",
      "                      0.5722569227218628,\n",
      "                      0.5627864599227905,\n",
      "                      0.5507577061653137,\n",
      "                      0.566418468952179,\n",
      "                      0.5441908240318298,\n",
      "                      0.5367706418037415,\n",
      "                      0.5474523901939392,\n",
      "                      0.547152578830719,\n",
      "                      0.5391125082969666,\n",
      "                      0.5311370491981506],\n",
      "             'precision': [0.7371020913124084,\n",
      "                           0.7384259104728699,\n",
      "                           0.7365714311599731,\n",
      "                           0.7636469006538391,\n",
      "                           0.7461669445037842,\n",
      "                           0.7770588397979736,\n",
      "                           0.7756373882293701,\n",
      "                           0.7764114141464233,\n",
      "                           0.7729606628417969,\n",
      "                           0.7759022116661072,\n",
      "                           0.7965909242630005,\n",
      "                           0.7809248566627502,\n",
      "                           0.791121244430542,\n",
      "                           0.7903409004211426,\n",
      "                           0.7950631380081177,\n",
      "                           0.7867271900177002,\n",
      "                           0.8020954728126526,\n",
      "                           0.8092144131660461],\n",
      "             'recall': [0.6491058468818665,\n",
      "                        0.669816255569458,\n",
      "                        0.6915236115455627,\n",
      "                        0.6935654282569885,\n",
      "                        0.7079741358757019,\n",
      "                        0.6945320963859558,\n",
      "                        0.7274176478385925,\n",
      "                        0.7341437339782715,\n",
      "                        0.7161733508110046,\n",
      "                        0.7135974168777466,\n",
      "                        0.7461415529251099,\n",
      "                        0.7118018865585327,\n",
      "                        0.7389686107635498,\n",
      "                        0.7426588535308838,\n",
      "                        0.7297154664993286,\n",
      "                        0.7421081066131592,\n",
      "                        0.737687349319458,\n",
      "                        0.7142857313156128],\n",
      "             'val_accuracy': [0.6022727489471436,\n",
      "                              0.5568181872367859,\n",
      "                              0.5568181872367859,\n",
      "                              0.5909090638160706,\n",
      "                              0.7428977489471436,\n",
      "                              0.7556818127632141,\n",
      "                              0.7443181872367859,\n",
      "                              0.7571022510528564,\n",
      "                              0.7301136255264282,\n",
      "                              0.7627840638160706,\n",
      "                              0.7826704382896423,\n",
      "                              0.7926136255264282,\n",
      "                              0.7954545617103577,\n",
      "                              0.78125,\n",
      "                              0.7528409361839294,\n",
      "                              0.7571022510528564,\n",
      "                              0.7855113744735718,\n",
      "                              0.7982954382896423],\n",
      "             'val_auc': [0.7483533024787903,\n",
      "                         0.7661973237991333,\n",
      "                         0.7770718336105347,\n",
      "                         0.8019689321517944,\n",
      "                         0.8087633848190308,\n",
      "                         0.8239060044288635,\n",
      "                         0.8099954128265381,\n",
      "                         0.8167027235031128,\n",
      "                         0.7856362462043762,\n",
      "                         0.8146858811378479,\n",
      "                         0.842725396156311,\n",
      "                         0.8377827405929565,\n",
      "                         0.8525207042694092,\n",
      "                         0.8412644267082214,\n",
      "                         0.8284096121788025,\n",
      "                         0.8402920365333557,\n",
      "                         0.8510186672210693,\n",
      "                         0.8555063605308533],\n",
      "             'val_f1_score': [0.6210100650787354,\n",
      "                              0.5755555629730225,\n",
      "                              0.5755555629730225,\n",
      "                              0.5694142580032349,\n",
      "                              0.48467037081718445,\n",
      "                              0.5349258780479431,\n",
      "                              0.6125622391700745,\n",
      "                              0.623133659362793,\n",
      "                              0.6437798142433167,\n",
      "                              0.6473883986473083,\n",
      "                              0.6549135446548462,\n",
      "                              0.6627895832061768,\n",
      "                              0.6599605083465576,\n",
      "                              0.643505871295929,\n",
      "                              0.6197112202644348,\n",
      "                              0.6262819766998291,\n",
      "                              0.6030559539794922,\n",
      "                              0.6119217872619629],\n",
      "             'val_loss': [0.6729295253753662,\n",
      "                          0.7098045945167542,\n",
      "                          0.6657520532608032,\n",
      "                          0.6215300559997559,\n",
      "                          0.5940096974372864,\n",
      "                          0.5633289813995361,\n",
      "                          0.546846330165863,\n",
      "                          0.5286845564842224,\n",
      "                          0.5513374209403992,\n",
      "                          0.5219541192054749,\n",
      "                          0.47671687602996826,\n",
      "                          0.4896082580089569,\n",
      "                          0.475554496049881,\n",
      "                          0.498046875,\n",
      "                          0.5193234086036682,\n",
      "                          0.5163058042526245,\n",
      "                          0.49129340052604675,\n",
      "                          0.47818031907081604],\n",
      "             'val_precision': [0.6022727489471436,\n",
      "                               0.5568181872367859,\n",
      "                               0.5568181872367859,\n",
      "                               0.5787878632545471,\n",
      "                               0.8149253726005554,\n",
      "                               0.7546296119689941,\n",
      "                               0.8719806671142578,\n",
      "                               0.8729411959648132,\n",
      "                               0.8355555534362793,\n",
      "                               0.8770301342010498,\n",
      "                               0.8586723804473877,\n",
      "                               0.8701298832893372,\n",
      "                               0.8839285969734192,\n",
      "                               0.89952152967453,\n",
      "                               0.8905472755432129,\n",
      "                               0.905370831489563,\n",
      "                               0.8860759735107422,\n",
      "                               0.8774038553237915],\n",
      "             'val_recall': [1.0,\n",
      "                            1.0,\n",
      "                            1.0,\n",
      "                            0.9744898080825806,\n",
      "                            0.6964285969734192,\n",
      "                            0.831632673740387,\n",
      "                            0.7397540807723999,\n",
      "                            0.7602459192276001,\n",
      "                            0.7642276287078857,\n",
      "                            0.7682926654815674,\n",
      "                            0.8217213153839111,\n",
      "                            0.8237704634666443,\n",
      "                            0.811475396156311,\n",
      "                            0.7704917788505554,\n",
      "                            0.7336065769195557,\n",
      "                            0.7254098653793335,\n",
      "                            0.7675438523292542,\n",
      "                            0.8004385828971863]},\n",
      " 'optimal_threshold': 0.5983115434646606,\n",
      " 'train_counts': {'fire': 1338, 'nofire': 1765},\n",
      " 'train_counts_total': 3103,\n",
      " 'train_dataset_size': 3072,\n",
      " 'training_time': 441.1918640136719,\n",
      " 'val_counts': {'fire': 308, 'nofire': 398},\n",
      " 'val_counts_total': 706,\n",
      " 'val_dataset_size': 704}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MobileNetV2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MobileNetV2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,120</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ mobilenetv2_1.00_224            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │         \u001b[38;5;34m5,120\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m327,936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,592,321</span> (9.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,592,321\u001b[0m (9.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">331,265</span> (1.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m331,265\u001b[0m (1.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,261,056</span> (8.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,261,056\u001b[0m (8.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: MobileNetV2 on dataset: The Wildfire Dataset\n",
      "Class weights: {0: 1.2924657534246575, 1: 0.8154710458081245}\n",
      "Epoch 1/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 394ms/step - accuracy: 0.6892 - auc: 0.7620 - f1_score: 0.7146 - loss: 0.7188 - precision: 0.7630 - recall: 0.7182 - val_accuracy: 0.8307 - val_auc: 0.9000 - val_f1_score: 0.5930 - val_loss: 0.3983 - val_precision: 0.8622 - val_recall: 0.8509 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 338ms/step - accuracy: 0.7756 - auc: 0.8516 - f1_score: 0.8024 - loss: 0.5661 - precision: 0.8578 - recall: 0.7573 - val_accuracy: 0.8464 - val_auc: 0.9208 - val_f1_score: 0.5957 - val_loss: 0.3734 - val_precision: 0.8894 - val_recall: 0.8465 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 356ms/step - accuracy: 0.7653 - auc: 0.8592 - f1_score: 0.7948 - loss: 0.5214 - precision: 0.8498 - recall: 0.7492 - val_accuracy: 0.8594 - val_auc: 0.9315 - val_f1_score: 0.6248 - val_loss: 0.3431 - val_precision: 0.8398 - val_recall: 0.9430 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 374ms/step - accuracy: 0.7930 - auc: 0.8837 - f1_score: 0.8222 - loss: 0.4713 - precision: 0.8721 - recall: 0.7801 - val_accuracy: 0.8594 - val_auc: 0.9348 - val_f1_score: 0.6236 - val_loss: 0.3345 - val_precision: 0.8425 - val_recall: 0.9386 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 367ms/step - accuracy: 0.8142 - auc: 0.8941 - f1_score: 0.8415 - loss: 0.4207 - precision: 0.8737 - recall: 0.8150 - val_accuracy: 0.8646 - val_auc: 0.9318 - val_f1_score: 0.6149 - val_loss: 0.3321 - val_precision: 0.8826 - val_recall: 0.8904 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 350ms/step - accuracy: 0.8154 - auc: 0.8986 - f1_score: 0.8437 - loss: 0.4123 - precision: 0.8813 - recall: 0.8122 - val_accuracy: 0.8698 - val_auc: 0.9390 - val_f1_score: 0.6173 - val_loss: 0.3208 - val_precision: 0.8739 - val_recall: 0.9123 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 354ms/step - accuracy: 0.8173 - auc: 0.9047 - f1_score: 0.8420 - loss: 0.3985 - precision: 0.8871 - recall: 0.8062 - val_accuracy: 0.8724 - val_auc: 0.9480 - val_f1_score: 0.5956 - val_loss: 0.2970 - val_precision: 0.8714 - val_recall: 0.9211 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 344ms/step - accuracy: 0.7981 - auc: 0.8921 - f1_score: 0.8343 - loss: 0.4280 - precision: 0.8813 - recall: 0.7930 - val_accuracy: 0.8724 - val_auc: 0.9361 - val_f1_score: 0.6557 - val_loss: 0.3218 - val_precision: 0.8924 - val_recall: 0.9106 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 345ms/step - accuracy: 0.8387 - auc: 0.9139 - f1_score: 0.8601 - loss: 0.3824 - precision: 0.8896 - recall: 0.8320 - val_accuracy: 0.8958 - val_auc: 0.9444 - val_f1_score: 0.6618 - val_loss: 0.3065 - val_precision: 0.9364 - val_recall: 0.8984 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 354ms/step - accuracy: 0.8263 - auc: 0.9045 - f1_score: 0.8523 - loss: 0.3942 - precision: 0.8843 - recall: 0.8249 - val_accuracy: 0.8854 - val_auc: 0.9466 - val_f1_score: 0.6640 - val_loss: 0.2960 - val_precision: 0.8915 - val_recall: 0.9350 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 351ms/step - accuracy: 0.8138 - auc: 0.9035 - f1_score: 0.8399 - loss: 0.3998 - precision: 0.8942 - recall: 0.7944 - val_accuracy: 0.8854 - val_auc: 0.9403 - val_f1_score: 0.6612 - val_loss: 0.3063 - val_precision: 0.9040 - val_recall: 0.9187 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 350ms/step - accuracy: 0.8350 - auc: 0.9196 - f1_score: 0.8587 - loss: 0.3620 - precision: 0.8945 - recall: 0.8285 - val_accuracy: 0.8880 - val_auc: 0.9445 - val_f1_score: 0.6253 - val_loss: 0.3006 - val_precision: 0.9129 - val_recall: 0.9091 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.8190 - auc: 0.9131 - f1_score: 0.8436 - loss: 0.3750 - precision: 0.8852 - recall: 0.8087\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 352ms/step - accuracy: 0.8192 - auc: 0.9132 - f1_score: 0.8437 - loss: 0.3748 - precision: 0.8853 - recall: 0.8088 - val_accuracy: 0.8906 - val_auc: 0.9475 - val_f1_score: 0.6131 - val_loss: 0.2990 - val_precision: 0.9227 - val_recall: 0.8904 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 357ms/step - accuracy: 0.8454 - auc: 0.9326 - f1_score: 0.8701 - loss: 0.3264 - precision: 0.9189 - recall: 0.8290 - val_accuracy: 0.8906 - val_auc: 0.9481 - val_f1_score: 0.6139 - val_loss: 0.2969 - val_precision: 0.9189 - val_recall: 0.8947 - learning_rate: 5.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 370ms/step - accuracy: 0.8278 - auc: 0.9198 - f1_score: 0.8588 - loss: 0.3581 - precision: 0.8900 - recall: 0.8300 - val_accuracy: 0.8932 - val_auc: 0.9466 - val_f1_score: 0.6174 - val_loss: 0.3030 - val_precision: 0.9119 - val_recall: 0.9079 - learning_rate: 5.0000e-04\n",
      "Training time: 313.18 seconds\n",
      "Evaluating MobileNetV2 on The Wildfire Dataset...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 888ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 842ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 182ms/step - accuracy: 0.6992 - auc: 0.5447 - f1_score: 0.2480 - loss: 0.6184 - precision: 0.3773 - recall: 0.5443  \n",
      "Training results for MobileNetV2 on The Wildfire Dataset:\n",
      "{'class_weights': {0: 1.2924657534246575, 1: 0.8154710458081245},\n",
      " 'evaluation': {'accuracy': 0.78125,\n",
      "                'auc': 0.8848369717597961,\n",
      "                'f1_score': 0.5354744791984558,\n",
      "                'loss': 0.4584093987941742,\n",
      "                'precision': 0.7416666746139526,\n",
      "                'recall': 0.8899999856948853},\n",
      " 'history': {'accuracy': [0.7155172228813171,\n",
      "                          0.772090494632721,\n",
      "                          0.7677801847457886,\n",
      "                          0.7995689511299133,\n",
      "                          0.8098060488700867,\n",
      "                          0.8135775923728943,\n",
      "                          0.8238146305084229,\n",
      "                          0.8081896305084229,\n",
      "                          0.8254310488700867,\n",
      "                          0.8292025923728943,\n",
      "                          0.8135775923728943,\n",
      "                          0.8351293206214905,\n",
      "                          0.828125,\n",
      "                          0.850215494632721,\n",
      "                          0.8459051847457886],\n",
      "             'auc': [0.7840461134910583,\n",
      "                     0.8579847812652588,\n",
      "                     0.8551725149154663,\n",
      "                     0.8888939023017883,\n",
      "                     0.8926750421524048,\n",
      "                     0.8988243937492371,\n",
      "                     0.9047632217407227,\n",
      "                     0.8981510996818542,\n",
      "                     0.9087445735931396,\n",
      "                     0.9086596369743347,\n",
      "                     0.9064264297485352,\n",
      "                     0.92061847448349,\n",
      "                     0.9167153239250183,\n",
      "                     0.9302412271499634,\n",
      "                     0.9270942807197571],\n",
      "             'f1_score': [0.7421188950538635,\n",
      "                          0.8027024269104004,\n",
      "                          0.7985419631004333,\n",
      "                          0.8274598121643066,\n",
      "                          0.8346065878868103,\n",
      "                          0.8403820991516113,\n",
      "                          0.8485785722732544,\n",
      "                          0.8404310941696167,\n",
      "                          0.8492583632469177,\n",
      "                          0.854867696762085,\n",
      "                          0.8378250002861023,\n",
      "                          0.8575544953346252,\n",
      "                          0.8513875007629395,\n",
      "                          0.8704556226730347,\n",
      "                          0.8724201321601868],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257],\n",
      "             'loss': [0.693175733089447,\n",
      "                      0.5385851860046387,\n",
      "                      0.5325993299484253,\n",
      "                      0.4531603455543518,\n",
      "                      0.4236261546611786,\n",
      "                      0.41240590810775757,\n",
      "                      0.39852169156074524,\n",
      "                      0.409797728061676,\n",
      "                      0.3879302442073822,\n",
      "                      0.3843354880809784,\n",
      "                      0.38822418451309204,\n",
      "                      0.35848715901374817,\n",
      "                      0.36751383543014526,\n",
      "                      0.3332361578941345,\n",
      "                      0.34277892112731934],\n",
      "             'precision': [0.7994880676269531,\n",
      "                           0.8532019853591919,\n",
      "                           0.8453202247619629,\n",
      "                           0.8714975714683533,\n",
      "                           0.871524453163147,\n",
      "                           0.8791627287864685,\n",
      "                           0.8815165758132935,\n",
      "                           0.8807511925697327,\n",
      "                           0.8902912735939026,\n",
      "                           0.8843985199928284,\n",
      "                           0.8832046389579773,\n",
      "                           0.8890995383262634,\n",
      "                           0.8926174640655518,\n",
      "                           0.9100478291511536,\n",
      "                           0.9004608392715454],\n",
      "             'recall': [0.7008227109909058,\n",
      "                        0.7596490979194641,\n",
      "                        0.7579505443572998,\n",
      "                        0.7905346155166626,\n",
      "                        0.8058510422706604,\n",
      "                        0.808398962020874,\n",
      "                        0.8215547800064087,\n",
      "                        0.8037703633308411,\n",
      "                        0.8129432797431946,\n",
      "                        0.8290749192237854,\n",
      "                        0.8026315569877625,\n",
      "                        0.8322981595993042,\n",
      "                        0.8181019425392151,\n",
      "                        0.8378854393959045,\n",
      "                        0.8458874225616455],\n",
      "             'val_accuracy': [0.8307291865348816,\n",
      "                              0.8463541865348816,\n",
      "                              0.859375,\n",
      "                              0.859375,\n",
      "                              0.8645833134651184,\n",
      "                              0.8697916865348816,\n",
      "                              0.8723958134651184,\n",
      "                              0.8723958134651184,\n",
      "                              0.8958333134651184,\n",
      "                              0.8854166865348816,\n",
      "                              0.8854166865348816,\n",
      "                              0.8880208134651184,\n",
      "                              0.890625,\n",
      "                              0.890625,\n",
      "                              0.8932291865348816],\n",
      "             'val_auc': [0.8999943137168884,\n",
      "                         0.9207855463027954,\n",
      "                         0.9314552545547485,\n",
      "                         0.93482905626297,\n",
      "                         0.931764543056488,\n",
      "                         0.9390462636947632,\n",
      "                         0.948015034198761,\n",
      "                         0.9360640048980713,\n",
      "                         0.9444297552108765,\n",
      "                         0.9465506076812744,\n",
      "                         0.940335214138031,\n",
      "                         0.9444621801376343,\n",
      "                         0.9474808573722839,\n",
      "                         0.9481275081634521,\n",
      "                         0.9465671181678772],\n",
      "             'val_f1_score': [0.5929876565933228,\n",
      "                              0.59566730260849,\n",
      "                              0.624784529209137,\n",
      "                              0.6235646605491638,\n",
      "                              0.6149107813835144,\n",
      "                              0.6173296570777893,\n",
      "                              0.5956324934959412,\n",
      "                              0.6556999087333679,\n",
      "                              0.6617639660835266,\n",
      "                              0.6640400290489197,\n",
      "                              0.6611761450767517,\n",
      "                              0.6252620816230774,\n",
      "                              0.6130701899528503,\n",
      "                              0.6138847470283508,\n",
      "                              0.6174344420433044],\n",
      "             'val_loss': [0.3982514441013336,\n",
      "                          0.37343931198120117,\n",
      "                          0.3430967330932617,\n",
      "                          0.3345472514629364,\n",
      "                          0.33213093876838684,\n",
      "                          0.3207623064517975,\n",
      "                          0.29699787497520447,\n",
      "                          0.32180410623550415,\n",
      "                          0.3064957857131958,\n",
      "                          0.29598569869995117,\n",
      "                          0.3063230514526367,\n",
      "                          0.3005649745464325,\n",
      "                          0.29895663261413574,\n",
      "                          0.29686108231544495,\n",
      "                          0.30297961831092834],\n",
      "             'val_precision': [0.8622221946716309,\n",
      "                               0.8894008994102478,\n",
      "                               0.83984375,\n",
      "                               0.8425197005271912,\n",
      "                               0.8826087117195129,\n",
      "                               0.8739495873451233,\n",
      "                               0.8713693022727966,\n",
      "                               0.892430305480957,\n",
      "                               0.9364407062530518,\n",
      "                               0.8914728760719299,\n",
      "                               0.9039999842643738,\n",
      "                               0.9128630757331848,\n",
      "                               0.9227272868156433,\n",
      "                               0.9189189076423645,\n",
      "                               0.9118942618370056],\n",
      "             'val_recall': [0.8508771657943726,\n",
      "                            0.8464912176132202,\n",
      "                            0.9429824352264404,\n",
      "                            0.9385964870452881,\n",
      "                            0.890350878238678,\n",
      "                            0.9122806787490845,\n",
      "                            0.9210526347160339,\n",
      "                            0.9105691313743591,\n",
      "                            0.8983739614486694,\n",
      "                            0.934959352016449,\n",
      "                            0.9186992049217224,\n",
      "                            0.9090909361839294,\n",
      "                            0.890350878238678,\n",
      "                            0.8947368264198303,\n",
      "                            0.9078947305679321]},\n",
      " 'optimal_threshold': 0.5887654423713684,\n",
      " 'train_counts': {'fire': 730, 'nofire': 1157},\n",
      " 'train_counts_total': 1887,\n",
      " 'train_dataset_size': 1856,\n",
      " 'training_time': 313.18410873413086,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_counts_total': 402,\n",
      " 'val_dataset_size': 384}\n",
      "Training model: MobileNetV2 on dataset: DeepFire\n",
      "Class weights: {0: 1.0, 1: 1.0}\n",
      "Epoch 1/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 425ms/step - accuracy: 0.8194 - auc: 0.9019 - f1_score: 0.8187 - loss: 0.4398 - precision: 0.8067 - recall: 0.8588 - val_accuracy: 0.9306 - val_auc: 0.9855 - val_f1_score: 0.5275 - val_loss: 0.1780 - val_precision: 0.9559 - val_recall: 0.9028 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 330ms/step - accuracy: 0.9437 - auc: 0.9892 - f1_score: 0.9440 - loss: 0.1322 - precision: 0.9495 - recall: 0.9418 - val_accuracy: 0.9375 - val_auc: 0.9854 - val_f1_score: 0.5334 - val_loss: 0.1496 - val_precision: 0.9338 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 361ms/step - accuracy: 0.9621 - auc: 0.9927 - f1_score: 0.9609 - loss: 0.1060 - precision: 0.9513 - recall: 0.9718 - val_accuracy: 0.9653 - val_auc: 0.9902 - val_f1_score: 0.5388 - val_loss: 0.1144 - val_precision: 0.9701 - val_recall: 0.9559 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 369ms/step - accuracy: 0.9715 - auc: 0.9896 - f1_score: 0.9696 - loss: 0.1187 - precision: 0.9735 - recall: 0.9711 - val_accuracy: 0.9444 - val_auc: 0.9878 - val_f1_score: 0.5328 - val_loss: 0.1477 - val_precision: 0.9615 - val_recall: 0.9191 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 344ms/step - accuracy: 0.9410 - auc: 0.9855 - f1_score: 0.9405 - loss: 0.1619 - precision: 0.9486 - recall: 0.9343 - val_accuracy: 0.9583 - val_auc: 0.9899 - val_f1_score: 0.5366 - val_loss: 0.1400 - val_precision: 0.9769 - val_recall: 0.9338 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 358ms/step - accuracy: 0.9557 - auc: 0.9912 - f1_score: 0.9548 - loss: 0.1186 - precision: 0.9564 - recall: 0.9545 - val_accuracy: 0.9722 - val_auc: 0.9933 - val_f1_score: 0.5466 - val_loss: 0.1012 - val_precision: 0.9776 - val_recall: 0.9632 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 350ms/step - accuracy: 0.9666 - auc: 0.9943 - f1_score: 0.9650 - loss: 0.0807 - precision: 0.9649 - recall: 0.9669 - val_accuracy: 0.9583 - val_auc: 0.9940 - val_f1_score: 0.6486 - val_loss: 0.1133 - val_precision: 0.9795 - val_recall: 0.9408 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 359ms/step - accuracy: 0.9718 - auc: 0.9941 - f1_score: 0.9708 - loss: 0.0874 - precision: 0.9742 - recall: 0.9679 - val_accuracy: 0.9618 - val_auc: 0.9939 - val_f1_score: 0.6504 - val_loss: 0.1158 - val_precision: 0.9796 - val_recall: 0.9474 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.9763 - auc: 0.9957 - f1_score: 0.9753 - loss: 0.0684 - precision: 0.9780 - recall: 0.9745\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 353ms/step - accuracy: 0.9759 - auc: 0.9957 - f1_score: 0.9749 - loss: 0.0693 - precision: 0.9777 - recall: 0.9741 - val_accuracy: 0.9688 - val_auc: 0.9952 - val_f1_score: 0.6449 - val_loss: 0.1114 - val_precision: 0.9931 - val_recall: 0.9474 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 356ms/step - accuracy: 0.9533 - auc: 0.9913 - f1_score: 0.9546 - loss: 0.1287 - precision: 0.9633 - recall: 0.9470 - val_accuracy: 0.9653 - val_auc: 0.9946 - val_f1_score: 0.6504 - val_loss: 0.1204 - val_precision: 0.9863 - val_recall: 0.9474 - learning_rate: 5.0000e-04\n",
      "Epoch 11/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 367ms/step - accuracy: 0.9686 - auc: 0.9953 - f1_score: 0.9680 - loss: 0.0890 - precision: 0.9731 - recall: 0.9652 - val_accuracy: 0.9688 - val_auc: 0.9936 - val_f1_score: 0.5466 - val_loss: 0.1184 - val_precision: 0.9720 - val_recall: 0.9653 - learning_rate: 5.0000e-04\n",
      "Training time: 153.72 seconds\n",
      "Evaluating MobileNetV2 on DeepFire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 197ms/step - accuracy: 0.9797 - auc: 0.6124 - f1_score: 0.2658 - loss: 0.0796 - precision: 0.5859 - recall: 0.6085  \n",
      "Training results for MobileNetV2 on DeepFire:\n",
      "{'class_weights': {0: 1.0, 1: 1.0},\n",
      " 'evaluation': {'accuracy': 0.9765625,\n",
      "                'auc': 0.9949048757553101,\n",
      "                'f1_score': 0.5754744410514832,\n",
      "                'loss': 0.08750852942466736,\n",
      "                'precision': 0.9751243591308594,\n",
      "                'recall': 0.9800000190734863},\n",
      " 'history': {'accuracy': [0.8889802694320679,\n",
      "                          0.9449012875556946,\n",
      "                          0.9613487124443054,\n",
      "                          0.9621710777282715,\n",
      "                          0.9473684430122375,\n",
      "                          0.9597039222717285,\n",
      "                          0.9605262875556946,\n",
      "                          0.9703947305679321,\n",
      "                          0.9613487124443054,\n",
      "                          0.9580591917037964,\n",
      "                          0.9679276347160339],\n",
      "             'auc': [0.9435276985168457,\n",
      "                     0.9870858192443848,\n",
      "                     0.9911779165267944,\n",
      "                     0.9872443079948425,\n",
      "                     0.9882181882858276,\n",
      "                     0.9921794533729553,\n",
      "                     0.9895796775817871,\n",
      "                     0.9930489659309387,\n",
      "                     0.9926785826683044,\n",
      "                     0.9916023015975952,\n",
      "                     0.9957646131515503],\n",
      "             'f1_score': [0.8866531848907471,\n",
      "                          0.9448666572570801,\n",
      "                          0.9600410461425781,\n",
      "                          0.9578987956047058,\n",
      "                          0.9463983774185181,\n",
      "                          0.9586222767829895,\n",
      "                          0.960135281085968,\n",
      "                          0.9703571796417236,\n",
      "                          0.960089921951294,\n",
      "                          0.9580065011978149,\n",
      "                          0.9683537483215332],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257],\n",
      "             'loss': [0.2848537266254425,\n",
      "                      0.14978928864002228,\n",
      "                      0.11146751046180725,\n",
      "                      0.13539469242095947,\n",
      "                      0.14094102382659912,\n",
      "                      0.11385824531316757,\n",
      "                      0.11045700311660767,\n",
      "                      0.09123179316520691,\n",
      "                      0.10382073372602463,\n",
      "                      0.11297290027141571,\n",
      "                      0.08577976375818253],\n",
      "             'precision': [0.8466112017631531,\n",
      "                           0.9527687430381775,\n",
      "                           0.9539473652839661,\n",
      "                           0.9594813585281372,\n",
      "                           0.9463414549827576,\n",
      "                           0.9645868539810181,\n",
      "                           0.9605911374092102,\n",
      "                           0.9781879186630249,\n",
      "                           0.9636963605880737,\n",
      "                           0.9553719162940979,\n",
      "                           0.9786184430122375],\n",
      "             'recall': [0.8877805471420288,\n",
      "                        0.9390048384666443,\n",
      "                        0.9682804942131042,\n",
      "                        0.9657422304153442,\n",
      "                        0.9494290351867676,\n",
      "                        0.95333331823349,\n",
      "                        0.9605911374092102,\n",
      "                        0.962046205997467,\n",
      "                        0.958949089050293,\n",
      "                        0.960132896900177,\n",
      "                        0.9581320285797119],\n",
      "             'val_accuracy': [0.9305555820465088,\n",
      "                              0.9375,\n",
      "                              0.9652777910232544,\n",
      "                              0.9444444179534912,\n",
      "                              0.9583333134651184,\n",
      "                              0.9722222089767456,\n",
      "                              0.9583333134651184,\n",
      "                              0.9618055820465088,\n",
      "                              0.96875,\n",
      "                              0.9652777910232544,\n",
      "                              0.96875],\n",
      "             'val_auc': [0.985460102558136,\n",
      "                         0.9854392409324646,\n",
      "                         0.9901798367500305,\n",
      "                         0.9877853989601135,\n",
      "                         0.989913821220398,\n",
      "                         0.9932517409324646,\n",
      "                         0.9939773678779602,\n",
      "                         0.9938564300537109,\n",
      "                         0.9951868057250977,\n",
      "                         0.9946062564849854,\n",
      "                         0.993561863899231],\n",
      "             'val_f1_score': [0.5274766087532043,\n",
      "                              0.533375084400177,\n",
      "                              0.53883957862854,\n",
      "                              0.5327836275100708,\n",
      "                              0.5366067886352539,\n",
      "                              0.5465637445449829,\n",
      "                              0.6485692262649536,\n",
      "                              0.6504495143890381,\n",
      "                              0.6448626518249512,\n",
      "                              0.6504495143890381,\n",
      "                              0.5465637445449829],\n",
      "             'val_loss': [0.17803016304969788,\n",
      "                          0.14956165850162506,\n",
      "                          0.11437853425741196,\n",
      "                          0.14774149656295776,\n",
      "                          0.1400277316570282,\n",
      "                          0.10116918385028839,\n",
      "                          0.11326636373996735,\n",
      "                          0.11575886607170105,\n",
      "                          0.11139265447854996,\n",
      "                          0.1203790009021759,\n",
      "                          0.1183752715587616],\n",
      "             'val_precision': [0.9558823704719543,\n",
      "                               0.9338235259056091,\n",
      "                               0.9701492786407471,\n",
      "                               0.9615384340286255,\n",
      "                               0.9769230484962463,\n",
      "                               0.9776119589805603,\n",
      "                               0.9794520735740662,\n",
      "                               0.9795918464660645,\n",
      "                               0.9931034445762634,\n",
      "                               0.9863013625144958,\n",
      "                               0.9720279574394226],\n",
      "             'val_recall': [0.9027777910232544,\n",
      "                            0.9338235259056091,\n",
      "                            0.9558823704719543,\n",
      "                            0.9191176295280457,\n",
      "                            0.9338235259056091,\n",
      "                            0.9632353186607361,\n",
      "                            0.9407894611358643,\n",
      "                            0.9473684430122375,\n",
      "                            0.9473684430122375,\n",
      "                            0.9473684430122375,\n",
      "                            0.9652777910232544]},\n",
      " 'optimal_threshold': 0.456683486700058,\n",
      " 'train_counts': {'fire': 608, 'nofire': 608},\n",
      " 'train_counts_total': 1216,\n",
      " 'train_dataset_size': 1216,\n",
      " 'training_time': 153.71636581420898,\n",
      " 'val_counts': {'fire': 152, 'nofire': 152},\n",
      " 'val_counts_total': 304,\n",
      " 'val_dataset_size': 288}\n",
      "Training model: MobileNetV2 on dataset: The Wildfire Dataset_DeepFire\n",
      "Class weights: {0: 1.1595665171898355, 1: 0.8790368271954674}\n",
      "Epoch 1/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 408ms/step - accuracy: 0.6864 - auc: 0.8627 - f1_score: 0.7230 - loss: 0.7371 - precision: 0.8469 - recall: 0.7566 - val_accuracy: 0.8040 - val_auc: 0.8999 - val_f1_score: 0.5671 - val_loss: 0.4062 - val_precision: 0.7797 - val_recall: 0.9031 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 351ms/step - accuracy: 0.7955 - auc: 0.8747 - f1_score: 0.8288 - loss: 0.4764 - precision: 0.8648 - recall: 0.7989 - val_accuracy: 0.8381 - val_auc: 0.9177 - val_f1_score: 0.5710 - val_loss: 0.3660 - val_precision: 0.8263 - val_recall: 0.8980 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 361ms/step - accuracy: 0.7942 - auc: 0.8859 - f1_score: 0.8233 - loss: 0.4429 - precision: 0.8457 - recall: 0.8081 - val_accuracy: 0.8665 - val_auc: 0.9271 - val_f1_score: 0.5850 - val_loss: 0.3468 - val_precision: 0.8465 - val_recall: 0.9286 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 361ms/step - accuracy: 0.8160 - auc: 0.8982 - f1_score: 0.8465 - loss: 0.4108 - precision: 0.8742 - recall: 0.8207 - val_accuracy: 0.8537 - val_auc: 0.9327 - val_f1_score: 0.5830 - val_loss: 0.3369 - val_precision: 0.8400 - val_recall: 0.9107 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 363ms/step - accuracy: 0.8066 - auc: 0.8908 - f1_score: 0.8382 - loss: 0.4230 - precision: 0.8627 - recall: 0.8172 - val_accuracy: 0.8679 - val_auc: 0.9367 - val_f1_score: 0.5819 - val_loss: 0.3326 - val_precision: 0.8501 - val_recall: 0.9260 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 361ms/step - accuracy: 0.8388 - auc: 0.9197 - f1_score: 0.8646 - loss: 0.3598 - precision: 0.8892 - recall: 0.8427 - val_accuracy: 0.8551 - val_auc: 0.9352 - val_f1_score: 0.5819 - val_loss: 0.3353 - val_precision: 0.8341 - val_recall: 0.9235 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 355ms/step - accuracy: 0.8448 - auc: 0.9197 - f1_score: 0.8738 - loss: 0.3489 - precision: 0.8782 - recall: 0.8723 - val_accuracy: 0.8864 - val_auc: 0.9385 - val_f1_score: 0.5818 - val_loss: 0.3204 - val_precision: 0.8980 - val_recall: 0.8980 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 360ms/step - accuracy: 0.8351 - auc: 0.9150 - f1_score: 0.8617 - loss: 0.3686 - precision: 0.8688 - recall: 0.8557 - val_accuracy: 0.8622 - val_auc: 0.9429 - val_f1_score: 0.5862 - val_loss: 0.3247 - val_precision: 0.8391 - val_recall: 0.9311 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 367ms/step - accuracy: 0.8497 - auc: 0.9297 - f1_score: 0.8772 - loss: 0.3305 - precision: 0.8955 - recall: 0.8583 - val_accuracy: 0.8750 - val_auc: 0.9438 - val_f1_score: 0.5899 - val_loss: 0.3170 - val_precision: 0.8519 - val_recall: 0.9388 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 361ms/step - accuracy: 0.8519 - auc: 0.9320 - f1_score: 0.8740 - loss: 0.3300 - precision: 0.8845 - recall: 0.8656 - val_accuracy: 0.8651 - val_auc: 0.9471 - val_f1_score: 0.5809 - val_loss: 0.3091 - val_precision: 0.8494 - val_recall: 0.9209 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 365ms/step - accuracy: 0.8345 - auc: 0.9199 - f1_score: 0.8625 - loss: 0.3513 - precision: 0.8826 - recall: 0.8462 - val_accuracy: 0.8722 - val_auc: 0.9455 - val_f1_score: 0.5848 - val_loss: 0.3108 - val_precision: 0.8578 - val_recall: 0.9235 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 352ms/step - accuracy: 0.8496 - auc: 0.9299 - f1_score: 0.8736 - loss: 0.3323 - precision: 0.8955 - recall: 0.8546 - val_accuracy: 0.8764 - val_auc: 0.9495 - val_f1_score: 0.5811 - val_loss: 0.2968 - val_precision: 0.8841 - val_recall: 0.8954 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 339ms/step - accuracy: 0.8388 - auc: 0.9213 - f1_score: 0.8666 - loss: 0.3500 - precision: 0.8833 - recall: 0.8517 - val_accuracy: 0.8807 - val_auc: 0.9490 - val_f1_score: 0.5940 - val_loss: 0.2979 - val_precision: 0.8632 - val_recall: 0.9337 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 349ms/step - accuracy: 0.8518 - auc: 0.9308 - f1_score: 0.8779 - loss: 0.3256 - precision: 0.8951 - recall: 0.8630 - val_accuracy: 0.8821 - val_auc: 0.9499 - val_f1_score: 0.5955 - val_loss: 0.2982 - val_precision: 0.8635 - val_recall: 0.9362 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 358ms/step - accuracy: 0.8639 - auc: 0.9369 - f1_score: 0.8847 - loss: 0.3199 - precision: 0.8864 - recall: 0.8872 - val_accuracy: 0.8835 - val_auc: 0.9518 - val_f1_score: 0.5895 - val_loss: 0.2889 - val_precision: 0.8780 - val_recall: 0.9184 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 366ms/step - accuracy: 0.8729 - auc: 0.9423 - f1_score: 0.8935 - loss: 0.3031 - precision: 0.9023 - recall: 0.8883 - val_accuracy: 0.8778 - val_auc: 0.9452 - val_f1_score: 0.5880 - val_loss: 0.3004 - val_precision: 0.8732 - val_recall: 0.9133 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 350ms/step - accuracy: 0.8531 - auc: 0.9325 - f1_score: 0.8766 - loss: 0.3253 - precision: 0.8996 - recall: 0.8565 - val_accuracy: 0.8778 - val_auc: 0.9451 - val_f1_score: 0.5846 - val_loss: 0.3051 - val_precision: 0.8660 - val_recall: 0.9235 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.8651 - auc: 0.9350 - f1_score: 0.8895 - loss: 0.3206 - precision: 0.9032 - recall: 0.8746\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 345ms/step - accuracy: 0.8651 - auc: 0.9350 - f1_score: 0.8894 - loss: 0.3207 - precision: 0.9031 - recall: 0.8746 - val_accuracy: 0.9006 - val_auc: 0.9491 - val_f1_score: 0.5978 - val_loss: 0.2993 - val_precision: 0.8852 - val_recall: 0.9439 - learning_rate: 0.0010\n",
      "Epoch 19/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 355ms/step - accuracy: 0.8539 - auc: 0.9344 - f1_score: 0.8762 - loss: 0.3196 - precision: 0.9001 - recall: 0.8562 - val_accuracy: 0.9006 - val_auc: 0.9517 - val_f1_score: 0.5993 - val_loss: 0.2940 - val_precision: 0.8815 - val_recall: 0.9490 - learning_rate: 5.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 351ms/step - accuracy: 0.8707 - auc: 0.9463 - f1_score: 0.8925 - loss: 0.2920 - precision: 0.9130 - recall: 0.8756 - val_accuracy: 0.8892 - val_auc: 0.9527 - val_f1_score: 0.5947 - val_loss: 0.2874 - val_precision: 0.8756 - val_recall: 0.9337 - learning_rate: 5.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 341ms/step - accuracy: 0.8647 - auc: 0.9368 - f1_score: 0.8872 - loss: 0.3143 - precision: 0.8930 - recall: 0.8843 - val_accuracy: 0.8892 - val_auc: 0.9532 - val_f1_score: 0.5926 - val_loss: 0.2861 - val_precision: 0.8792 - val_recall: 0.9286 - learning_rate: 5.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 348ms/step - accuracy: 0.8606 - auc: 0.9395 - f1_score: 0.8833 - loss: 0.3100 - precision: 0.8875 - recall: 0.8827 - val_accuracy: 0.8793 - val_auc: 0.9500 - val_f1_score: 0.5852 - val_loss: 0.2924 - val_precision: 0.8699 - val_recall: 0.9209 - learning_rate: 5.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 345ms/step - accuracy: 0.8665 - auc: 0.9402 - f1_score: 0.8885 - loss: 0.3072 - precision: 0.9015 - recall: 0.8796 - val_accuracy: 0.8849 - val_auc: 0.9529 - val_f1_score: 0.5934 - val_loss: 0.2944 - val_precision: 0.8608 - val_recall: 0.9464 - learning_rate: 5.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 348ms/step - accuracy: 0.8696 - auc: 0.9425 - f1_score: 0.8907 - loss: 0.3037 - precision: 0.9237 - recall: 0.8615 - val_accuracy: 0.8807 - val_auc: 0.9542 - val_f1_score: 0.5936 - val_loss: 0.2826 - val_precision: 0.8632 - val_recall: 0.9337 - learning_rate: 5.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 344ms/step - accuracy: 0.8803 - auc: 0.9496 - f1_score: 0.9003 - loss: 0.2817 - precision: 0.9200 - recall: 0.8831 - val_accuracy: 0.8821 - val_auc: 0.9543 - val_f1_score: 0.5955 - val_loss: 0.2909 - val_precision: 0.8535 - val_recall: 0.9515 - learning_rate: 5.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 342ms/step - accuracy: 0.8741 - auc: 0.9427 - f1_score: 0.8942 - loss: 0.3025 - precision: 0.9044 - recall: 0.8879 - val_accuracy: 0.8977 - val_auc: 0.9545 - val_f1_score: 0.5923 - val_loss: 0.2854 - val_precision: 0.8846 - val_recall: 0.9388 - learning_rate: 5.0000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.8743 - auc: 0.9476 - f1_score: 0.8934 - loss: 0.2899 - precision: 0.9003 - recall: 0.8884\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 345ms/step - accuracy: 0.8743 - auc: 0.9476 - f1_score: 0.8934 - loss: 0.2899 - precision: 0.9004 - recall: 0.8884 - val_accuracy: 0.8821 - val_auc: 0.9529 - val_f1_score: 0.5940 - val_loss: 0.2890 - val_precision: 0.8568 - val_recall: 0.9464 - learning_rate: 5.0000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 351ms/step - accuracy: 0.8734 - auc: 0.9462 - f1_score: 0.8947 - loss: 0.2925 - precision: 0.9121 - recall: 0.8777 - val_accuracy: 0.8878 - val_auc: 0.9531 - val_f1_score: 0.5919 - val_loss: 0.2875 - val_precision: 0.8682 - val_recall: 0.9413 - learning_rate: 2.5000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 344ms/step - accuracy: 0.8698 - auc: 0.9435 - f1_score: 0.8933 - loss: 0.2980 - precision: 0.9088 - recall: 0.8802 - val_accuracy: 0.8821 - val_auc: 0.9523 - val_f1_score: 0.5952 - val_loss: 0.2932 - val_precision: 0.8535 - val_recall: 0.9515 - learning_rate: 2.5000e-04\n",
      "Training time: 987.51 seconds\n",
      "Evaluating MobileNetV2 on The Wildfire Dataset_DeepFire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 876ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 219ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 206ms/step - accuracy: 0.7159 - auc: 0.5545 - f1_score: 0.2534 - loss: 0.6380 - precision: 0.3941 - recall: 0.5649  \n",
      "Training results for MobileNetV2 on The Wildfire Dataset_DeepFire:\n",
      "{'class_weights': {0: 1.1595665171898355, 1: 0.8790368271954674},\n",
      " 'evaluation': {'accuracy': 0.8125,\n",
      "                'auc': 0.9037228226661682,\n",
      "                'f1_score': 0.5472989678382874,\n",
      "                'loss': 0.43930402398109436,\n",
      "                'precision': 0.7644628286361694,\n",
      "                'recall': 0.925000011920929},\n",
      " 'history': {'accuracy': [0.7376301884651184,\n",
      "                          0.7913411259651184,\n",
      "                          0.8014323115348816,\n",
      "                          0.8225911259651184,\n",
      "                          0.8196614384651184,\n",
      "                          0.8352864384651184,\n",
      "                          0.8453776240348816,\n",
      "                          0.8404948115348816,\n",
      "                          0.8470051884651184,\n",
      "                          0.8492838740348816,\n",
      "                          0.8391926884651184,\n",
      "                          0.8544921875,\n",
      "                          0.8359375,\n",
      "                          0.8434244990348816,\n",
      "                          0.859375,\n",
      "                          0.8642578125,\n",
      "                          0.8570963740348816,\n",
      "                          0.8603515625,\n",
      "                          0.8509114384651184,\n",
      "                          0.875,\n",
      "                          0.8645833134651184,\n",
      "                          0.8600260615348816,\n",
      "                          0.8727213740348816,\n",
      "                          0.869140625,\n",
      "                          0.8743489384651184,\n",
      "                          0.8626301884651184,\n",
      "                          0.8723958134651184,\n",
      "                          0.8668619990348816,\n",
      "                          0.8655598759651184],\n",
      "             'auc': [0.8461914658546448,\n",
      "                     0.8735718727111816,\n",
      "                     0.888906717300415,\n",
      "                     0.9004507064819336,\n",
      "                     0.9027553200721741,\n",
      "                     0.9163663983345032,\n",
      "                     0.9213405847549438,\n",
      "                     0.9171396493911743,\n",
      "                     0.9246718883514404,\n",
      "                     0.9283895492553711,\n",
      "                     0.9197881817817688,\n",
      "                     0.9281126260757446,\n",
      "                     0.9190841913223267,\n",
      "                     0.9270526170730591,\n",
      "                     0.9310786128044128,\n",
      "                     0.9343610405921936,\n",
      "                     0.936971127986908,\n",
      "                     0.9303132891654968,\n",
      "                     0.9334033727645874,\n",
      "                     0.9466107487678528,\n",
      "                     0.9385054111480713,\n",
      "                     0.9401329755783081,\n",
      "                     0.941663920879364,\n",
      "                     0.9424232244491577,\n",
      "                     0.943652331829071,\n",
      "                     0.9362239241600037,\n",
      "                     0.9451909065246582,\n",
      "                     0.944950520992279,\n",
      "                     0.9399310350418091],\n",
      "             'f1_score': [0.7693865895271301,\n",
      "                          0.8246476650238037,\n",
      "                          0.8324852585792542,\n",
      "                          0.8505824208259583,\n",
      "                          0.8495185375213623,\n",
      "                          0.8615260124206543,\n",
      "                          0.8726136088371277,\n",
      "                          0.8653931021690369,\n",
      "                          0.8744342923164368,\n",
      "                          0.8726194500923157,\n",
      "                          0.8647894263267517,\n",
      "                          0.8780304789543152,\n",
      "                          0.8631041049957275,\n",
      "                          0.8701046109199524,\n",
      "                          0.8820661902427673,\n",
      "                          0.8863903880119324,\n",
      "                          0.8802759051322937,\n",
      "                          0.8842561841011047,\n",
      "                          0.8741051554679871,\n",
      "                          0.895728588104248,\n",
      "                          0.8867592215538025,\n",
      "                          0.8823652863502502,\n",
      "                          0.8939039707183838,\n",
      "                          0.8893213868141174,\n",
      "                          0.8943325877189636,\n",
      "                          0.8852904438972473,\n",
      "                          0.8930575251579285,\n",
      "                          0.8894033432006836,\n",
      "                          0.8884119391441345],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0002500000118743628,\n",
      "                               0.0002500000118743628],\n",
      "             'loss': [0.6352633833885193,\n",
      "                      0.4798729121685028,\n",
      "                      0.4332050383090973,\n",
      "                      0.4060509502887726,\n",
      "                      0.39322006702423096,\n",
      "                      0.3675704300403595,\n",
      "                      0.35106876492500305,\n",
      "                      0.36247214674949646,\n",
      "                      0.3421424329280853,\n",
      "                      0.3375895917415619,\n",
      "                      0.35440054535865784,\n",
      "                      0.33533287048339844,\n",
      "                      0.3545100688934326,\n",
      "                      0.33590903878211975,\n",
      "                      0.33026018738746643,\n",
      "                      0.32111504673957825,\n",
      "                      0.3140544295310974,\n",
      "                      0.3318917453289032,\n",
      "                      0.32175254821777344,\n",
      "                      0.29034483432769775,\n",
      "                      0.31070777773857117,\n",
      "                      0.3062261641025543,\n",
      "                      0.3038187026977539,\n",
      "                      0.30174583196640015,\n",
      "                      0.2973509132862091,\n",
      "                      0.31681305170059204,\n",
      "                      0.2942315638065338,\n",
      "                      0.29533660411834717,\n",
      "                      0.3074703514575958],\n",
      "             'precision': [0.8346752524375916,\n",
      "                           0.8562605381011963,\n",
      "                           0.8531042337417603,\n",
      "                           0.8680400848388672,\n",
      "                           0.8699724674224854,\n",
      "                           0.8811771273612976,\n",
      "                           0.8844492435455322,\n",
      "                           0.8769906759262085,\n",
      "                           0.8956283926963806,\n",
      "                           0.886426568031311,\n",
      "                           0.8844026327133179,\n",
      "                           0.8950276374816895,\n",
      "                           0.8793859481811523,\n",
      "                           0.884239137172699,\n",
      "                           0.8957762122154236,\n",
      "                           0.8982589840888977,\n",
      "                           0.8986710906028748,\n",
      "                           0.897646427154541,\n",
      "                           0.8957871198654175,\n",
      "                           0.9168959856033325,\n",
      "                           0.8952226042747498,\n",
      "                           0.8916441798210144,\n",
      "                           0.9033998847007751,\n",
      "                           0.9139183759689331,\n",
      "                           0.9132344722747803,\n",
      "                           0.9006550312042236,\n",
      "                           0.905205488204956,\n",
      "                           0.9080841541290283,\n",
      "                           0.8986998796463013],\n",
      "             'recall': [0.7541221976280212,\n",
      "                        0.7984293103218079,\n",
      "                        0.8168789744377136,\n",
      "                        0.8350294828414917,\n",
      "                        0.8323668837547302,\n",
      "                        0.8445981740951538,\n",
      "                        0.8625592589378357,\n",
      "                        0.8572195172309875,\n",
      "                        0.8545359969139099,\n",
      "                        0.86114102602005,\n",
      "                        0.8487260937690735,\n",
      "                        0.8630793690681458,\n",
      "                        0.8495762944221497,\n",
      "                        0.8585752248764038,\n",
      "                        0.8709333539009094,\n",
      "                        0.8777245879173279,\n",
      "                        0.863757312297821,\n",
      "                        0.8714134097099304,\n",
      "                        0.8568398952484131,\n",
      "                        0.8773038387298584,\n",
      "                        0.8808760643005371,\n",
      "                        0.8783855438232422,\n",
      "                        0.8875927925109863,\n",
      "                        0.8682952523231506,\n",
      "                        0.8794288635253906,\n",
      "                        0.8730158805847168,\n",
      "                        0.8829503059387207,\n",
      "                        0.8709506392478943,\n",
      "                        0.8801060914993286],\n",
      "             'val_accuracy': [0.8039772510528564,\n",
      "                              0.8380681872367859,\n",
      "                              0.8664772510528564,\n",
      "                              0.8536931872367859,\n",
      "                              0.8678977489471436,\n",
      "                              0.8551136255264282,\n",
      "                              0.8863636255264282,\n",
      "                              0.8622159361839294,\n",
      "                              0.875,\n",
      "                              0.8650568127632141,\n",
      "                              0.8721590638160706,\n",
      "                              0.8764204382896423,\n",
      "                              0.8806818127632141,\n",
      "                              0.8821022510528564,\n",
      "                              0.8835227489471436,\n",
      "                              0.8778409361839294,\n",
      "                              0.8778409361839294,\n",
      "                              0.9005681872367859,\n",
      "                              0.9005681872367859,\n",
      "                              0.8892045617103577,\n",
      "                              0.8892045617103577,\n",
      "                              0.8792613744735718,\n",
      "                              0.8849431872367859,\n",
      "                              0.8806818127632141,\n",
      "                              0.8821022510528564,\n",
      "                              0.8977272510528564,\n",
      "                              0.8821022510528564,\n",
      "                              0.8877840638160706,\n",
      "                              0.8821022510528564],\n",
      "             'val_auc': [0.8999051451683044,\n",
      "                         0.9177296161651611,\n",
      "                         0.927083432674408,\n",
      "                         0.9327331781387329,\n",
      "                         0.9366905689239502,\n",
      "                         0.9352352023124695,\n",
      "                         0.9385384321212769,\n",
      "                         0.9429372549057007,\n",
      "                         0.9438366889953613,\n",
      "                         0.9470580816268921,\n",
      "                         0.9455046057701111,\n",
      "                         0.9494701623916626,\n",
      "                         0.9490368366241455,\n",
      "                         0.9499117136001587,\n",
      "                         0.9518413543701172,\n",
      "                         0.9451775550842285,\n",
      "                         0.9450549483299255,\n",
      "                         0.94914311170578,\n",
      "                         0.951702356338501,\n",
      "                         0.9526588916778564,\n",
      "                         0.9531658887863159,\n",
      "                         0.9500425457954407,\n",
      "                         0.952904224395752,\n",
      "                         0.9541797637939453,\n",
      "                         0.9542778730392456,\n",
      "                         0.9544986486434937,\n",
      "                         0.952863335609436,\n",
      "                         0.9530595541000366,\n",
      "                         0.9522746801376343],\n",
      "             'val_f1_score': [0.5671470761299133,\n",
      "                              0.5710117816925049,\n",
      "                              0.5850257277488708,\n",
      "                              0.5830223560333252,\n",
      "                              0.5819475650787354,\n",
      "                              0.5818637609481812,\n",
      "                              0.5817972421646118,\n",
      "                              0.5862308144569397,\n",
      "                              0.5898983478546143,\n",
      "                              0.5808504819869995,\n",
      "                              0.584847092628479,\n",
      "                              0.5810524821281433,\n",
      "                              0.5940125584602356,\n",
      "                              0.5955022573471069,\n",
      "                              0.5895466208457947,\n",
      "                              0.588031530380249,\n",
      "                              0.584600031375885,\n",
      "                              0.5977844595909119,\n",
      "                              0.5992507338523865,\n",
      "                              0.5946795344352722,\n",
      "                              0.5926271677017212,\n",
      "                              0.5851536393165588,\n",
      "                              0.5933814644813538,\n",
      "                              0.5936082601547241,\n",
      "                              0.5955002307891846,\n",
      "                              0.5923396348953247,\n",
      "                              0.5940338969230652,\n",
      "                              0.5919151902198792,\n",
      "                              0.5951797962188721],\n",
      "             'val_loss': [0.4061817228794098,\n",
      "                          0.3659835159778595,\n",
      "                          0.3467511832714081,\n",
      "                          0.3369350731372833,\n",
      "                          0.33258742094039917,\n",
      "                          0.3353349566459656,\n",
      "                          0.3203742206096649,\n",
      "                          0.3246823847293854,\n",
      "                          0.31696510314941406,\n",
      "                          0.30912405252456665,\n",
      "                          0.31079354882240295,\n",
      "                          0.29678985476493835,\n",
      "                          0.2978940010070801,\n",
      "                          0.298219233751297,\n",
      "                          0.2889333665370941,\n",
      "                          0.30044257640838623,\n",
      "                          0.30511215329170227,\n",
      "                          0.2992573380470276,\n",
      "                          0.29404664039611816,\n",
      "                          0.2873925268650055,\n",
      "                          0.28609418869018555,\n",
      "                          0.29240283370018005,\n",
      "                          0.2944291830062866,\n",
      "                          0.2826007008552551,\n",
      "                          0.29094961285591125,\n",
      "                          0.2853672504425049,\n",
      "                          0.288965106010437,\n",
      "                          0.2874853312969208,\n",
      "                          0.2931939363479614],\n",
      "             'val_precision': [0.7797356843948364,\n",
      "                               0.8262910842895508,\n",
      "                               0.8465116024017334,\n",
      "                               0.8399999737739563,\n",
      "                               0.8501170873641968,\n",
      "                               0.8341013789176941,\n",
      "                               0.8979591727256775,\n",
      "                               0.8390804529190063,\n",
      "                               0.8518518805503845,\n",
      "                               0.8494117856025696,\n",
      "                               0.8578199148178101,\n",
      "                               0.8841309547424316,\n",
      "                               0.8632075190544128,\n",
      "                               0.8635293841362,\n",
      "                               0.8780487775802612,\n",
      "                               0.8731707334518433,\n",
      "                               0.8660287261009216,\n",
      "                               0.8851674795150757,\n",
      "                               0.8815165758132935,\n",
      "                               0.8755980730056763,\n",
      "                               0.8792270421981812,\n",
      "                               0.8698795437812805,\n",
      "                               0.860788881778717,\n",
      "                               0.8632075190544128,\n",
      "                               0.8535469174385071,\n",
      "                               0.8846153616905212,\n",
      "                               0.8568129539489746,\n",
      "                               0.8682352900505066,\n",
      "                               0.8535469174385071],\n",
      "             'val_recall': [0.9030612111091614,\n",
      "                            0.8979591727256775,\n",
      "                            0.9285714030265808,\n",
      "                            0.9107142686843872,\n",
      "                            0.9260203838348389,\n",
      "                            0.9234693646430969,\n",
      "                            0.8979591727256775,\n",
      "                            0.9311224222183228,\n",
      "                            0.9387755393981934,\n",
      "                            0.920918345451355,\n",
      "                            0.9234693646430969,\n",
      "                            0.8954081535339355,\n",
      "                            0.9336734414100647,\n",
      "                            0.9362244606018066,\n",
      "                            0.918367326259613,\n",
      "                            0.9132652878761292,\n",
      "                            0.9234693646430969,\n",
      "                            0.9438775777816772,\n",
      "                            0.9489796161651611,\n",
      "                            0.9336734414100647,\n",
      "                            0.9285714030265808,\n",
      "                            0.920918345451355,\n",
      "                            0.9464285969734192,\n",
      "                            0.9336734414100647,\n",
      "                            0.9515306353569031,\n",
      "                            0.9387755393981934,\n",
      "                            0.9464285969734192,\n",
      "                            0.9413265585899353,\n",
      "                            0.9515306353569031]},\n",
      " 'optimal_threshold': 0.4703601002693176,\n",
      " 'train_counts': {'fire': 1338, 'nofire': 1765},\n",
      " 'train_counts_total': 3103,\n",
      " 'train_dataset_size': 3072,\n",
      " 'training_time': 987.5144090652466,\n",
      " 'val_counts': {'fire': 308, 'nofire': 398},\n",
      " 'val_counts_total': 706,\n",
      " 'val_dataset_size': 704}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"WildfireNet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"WildfireNet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100352</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,690,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100352\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m25,690,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,819,073</span> (98.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,819,073\u001b[0m (98.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,817,857</span> (98.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,817,857\u001b[0m (98.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,216</span> (4.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,216\u001b[0m (4.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: WildfireNet on dataset: The Wildfire Dataset\n",
      "Class weights: {0: 1.2924657534246575, 1: 0.8154710458081245}\n",
      "Epoch 1/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 745ms/step - accuracy: 0.6196 - auc: 0.7595 - f1_score: 0.6527 - loss: 0.8189 - precision: 0.7459 - recall: 0.6980 - val_accuracy: 0.4062 - val_auc: 0.6483 - val_f1_score: 0.0000e+00 - val_loss: 2.8126 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 720ms/step - accuracy: 0.6531 - auc: 0.7207 - f1_score: 0.6909 - loss: 0.7255 - precision: 0.7724 - recall: 0.6312 - val_accuracy: 0.4062 - val_auc: 0.6497 - val_f1_score: 0.0000e+00 - val_loss: 1.7924 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 723ms/step - accuracy: 0.6716 - auc: 0.7577 - f1_score: 0.7060 - loss: 0.6428 - precision: 0.8183 - recall: 0.6256 - val_accuracy: 0.4948 - val_auc: 0.6879 - val_f1_score: 0.2032 - val_loss: 0.9858 - val_precision: 0.7656 - val_recall: 0.2149 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 725ms/step - accuracy: 0.7212 - auc: 0.7872 - f1_score: 0.7465 - loss: 0.5874 - precision: 0.8101 - recall: 0.6942 - val_accuracy: 0.4948 - val_auc: 0.6548 - val_f1_score: 0.2783 - val_loss: 1.0204 - val_precision: 0.8023 - val_recall: 0.2805 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 752ms/step - accuracy: 0.6961 - auc: 0.7817 - f1_score: 0.7244 - loss: 0.5793 - precision: 0.8194 - recall: 0.6527 - val_accuracy: 0.5104 - val_auc: 0.6995 - val_f1_score: 0.2896 - val_loss: 1.0439 - val_precision: 0.8372 - val_recall: 0.2927 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.7315 - auc: 0.8039 - f1_score: 0.7707 - loss: 0.5658 - precision: 0.8200 - recall: 0.7330 - val_accuracy: 0.6510 - val_auc: 0.6967 - val_f1_score: 0.4799 - val_loss: 0.6443 - val_precision: 0.7448 - val_recall: 0.6272 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 766ms/step - accuracy: 0.7509 - auc: 0.8255 - f1_score: 0.7733 - loss: 0.5275 - precision: 0.8399 - recall: 0.7194 - val_accuracy: 0.6510 - val_auc: 0.7153 - val_f1_score: 0.4614 - val_loss: 0.6097 - val_precision: 0.7640 - val_recall: 0.5965 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 779ms/step - accuracy: 0.7549 - auc: 0.8438 - f1_score: 0.7858 - loss: 0.5012 - precision: 0.8359 - recall: 0.7439 - val_accuracy: 0.5911 - val_auc: 0.8568 - val_f1_score: 0.3142 - val_loss: 0.6579 - val_precision: 0.9610 - val_recall: 0.3246 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 803ms/step - accuracy: 0.7601 - auc: 0.8360 - f1_score: 0.7891 - loss: 0.5083 - precision: 0.8600 - recall: 0.7290 - val_accuracy: 0.6432 - val_auc: 0.7897 - val_f1_score: 0.3917 - val_loss: 0.6631 - val_precision: 0.8889 - val_recall: 0.4561 - learning_rate: 0.0010\n",
      "Epoch 10/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 789ms/step - accuracy: 0.7645 - auc: 0.8508 - f1_score: 0.7971 - loss: 0.4844 - precision: 0.8303 - recall: 0.7676 - val_accuracy: 0.7135 - val_auc: 0.8091 - val_f1_score: 0.5414 - val_loss: 0.5634 - val_precision: 0.8469 - val_recall: 0.6748 - learning_rate: 0.0010\n",
      "Epoch 11/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 801ms/step - accuracy: 0.7488 - auc: 0.8389 - f1_score: 0.7861 - loss: 0.4907 - precision: 0.8417 - recall: 0.7426 - val_accuracy: 0.6484 - val_auc: 0.8823 - val_f1_score: 0.4127 - val_loss: 0.6527 - val_precision: 0.9744 - val_recall: 0.4634 - learning_rate: 0.0010\n",
      "Epoch 12/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 816ms/step - accuracy: 0.7859 - auc: 0.8624 - f1_score: 0.8141 - loss: 0.4635 - precision: 0.8735 - recall: 0.7625 - val_accuracy: 0.5651 - val_auc: 0.8051 - val_f1_score: 0.2998 - val_loss: 1.0173 - val_precision: 1.0000 - val_recall: 0.3099 - learning_rate: 0.0010\n",
      "Epoch 13/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 825ms/step - accuracy: 0.7451 - auc: 0.8301 - f1_score: 0.7762 - loss: 0.5103 - precision: 0.8314 - recall: 0.7295 - val_accuracy: 0.7396 - val_auc: 0.8681 - val_f1_score: 0.4838 - val_loss: 0.5076 - val_precision: 0.9324 - val_recall: 0.6053 - learning_rate: 0.0010\n",
      "Epoch 14/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 824ms/step - accuracy: 0.7588 - auc: 0.8380 - f1_score: 0.7926 - loss: 0.5019 - precision: 0.8495 - recall: 0.7468 - val_accuracy: 0.7995 - val_auc: 0.8805 - val_f1_score: 0.5787 - val_loss: 0.4316 - val_precision: 0.8297 - val_recall: 0.8333 - learning_rate: 0.0010\n",
      "Epoch 15/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 806ms/step - accuracy: 0.7778 - auc: 0.8649 - f1_score: 0.8067 - loss: 0.4574 - precision: 0.8519 - recall: 0.7706 - val_accuracy: 0.7448 - val_auc: 0.8470 - val_f1_score: 0.4985 - val_loss: 0.4929 - val_precision: 0.8869 - val_recall: 0.6535 - learning_rate: 0.0010\n",
      "Epoch 16/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 793ms/step - accuracy: 0.7978 - auc: 0.8798 - f1_score: 0.8242 - loss: 0.4299 - precision: 0.8843 - recall: 0.7741 - val_accuracy: 0.7448 - val_auc: 0.8706 - val_f1_score: 0.4676 - val_loss: 0.4999 - val_precision: 0.9167 - val_recall: 0.6272 - learning_rate: 0.0010\n",
      "Epoch 17/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780ms/step - accuracy: 0.7783 - auc: 0.8548 - f1_score: 0.8080 - loss: 0.4789 - precision: 0.8654 - recall: 0.7587\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 808ms/step - accuracy: 0.7785 - auc: 0.8551 - f1_score: 0.8081 - loss: 0.4784 - precision: 0.8655 - recall: 0.7588 - val_accuracy: 0.7057 - val_auc: 0.8732 - val_f1_score: 0.5001 - val_loss: 0.5878 - val_precision: 0.9650 - val_recall: 0.5610 - learning_rate: 0.0010\n",
      "Epoch 18/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 811ms/step - accuracy: 0.7825 - auc: 0.8749 - f1_score: 0.8068 - loss: 0.4447 - precision: 0.8752 - recall: 0.7504 - val_accuracy: 0.6354 - val_auc: 0.8890 - val_f1_score: 0.3992 - val_loss: 0.7683 - val_precision: 0.9907 - val_recall: 0.4350 - learning_rate: 5.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 806ms/step - accuracy: 0.7899 - auc: 0.8902 - f1_score: 0.8166 - loss: 0.4143 - precision: 0.8734 - recall: 0.7694 - val_accuracy: 0.6771 - val_auc: 0.8651 - val_f1_score: 0.3995 - val_loss: 0.7581 - val_precision: 0.9727 - val_recall: 0.4693 - learning_rate: 5.0000e-04\n",
      "Training time: 885.42 seconds\n",
      "Evaluating WildfireNet on The Wildfire Dataset...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.5780 - auc: 0.4839 - f1_score: 0.2431 - loss: 0.8240 - precision: 0.3244 - recall: 0.5491  \n",
      "Training results for WildfireNet on The Wildfire Dataset:\n",
      "{'class_weights': {0: 1.2924657534246575, 1: 0.8154710458081245},\n",
      " 'evaluation': {'accuracy': 0.6848958134651184,\n",
      "                'auc': 0.7617255449295044,\n",
      "                'f1_score': 0.5028466582298279,\n",
      "                'loss': 0.6421658992767334,\n",
      "                'precision': 0.6479400992393494,\n",
      "                'recall': 0.8650000095367432},\n",
      " 'history': {'accuracy': [0.6212284564971924,\n",
      "                          0.6664870977401733,\n",
      "                          0.6842672228813171,\n",
      "                          0.7133620977401733,\n",
      "                          0.7230603694915771,\n",
      "                          0.7235991358757019,\n",
      "                          0.7424569129943848,\n",
      "                          0.751616358757019,\n",
      "                          0.7478448152542114,\n",
      "                          0.75,\n",
      "                          0.7580819129943848,\n",
      "                          0.7737069129943848,\n",
      "                          0.7559267282485962,\n",
      "                          0.7586206793785095,\n",
      "                          0.7780172228813171,\n",
      "                          0.7957974076271057,\n",
      "                          0.7909482717514038,\n",
      "                          0.7909482717514038,\n",
      "                          0.7920258641242981],\n",
      "             'auc': [0.7209115624427795,\n",
      "                     0.7264118194580078,\n",
      "                     0.7595528960227966,\n",
      "                     0.7887719869613647,\n",
      "                     0.8139830827713013,\n",
      "                     0.7997432947158813,\n",
      "                     0.8285014033317566,\n",
      "                     0.8372344374656677,\n",
      "                     0.834412157535553,\n",
      "                     0.836574912071228,\n",
      "                     0.8408933877944946,\n",
      "                     0.8471992611885071,\n",
      "                     0.8471397161483765,\n",
      "                     0.8456535935401917,\n",
      "                     0.8646616339683533,\n",
      "                     0.8761914372444153,\n",
      "                     0.8705750107765198,\n",
      "                     0.8833547234535217,\n",
      "                     0.8875471949577332],\n",
      "             'f1_score': [0.6564204692840576,\n",
      "                          0.6991492509841919,\n",
      "                          0.717279851436615,\n",
      "                          0.7450383901596069,\n",
      "                          0.7517613172531128,\n",
      "                          0.7597609162330627,\n",
      "                          0.767022430896759,\n",
      "                          0.780306875705719,\n",
      "                          0.7822690010070801,\n",
      "                          0.7787584662437439,\n",
      "                          0.7893882393836975,\n",
      "                          0.8008846640586853,\n",
      "                          0.7878614068031311,\n",
      "                          0.7888882160186768,\n",
      "                          0.8053022027015686,\n",
      "                          0.8214067220687866,\n",
      "                          0.8172298073768616,\n",
      "                          0.8166623711585999,\n",
      "                          0.8189317584037781],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257],\n",
      "             'loss': [0.7997464537620544,\n",
      "                      0.7015389800071716,\n",
      "                      0.6422469019889832,\n",
      "                      0.5835474133491516,\n",
      "                      0.5357438921928406,\n",
      "                      0.5702878832817078,\n",
      "                      0.5135255455970764,\n",
      "                      0.5088587403297424,\n",
      "                      0.506555438041687,\n",
      "                      0.50279700756073,\n",
      "                      0.4939626455307007,\n",
      "                      0.4884246289730072,\n",
      "                      0.48129773139953613,\n",
      "                      0.48584410548210144,\n",
      "                      0.45635178685188293,\n",
      "                      0.437958300113678,\n",
      "                      0.44949615001678467,\n",
      "                      0.42823612689971924,\n",
      "                      0.4188447594642639],\n",
      "             'precision': [0.739279568195343,\n",
      "                           0.7620545029640198,\n",
      "                           0.7995758056640625,\n",
      "                           0.8206465244293213,\n",
      "                           0.8290870785713196,\n",
      "                           0.8110235929489136,\n",
      "                           0.8460721969604492,\n",
      "                           0.8451281785964966,\n",
      "                           0.8466195464134216,\n",
      "                           0.8375634551048279,\n",
      "                           0.8375734090805054,\n",
      "                           0.8670756816864014,\n",
      "                           0.8391261100769043,\n",
      "                           0.847152829170227,\n",
      "                           0.8629032373428345,\n",
      "                           0.8796389102935791,\n",
      "                           0.8761329054832458,\n",
      "                           0.8821138143539429,\n",
      "                           0.8721506595611572],\n",
      "             'recall': [0.646661639213562,\n",
      "                        0.6496872305870056,\n",
      "                        0.6550825238227844,\n",
      "                        0.6861377358436584,\n",
      "                        0.6887125372886658,\n",
      "                        0.7196506261825562,\n",
      "                        0.7053097486495972,\n",
      "                        0.7266314029693604,\n",
      "                        0.7264069318771362,\n",
      "                        0.730735182762146,\n",
      "                        0.7515364289283752,\n",
      "                        0.7451669573783875,\n",
      "                        0.7438380122184753,\n",
      "                        0.7419072389602661,\n",
      "                        0.7561837434768677,\n",
      "                        0.7720070481300354,\n",
      "                        0.7665198445320129,\n",
      "                        0.761403501033783,\n",
      "                        0.7739665508270264],\n",
      "             'val_accuracy': [0.40625,\n",
      "                              0.40625,\n",
      "                              0.4947916567325592,\n",
      "                              0.4947916567325592,\n",
      "                              0.5104166865348816,\n",
      "                              0.6510416865348816,\n",
      "                              0.6510416865348816,\n",
      "                              0.5911458134651184,\n",
      "                              0.6432291865348816,\n",
      "                              0.7135416865348816,\n",
      "                              0.6484375,\n",
      "                              0.5651041865348816,\n",
      "                              0.7395833134651184,\n",
      "                              0.7994791865348816,\n",
      "                              0.7447916865348816,\n",
      "                              0.7447916865348816,\n",
      "                              0.7057291865348816,\n",
      "                              0.6354166865348816,\n",
      "                              0.6770833134651184],\n",
      "             'val_auc': [0.6483355760574341,\n",
      "                         0.6497132182121277,\n",
      "                         0.6879357695579529,\n",
      "                         0.6547662019729614,\n",
      "                         0.6994962692260742,\n",
      "                         0.6967358589172363,\n",
      "                         0.7153199911117554,\n",
      "                         0.8567672967910767,\n",
      "                         0.789684534072876,\n",
      "                         0.8090609312057495,\n",
      "                         0.8822906017303467,\n",
      "                         0.8050576448440552,\n",
      "                         0.8681398630142212,\n",
      "                         0.8805105686187744,\n",
      "                         0.8469691872596741,\n",
      "                         0.8706139922142029,\n",
      "                         0.8732178807258606,\n",
      "                         0.8889625072479248,\n",
      "                         0.8650753498077393],\n",
      "             'val_f1_score': [0.0,\n",
      "                              0.0,\n",
      "                              0.20323799550533295,\n",
      "                              0.27827033400535583,\n",
      "                              0.28961730003356934,\n",
      "                              0.4799197018146515,\n",
      "                              0.46142876148223877,\n",
      "                              0.31415215134620667,\n",
      "                              0.3916819989681244,\n",
      "                              0.5413762927055359,\n",
      "                              0.4127105176448822,\n",
      "                              0.2998282015323639,\n",
      "                              0.4838050603866577,\n",
      "                              0.5786516070365906,\n",
      "                              0.4984872043132782,\n",
      "                              0.4676190912723541,\n",
      "                              0.500109851360321,\n",
      "                              0.3992052376270294,\n",
      "                              0.3995366096496582],\n",
      "             'val_loss': [2.8126256465911865,\n",
      "                          1.7923717498779297,\n",
      "                          0.9857599139213562,\n",
      "                          1.0204135179519653,\n",
      "                          1.0438934564590454,\n",
      "                          0.6443394422531128,\n",
      "                          0.6096867918968201,\n",
      "                          0.6578882336616516,\n",
      "                          0.6631017327308655,\n",
      "                          0.5634182095527649,\n",
      "                          0.6527137160301208,\n",
      "                          1.0173320770263672,\n",
      "                          0.5076138377189636,\n",
      "                          0.4315788447856903,\n",
      "                          0.49286767840385437,\n",
      "                          0.4998806416988373,\n",
      "                          0.5878238081932068,\n",
      "                          0.7683355212211609,\n",
      "                          0.7581346035003662],\n",
      "             'val_precision': [0.0,\n",
      "                               0.0,\n",
      "                               0.765625,\n",
      "                               0.8023256063461304,\n",
      "                               0.8372092843055725,\n",
      "                               0.7447916865348816,\n",
      "                               0.7640449404716492,\n",
      "                               0.9610389471054077,\n",
      "                               0.8888888955116272,\n",
      "                               0.8469387888908386,\n",
      "                               0.9743589758872986,\n",
      "                               1.0,\n",
      "                               0.9324324131011963,\n",
      "                               0.8296943306922913,\n",
      "                               0.886904776096344,\n",
      "                               0.9166666865348816,\n",
      "                               0.9650349617004395,\n",
      "                               0.9907407164573669,\n",
      "                               0.9727272987365723],\n",
      "             'val_recall': [0.0,\n",
      "                            0.0,\n",
      "                            0.2149122804403305,\n",
      "                            0.2804878056049347,\n",
      "                            0.2926829159259796,\n",
      "                            0.6271929740905762,\n",
      "                            0.5964912176132202,\n",
      "                            0.3245614171028137,\n",
      "                            0.45614033937454224,\n",
      "                            0.6747967600822449,\n",
      "                            0.46341463923454285,\n",
      "                            0.3099173605442047,\n",
      "                            0.6052631735801697,\n",
      "                            0.8333333134651184,\n",
      "                            0.6535087823867798,\n",
      "                            0.6271929740905762,\n",
      "                            0.5609756112098694,\n",
      "                            0.434959352016449,\n",
      "                            0.46929824352264404]},\n",
      " 'optimal_threshold': 0.4125778079032898,\n",
      " 'train_counts': {'fire': 730, 'nofire': 1157},\n",
      " 'train_counts_total': 1887,\n",
      " 'train_dataset_size': 1856,\n",
      " 'training_time': 885.419896364212,\n",
      " 'val_counts': {'fire': 156, 'nofire': 246},\n",
      " 'val_counts_total': 402,\n",
      " 'val_dataset_size': 384}\n",
      "Training model: WildfireNet on dataset: DeepFire\n",
      "Class weights: {0: 1.0, 1: 1.0}\n",
      "Epoch 1/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 810ms/step - accuracy: 0.8270 - auc: 0.8647 - f1_score: 0.8079 - loss: 0.4028 - precision: 0.7439 - recall: 0.8494 - val_accuracy: 0.4722 - val_auc: 0.9621 - val_f1_score: 0.5026 - val_loss: 1.4114 - val_precision: 0.4722 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 762ms/step - accuracy: 0.9124 - auc: 0.9702 - f1_score: 0.9097 - loss: 0.2297 - precision: 0.9001 - recall: 0.9232 - val_accuracy: 0.5868 - val_auc: 0.9659 - val_f1_score: 0.5070 - val_loss: 0.5658 - val_precision: 0.5339 - val_recall: 0.9853 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 781ms/step - accuracy: 0.9119 - auc: 0.9663 - f1_score: 0.9113 - loss: 0.2460 - precision: 0.9154 - recall: 0.9085 - val_accuracy: 0.5278 - val_auc: 0.9883 - val_f1_score: 0.0000e+00 - val_loss: 1.3401 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 778ms/step - accuracy: 0.9372 - auc: 0.9797 - f1_score: 0.9354 - loss: 0.1850 - precision: 0.9433 - recall: 0.9305 - val_accuracy: 0.4722 - val_auc: 0.9864 - val_f1_score: 0.0000e+00 - val_loss: 1.2634 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772ms/step - accuracy: 0.9305 - auc: 0.9786 - f1_score: 0.9333 - loss: 0.1930 - precision: 0.9370 - recall: 0.9318\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 806ms/step - accuracy: 0.9308 - auc: 0.9787 - f1_score: 0.9335 - loss: 0.1924 - precision: 0.9371 - recall: 0.9321 - val_accuracy: 0.4722 - val_auc: 0.9819 - val_f1_score: 0.0000e+00 - val_loss: 1.6822 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 779ms/step - accuracy: 0.9230 - auc: 0.9787 - f1_score: 0.9231 - loss: 0.1856 - precision: 0.9201 - recall: 0.9267 - val_accuracy: 0.5000 - val_auc: 0.9705 - val_f1_score: 0.0000e+00 - val_loss: 1.4933 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 5.0000e-04\n",
      "Epoch 7/80\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 738ms/step - accuracy: 0.9313 - auc: 0.9825 - f1_score: 0.9291 - loss: 0.1776 - precision: 0.9432 - recall: 0.9177 - val_accuracy: 0.5417 - val_auc: 0.9494 - val_f1_score: 0.0329 - val_loss: 0.9804 - val_precision: 1.0000 - val_recall: 0.0294 - learning_rate: 5.0000e-04\n",
      "Training time: 209.86 seconds\n",
      "Evaluating WildfireNet on DeepFire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 0.3489 - auc: 0.5502 - f1_score: 0.2568 - loss: 0.7853 - precision: 0.2686 - recall: 0.6154  \n",
      "Training results for WildfireNet on DeepFire:\n",
      "{'class_weights': {0: 1.0, 1: 1.0},\n",
      " 'evaluation': {'accuracy': 0.6015625,\n",
      "                'auc': 0.8914538621902466,\n",
      "                'f1_score': 0.5513467788696289,\n",
      "                'loss': 0.5970901846885681,\n",
      "                'precision': 0.5665722489356995,\n",
      "                'recall': 1.0},\n",
      " 'history': {'accuracy': [0.8848684430122375,\n",
      "                          0.9103618264198303,\n",
      "                          0.9120065569877625,\n",
      "                          0.9284539222717285,\n",
      "                          0.9416118264198303,\n",
      "                          0.9317434430122375,\n",
      "                          0.9268091917037964],\n",
      "             'auc': [0.9219022989273071,\n",
      "                     0.9693979024887085,\n",
      "                     0.9667437672615051,\n",
      "                     0.9777116179466248,\n",
      "                     0.9807252883911133,\n",
      "                     0.9811306595802307,\n",
      "                     0.9806119203567505],\n",
      "             'f1_score': [0.8792020678520203,\n",
      "                          0.9051427245140076,\n",
      "                          0.9105488657951355,\n",
      "                          0.9266209602355957,\n",
      "                          0.9402781128883362,\n",
      "                          0.9314369559288025,\n",
      "                          0.9252026081085205],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257],\n",
      "             'loss': [0.2862943708896637,\n",
      "                      0.2323462814092636,\n",
      "                      0.24069921672344208,\n",
      "                      0.19505417346954346,\n",
      "                      0.17167802155017853,\n",
      "                      0.1709015667438507,\n",
      "                      0.18624399602413177],\n",
      "             'precision': [0.8106235861778259,\n",
      "                           0.9032787084579468,\n",
      "                           0.9096879959106445,\n",
      "                           0.9333333373069763,\n",
      "                           0.9391447305679321,\n",
      "                           0.9263502359390259,\n",
      "                           0.9373942613601685],\n",
      "             'recall': [0.8785982728004456,\n",
      "                        0.9168053269386292,\n",
      "                        0.9141914248466492,\n",
      "                        0.92580646276474,\n",
      "                        0.9438016414642334,\n",
      "                        0.9370861053466797,\n",
      "                        0.9141914248466492],\n",
      "             'val_accuracy': [0.4722222089767456,\n",
      "                              0.5868055820465088,\n",
      "                              0.5277777910232544,\n",
      "                              0.4722222089767456,\n",
      "                              0.4722222089767456,\n",
      "                              0.5,\n",
      "                              0.5416666865348816],\n",
      "             'val_auc': [0.9621468782424927,\n",
      "                         0.9658958911895752,\n",
      "                         0.9882933497428894,\n",
      "                         0.9864309430122375,\n",
      "                         0.981859564781189,\n",
      "                         0.9705102443695068,\n",
      "                         0.9494485259056091],\n",
      "             'val_f1_score': [0.5026454925537109,\n",
      "                              0.5070180296897888,\n",
      "                              0.0,\n",
      "                              0.0,\n",
      "                              0.0,\n",
      "                              0.0,\n",
      "                              0.03287779167294502],\n",
      "             'val_loss': [1.4114136695861816,\n",
      "                          0.5658103823661804,\n",
      "                          1.340052604675293,\n",
      "                          1.2633566856384277,\n",
      "                          1.682237148284912,\n",
      "                          1.4933066368103027,\n",
      "                          0.9804466962814331],\n",
      "             'val_precision': [0.4722222089767456,\n",
      "                               0.5338645577430725,\n",
      "                               0.0,\n",
      "                               0.0,\n",
      "                               0.0,\n",
      "                               0.0,\n",
      "                               1.0],\n",
      "             'val_recall': [1.0,\n",
      "                            0.9852941036224365,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.0,\n",
      "                            0.029411764815449715]},\n",
      " 'optimal_threshold': 0.6860173344612122,\n",
      " 'train_counts': {'fire': 608, 'nofire': 608},\n",
      " 'train_counts_total': 1216,\n",
      " 'train_dataset_size': 1216,\n",
      " 'training_time': 209.86321425437927,\n",
      " 'val_counts': {'fire': 152, 'nofire': 152},\n",
      " 'val_counts_total': 304,\n",
      " 'val_dataset_size': 288}\n",
      "Training model: WildfireNet on dataset: The Wildfire Dataset_DeepFire\n",
      "Class weights: {0: 1.1595665171898355, 1: 0.8790368271954674}\n",
      "Epoch 1/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 772ms/step - accuracy: 0.6309 - auc: 0.6953 - f1_score: 0.6708 - loss: 0.7995 - precision: 0.6796 - recall: 0.7203 - val_accuracy: 0.4432 - val_auc: 0.6324 - val_f1_score: 0.0000e+00 - val_loss: 1.0729 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 785ms/step - accuracy: 0.6780 - auc: 0.7439 - f1_score: 0.7197 - loss: 0.6662 - precision: 0.7400 - recall: 0.7036 - val_accuracy: 0.5185 - val_auc: 0.5858 - val_f1_score: 0.4591 - val_loss: 0.6835 - val_precision: 0.5565 - val_recall: 0.6658 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 774ms/step - accuracy: 0.6977 - auc: 0.7772 - f1_score: 0.7336 - loss: 0.5933 - precision: 0.7973 - recall: 0.6829 - val_accuracy: 0.5852 - val_auc: 0.5923 - val_f1_score: 0.3592 - val_loss: 0.6861 - val_precision: 0.7016 - val_recall: 0.4439 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 788ms/step - accuracy: 0.7257 - auc: 0.7970 - f1_score: 0.7681 - loss: 0.5548 - precision: 0.8050 - recall: 0.7385 - val_accuracy: 0.5895 - val_auc: 0.6163 - val_f1_score: 0.4286 - val_loss: 0.6904 - val_precision: 0.6435 - val_recall: 0.5893 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 862ms/step - accuracy: 0.7359 - auc: 0.8125 - f1_score: 0.7767 - loss: 0.5282 - precision: 0.8049 - recall: 0.7550 - val_accuracy: 0.6676 - val_auc: 0.7499 - val_f1_score: 0.4109 - val_loss: 0.6046 - val_precision: 0.8264 - val_recall: 0.5102 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 776ms/step - accuracy: 0.7223 - auc: 0.7886 - f1_score: 0.7601 - loss: 0.5543 - precision: 0.8031 - recall: 0.7253 - val_accuracy: 0.6165 - val_auc: 0.6851 - val_f1_score: 0.3651 - val_loss: 0.6688 - val_precision: 0.7699 - val_recall: 0.4439 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 873ms/step - accuracy: 0.7461 - auc: 0.8236 - f1_score: 0.7777 - loss: 0.5124 - precision: 0.8146 - recall: 0.7495 - val_accuracy: 0.6179 - val_auc: 0.8178 - val_f1_score: 0.2902 - val_loss: 0.7111 - val_precision: 0.9843 - val_recall: 0.3189 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7825 - auc: 0.8534 - f1_score: 0.8132 - loss: 0.4709 - precision: 0.8494 - recall: 0.7827\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 1s/step - accuracy: 0.7825 - auc: 0.8534 - f1_score: 0.8132 - loss: 0.4709 - precision: 0.8494 - recall: 0.7827 - val_accuracy: 0.6108 - val_auc: 0.7571 - val_f1_score: 0.2839 - val_loss: 0.9502 - val_precision: 0.9836 - val_recall: 0.3061 - learning_rate: 0.0010\n",
      "Epoch 9/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 1s/step - accuracy: 0.7834 - auc: 0.8619 - f1_score: 0.8129 - loss: 0.4583 - precision: 0.8399 - recall: 0.7897 - val_accuracy: 0.6364 - val_auc: 0.7879 - val_f1_score: 0.3354 - val_loss: 0.7021 - val_precision: 0.9048 - val_recall: 0.3878 - learning_rate: 5.0000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 914ms/step - accuracy: 0.7733 - auc: 0.8482 - f1_score: 0.8060 - loss: 0.4770 - precision: 0.8397 - recall: 0.7756 - val_accuracy: 0.6364 - val_auc: 0.8442 - val_f1_score: 0.3228 - val_loss: 0.7206 - val_precision: 0.9595 - val_recall: 0.3622 - learning_rate: 5.0000e-04\n",
      "Training time: 845.76 seconds\n",
      "Evaluating WildfireNet on The Wildfire Dataset_DeepFire...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 126ms/step - accuracy: 0.6620 - auc: 0.4596 - f1_score: 0.2183 - loss: 0.6288 - precision: 0.3427 - recall: 0.4423  \n",
      "Training results for WildfireNet on The Wildfire Dataset_DeepFire:\n",
      "{'class_weights': {0: 1.1595665171898355, 1: 0.8790368271954674},\n",
      " 'evaluation': {'accuracy': 0.6875,\n",
      "                'auc': 0.750067949295044,\n",
      "                'f1_score': 0.46700775623321533,\n",
      "                'loss': 0.5951748490333557,\n",
      "                'precision': 0.6941747665405273,\n",
      "                'recall': 0.7149999737739563},\n",
      " 'history': {'accuracy': [0.65625,\n",
      "                          0.6940104365348816,\n",
      "                          0.7060546875,\n",
      "                          0.7242838740348816,\n",
      "                          0.7379557490348816,\n",
      "                          0.7190755009651184,\n",
      "                          0.7434895634651184,\n",
      "                          0.7828776240348816,\n",
      "                          0.7757161259651184,\n",
      "                          0.7727864384651184],\n",
      "             'auc': [0.7013323903083801,\n",
      "                     0.7601082921028137,\n",
      "                     0.7834171652793884,\n",
      "                     0.79466313123703,\n",
      "                     0.8080514073371887,\n",
      "                     0.7875630855560303,\n",
      "                     0.8231884837150574,\n",
      "                     0.8544912338256836,\n",
      "                     0.8585823178291321,\n",
      "                     0.8519609570503235],\n",
      "             'f1_score': [0.6992077827453613,\n",
      "                          0.7325431704521179,\n",
      "                          0.7442824840545654,\n",
      "                          0.7630298733711243,\n",
      "                          0.7773392796516418,\n",
      "                          0.7574527859687805,\n",
      "                          0.7761397957801819,\n",
      "                          0.8136071562767029,\n",
      "                          0.8078761100769043,\n",
      "                          0.8067371249198914],\n",
      "             'learning_rate': [0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0010000000474974513,\n",
      "                               0.0005000000237487257,\n",
      "                               0.0005000000237487257],\n",
      "             'loss': [0.7256894111633301,\n",
      "                      0.6340543627738953,\n",
      "                      0.5812551379203796,\n",
      "                      0.5627854466438293,\n",
      "                      0.5332558751106262,\n",
      "                      0.5547353625297546,\n",
      "                      0.5102475881576538,\n",
      "                      0.4686919152736664,\n",
      "                      0.4588311016559601,\n",
      "                      0.46916231513023376],\n",
      "             'precision': [0.7239324450492859,\n",
      "                           0.7686390280723572,\n",
      "                           0.7921381592750549,\n",
      "                           0.8026620149612427,\n",
      "                           0.8083900213241577,\n",
      "                           0.800000011920929,\n",
      "                           0.824999988079071,\n",
      "                           0.8520023226737976,\n",
      "                           0.8472706079483032,\n",
      "                           0.8443803787231445],\n",
      "             'recall': [0.6906679272651672,\n",
      "                        0.7029221057891846,\n",
      "                        0.7059447765350342,\n",
      "                        0.7326993942260742,\n",
      "                        0.7533016204833984,\n",
      "                        0.7232237458229065,\n",
      "                        0.7372340559959412,\n",
      "                        0.7808510661125183,\n",
      "                        0.7740052938461304,\n",
      "                        0.7739038467407227],\n",
      "             'val_accuracy': [0.4431818127632141,\n",
      "                              0.5184659361839294,\n",
      "                              0.5852272510528564,\n",
      "                              0.5894886255264282,\n",
      "                              0.6676136255264282,\n",
      "                              0.6164772510528564,\n",
      "                              0.6178977489471436,\n",
      "                              0.6107954382896423,\n",
      "                              0.6363636255264282,\n",
      "                              0.6363636255264282],\n",
      "             'val_auc': [0.6323505640029907,\n",
      "                         0.5858190059661865,\n",
      "                         0.5922619104385376,\n",
      "                         0.6162594556808472,\n",
      "                         0.7498610019683838,\n",
      "                         0.68507981300354,\n",
      "                         0.8177737593650818,\n",
      "                         0.7570643424987793,\n",
      "                         0.787872850894928,\n",
      "                         0.844224214553833],\n",
      "             'val_f1_score': [0.0,\n",
      "                              0.4591220021247864,\n",
      "                              0.359186053276062,\n",
      "                              0.428602010011673,\n",
      "                              0.4109440743923187,\n",
      "                              0.36514776945114136,\n",
      "                              0.29015424847602844,\n",
      "                              0.28386619687080383,\n",
      "                              0.3353596031665802,\n",
      "                              0.3227541446685791],\n",
      "             'val_loss': [1.0729191303253174,\n",
      "                          0.6835193037986755,\n",
      "                          0.6861006617546082,\n",
      "                          0.6903740763664246,\n",
      "                          0.6045506596565247,\n",
      "                          0.6688392758369446,\n",
      "                          0.7110573649406433,\n",
      "                          0.9501696228981018,\n",
      "                          0.7020754814147949,\n",
      "                          0.7205756306648254],\n",
      "             'val_precision': [0.0,\n",
      "                               0.556503176689148,\n",
      "                               0.7016128897666931,\n",
      "                               0.6434540152549744,\n",
      "                               0.8264462947845459,\n",
      "                               0.769911527633667,\n",
      "                               0.9842519760131836,\n",
      "                               0.9836065769195557,\n",
      "                               0.9047619104385376,\n",
      "                               0.9594594836235046],\n",
      "             'val_recall': [0.0,\n",
      "                            0.6658163070678711,\n",
      "                            0.44387754797935486,\n",
      "                            0.5892857313156128,\n",
      "                            0.5102040767669678,\n",
      "                            0.44387754797935486,\n",
      "                            0.31887754797935486,\n",
      "                            0.30612245202064514,\n",
      "                            0.3877550959587097,\n",
      "                            0.3622449040412903]},\n",
      " 'optimal_threshold': 0.54756760597229,\n",
      " 'train_counts': {'fire': 1338, 'nofire': 1765},\n",
      " 'train_counts_total': 3103,\n",
      " 'train_dataset_size': 3072,\n",
      " 'training_time': 845.7584338188171,\n",
      " 'val_counts': {'fire': 308, 'nofire': 398},\n",
      " 'val_counts_total': 706,\n",
      " 'val_dataset_size': 704}\n"
     ]
    }
   ],
   "source": [
    "training_results = {}\n",
    "results_file = os.path.join(run_dir, 'training_results.json')\n",
    "\n",
    "for base_model, custom_bool in zip(all_models, is_custom_model):\n",
    "    model = generate_model(base_model, custom=custom_bool, to_dir=run_dir) # Generate the model and its initial weights\n",
    "    model.summary()\n",
    "    model_dir = os.path.join(run_dir, model.name)\n",
    "    training_results[model.name] = {} # Initialize the model results dictionary\n",
    "    plot_model(model, show_shapes=True, show_layer_names=True, to_file=os.path.join(model_dir, f\"{model.name}_architecture.png\"))\n",
    "    # Main training and evaluation loop - unpack the training parameters for each combination\n",
    "    for dataset_id, train_dataset, val_dataset, steps_per_epoch, validation_steps, train_counts_dict, val_counts_dict in training_params:\n",
    "        # Reload the initial weights for each dataset\n",
    "        model.load_weights(os.path.join(run_dir, model.name, f\"{model.name}_initial.weights.h5\"))\n",
    "        print(f\"Training model: {model.name} on dataset: {dataset_id}\")\n",
    "        # Calculate class weights of the current dataset for class-weighted training\n",
    "        class_weights = class_weights_from_counts(train_counts_dict, class_indices=class_indices)\n",
    "        print(\"Class weights:\", class_weights)\n",
    "        # Record the start time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Model training\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            epochs=epochs,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=val_dataset,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=callbacks_list,\n",
    "            class_weight=class_weights\n",
    "        )\n",
    "\n",
    "        # Record the end time\n",
    "        end_time = time.time()\n",
    "        # Calculate the training time\n",
    "        training_time = end_time - start_time\n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "        model_ds_dir = os.path.join(model_dir, dataset_id)\n",
    "        os.makedirs(model_ds_dir, exist_ok=True)\n",
    "        # Save the model\n",
    "        model.save(os.path.join(model_ds_dir, f\"{model.name}_{dataset_id}.keras\"))\n",
    "\n",
    "        ###### Evaluation stage ######\n",
    "        optimal_threshold = full_evaluation(model_ds_dir, history, model, dataset_id, test_generators)\n",
    "        evaluation = model.evaluate(test_dataset, return_dict=True, steps=test_steps)\n",
    "\n",
    "        training_results[model.name][dataset_id] = {\n",
    "            'history': history.history,\n",
    "            'training_time': training_time,\n",
    "            'optimal_threshold': float(optimal_threshold),\n",
    "            'train_dataset_size': steps_per_epoch * batch_size,\n",
    "            'val_dataset_size': validation_steps * batch_size,\n",
    "            'train_counts': train_counts_dict,\n",
    "            'val_counts': val_counts_dict,\n",
    "            'train_counts_total': sum(train_counts_dict.values()),\n",
    "            'val_counts_total': sum(val_counts_dict.values()),\n",
    "            'class_weights': {k: float(v) for k, v in class_weights.items()}, # np.float64 to float typecast\n",
    "            \"evaluation\": evaluation\n",
    "        }\n",
    "        print(f\"Training results for {model.name} on {dataset_id}:\")\n",
    "        pprint(training_results[model.name][dataset_id]) # Print the results for this model and dataset\n",
    "        # Save the training results to a file after each iteration\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(training_results, f, indent=4)\n",
    "        \n",
    "        model.compile(optimizer=optimizer_fn, loss=loss_fn, metrics=metrics_list) # Reset the model for the next iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brute force loop completed!\n",
      "All models are now available at: runs\\run_31\n"
     ]
    }
   ],
   "source": [
    "print(\"Brute force loop completed!\")\n",
    "print(f\"All models are now available at: {run_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dir = os.path.join(run_dir, \"evaluations\")\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "# Extract the training and evaluation data from the training results and save it to a CSV file\n",
    "rows = extract_evaluation_data(training_results)\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(os.path.join(eval_dir, \"training_data.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dissertation\\Kaggle Data\\wildfire-detection\\utils\\evaluator.py:169: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  plot = sns.barplot(\n",
      "d:\\Dissertation\\Kaggle Data\\wildfire-detection\\utils\\evaluator.py:186: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  plot = sns.barplot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fire': 730, 'nofire': 1157}\n",
      "<class 'dict'>\n",
      "{'fire': 608, 'nofire': 608}\n",
      "<class 'dict'>\n",
      "{'fire': 604, 'nofire': 196}\n",
      "<class 'dict'>\n",
      "{'fire': 1338, 'nofire': 1765}\n",
      "<class 'dict'>\n",
      "{'fire': 1334, 'nofire': 1353}\n",
      "<class 'dict'>\n",
      "{'fire': 1212, 'nofire': 804}\n",
      "<class 'dict'>\n",
      "{'fire': 1942, 'nofire': 1961}\n",
      "<class 'dict'>\n",
      "{'fire': 730, 'nofire': 1157}\n",
      "<class 'dict'>\n",
      "{'fire': 608, 'nofire': 608}\n",
      "<class 'dict'>\n",
      "{'fire': 604, 'nofire': 196}\n",
      "<class 'dict'>\n",
      "{'fire': 1338, 'nofire': 1765}\n",
      "<class 'dict'>\n",
      "{'fire': 1334, 'nofire': 1353}\n",
      "<class 'dict'>\n",
      "{'fire': 1212, 'nofire': 804}\n",
      "<class 'dict'>\n",
      "{'fire': 1942, 'nofire': 1961}\n",
      "<class 'dict'>\n",
      "{'fire': 730, 'nofire': 1157}\n",
      "<class 'dict'>\n",
      "{'fire': 608, 'nofire': 608}\n",
      "<class 'dict'>\n",
      "{'fire': 604, 'nofire': 196}\n",
      "<class 'dict'>\n",
      "{'fire': 1338, 'nofire': 1765}\n",
      "<class 'dict'>\n",
      "{'fire': 1334, 'nofire': 1353}\n",
      "<class 'dict'>\n",
      "{'fire': 1212, 'nofire': 804}\n",
      "<class 'dict'>\n",
      "{'fire': 1942, 'nofire': 1961}\n",
      "<class 'dict'>\n",
      "{'fire': 730, 'nofire': 1157}\n",
      "<class 'dict'>\n",
      "{'fire': 608, 'nofire': 608}\n",
      "<class 'dict'>\n",
      "{'fire': 604, 'nofire': 196}\n",
      "<class 'dict'>\n",
      "{'fire': 1338, 'nofire': 1765}\n",
      "<class 'dict'>\n",
      "{'fire': 1334, 'nofire': 1353}\n",
      "<class 'dict'>\n",
      "{'fire': 1212, 'nofire': 804}\n",
      "<class 'dict'>\n",
      "{'fire': 1942, 'nofire': 1961}\n",
      "<class 'dict'>\n",
      "{'fire': 730, 'nofire': 1157}\n",
      "<class 'dict'>\n",
      "{'fire': 608, 'nofire': 608}\n",
      "<class 'dict'>\n",
      "{'fire': 604, 'nofire': 196}\n",
      "<class 'dict'>\n",
      "{'fire': 1338, 'nofire': 1765}\n",
      "<class 'dict'>\n",
      "{'fire': 1334, 'nofire': 1353}\n",
      "<class 'dict'>\n",
      "{'fire': 1212, 'nofire': 804}\n",
      "<class 'dict'>\n",
      "{'fire': 1942, 'nofire': 1961}\n",
      "<class 'dict'>\n",
      "{'fire': 730, 'nofire': 1157}\n",
      "<class 'dict'>\n",
      "{'fire': 608, 'nofire': 608}\n",
      "<class 'dict'>\n",
      "{'fire': 604, 'nofire': 196}\n",
      "<class 'dict'>\n",
      "{'fire': 1338, 'nofire': 1765}\n",
      "<class 'dict'>\n",
      "{'fire': 1334, 'nofire': 1353}\n",
      "<class 'dict'>\n",
      "{'fire': 1212, 'nofire': 804}\n",
      "<class 'dict'>\n",
      "{'fire': 1942, 'nofire': 1961}\n",
      "<class 'dict'>\n",
      "{'fire': 730, 'nofire': 1157}\n",
      "<class 'dict'>\n",
      "{'fire': 608, 'nofire': 608}\n",
      "<class 'dict'>\n",
      "{'fire': 604, 'nofire': 196}\n",
      "<class 'dict'>\n",
      "{'fire': 1338, 'nofire': 1765}\n",
      "<class 'dict'>\n",
      "{'fire': 1334, 'nofire': 1353}\n",
      "<class 'dict'>\n",
      "{'fire': 1212, 'nofire': 804}\n",
      "<class 'dict'>\n",
      "{'fire': 1942, 'nofire': 1961}\n",
      "<class 'dict'>\n",
      "Average Training Time: 1515.473234994071\n",
      "Number of Distinct Models: 7\n",
      "Number of Singular Datasets: 3\n",
      "All evaluations completed!\n",
      "Results are available at: runs\\run_30\\evaluations\n"
     ]
    }
   ],
   "source": [
    "plot_metric_chart(df, \"Training Time\", eval_dir, highlight_max=False)\n",
    "plot_dataset_sizes(df, eval_dir)\n",
    "\n",
    "for metric in evaluation:\n",
    "    if metric == \"loss\":\n",
    "        continue # Loss is not useful in this context\n",
    "    else:\n",
    "        plot_metric_chart(df, metric, eval_dir)\n",
    "\n",
    "plot_time_extrapolation(df, eval_dir)\n",
    "plot_sum_of_metrics_heatmaps(eval_dir, df, metric_weights)\n",
    "print(\"All evaluations completed!\")\n",
    "print(f\"Results are available at: {eval_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1351460,
     "sourceId": 2247205,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
